# Standard library imports
import csv
import math
import os
import re
import sys
import time
import warnings
from datetime import datetime, timedelta
from functools import partial
from itertools import combinations, groupby
from multiprocessing import Manager, Pool, Process, cpu_count, shared_memory, Lock
from collections import defaultdict
import io
from typing import Optional, Dict, Any, Union, List, Tuple
# import ollama
import platform
import urllib.request
import zipfile
import osmnx as ox


import numba
import operator
from operator import itemgetter
import random
from scipy.spatial import cKDTree, KDTree
from scipy.spatial import distance_matrix
import plotly.express as px
import plotly.figure_factory as ff
import plotly.graph_objects as go

from plotly.subplots import make_subplots
import natsort

# Third-party imports
import ezdxf
from ezdxf import appsettings, zoom, xref
from ezdxf.enums import TextEntityAlignment
from ezdxf.addons import Importer
from tqdm import tqdm
from ezdxf.math import Vec3
from ezdxf.entities import MText
from ezdxf.enums import MTextLineAlignment
from ezdxf.math import BoundingBox, Matrix44, Vec2
from ezdxf.render import ARROWS, mleader
from ezdxf.tools.text import estimate_mtext_extents


base_dir = f"{os.sep}".join(sys.executable.split(os.sep)[:-1])
os.environ.update({"GDAL_DATA": os.path.join(base_dir, "Library", "share", "gdal"), "GDAL_DRIVER_PATH": os.path.join(base_dir, "Library", "lib", "gdalplugins")})


import geopandas as gpd
from pathlib import Path
# import osmnx as ox
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import networkx as nx
import numpy as np
import pandas as pd
#import ollama
import rasterio
import scipy.optimize as opt
import shapefile
import shapely
from PIL import ImageFont, Image
from detect_delimiter import detect
from geopy.extra.rate_limiter import RateLimiter
import pickle
import subprocess
import requests
import base64
from typing import Optional
import signal

from line_profiler_pycharm import profile
from matplotlib.ticker import MaxNLocator
from natsort import index_natsorted, natsorted, order_by_index
from osgeo import gdal, ogr
from pygeodesy import ellipsoidalKarney, GeoidKarney
from pyproj import CRS, Transformer
from scipy import spatial
from scipy.interpolate import LinearNDInterpolator
from scipy.spatial import distance
from shapely.geometry import LineString, MultiPoint, MultiPolygon, Point, Polygon
from shapely.ops import split
from geopy.distance import geodesic
from geopy.geocoders import Nominatim
import geopy
from swmm.toolkit.shared_enum import LinkAttribute, NodeAttribute, SubcatchAttribute
from pyswmm import Nodes, Output, Simulation, Subcatchments, LinkSeries, NodeSeries
from scipy.interpolate import CubicSpline

# Suppress all warnings
warnings.filterwarnings("ignore")
np.seterr(divide="ignore", invalid="ignore")
warnings.filterwarnings("ignore", category=FutureWarning)
# np.VisibleDeprecationWarning removed in numpy 2.x

pd.options.mode.chained_assignment = None
os.environ["USE_PYGEOS"] = "0"
import config
config.setup_sys_path()

from pypiper_compiled import nb_isBetween, nb_line_intersect, nb_get_line_intersect, is_inside_sm, nb_is_inside_parallel, nb_cdist, nb_ortoSegmentPoint_all
from RUT_0 import find_classes_and_functions
from rut_02_elevation import ElevationSource, ElevationGetter, KDTreeSaveLoad




def par_basicos(h_min=0, D_min=0, h_D_max=0, seccion_min=0):
    if h_min != 0:
        return 8

    if D_min != 0:
        return 0.28
        
    
    if h_D_max != 0:
        return 0.65
    
    if seccion_min != 0:
        return 0.3


map_calado_dict = {
    "critico": 0.7,
    "sub-critico": 0.7,
    "super-critico": 0.65,
    "": 0.65,
}
velocidad_maxima_pypiper = {"PVC": 3.5, "PVC-1MPa": 9.0, "PEAD": 5.9, "PRFV": 3.5, "HS": 5.0, "HA": 5.9, "HD": 9.0}
pendiente_minima_pypiper = {
    "PVC": 0.004,
    "PVC-1MPa": 0.004,
    "PEAD": 0.004,
    "PRFV": 0.004,
    "HS": 0.01,
    "HA": 0.01,
    "HD": 0.004,
    "seccion": ["rectangular"],
}
rugosidad_pypiper = {
    "manning": {
        "PVC": 0.011,
        "PVC-1MPa": 0.011,
        "PEAD": 0.010,
        "PRFV": 0.011,
        "HS": 0.013,
        "HA": 0.013,
        "HD": 0.012,
    }
}
diametro_interno_externo_pypiper = {
    "PVC": {
        0.1: 0.11,
        0.145: 0.16,
        0.183: 0.2,
        0.228: 0.25,
        0.286: 0.315,
        0.4: 0.44,
        0.5: 0.54,
        0.6: 0.65,
        0.7: 0.76,
        0.8: 0.875,
        0.9: 0.975,
    },
    "PVC-1MPa": {
        0.11,
        0.16,
        0.2,
        0.25,
        0.315,
        0.4,
        0.45,
        0.5,
        0.56,
        0.63,
        0.71,
        0.8,
        0.9,
        1.0,
    },
    "PEAD": {
        0.1846: 0.200,  # 200 mm exterior - 2 * 7.7 mm de espesor PN6
        0.2728: 0.315,  # 315 mm exterior - 2 * 21.1 mm de espesor
        0.3278: 0.400,  # 400 mm exterior - 2 * 15.3 mm de espesor
        0.4156: 0.500,  # 500 mm exterior - 2 * 19.1 mm de espesor
        0.5272: 0.630,  # 630 mm exterior - 2 * 21.4 mm de espesor
        0.6556: 0.710,  # 710 mm exterior - 2 * 27.2 mm de espesor
        0.7388: 0.800,  # 800 mm exterior - 2 * 30.6 mm de espesor
        0.8312: 0.900,  # 900 mm exterior - 2 * 34.4 mm de espesor
        0.9236: 1.000,  # 1000 mm exterior - 2 * 38.2 mm de espesor
        1.160: 1.200,  # 1200 mm exterior - 2 * 45.9 mm de espesor
    },
    "PRFV": {
        0.3: 0.3,
        0.4: 0.4,
        0.5: 0.5,
        0.6: 0.6,
        0.7: 0.7,
        0.8: 0.8,
        0.9: 0.9,
        1.0: 1.0,
        1.2: 1.2,
        1.5: 1.5,
        1.6: 1.6,
        1.7: 1.7,
        1.8: 1.8,
        1.9: 1.9,
        2.0: 2.0,
    },
    "HS": {0.16: 0.16, 0.2: 0.2, 0.3: 0.3, 0.4: 0.4, 0.5: 0.5, 0.6: 0.6},
    "HA": {
        0.5: 0.5,
        0.6: 0.6,
        0.7: 0.7,
        0.8: 0.8,
        0.9: 0.9,
        1.0: 1.0,
        1.2: 1.2,
        1.5: 1.5,
        1.7: 1.7,
        1.8: 1.8,
        2.0: 2.0,
    },
    "metodo_constructivo_diameter_max": {"perforacion horizontal dirigida": 0.97},
}

"#######################################################################################################################"
"CREAR DIRECTORIOS Y CAPPETAS"
"#######################################################################################################################"


def check_path(shp_name):
    """

    :param shp_name: Nombre del proyecto el cual se revisa
    :return:
    """
    if not os.path.exists("_PROYECTO_" + shp_name):
        os.mkdir("PROYECTO_" + shp_name)
        os.mkdir("PROYECTO_" + shp_name + os.path.sep + "00_GIS")
        os.mkdir("PROYECTO_" + shp_name + os.path.sep + "01_DXF")
        os.mkdir("PROYECTO_" + shp_name + os.path.sep + "00_GIS" + os.path.sep + "00_IN")
        os.mkdir("PROYECTO_" + shp_name + os.path.sep + "00_GIS" + os.path.sep + "01_DEM")
        os.mkdir("PROYECTO_" + shp_name + os.path.sep + "00_GIS" + os.path.sep + "02_OUT")
        os.mkdir("PROYECTO_" + shp_name + os.path.sep + "01_DXF" + os.path.sep + "00_IN")
        os.mkdir("PROYECTO_" + shp_name + os.path.sep + "01_DXF" + os.path.sep + "01_OUT_PL_PF")
    else:
        print("La carpeta " + shp_name + " ya existe!, compruebe su contenido!")


def pp_char_split(str_array, _split):
    _len = len(str_array)
    a1 = np.empty(shape=(_len), dtype="<U10")
    a2 = np.empty_like(a1, dtype="<U10")
    for i in range(_len):
        _str = str_array[i].split(_split)
        if len(_str) > 1:
            a1[i] = _str[0]
            a2[i] = _str[1]
        else:
            a1[i] = _str[0]
            a2[i] = str(0)
    return a1, a2


def pp_minDistance_Point_Line(m_ramales, p_array, reference=None):
    # CREAR ARRAYS x_array, y_array
    df_m_ramales = pd.DataFrame(m_ramales)
    xy = df_m_ramales.loc[["X", "Y"]]
    _x, _y = xy.iloc[0, :], xy.iloc[1, :]
    xy_index = np.cumsum(list(map(len, _x))) - 1
    _x_flat, _y_flat = np.concatenate(_x), np.concatenate(_y)
    x_array = np.array([_x_flat[:-1], _x_flat[1:]]).T
    x_array = np.delete(x_array, xy_index[:-1], axis=0)
    y_array = np.array([_y_flat[:-1], _y_flat[1:]]).T
    y_array = np.delete(y_array, xy_index[:-1], axis=0)

    # CREAR MASCARA PARA PUNTOS CON SEGMENTOS ORTOGONALES
    mask = nb_ortoSegmentPoint_all(p_array.copy(), x_array, y_array)

    # CALCULAR DISTANCIA ORTOGONAL
    dist_orto, idx_orto = nb_ortoDistancePointLine_indx(x_array, y_array, p_array.copy(), mask)

    if reference == "Tramo":
        # OBTENER TEXTOS DE TRAMO
        _tramo = np.concatenate(df_m_ramales.loc["Tramo"].to_list())
        xy_index = np.cumsum(list(map(len, _x)))
        xy_index = np.insert(xy_index[:-1], 0, 0)
        _tramo_name = np.delete(_tramo, xy_index, axis=0)
        return dist_orto, _tramo_name
    else:
        return dist_orto


"#######################################################################################################################"
"LEER GEOMETRIA DESDE SHP O AUTOCAD"
"#######################################################################################################################"


def get_geometry_GIS(shp_name, dmax, m_ramales=None, append_m_ramales="No", include_m_ramales=[]):
    """

    :param shp_name:
    :param m_ramales:
    :param ramal:
    :param dmax:
    :param append_m_ramales:
    :param include_m_ramales:
    :return:
    """

    lista_shp = shp_name
    if m_ramales is None or append_m_ramales == "No":
        m_ramales = {}
        ramal = {}
        len_ramal = 0
    else:
        len_ramal = len(m_ramales)

    cont = 0
    for num, file in enumerate(lista_shp):
        # 'Append Files'
        if file not in include_m_ramales:
            sf = shapefile.Reader(file)
            for r in sf.shapeRecords():
                try:
                    Coordenadas = np.array(r.shape.points).T
                    CoordX = Coordenadas[0]
                    CoordY = Coordenadas[1]
                    CoordZ = [0] * len(CoordX)
                except:
                    continue

                # 'VERFIICAR QUE NO EXISTAN DISTANCIAS MENORES A "dmax"'
                d = dist2d_vector(CoordX, CoordY)
                index = np.where(d < dmax)
                if np.array(index).size > 0:
                    CoordX = np.delete(CoordX, index)
                    CoordY = np.delete(CoordY, index)
                    CoordZ = np.delete(CoordZ, index)

                if r.record["Ramal"]:
                    Ramal = [str(r.record.Ramal)] * len(CoordX)
                else:
                    Ramal = [str(cont + len_ramal)] * len(CoordX)
                    cont = cont + 1

                if r.record["Tipo"]:
                    Tipo = [r.record["Tipo"]] * len(CoordX)
                else:
                    Tipo = ["Sanitario"] * len(CoordX)

                if r.record["Material"] in [
                    "PVC",
                    "PVC-1MPa",
                    "PEAD",
                    "PRFV",
                    "HS",
                    "HA",
                    "HD",
                ]:
                    Material = [r.record["Material"]] * len(CoordX)
                else:
                    Material = ["PVC"] * len(CoordX)

                if r.record["Seccion"] in ["circular", "rectangular"]:
                    Seccion = [r.record["Seccion"]] * len(CoordX)
                else:
                    Seccion = ["circular"] * len(CoordX)

                if r.record["Derivacion"]:
                    Derivacion = np.array([r.record["Derivacion"]] * len(CoordX))
                else:
                    Derivacion = np.array([None] * len(CoordX))

                if r.record["Rugosidad"]:
                    Rugosidad = np.array([r.record["Rugosidad"]] * len(CoordX))
                else:
                    Rugosidad = np.array(["liso"] * len(CoordX))

                if r.record["Estado"]:
                    Estado = np.array([r.record["Estado"]] * len(CoordX))
                else:
                    Estado = np.array(["nuevo"] * len(CoordX))

                if r.record["Fase"]:
                    Fase = np.array([r.record["Fase"]] * len(CoordX))
                else:
                    Fase = np.array(["1"] * len(CoordX))

                Conexion = [None] * len(CoordX)
                Pozo = [Ramal[0] + "." + str(i) for i in range(len(CoordX))]
                Tramo = [""] + [str(Pozo[i]) + "-" + str(Pozo[i + 1]) for i in range(len(Pozo) - 1)]

                m_ramales[Ramal[0]] = {
                    "Ramal": np.array(Ramal).astype("U256"),
                    "Tipo": np.array(Tipo),
                    "Conexion": np.array(Conexion),
                    "Pozo": np.array(Pozo),
                    "Tramo": np.array(Tramo),
                    "X": CoordX,
                    "Y": CoordY,
                    "Z": np.array(CoordZ),
                    "L": np.array([""] * len(CoordX)),
                    "LT": np.array([""] * len(CoordX)),
                    "Material": np.array(Material).astype("U256"),
                    "Estado": np.array(Estado).astype("U256"),
                    "Fase": np.array(Fase).astype("U256"),
                    "Seccion": np.array(Seccion).astype("U256"),
                    "Rugosidad": np.array(Rugosidad).astype("U256"),
                    "Pozo_hmin": np.array([0.0] * len(CoordX)).astype(float),
                    "cobertura_min": np.array([0.0] * len(CoordX)).astype(float),
                    "D_min": np.array([None] * len(CoordX)).astype(float),
                    "S_min": np.array([None] * len(CoordX)).astype(float),
                    "Derivacion": Derivacion.astype(str).astype("U256"),
                    "Obs": np.array([""] * len(CoordX)).astype("U256"),
                }

                ramal[Ramal[0]] = Ramal[0]
            len_ramal = len(m_ramales)

    return m_ramales, ramal


# this one in on the app
@profile
def get_geometry_GIS_V1(
    vector_name,
    dmax,
    m_ramales=None,
    DataFrame=False,
    append_m_ramales="No",
    include_m_ramales=[],
):
    """
    Reads vector files, filters valid geometries and lines, removes points closer than dmax, and creates the m_ramales dictionary

    Args:
        vector_name (str or list): File path or list of file paths to vector files.
        dmax (float): Maximum distance between two points in a line.
        m_ramales (dict, optional): Dictionary containing existing data. Defaults to None.
        DataFrame (bool, optional): Flag to return data as a pandas DataFrame. Defaults to False.
        append_m_ramales (str, optional): Flag to append data to m_ramales. Defaults to 'No'.
        include_m_ramales (list, optional): List of ramal names to include in the data. Defaults to [].

    Returns:
        tuple: Tuple containing the m_ramales and ramal dictionaries, and optionally the m_ramales DataFrame.

    """

    # convert vector_name to list if not already
    lista_vector = vector_name if isinstance(vector_name, list) else [vector_name]

    # If m_ramales is None or append_m_ramales is 'No', create new empty dictionaries for m_ramales and ramal and set len_ramal to 0.
    if m_ramales is None or append_m_ramales == "No":
        m_ramales = {}
        ramal = {}
        len_ramal = 0
    else:
        # Otherwise, set len_ramal to the length of m_ramales.
        len_ramal = len(m_ramales)

    # loop through each file in lista_vector
    for num, file in enumerate(lista_vector):
        # append Files
        if file not in include_m_ramales:
            # ----------------------------------------------------------------
            # Read file and make sure geometry lines are valid
            # ----------------------------------------------------------------

            columns_read = [
                "Tipo",
                "Material",
                "Seccion",
                "Rugosidad",
                "Estado",
                "Pozo_hmin",
                "cobertura_min",
                "D_min",
                "S_min",
                "S",
                "Derivacion",
                "Fase",
                "Obs",
            ]
            # read file
            try:
                # df = pyogrio.read_dataframe(file, use_arrow=True, columns=columns_read)
                df = gpd.read_file(file, engine="pyogrio")
            except:
                df = gpd.read_file(file, engine="fiona")

            # Identify and remove repeated geometries
            df = df.drop_duplicates(subset="geometry")

            # If you want to reset the index, you can do the following:
            df.reset_index(drop=True, inplace=True)

            # Check for columns_read items are present in the df, if not the use the default value an type
            for column in columns_read:
                if column not in df.columns:
                    df[column] = np.nan

            # check for valid geometry
            mask_valid = df.geometry.is_valid
            df = df[mask_valid]

            # check for geomtry type
            mask_geometry = df.geom_type.isin(["MultiLineString", "LineString"])
            df = df[mask_geometry]

            # get array of coordinates
            coords, ramales = shapely.get_coordinates(df.geometry, return_index=True)
            ramales = ramales + len_ramal

            # Get the unique values in the array
            ramales_unicos, split_index, ramales_count = np.unique(ramales, return_index=True, return_counts=True)

            # ----------------------------------------------------------------
            # Remove points if they area too close (dmax)
            # ----------------------------------------------------------------

            # check for dmax distance in array
            x_coords, y_coords = coords.T
            point_distance = dist2d_vector(x_coords, y_coords)
            remove_index = np.where(point_distance < dmax)[0]

            if remove_index.size > 0:
                # check for points on the border of the line, erase the distances that area bewtewn diferent lines and not in the same polyline.
                remove_index_filter = remove_index[~np.isin(remove_index, split_index[1:] + 1)]

                # remove coordinates and pos_id positions
                coords = np.delete(coords, remove_index_filter, axis=0)
                x_coords, y_coords = coords.T
                ramales = np.delete(ramales, remove_index_filter)

                # update split_index
                ramales_unicos, split_index, ramales_count = np.unique(ramales, return_index=True, return_counts=True)

            # ----------------------------------------------------------------
            # Dictionaries for valid, default and types of data
            # ----------------------------------------------------------------

            # columns for initial new m_ramales
            columns = [
                "Ramal",
                "Tipo",
                "Conexion",
                "Pozo",
                "Tramo",
                "X",
                "Y",
                "Z",
                "L",
                "LT",
                "Material",
                "Seccion",
                "Rugosidad",
                "Estado",
                "Pozo_hmin",
                "cobertura_min",
                "D_min",
                "S_min",
                "Derivacion",
                "Fase",
                "Obs",
            ]

            valid_values_dict = {
                "Tipo": ["combinado", "pluvial", "sanitario"],
                "Material": ["PVC", "PVC-1MPa", "PEAD", "PRFV", "HS", "HA", "HD"],
                "Seccion": ["circular", "rectangular"],
                "Rugosidad": [
                    "liso",
                    "dados",
                    "barras_continuas",
                    "barras_cortadas",
                    "v_invertida",
                    "doble_zig_zag",
                ],
                "Estado": ["nuevo", "existente"],
                "Fase": np.arange(0, len(ramales)).astype("U256"),
                "Derivacion": [True, False],
            }

            default_values_dict = {
                "Tipo": "sanitario",
                "Conexion": None,
                "Material": "PVC",
                "Z": np.nan,
                "L": np.nan,
                "LT": np.nan,
                "Seccion": "circular",
                "Rugosidad": "liso",
                "Estado": "nuevo",
                "Pozo_hmin": 0.0,
                "cobertura_min": 0.0,
                "D_min": None,
                "S_min": None,
                "Derivacion": False,
                "Fase": 1,
                "Obs": "",
            }

            type_values_dict = {
                "Ramal": "U256",
                "Tipo": "U256",
                "Conexion": object,
                "Pozo": "U256",
                "Tramo": "U256",
                "X": float,
                "Y": float,
                "Z": float,
                "L": float,
                "LT": float,
                "Material": "U256",
                "Seccion": "U256",
                "Rugosidad": "U256",
                "Estado": "U256",
                "Pozo_hmin": float,
                "cobertura_min": float,
                "D_min": float,
                "S_min": float,
                "Derivacion": bool,
                "Fase": "U256",
                "Obs": "U256",
            }

            # ----------------------------------------------------------------
            # Create arrays to fill dataframe m_ramales_df
            # ----------------------------------------------------------------

            # crear data frame de m_ramales
            m_ramales_df = pd.DataFrame(columns=columns)

            # create Pozo array
            pozo_array = pd.Series(np.arange(ramales.size) - np.repeat(split_index, ramales_count)).astype("U256")
            ramal_array = pd.Series(ramales).astype("U256")
            pozo_array = ramal_array.str.cat(pozo_array, sep=".").to_numpy()

            # create Tramo array
            tramo_inicial = pd.Series(pozo_array[:-1])
            tramo_final = pd.Series(pozo_array[1:])
            tramo_array = tramo_inicial.str.cat(tramo_final, sep="-")
            tramo_array = pd.Series([""])._append(tramo_array, ignore_index=True)
            tramo_array[split_index] = ""

            Pozo_hmin = df["Pozo_hmin"].to_numpy()[ramales]
            cobertura_min = df["Pozo_hmin"].fillna(0.0).to_numpy()[ramales]
            obs = np.where(df["Obs"].to_numpy()[ramales] == None, "", df["Obs"].to_numpy()[ramales])
            D_min = df["D_min"].to_numpy()[ramales].astype(float)
            S_min = df["S_min"].to_numpy()[ramales].astype(float)

            array_values_dict = {
                "Ramal": ramales,
                "X": x_coords,
                "Y": y_coords,
                "Pozo": pozo_array,
                "Tramo": tramo_array,
                "Pozo_hmin": Pozo_hmin,
                "cobertura_min": cobertura_min,
                "Obs": obs,
                "D_min": D_min,
                "S_min": S_min,
            }

            # Loop through each column in `columns`
            for col in columns:
                # If the column is one of `Ramal`, `X`, `Y`, `Pozo`, or `Tramo`, use the values from `array_values_dict` to populate the column
                if col in array_values_dict.keys():
                    # valid and default values
                    m_ramales_df[col] = array_values_dict[col].astype(type_values_dict[col])

                # If the column is one of the other columns specified in `valid_values_dict`, check the values in the column to ensure they are valid and use the default value if they are not
                elif col in valid_values_dict.keys():
                    # valid and default values
                    type_value = type_values_dict[col]
                    valid_value = valid_values_dict[col]
                    default_value = default_values_dict[col]
                    # check for default value
                    default_array = np.where(pd.isnull(df[col]), default_value, df[col])

                    if col in ["Rugosidad"]:
                        # check for valid values
                        # string_values, float_values = pd.Series(default_array).str.extract('([a-zA-Z_]+)(-?\d+(\.\d*)?)', expand=False)[[0, 1]].to_numpy().T
                        string_values, float_values = pd.Series(default_array).str.extract(r"([a-zA-Z_]+)(-?\d+(\.\d*)?)", expand=False)[[0, 1]].to_numpy().T

                        # check for valid values
                        valid_mask = [False if _ in valid_value else True for _ in string_values]
                    else:
                        # check for valid values
                        valid_mask = [False if _ in valid_value else True for _ in default_array]

                    # get valid array
                    array = np.where(valid_mask, default_value, default_array)
                    # add to m_ramales data frame
                    m_ramales_df[col] = np.repeat(array, ramales_count).astype(type_value)

                    # #replace 0 row with empty string  # if col in ['Rugosidad', 'Estado']:  #     m_ramales_df[col][split_index] = ''

                # If the column is not one of the above, use the default value to populate the column
                else:
                    array = np.full(
                        fill_value=default_values_dict[col],
                        shape=ramales.size,
                        dtype=type_values_dict[col],
                    )
                    m_ramales_df[col] = array

            # ----------------------------------------------------------------
            # Create m_ramales dictionary
            # ----------------------------------------------------------------

            # Get the 'Ramal' array'
            ramal_array = m_ramales_df["Ramal"].to_numpy()
            # get column names in m_ramales_df
            cols = len(m_ramales_df.columns)
            # get a numpy array from the m_ramales_df
            m_ramales_array = m_ramales_df.to_numpy()

            for Ramal in ramales_unicos:
                Ramal = str(Ramal)
                # Create a mask to filter the dataframe by the current 'Ramal' value
                mask = ramal_array == Ramal
                array = m_ramales_array[mask, :]

                # Create a dictionary for the current 'Ramal' value and add the 'Ramal' key
                ramal[Ramal] = Ramal

                # Create a dictionary for the current 'Ramal' value using the column names as keys
                m_ramales[Ramal] = {columns[col]: array[:, col].astype(type_values_dict[columns[col]]) for col in range(cols)}

            # update the length ot the ramales count
            len_ramal = len(m_ramales)

    # return results
    if DataFrame:
        return m_ramales, ramal, m_ramales_df
    else:
        return m_ramales, ramal


def get_geometry_DXF(dxf_name, model=False):
    """

    :param dxf_name: Nombre del DXF
    :return:
    """
    doc = ezdxf.readfile(dxf_name)
    msp = doc.modelspace()
    m_ramales = {}
    ramal = {}
    t = -1
    # for e in msp:
    lista_materiales = [__.lower() for __ in ["PVC", "PVC-1MPa", "PEAD", "PRFV", "HS", "HA", "HD"]]
    for e in msp.query("LWPOLYLINE"):
        sep = detect(e.dxf.layer)
        atributos = e.dxf.layer.split(sep)
        _Material = [_.lower() for _ in atributos if _.lower() in lista_materiales]
        _Seccion = [_.lower() for _ in atributos if _.lower() in ["circular", "rectangular", "triangular", "trapezoidal"]]
        _Tipo = [_.lower() for _ in atributos if _.lower() in ["combinado", "pluvial", "sanitario"]]
        _Derivacion = [_.lower() for _ in atributos if _.lower() in ["derivacion"]]
        _Rugosidad = [_.lower() for _ in atributos if _.lower() in ["rugosidad"]]
        _Fase = [_.lower() for _ in atributos if _.lower() in ["Fase"]]

        Coordenadas = list(np.asarray(e.lwpoints.values)[np.asarray(e.lwpoints.values) > 0])
        CoordX = [i for i in Coordenadas if (Coordenadas.index(i) % 2) == 0]
        CoordY = [j for j in Coordenadas if not (Coordenadas.index(j) % 2) == 0]
        CoordZ = [0] * len(CoordX)

        t = t + 1
        Ramal = [str(t)] * len(CoordX)
        Conexion = [None] * len(CoordX)
        Pozo = [Ramal[0] + "." + str(i) for i in range(len(CoordX))]
        Tramo = np.insert([str(Pozo[i]) + "-" + str(Pozo[i + 1]) for i in range(len(Pozo) - 1)], 0, "")

        if len(_Material) == 1:
            Material = [_Material[0].upper()] * len(CoordX)
        else:
            Material = ["PVC"] * len(CoordX)

        if len(_Tipo) == 1:
            Tipo = [_Tipo[0]] * len(CoordX)
        else:
            Material = ["Sanitario"] * len(CoordX)

        if len(_Seccion) == 1:
            Seccion = [_Seccion[0]] * len(CoordX)
        else:
            Seccion = ["circular"] * len(CoordX)

        if len(_Derivacion) == 1:
            Derivacion = np.array([_Derivacion[0]] * len(CoordX))
        else:
            Derivacion = np.array([None] * len(CoordX))

        if len(_Rugosidad) == 1:
            Rugosidad = np.array([_Rugosidad[0]] * len(CoordX))
        else:
            Rugosidad = np.array(["liso"] * len(CoordX))

        # if len(_Fase) == 1:
        #     Fase = np.array([_Fase[0]] * len(CoordX))
        # else:
        #     Fase = np.array(['1'] * len(CoordX))

        m_ramales[Ramal[0]] = {
            "Ramal": np.array(Ramal).astype("U256"),
            "Tipo": np.array(Tipo),
            "Conexion": np.array(Conexion),
            "Pozo": np.array(Pozo),
            "Tramo": np.array(Tramo),
            "X": np.array(CoordX),
            "Y": np.array(CoordY),
            "Z": np.array(CoordZ),
            "L": np.array([""] * len(CoordX)),
            "LT": np.array([""] * len(CoordX)),
            "Material": np.array(Material).astype("U256"),
            "Fase": np.array(Material).astype("U256"),
            "Seccion": np.array(Seccion).astype("U256"),
            "Rugosidad": np.array(Rugosidad).astype("U256"),
            "Pozo_hmin": np.array([0.0] * len(CoordX)).astype(float),
            "cobertura_min": np.array([0.0] * len(CoordX)).astype(float),
            "D_min": np.array([None] * len(CoordX)).astype(float),
            "S_min": np.array([None] * len(CoordX)).astype(float),
            "Derivacion": Derivacion.astype(str).astype("U256"),
            "Obs": np.array([""] * len(CoordX)).astype("U256"),
        }

        ramal[Ramal[0]] = Ramal[0]

    if model == False:
        return m_ramales, ramal
    else:
        return m_ramales, ramal, doc


# @profile
def get_geometry_pypiper_dxf(file, elev_file=None, n_ramal_max=None):
    # GET GEOMETRY
    m_ramales, ramal, doc = get_geometry_DXF(file, model=True)

    # GET LENGTH
    m_ramales, ramal = get_len(m_ramales, ramal)

    # GET MODEL SPACE
    msp = doc.modelspace()

    # GET AL LAYERS FROM DXF
    layers = [_.lower() for _ in list(doc.layers.entries.keys())]

    # ASIGNAR DIAMETROS A TUBERIA
    if "diametro" in layers:
        DIAMETRO_ARRAY = []
        DIAMETRO_COORDS = []
        # entity query for all TEXT entities in modelspace
        for e in msp.query("TEXT"):
            if e.dxf.layer.lower() == "diametro":
                DIAMETRO_ARRAY.append(e.dxf.text)
                DIAMETRO_COORDS.append(e.dxf.insert.xyz[:2])
        DIAMETRO_COORDS = np.array(DIAMETRO_COORDS).astype(float)
        DIAMETRO_ARRAY = np.array(DIAMETRO_ARRAY).astype(str)

        # CALCULAR DISTANCIA ORTOGONAL
        dist_orto, _tramo_name = pp_minDistance_Point_Line(m_ramales=m_ramales, p_array=DIAMETRO_COORDS, reference="Tramo")

        # INDENTIFICAR INDICES
        array_pos = np.argsort(dist_orto, axis=0)
        pos_index = array_pos[:2, :].T
        start_arr, end_arr = DIAMETRO_ARRAY[pos_index].T
        index_notequal = np.where(start_arr != end_arr)[0]
        # MOESTAR ERROR SI LOS DOS EXTREMOS DEL TUBO O DOS PUNTOS MAS CERCANO EL TEXTO DEL DIAMETRO NO ES IGUAL
        if len(index_notequal):
            print("LAS SECCIONES NO SON IGUALES EN LAS COORDENADAS: ")
            print(DIAMETRO_COORDS[pos_index[index_notequal]])
            sys.exit()

        # CREAR DICCIONARIO DE DIAMETROS PARA TODOS LOS RAMALES
        diametro_dict = dict(zip(_tramo_name, start_arr))
        diametro_dict[""] = "0"

        # ASIGNAR VALORES DE DIAMETRO INTERNO Y EXTERNO PARA RAMALES
        for _ramal in ramal.keys():
            empty_array = np.zeros(shape=len(m_ramales[_ramal]["Tramo"]), dtype=float)
            # CREAR ARRAYS PARA LLENAR todo poner todas la variables que faltan
            m_ramales[_ramal]["S"] = empty_array.copy()
            m_ramales[_ramal]["Rug"] = empty_array.copy()
            m_ramales[_ramal]["q_san"] = empty_array.copy()
            m_ramales[_ramal]["q_pluvial"] = empty_array.copy()
            m_ramales[_ramal]["q_accu"] = empty_array.copy()
            m_ramales[_ramal]["D_int"] = empty_array.astype(str).copy()
            m_ramales[_ramal]["D_ext"] = empty_array.astype(str).copy()
            m_ramales[_ramal]["Q_SLL"] = empty_array.copy()
            m_ramales[_ramal]["V_SLL"] = empty_array.copy()
            m_ramales[_ramal]["ang"] = empty_array.copy()
            m_ramales[_ramal]["q/Q"] = empty_array.copy()
            m_ramales[_ramal]["h/D"] = empty_array.copy()
            m_ramales[_ramal]["v/V"] = empty_array.copy()
            m_ramales[_ramal]["v"] = empty_array.copy()
            m_ramales[_ramal]["h"] = empty_array.copy()
            m_ramales[_ramal]["ZTI"] = empty_array.copy()
            m_ramales[_ramal]["ZTF"] = empty_array.copy()
            m_ramales[_ramal]["ZFI"] = empty_array.copy()
            m_ramales[_ramal]["ZFF"] = empty_array.copy()
            m_ramales[_ramal]["HI"] = empty_array.copy()
            m_ramales[_ramal]["HF"] = empty_array.copy()
            m_ramales[_ramal]["SALTO"] = empty_array.copy()

            # DIAMETROS EXTERNOS
            D_ext_arr = np.array(itemgetter(*m_ramales[_ramal]["Tramo"])(diametro_dict))
            # LISTA DE MATERIALES DEL RAMAL
            _materiales = np.unique(m_ramales[_ramal]["Material"])

            # LOCALIZAR SECCIONES  CIRCULARES y NO CIRCULARES
            index_circular = [_ for _ in range(len(D_ext_arr)) if "x" not in D_ext_arr[_].lower()]
            index_no_circular = list(set(range(len(D_ext_arr))).difference(set(index_circular)))
            D_ext_circular = np.array(D_ext_arr[index_circular].astype(float) / 1000.0)
            # D_ext_no_circular = np.array(['x'.join((np.array(_.split('x')).astype(float) / 1000.0).astype(str)) for _ in D_ext_arr[index_no_circular]])

            D_ext_no_circular = []
            Secciones = []
            for _num, _ in enumerate(D_ext_arr[index_no_circular]):
                _res = _.lower().split("x")
                if len(_res) == 3:
                    _b, _h, _seccion = _.lower().split("x")
                    _b = str(float(_b) / 1000.0)
                    _h = str(float(_h) / 1000.0)
                    D_ext_no_circular.append("x".join([_b, _h]))
                    Secciones.append(_seccion)
                else:
                    print("Error: No tiene seccion definida")
                    print(m_ramales[_ramal]["X"][_num], m_ramales[_ramal]["Y"][_num])
            D_ext_no_circular = np.array(D_ext_no_circular)
            Secciones = np.array(Secciones)

            # ASIGNAR DIAMETRO EXTERNO
            m_ramales[_ramal]["D_ext"][index_no_circular] = D_ext_no_circular
            m_ramales[_ramal]["Seccion"][index_no_circular] = Secciones
            m_ramales[_ramal]["D_ext"][index_circular] = D_ext_circular

            # ASIGNAR DIAMETRO INTERNO
            for _material in _materiales:
                # SECCIONES CIRCULARES
                material_index = np.char.equal(m_ramales[_ramal]["Material"][index_circular], _material).nonzero()
                m_ramales[_ramal]["D_int"][index_circular] = D_int(D_ext_circular[material_index], _material)

                # SECCIONES NO CIRCULARES
                material_index = np.char.equal(m_ramales[_ramal]["Material"][index_no_circular], _material).nonzero()
                m_ramales[_ramal]["D_int"][index_no_circular] = D_ext_no_circular[material_index]

    # ASIGNAR ELEVACIONES DE POZO CONSIDERANO MEDIDAS DE PROFUNIDAD
    if "profundidad" in layers:
        PROFUNIDAD_ARRAY = []
        PROFUNIDAD_COORDS = []
        # entity query for all TEXT entities in modelspace
        for e in msp.query("TEXT"):
            if e.dxf.layer.lower() == "profundidad":
                PROFUNIDAD_ARRAY.append(e.dxf.text)
                PROFUNIDAD_COORDS.append(e.dxf.insert.xyz[:2])
        PROFUNIDAD_COORDS = np.array(PROFUNIDAD_COORDS).astype(float)
        PROFUNIDAD_ARRAY = np.array(PROFUNIDAD_ARRAY).astype(float)

        # CALCULAR DISTANCIA MINIMA
        x_flat = np.concatenate([m_ramales[_]["X"] for _ in ramal.keys()])
        y_flat = np.concatenate([m_ramales[_]["Y"] for _ in ramal.keys()])
        dist = nb_cdist(PROFUNIDAD_COORDS.copy(), x_flat, y_flat)

        # INDENTIFICAR INDICES
        pos_index = np.argmin(dist, axis=0)
        profundidad_dict = dict(
            zip(
                np.concatenate([m_ramales[_]["Pozo"] for _ in ramal.keys()]),
                PROFUNIDAD_ARRAY[pos_index],
            )
        )

        # PREPARAR DATOS DE ELEVACION
        elev_source, elev_file_type = get_elev_source(elev_file)
        elevation_results = get_elev_values(m_ramales, ramal, elev_source, elev_file_type, n_ramal_max)
        if len(elevation_results) == 3:
            m_ramales, ramal, tree_xyz = elevation_results
        elif len(elevation_results) == 2:
            m_ramales, ramal = elevation_results

        # GET ELEVATION AND SLOPE
        for _ramal in ramal.keys():
            # GET HEIGTH VALUES
            pi, pf = pp_char_split(m_ramales[_ramal]["Tramo"][1:], "-")
            m_ramales[_ramal]["HI"][1:] = np.array(itemgetter(*pi)(profundidad_dict))
            m_ramales[_ramal]["HF"][1:] = np.array(itemgetter(*pf)(profundidad_dict))
            # GET ELEVATION VALUES
            m_ramales[_ramal]["ZTI"][1:] = m_ramales[_ramal]["Z"][:-1]
            m_ramales[_ramal]["ZTF"][1:] = m_ramales[_ramal]["Z"][1:]
            m_ramales[_ramal]["ZFI"] = m_ramales[_ramal]["ZTI"] - m_ramales[_ramal]["HI"]
            m_ramales[_ramal]["ZFF"] = m_ramales[_ramal]["ZTF"] - m_ramales[_ramal]["HF"]
            # GET SLOPE VALUES
            m_ramales[_ramal]["S"][1:] = (m_ramales[_ramal]["ZFI"][1:] - m_ramales[_ramal]["ZFF"][1:]) / m_ramales[_ramal]["L"][1:]
            # CHECK FOR SLOPES VALUES <= 0 AND REPLACE IT FOR SMIN
            index_slope_negative = np.where(m_ramales[_ramal]["S"] <= 0)[0][1:]
            if index_slope_negative.size > 0:
                m_ramales[_ramal]["S"][index_slope_negative] = Smin(
                    m_ramales[_ramal]["Material"][index_slope_negative],
                    m_ramales,
                    _ramal,
                )

        return m_ramales, ramal


def to_bool(value):
    if value is None or pd.isna(value):
        return False
    if str(value).lower() == "false" or value == 0:
        return False
    return True


def ramal_rename_duplicates(old_ramal, new_ramal, continuar_numeracion_m_ramales):
    if continuar_numeracion_m_ramales in ["No"]:
        # Convert lists to pandas Series for convenience
        old_ramal = pd.Series(old_ramal)
        new_ramal = pd.Series(new_ramal)

        # Extract the part before underscore from old ramals
        old_ramal_base = old_ramal.str.split("_", expand=True)[0]
        old_ramal_base = pd.Series(old_ramal_base.unique())

        # Filter ramals that are in new_ramal and contain 'E'
        filtered_ramal = old_ramal_base[old_ramal_base.isin(new_ramal) & old_ramal_base.str.contains("E")]

        # Generate renaming_dict
        renaming_dict = {name: f"R0{name}" for name in filtered_ramal}
    else:
        # Convert lists to pandas Series for convenience
        old_ramal = pd.Series(old_ramal)
        new_ramal = pd.Series(new_ramal)

        # Extract the part before underscore from old ramals
        old_ramal_base = old_ramal.str.split("_", expand=True)[0]
        old_ramal_base = pd.Series(old_ramal_base.unique())

        # Filter ramals that are in new_ramal and contain 'E'
        filtered_ramal = old_ramal_base[old_ramal_base.isin(new_ramal) & old_ramal_base.str.contains("E")]

        max_ramal = old_ramal_base.str.replace("E", "").astype(int).max() + 1
        # Generate renaming_dict
        renaming_dict = {name: "E" + str(num + max_ramal) for name, num in zip(filtered_ramal, filtered_ramal.str.replace("E", "").astype(int))}

    return renaming_dict


def get_geometry_pypiper_GIS(vector_name, dmax, m_ramales=None, ramal=None, append_m_ramales="No", include_m_ramales=[], continuar_numeracion_m_ramales=" Si"):
    default_values_dict = {
        # Cadenas ("U256")
        "Estado": "nuevo",
        "Material": "PVC",
        "metodo_constructivo": "zanja abierta",
        "Obs": "",
        "Pozo": None,  # Añadido
        "Ramal": None,  # Añadido
        "Rugosidad": "liso",
        "Seccion": "circular",
        "Tipo": "sanitario",
        "tipo_nudo": "pozo",
        "Tramo": None,  # Añadido
        "Fase": "1",
        # Float
        "D_ext": "0.0",
        "D_int": "0.0",
        "D_min": None,
        "HF": np.nan,
        "HI": np.nan,
        "L": np.nan,
        "LT": np.nan,
        "Pozo_hmin": None,
        "Rug": np.nan,
        "S": np.nan,
        "SALTO": np.nan,
        "S_min": None,
        "S_user": None,
        "X": np.nan,  # Añadido
        "Y": np.nan,  # Añadido
        "Z": np.nan,
        "ZFF": np.nan,
        "ZFI": np.nan,
        "ZTF": np.nan,
        "ZTI": np.nan,
        # Bool
        "Derivacion": False,
        # Object
        "Conexion": None,
        'cobertura_min':np.nan
    }

    type_values_dict = {
        # Cadenas ("U256")
        "Estado": "U256",
        "Material": "U256",
        "metodo_constructivo": "U256",
        "Obs": "U1000",
        "Pozo": "U256",
        "Ramal": "U256",
        "Rugosidad": "U256",
        "Seccion": "U256",
        "Tipo": "U256",
        "tipo_nudo": "U256",
        "Tramo": "U256",
        "Fase": "U256",
        # Float
        "D_ext": "U256",
        "D_int": "U256",
        "D_min": float,
        "HF": float,
        "HI": float,
        "L": float,
        "LT": float,
        "Pozo_hmin": float,
        "Rug": float,
        "S": float,
        "SALTO": float,
        "S_min": float,
        "S_user": float,
        "X": float,
        "Y": float,
        "Z": float,
        "ZFF": float,
        "ZFI": float,
        "ZTF": float,
        "ZTI": float,
        # Bool
        "Derivacion": bool,
        # Object
        "Conexion": object,
        'cobertura_min':float
    }

    columns_read = list(type_values_dict.keys())

    # revisar si viene del catastro entonces desempacar
    if isinstance(vector_name, tuple):
        file_path = [vector_name[1]]
        file_df = [vector_name[0]]
    else:
        # convert vector_name to list if not already
        if isinstance(vector_name, list):
            file_path = vector_name
            file_df = [None] * len(file_path)
        else:
            file_path = [vector_name]
            file_df = [None]

    lista_vector = zip(file_path, file_df)

    # revisar si m_ramales existe o no se quiere agregar el archivo al proyecto actual
    if m_ramales is None or append_m_ramales == "No":
        m_ramales = {}
        ramal = {}
        len_ramal = 0
    else:
        # Otherwise, set len_ramal to the length of m_ramales.
        len_ramal = len(m_ramales)

    # iterar la lista de archivos shapefile
    for num, file in enumerate(lista_vector):
        file_path, file_df = file
        # 'Append Files'
        if file_path not in include_m_ramales:
            # ----------------------------------------------------------------
            # Read file and make sure geometry lines are valid
            # ----------------------------------------------------------------
            columns_read = columns_read
            # read file
            if not isinstance(file_df, gpd.GeoDataFrame):
                try:
                    df = gpd.read_file(file_path, engine="pyogrio", columns=columns_read)
                    df_derivacion = gpd.read_file(file_path, include_fields=["Derivacion"])
                    df["Derivacion"] = df_derivacion["Derivacion"]
                    df = df.reindex(columns=columns_read + ["geometry"])
                except:
                    df = gpd.read_file(file_path, engine="fiona")
                    # df = df[columns_read + ["geometry"]]
            else:
                df = file_df.copy()
                # Filter columns if they exist in the GeoDataFrame
                existing_columns = set(df.columns)
                selected_columns = list(existing_columns.intersection(columns_read + ["geometry"]))
                df = df[selected_columns]
                del file_path

            # Check for columns_read items are present in the df, if not the use the default value an type
            for column in columns_read:
                if column not in df.columns:
                    df[column] = default_values_dict[column]

            # check for valid geometry
            mask_valid = df.geometry.is_valid
            df = df[mask_valid]

            # avoid empty geometries
            not_empty_geometry = np.invert(df["geometry"].is_empty)
            df = df[not_empty_geometry]

            # check for geomtry type
            mask_geometry = df.geom_type.isin(["MultiLineString", "LineString"])
            df = df[mask_geometry]
            df = df.explode()

            # check for derivacion make all bool
            df["Derivacion"] = df["Derivacion"].apply(to_bool).to_numpy()

            # Sort dataframe to avoid conection errors, by Ramal
            # Get the sorted index using the custom sorting function defined by a lambda
            sorted_index = index_natsorted(df["Ramal"], key=lambda x: (x is None, x))
            # Sort DataFrame by this index
            df = df.reindex(index=order_by_index(df.index, sorted_index)).round(3)
            # Reindex
            df.reset_index(drop=True, inplace=True)
            df["Conexion"] = np.array([np.nan] * len(df["Conexion"]))

            # get ramal labels
            _r = df["Ramal"].dropna().unique().astype(str)
            # Get column position for each title name
            dict_key = {key: _ for _, key in enumerate(df.columns)}

            ############################################################################################################
            # Operaciones para modificar los ramales para tramos existentes y nuevos
            ############################################################################################################

            # Renumerar los ramales aumentando la numeracion para  los nuevos
            index_count = np.where(df["Ramal"].to_numpy() == None)[0]
            if len(index_count) > 0:
                # set Estado None to Nuevo
                df.loc[index_count, "Estado"] = "nuevo"
                if len(_r) > 0:
                    # start_count = np.max(_r.astype(int))
                    start_count = (
                        pd.to_numeric(
                            df["Ramal"].dropna().str.replace(r"[A-Za-z]", "", regex=True),
                            errors="coerce",
                        )
                        .dropna()
                        .astype(int)
                        .max()
                    )
                else:
                    start_count = -1
                diff_array = np.array((range(start_count + 1, start_count + len(index_count) + 1, 1))).astype(str)
                _r = np.append(_r, diff_array).astype(str)
                df.loc[index_count, "Ramal"] = diff_array

            # agregar 'E' en ramales, conexion, pozo y tramos existentes
            index_existente = np.where(df["Estado"] == "existente")[0]
            if len(index_existente):
                # modificar Ramal
                # ramal_existente = pd.Series(['E'] * len(index_existente), index=index_existente).str.cat(df['Ramal'][index_existente], sep='').to_numpy()
                ramal_existente = pd.Series(["E"] * len(index_existente), index=index_existente).str.cat(
                    df["Ramal"].str.replace(r"[A-Za-z]", "", regex=True)[index_existente],
                    sep="",
                )
                df.loc[index_existente, "Ramal"] = ramal_existente

                # modificar Pozo
                pozo_existente = (
                    pd.Series(["E"] * len(index_existente), index=index_existente)
                    .str.cat(
                        df["Pozo"].str.replace(r"[A-Za-z]", "", regex=True)[index_existente],
                        sep="",
                    )
                    .to_numpy()
                )
                df.loc[index_existente, "Pozo"] = pozo_existente

                # modificar Tramo
                start_pz, end_pz = pp_char_split(
                    df["Tramo"].str.replace("[^0-9._-]", "", regex=True)[index_existente].to_numpy(),
                    _split="-",
                )
                start_array = pd.Series(["E"] * len(index_existente), index=index_existente).str.cat(start_pz, sep="")
                end_array = pd.Series(["E"] * len(index_existente), index=index_existente).str.cat(end_pz, sep="")
                tramo_existente = start_array.str.cat(end_array, sep="-").to_numpy()
                df.loc[index_existente, "Tramo"] = tramo_existente

                # actualizar nombre de ramales
                _r = df["Ramal"].dropna().unique().astype(str)

            # Modificar cuando es un archivo de que se agrega a m_ramales existente
            if len_ramal > 0:
                # obtener los nombres de los ramales nuevos
                new_ramal_names = df["Ramal"].unique()
                # Modificar los ramales nuevos con E que estan repetidos en el m_ramales existente
                replace_dictionary = ramal_rename_duplicates(vg.m_ramales_df["Ramal"].unique(), new_ramal_names, continuar_numeracion_m_ramales)
                # verificar si existen ramales con numeros
                index_int_names = ~df["Ramal"].str.contains("E")
                index_str_names = df["Ramal"].str.contains("E")

                cond_str = index_str_names.to_numpy().nonzero()[0]
                if cond_str.size > 0 and len(replace_dictionary):
                    # replace ramal name
                    new_ramal = replace_name_in_series(df["Ramal"], replace_dictionary)
                    df["Ramal"] = new_ramal

                    # replace pozo name
                    new_pozo = replace_name_in_series(df["Pozo"], replace_dictionary)
                    df["Pozo"] = new_pozo

                    # replace pozo name
                    new_tramo = replace_name_in_series(df["Tramo"], replace_dictionary)
                    df["Tramo"] = new_tramo

                cond_int = index_int_names.to_numpy().nonzero()[0]
                if cond_int.size > 0:
                    new_r = df.loc[index_int_names, "Ramal"].to_numpy().astype(int)
                    max_ramal = np.max(new_r)
                    new_r = new_r - new_r[0]
                    _r_new = new_r + max_ramal + 1
                    df.loc[index_int_names, "Ramal"] = _r_new.astype(str)

                    # ToDo Pensa en que forma puedo aplicar esto a los tramo nuevos es mas rapido.  # count_series = df.groupby('Ramal').cumcount().astype(str)  # new_pozo = df['Ramal'] + '.' + count_series  # df.loc[index_int_names, 'Pozo'] = new_pozo

                # actualizar nombre de ramales
                _r = df["Ramal"].dropna().unique().astype(str)

            ramal = dict(zip(_r, _r))
            cols = list(df.columns)
            cols_iter = [_ for _ in cols if _ not in ["geometry"]]
            values = len(cols) * [0.0]
            in_dict = dict(zip(cols, values))

            array = df.to_numpy().copy()
            ramal_array = df["Ramal"].to_numpy().astype(str)
            estado_array = df["Estado"].to_numpy().astype(str)
            index_existente = np.char.equal(estado_array, "existente")
            index_nuevo = np.char.equal(estado_array, "nuevo")

            df.index = df["Ramal"]
            coords_df = df.get_coordinates()
            coords_ramal_array = np.array(coords_df.index).astype(str)
            x_real, y_real = coords_df["x"].to_numpy(), coords_df["y"].to_numpy()

            for i in ramal:
                index_ramal_pos = np.char.equal(ramal_array, i)
                check_state = set(estado_array[index_ramal_pos])

                for estado in check_state:
                    if estado.lower() in "existente":
                        index = np.intersect1d(index_ramal_pos.nonzero()[0], index_existente.nonzero()[0])
                        df_temp = array[index, :].copy()
                        s = df_temp[:, dict_key["Tramo"]]
                        if len(s) >= 2:
                            source, end = pp_char_split(s, _split="-")
                            new_join = np.array(["-".join(_) for _ in np.array([end[:-1], source[1:]]).T])
                            index_insert = np.arange(1, len(new_join) * 2, 2)
                            tramo_join = s.copy()
                            for _ in range(len(index_insert)):
                                tramo_join = np.insert(tramo_join, index_insert[_], new_join[_])
                        else:
                            tramo_join = s.copy()
                        # revisar tramos separados fisicamente por distancia de pozos
                        check_index = np.char.equal(coords_ramal_array, i).nonzero()[0]
                        x_check = x_real[check_index]
                        y_check = y_real[check_index]
                        index_missing = np.where(dist2d_vector(x_check, y_check) != 0)[0]
                        index_split = index_missing[index_missing % 2 != 0]
                        # juntar los dos split index
                        tramos = [_ for _ in np.split(tramo_join, index_split) if len(_) > 0]

                        if len(tramos) == 1:
                            i_array = [i]
                        else:
                            i_array = [i + "_" + str(_) for _ in range(len(tramos))]

                        for i_iter, tramo in zip(i_array, tramos):
                            index_split = np.isin(s.astype(str), tramo.astype(str)).nonzero()[0]
                            df_split = df_temp[index_split, :].copy()

                            # modificar coordenadas
                            # coordenadas desde geometria de shapefile
                            x_arr_source, x_arr_end = np.array([df_split[_, dict_key["geometry"]].coords.xy[0] for _ in range(df_split.shape[0])]).T
                            y_arr_source, y_arr_end = np.array([df_split[_, dict_key["geometry"]].coords.xy[1] for _ in range(df_split.shape[0])]).T
                            # crear coordenadas completas de las lineas 0:
                            x_arr = np.append(x_arr_source, x_arr_end[-1])
                            y_arr = np.append(y_arr_source, y_arr_end[-1])
                            # modificar las coordenadas antiguas por las nuevas de la geometria
                            df_split[:, dict_key["X"]] = x_arr[1:]
                            df_split[:, dict_key["Y"]] = y_arr[1:]
                            # modificar las obervaciones
                            df_split[:, dict_key["Obs"]] = np.where(
                                df_split[:, dict_key["Obs"]] != None,
                                df_split[:, dict_key["Obs"]],
                                "",
                            )
                            # modificar pendientes
                            df_split[:, dict_key["S"]] = np.round(
                                np.array(
                                    (df_split[:, dict_key["ZFI"]] - df_split[:, dict_key["ZFF"]]) / df_split[:, dict_key["L"]],
                                    dtype=float,
                                ),
                                3,
                            )

                            in_dict["Ramal"] = i_iter
                            in_dict["Tipo"] = df_split[0, dict_key["Tipo"]]
                            in_dict["Tramo"] = ""
                            in_dict["Seccion"] = df_split[0, dict_key["Seccion"]]
                            in_dict["Rugosidad"] = df_split[0, dict_key["Rugosidad"]]
                            in_dict["Pozo"] = str(i_iter) + "." + str(int(df_split[0, dict_key["Pozo"]].split(".")[1]) - 1)
                            in_dict["X"] = x_arr[0]
                            in_dict["Y"] = y_arr[0]
                            in_dict["Z"] = float(df_split[0, dict_key["ZTI"]])
                            in_dict["L"] = 0.0
                            in_dict["LT"] = 0.0
                            in_dict["Material"] = df_split[0, dict_key["Material"]]
                            in_dict["S"] = round(
                                (df_split[0, dict_key["ZFI"]] - df_split[0, dict_key["ZFF"]]) / df_split[0, dict_key["L"]],
                                3,
                            )
                            in_dict["Rug"] = df_split[0, dict_key["Rug"]]
                            in_dict["Estado"] = "existente"
                            in_dict["Derivacion"] = df_split[0, dict_key["Derivacion"]]
                            in_dict["Fase"] = "0"
                            in_dict["Obs"] = ""
                            df_insert = np.array(list(in_dict.values())).reshape(1, len(cols))

                            # concatenar la primera fila y el resto de la matriz
                            c = np.concatenate([df_insert, df_split], axis=0)
                            read_dict = dict(zip(cols, c.T))
                            read_dict.pop("geometry", None)

                            # modificar dtypes de cada array del diciconario
                            # type_values_dict = type_values_dict
                            for col in cols_iter:
                                if col in type_values_dict.keys():
                                    value_type = type_values_dict[col]
                                    read_dict[col] = read_dict[col].astype(value_type)

                            # reemplazar None string a None Type
                            read_dict["Conexion"] = np.array([None] * len(x_arr))

                            # #check for derivacion make all bool
                            # [False if str(x).lower() == 'false' else True for x in read_dict['Derivacion']]

                            # modificar Pozo si comienza por numero mayor a 0
                            pz_array, pos_array = pp_char_split(read_dict["Pozo"], _split=".")
                            pos_array = pos_array.astype(int)
                            if pos_array[0] > 0:
                                read_dict["Pozo"] = np.array([i_iter + "." + str(ii) for ii in range(len(x_arr))])
                                read_dict["Tramo"] = np.array(
                                    [""] + [str(read_dict["Pozo"][ii]) + "-" + str(read_dict["Pozo"][ii + 1]) for ii in range(len(read_dict["Pozo"]) - 1)]
                                )

                            # modificar Pozo, Tramo, Tramal si la longitud de i_array es mayor a 1
                            if len(i_array) > 1:
                                read_dict["Pozo"] = np.array([i_iter + "." + str(ii) for ii in range(len(x_arr))])
                                read_dict["Tramo"] = np.array(
                                    [""] + [str(read_dict["Pozo"][ii]) + "-" + str(read_dict["Pozo"][ii + 1]) for ii in range(len(read_dict["Pozo"]) - 1)]
                                )
                                read_dict["Ramal"] = np.array([i_iter] * len(x_arr))

                            # agregar diccionario a m_ramales
                            m_ramales[i_iter] = read_dict

                    elif estado.lower() in "nuevo":
                        index = np.intersect1d(index_ramal_pos.nonzero()[0], index_nuevo.nonzero()[0])
                        df_temp = array[index, :].copy()

                        try:
                            Coordenadas = df_temp[:, dict_key["geometry"]][0].coords.xy
                            CoordX = np.array(Coordenadas[0])
                            CoordY = np.array(Coordenadas[1])
                            CoordZ = np.array([0] * len(CoordX))
                        except:
                            continue

                            # 'VERFIICAR QUE NO EXISTAN DISTANCIAS MENORES A "dmax"'
                        d = dist2d_vector(CoordX, CoordY)
                        index = np.where(d < dmax)
                        if np.array(index).size > 0:
                            CoordX = np.delete(CoordX, index)
                            CoordY = np.delete(CoordY, index)
                            CoordZ = np.delete(CoordZ, index)

                        temp_dictionary = {key: None for key in columns_read}
                        Estado_Nuevo = np.array(["nuevo"] * len(CoordX))
                        Conexion = np.array([None] * len(CoordX))
                        Pozo = np.array([i + "." + str(ii) for ii in range(len(CoordX))])
                        Tramo = np.array([""] + [str(Pozo[ii]) + "-" + str(Pozo[ii + 1]) for ii in range(len(Pozo) - 1)])
                        pozo_hmin = [None] * len(Tramo)
                        pozo_hmin[0] = df_temp[0, dict_key["Pozo_hmin"]]

                        # fill value arrays
                        temp_dictionary["Estado"] = Estado_Nuevo.astype(type_values_dict["Estado"])
                        temp_dictionary["Conexion"] = Conexion.astype(type_values_dict["Conexion"])
                        temp_dictionary["Pozo"] = Pozo.astype(type_values_dict["Pozo"])
                        temp_dictionary["Tramo"] = Tramo.astype(type_values_dict["Tramo"])
                        temp_dictionary["X"] = CoordX.astype(type_values_dict["X"])
                        temp_dictionary["Y"] = CoordY.astype(type_values_dict["Y"])
                        temp_dictionary["Z"] = CoordZ.astype(type_values_dict["Z"])
                        temp_dictionary["Pozo_hmin"] = np.array(pozo_hmin).astype(type_values_dict["Pozo_hmin"])

                        for col in columns_read:
                            # check for  None value to fill, not None values are not filled
                            if col not in [
                                "Estado",
                                "Conexion",
                                "Pozo",
                                "Tramo",
                                "X",
                                "Y",
                                "Z",
                                "Pozo_hmin",
                            ]:
                                value = df_temp[0, dict_key[col]]
                                if (
                                    value
                                ):  # and col not in ['S', 'Rug', 'L', 'LT', 'ZTI', 'ZTF', 'ZFI', 'ZFF', 'HI', 'HF', 'SALTO', 'Pozo_hmin', 'cobertura_min', 'D_min', 'S_min']:
                                    value_array = np.array([value] * len(CoordX))
                                    temp_dictionary[col] = value_array.astype(type_values_dict[col])
                                else:
                                    value_array = np.array([default_values_dict[col]] * len(CoordX))
                                    temp_dictionary[col] = value_array.astype(type_values_dict[col])

                        m_ramales[i] = temp_dictionary

            ramal = {key: key for key in m_ramales}

    return m_ramales, ramal


"#######################################################################################################################"
"SIMPLIFICAR GEOMETRIA"
"#######################################################################################################################"


def is_empty(any_structure):
    if any_structure.size > 0:
        return False
    else:
        return True


def iter_func(m_ramales, dmax, p, coords, iter):
    i = iter.split(",")
    a = list(zip(m_ramales[i[0]]["X"], m_ramales[i[0]]["Y"]))
    b = list(zip(m_ramales[i[1]]["X"], m_ramales[i[1]]["Y"]))
    c = np.where(distance.cdist(a, b, "euclidean") < dmax)
    if is_empty(c[0]) == True:
        pass
    else:
        temp1_MP = np.asarray(m_ramales[i[1]]["Pozo"][int(c[1])])
        temp2_MP = np.asarray(m_ramales[i[0]]["Pozo"][int(c[0])])
        x = round(
            (float(m_ramales[i[0]]["X"][c[0]]) + float(m_ramales[i[1]]["X"][c[1]])) / 2.0,
            2,
        )
        y = round(
            (float(m_ramales[i[0]]["Y"][c[0]]) + float(m_ramales[i[1]]["Y"][c[1]])) / 2.0,
            2,
        )
        p.append([",".join(temp1_MP[temp1_MP != None]), ",".join(temp2_MP[temp2_MP != None])])
        coords.append([x, y])
        return (p, coords)


def del_duplicate_dict(dict_data):
    import numpy as np

    temp2 = {}
    temp1 = dict(
        zip(
            [str(np.array(dict_data[i]).tolist()) for i in dict_data.keys()],
            dict_data.keys(),
        )
    )
    for j in temp1.values():
        temp2[j] = dict_data[j]

    return temp2


def clean_dict(p1, p3, coords):
    from itertools import chain

    a = [k[0] for k in [[list((i, coords[p1.index(j)])) for j in p1 if set(i).intersection(set(j)) != set([])] for i in p3]]
    b = [zip(i[0], [i[1]] * len(i[0])) for i in a]
    return dict(list(chain(*b)))


def simple_geometry(m_ramales, ramal, dmax):
    """

    :param m_ramales: matriz de datos de ramales
    :param ramal: numero de ramales
    :param dmax: distancia maxima entre pozos
    :return:
    """

    # SIMPLFICAR GEOMETRIA
    if len(ramal) == 1:
        p4, p5 = [], []
        return (m_ramales, ramal, [p4, p5])
    else:
        remove_ramal = [_ for _ in m_ramales.keys() if m_ramales[_]["Derivacion"][0] == "Derivacion"]
        ramal_modificado = [_ for _ in ramal if _ not in remove_ramal]
        iter = [",".join(map(str, comb)) for comb in combinations(ramal_modificado, 2)]
        p1 = []
        coords = []
        for i in iter:
            i = i.split(",")
            a = list(zip(m_ramales[i[0]]["X"], m_ramales[i[0]]["Y"]))
            b = list(zip(m_ramales[i[1]]["X"], m_ramales[i[1]]["Y"]))
            c = np.array(np.where(distance.cdist(a, b, "euclidean") < dmax))
            if is_empty(c) == False:
                x = round(
                    (float(m_ramales[i[0]]["X"][c[0]]) + float(m_ramales[i[1]]["X"][c[1]])) / 2.0,
                    2,
                )
                y = round(
                    (float(m_ramales[i[0]]["Y"][c[0]]) + float(m_ramales[i[1]]["Y"][c[1]])) / 2.0,
                    2,
                )
                p1.append(
                    [
                        m_ramales[i[0]]["Pozo"][int(c[0])],
                        m_ramales[i[1]]["Pozo"][int(c[1])],
                    ]
                )
                coords.append([x, y])

        iter1 = list(combinations(p1, 2))
        iter2 = {k: v for k, v in enumerate([set(i).intersection(set(j)) for i, j in iter1]) if v != set()}
        iter3 = del_duplicate_dict({k: v for k, v in zip(range(len(iter1)), [np.unique(iter1[i]) for i in range(len(iter1))]) if k in iter2.keys()})
        p2 = [list(list(iter3.values())[i]) for i in range(len(list(iter3.values())))]
        p3 = list(
            filter(
                None,
                [i for i in p1 if set(np.unique(p2)).intersection(set(i)) == set()] + p2,
            )
        )
        coords_dict = clean_dict(p1, p3, coords)
        p4, p5 = [], []
        for i in range(len(p3)):
            for j in range(len(p3[i])):
                if int(p3[i][j].split(".")[1]) + 1 == len(m_ramales[p3[i][j].split(".")[0]]["Conexion"]):
                    temp_remove = p3[i][:]
                    temp_remove.remove(m_ramales[p3[i][j].split(".")[0]]["Pozo"][int(p3[i][j].split(".")[1])])
                    temp2 = [k for k in temp_remove if len(m_ramales[k.split(".")[0]]["Conexion"]) != int(k.split(".")[1]) + 1]
                    m_ramales[p3[i][j].split(".")[0]]["Conexion"].__setitem__(int(p3[i][j].split(".")[1]), "".join(temp2))
                    m_ramales[p3[i][j].split(".")[0]]["X"].__setitem__(int(p3[i][j].split(".")[1]), coords_dict[p3[i][j]][0])
                    m_ramales[p3[i][j].split(".")[0]]["Y"].__setitem__(int(p3[i][j].split(".")[1]), coords_dict[p3[i][j]][1])
                else:
                    temp_remove = p3[i][:]
                    temp_remove.remove(m_ramales[p3[i][j].split(".")[0]]["Pozo"][int(p3[i][j].split(".")[1])])
                    m_ramales[p3[i][j].split(".")[0]]["Conexion"].__setitem__(int(p3[i][j].split(".")[1]), ",".join(temp_remove))
                    m_ramales[p3[i][j].split(".")[0]]["X"].__setitem__(int(p3[i][j].split(".")[1]), coords_dict[p3[i][j]][0])
                    m_ramales[p3[i][j].split(".")[0]]["Y"].__setitem__(int(p3[i][j].split(".")[1]), coords_dict[p3[i][j]][1])
                    (p4.append(p3[i][j]), p5.append(temp_remove))

        for _ in m_ramales.keys():
            if m_ramales[_]["Conexion"][-1] == "":
                m_ramales[_]["Conexion"][-1] = None

        # IDENTIFICAR POZOS DE DERIVACION
        if len(ramal_modificado) > 0:
            x_array, y_array, pz_array = [], [], []
            [
                (
                    x_array.append(m_ramales[_]["X"]),
                    y_array.append(m_ramales[_]["Y"]),
                    pz_array.append(m_ramales[_]["Pozo"]),
                )
                for _ in m_ramales.keys()
                if _ not in remove_ramal
            ]
            x_array = np.concatenate(x_array)
            y_array = np.concatenate(y_array)
            pz_array = np.concatenate(pz_array)
            coords_array = list(zip(x_array, y_array))

            for _ in remove_ramal:
                x_derivador = m_ramales[_]["X"][0]
                y_derivador = m_ramales[_]["Y"][0]
                coords_derivador = np.array([[x_derivador, y_derivador]])
                d = distance.cdist(coords_derivador, coords_array)
                index = np.argmin(d)
                _ramal, _pz = pz_array[index].split(".")

                m_ramales[_ramal]["Derivacion"][int(_pz)] = "Derivacion"
                m_ramales[_ramal]["Obs"][int(_pz)] = "Derivacion Pluvial a Ramal " + str(_)

        return (m_ramales, ramal, [p4, p5])


def simple_geometryV2(m_ramales, ramal, dmax):
    x_end, y_end, pz_end = np.array([(m_ramales[_]["X"][-1], m_ramales[_]["Y"][-1], m_ramales[_]["Pozo"][-1]) for _ in ramal]).T
    x_end = x_end.astype(float)
    y_end = y_end.astype(float)

    xyPz = [(m_ramales[_]["X"], m_ramales[_]["Y"], m_ramales[_]["Pozo"]) for _ in ramal]
    x_arr, y_arr, pz_arr = np.concatenate(xyPz, axis=1)
    x_arr = x_arr.astype(float)
    y_arr = y_arr.astype(float)

    xyCoords = np.array([x_arr, y_arr]).T
    xyEndCoords = np.array([x_end, y_end]).T
    c = distance.cdist(xyEndCoords, xyCoords, "euclidean")
    df = pd.DataFrame(c, columns=pz_arr, index=pz_end)
    cond = df.where(cond=(df < dmax))  # TRATA DE HACER CON NUMPY
    # rows, cols = np.where(c <= dmax)
    conexionDesde = []
    conexionHacia = []
    for pz in df.index:
        a = cond.loc[pz].dropna().index
        b = list(a[a != pz])

        if b == []:
            _pz, _pos = pz.split(".")
            m_ramales[_pz]["Conexion"][int(_pos)] = None
        else:
            if len(b) == 1:
                conexionDesde.append([pz])
                conexionHacia.append(b[0])

                # INDICES
                _pzDesde, _posDesde = b[0].split(".")
                _pzHacia, _posHacia = pz.split(".")

                # COORDENADAS PROMEDIO
                _x, _y = (
                    (m_ramales[_pzDesde]["X"][int(_posDesde)] + m_ramales[_pzHacia]["X"][int(_posHacia)]) / 2.0,
                    (m_ramales[_pzDesde]["Y"][int(_posDesde)] + m_ramales[_pzHacia]["Y"][int(_posHacia)]) / 2.0,
                )

                # DESDE
                content = m_ramales[_pzDesde]["Conexion"][int(_posDesde)]
                if content != None:
                    content = content.split(",")
                    new_content = np.unique([pz] + content)
                else:
                    new_content = [pz]
                m_ramales[_pzDesde]["Conexion"][int(_posDesde)] = ",".join(new_content)
                m_ramales[_pzDesde]["X"][int(_posDesde)] = _x
                m_ramales[_pzDesde]["Y"][int(_posDesde)] = _y

                # HACIA
                content = m_ramales[_pzHacia]["Conexion"][int(_posHacia)]
                if content != None:
                    content = content.split(",")
                    new_content = np.unique(b + content)
                else:
                    new_content = b
                m_ramales[_pzHacia]["Conexion"][int(_posHacia)] = ",".join(new_content)
                m_ramales[_pzHacia]["X"][int(_posHacia)] = _x
                m_ramales[_pzHacia]["Y"][int(_posHacia)] = _y

            else:
                len_obj = np.array([len(m_ramales[_.split(".")[0]]["Pozo"]) for _ in b])
                pos_obj = np.array([int(_.split(".")[1]) for _ in b]) + 1
                indexDesde = list(np.where(len_obj == pos_obj)[0])
                indexHacia = list(set(range(len(pos_obj))).difference(set(indexDesde)))

                # COORDENADAS
                x_temp, y_temp = [], []

                # HACIA
                arrDesde = [pz] + list(np.array(b)[indexDesde])
                _pzHacia, _posHacia = np.array(b)[indexHacia[0]].split(".")

                content = m_ramales[_pzHacia]["Conexion"][int(_posHacia)]
                if content != None:
                    content = content.split(",")
                    new_content = np.unique(arrDesde + content)
                else:
                    new_content = arrDesde
                m_ramales[_pzHacia]["Conexion"][int(_posHacia)] = ",".join(new_content)
                x_temp.append(m_ramales[_pzHacia]["X"][int(_posHacia)])
                y_temp.append(m_ramales[_pzHacia]["Y"][int(_posHacia)])
                conexionDesde.append(list(new_content))

                # DESDE
                for _ in arrDesde:
                    _pz, _pos = _.split(".")
                    content = m_ramales[_pz]["Conexion"][int(_pos)]
                    if content != None:
                        content = content.split(",")
                        new_content = np.unique(list(np.array(b)[indexHacia]) + content)
                    else:
                        new_content = list(np.array(b)[indexHacia])
                    m_ramales[_pz]["Conexion"][int(_pos)] = ",".join(new_content)
                    x_temp.append(m_ramales[_pz]["X"][int(_pos)])
                    y_temp.append(m_ramales[_pz]["Y"][int(_pos)])
                conexionHacia.append(new_content[0])

                # MODIFICAR COORDENADAS
                arr = list(arrDesde) + list(np.array(b)[indexHacia])
                x_m, y_m = np.mean(x_temp), np.mean(y_temp)
                for _ in arr:
                    _pz, _pos = _.split(".")
                    m_ramales[_pz]["X"][int(_pos)] = x_m
                    m_ramales[_pz]["Y"][int(_pos)] = y_m

    # IDENTIFICAR POZOS DE DERIVACION
    remove_ramal = [_ for _ in m_ramales.keys() if m_ramales[_]["Derivacion"][0] == "Derivacion"]
    ramal_modificado = [_ for _ in ramal if _ not in remove_ramal]
    if len(ramal_modificado) > 0:
        x_array, y_array, pz_array = [], [], []
        [
            (
                x_array.append(m_ramales[_]["X"]),
                y_array.append(m_ramales[_]["Y"]),
                pz_array.append(m_ramales[_]["Pozo"]),
            )
            for _ in m_ramales.keys()
            if _ not in remove_ramal
        ]
        x_array = np.concatenate(x_array)
        y_array = np.concatenate(y_array)
        pz_array = np.concatenate(pz_array)
        coords_array = list(zip(x_array, y_array))

        for _ in remove_ramal:
            x_derivador = m_ramales[_]["X"][0]
            y_derivador = m_ramales[_]["Y"][0]
            coords_derivador = np.array([[x_derivador, y_derivador]])
            d = distance.cdist(coords_derivador, coords_array)
            index = np.argmin(d)
            _ramal, _pz = pz_array[index].split(".")
            m_ramales[_ramal]["Derivacion"][int(_pz)] = "Derivacion"
            m_ramales[_ramal]["Obs"][int(_pz)] = "Derivacion Pluvial a Ramal " + str(_)

    # REMOVER LOS REPETIDOS
    uniques, uniq_idx, counts = np.unique(conexionHacia, return_index=True, return_counts=True)
    index = sorted(uniq_idx)

    return (
        m_ramales,
        ramal,
        [np.array(conexionHacia)[index], np.array(conexionDesde)[index]],
    )


def simple_geometryV3_old(m_ramales, ramal, dmax):
    # coordenadas y nombre de pozo final de todos los ramales
    x_end, y_end, pz_end = np.array([(m_ramales[_]["X"][-1], m_ramales[_]["Y"][-1], m_ramales[_]["Pozo"][-1]) for _ in ramal]).T
    x_end = x_end.astype(float)
    y_end = y_end.astype(float)
    # coordenadas y nombres de pozos generales
    xyPz = [(m_ramales[_]["X"], m_ramales[_]["Y"], m_ramales[_]["Pozo"]) for _ in ramal]
    x_arr, y_arr, pz_arr = np.concatenate(xyPz, axis=1)
    x_arr = x_arr.astype(float)
    y_arr = y_arr.astype(float)

    # interseccion de pozos finales y pozos generales
    xyCoords = np.array([x_arr, y_arr]).T
    xyEndCoords = np.array([x_end, y_end]).T
    c = distance.cdist(xyEndCoords, xyCoords, "euclidean")
    rows, cols = np.where(c <= dmax)
    conexionDesde = []
    conexionHacia = []
    for pz_index in range(len(pz_end)):
        pz_pos = np.where(rows == pz_index)
        join_index = cols[pz_pos]
        a = pz_arr[join_index]
        pz = pz_end[pz_index]
        b = list(a[a != pz])

        if len(b) == 0:
            _pz, _pos = pz.split(".")
            m_ramales[_pz]["Conexion"][int(_pos)] = None
        else:
            if len(b) == 1:
                conexionDesde.append([pz])
                conexionHacia.append(b[0])

                # INDICES
                _pzDesde, _posDesde = b[0].split(".")
                _pzHacia, _posHacia = pz.split(".")

                # COORDENADAS PROMEDIO
                _x, _y = (
                    (m_ramales[_pzDesde]["X"][int(_posDesde)] + m_ramales[_pzHacia]["X"][int(_posHacia)]) / 2.0,
                    (m_ramales[_pzDesde]["Y"][int(_posDesde)] + m_ramales[_pzHacia]["Y"][int(_posHacia)]) / 2.0,
                )

                # DESDE
                content = m_ramales[_pzDesde]["Conexion"][int(_posDesde)]
                if content != None:
                    content = content.split(",")
                    new_content = np.unique([pz] + content)
                else:
                    new_content = [pz]
                m_ramales[_pzDesde]["Conexion"][int(_posDesde)] = ",".join(new_content)
                m_ramales[_pzDesde]["X"][int(_posDesde)] = _x
                m_ramales[_pzDesde]["Y"][int(_posDesde)] = _y

                # HACIA
                content = m_ramales[_pzHacia]["Conexion"][int(_posHacia)]
                if content != None:
                    content = content.split(",")
                    new_content = np.unique(b + content)
                else:
                    new_content = b
                m_ramales[_pzHacia]["Conexion"][int(_posHacia)] = ",".join(new_content)
                m_ramales[_pzHacia]["X"][int(_posHacia)] = _x
                m_ramales[_pzHacia]["Y"][int(_posHacia)] = _y

            else:
                len_obj = np.array([len(m_ramales[_.split(".")[0]]["Pozo"]) for _ in b])
                pos_obj = np.array([int(_.split(".")[1]) for _ in b]) + 1
                indexDesde = list(np.where(len_obj == pos_obj)[0])
                indexHacia = list(set(range(len(pos_obj))).difference(set(indexDesde)))

                # COORDENADAS
                x_temp, y_temp = [], []

                # HACIA
                arrDesde = [pz] + list(np.array(b)[indexDesde])
                _pzHacia, _posHacia = np.array(b)[indexHacia[0]].split(".")
                content = m_ramales[_pzHacia]["Conexion"][int(_posHacia)]

                if content != None:
                    content = content.split(",")
                    new_content = np.unique(arrDesde + content)
                else:
                    new_content = arrDesde

                m_ramales[_pzHacia]["Conexion"][int(_posHacia)] = ",".join(new_content)

                x_temp.append(m_ramales[_pzHacia]["X"][int(_posHacia)])
                y_temp.append(m_ramales[_pzHacia]["Y"][int(_posHacia)])
                conexionDesde.append(list(new_content))

                # DESDE
                for _ in arrDesde:
                    _pz, _pos = _.split(".")
                    content = m_ramales[_pz]["Conexion"][int(_pos)]
                    if content != None:
                        content = content.split(",")
                        new_content = np.unique(list(np.array(b)[indexHacia]) + content)
                    else:
                        new_content = list(np.array(b)[indexHacia])
                    m_ramales[_pz]["Conexion"][int(_pos)] = ",".join(new_content)
                    x_temp.append(m_ramales[_pz]["X"][int(_pos)])
                    y_temp.append(m_ramales[_pz]["Y"][int(_pos)])
                conexionHacia.append(new_content[0])

                # MODIFICAR COORDENADAS
                arr = list(arrDesde) + list(np.array(b)[indexHacia])
                x_m, y_m = np.mean(x_temp), np.mean(y_temp)
                for _ in arr:
                    _pz, _pos = _.split(".")
                    m_ramales[_pz]["X"][int(_pos)] = x_m
                    m_ramales[_pz]["Y"][int(_pos)] = y_m

    # IDENTIFICAR POZOS DE DERIVACION
    remove_ramal = [_ for _ in m_ramales.keys() if m_ramales[_]["Derivacion"][0] == "Derivacion"]
    ramal_modificado = [_ for _ in ramal if _ not in remove_ramal]
    if len(ramal_modificado) > 0:
        x_array, y_array, pz_array = [], [], []
        [
            (
                x_array.append(m_ramales[_]["X"]),
                y_array.append(m_ramales[_]["Y"]),
                pz_array.append(m_ramales[_]["Pozo"]),
            )
            for _ in m_ramales.keys()
            if _ not in remove_ramal
        ]
        x_array = np.concatenate(x_array)
        y_array = np.concatenate(y_array)
        pz_array = np.concatenate(pz_array)
        coords_array = list(zip(x_array, y_array))

        for _ in remove_ramal:
            x_derivador = m_ramales[_]["X"][0]
            y_derivador = m_ramales[_]["Y"][0]
            coords_derivador = np.array([[x_derivador, y_derivador]])
            d = distance.cdist(coords_derivador, coords_array)
            index = np.argmin(d)
            _ramal, _pz = pz_array[index].split(".")

            m_ramales[_]["X"][0] = m_ramales[_ramal]["X"][int(_pz)]
            m_ramales[_]["Y"][0] = m_ramales[_ramal]["Y"][int(_pz)]
            m_ramales[_ramal]["Derivacion"][int(_pz)] = "Derivacion"
            m_ramales[_ramal]["Obs"][int(_pz)] = "Derivacion Pluvial a Ramal " + str(_)

    # REMOVER LOS REPETIDOS
    uniques, uniq_idx, counts = np.unique(conexionHacia, return_index=True, return_counts=True)
    index = sorted(uniq_idx)

    # REMOVER POZOS QUE LLEGAN A POZOS EXISTENTES SIMULTANEAMENTE
    index_repeat = np.where(np.sum(distance.cdist(xyEndCoords, xyEndCoords, "euclidean") <= dmax, axis=1) > 1)
    for _ in pz_end[index_repeat]:
        _ramal, _pz = _.split(".")

        intersection_array = np.array(m_ramales[_ramal]["Conexion"][int(_pz)].split(","))
        ramales_check, pzs_check = pp_char_split(intersection_array, _split=".")

        for ramal_check, pz_check in zip(ramales_check, pzs_check):
            # ramal_check, pz_check = m_ramales[_ramal]['Conexion'][int(_pz)].split('.')
            ramal_len = len(m_ramales[ramal_check]["Conexion"]) - 1
            if ramal_len == int(pz_check):
                # remove from conexionHacia
                index_remove1 = np.char.equal(conexionHacia, _).nonzero()[0]
                [index.remove(_rev) for _rev in index_remove1]

                content = m_ramales[_ramal]["Conexion"][-1].split(", ")
                remove_from = ".".join([ramal_check, pz_check])
                content.remove(remove_from)
                if len(content) == 0:
                    m_ramales[_ramal]["Conexion"][int(_pz)] = None

    conexion = np.concatenate([m_ramales[_]["Conexion"] for _ in ramal.keys()])
    conexion_no_none = conexion[np.where(conexion)]
    # REMOVE 0 PZ FROM DERIVACION
    for _ in remove_ramal:
        index_remove = np.where(np.char.find(conexion_no_none.astype(str), _ + ".0") != -1)
        index_found = np.where(conexion == conexion_no_none[index_remove])
        pz_list = pz_array[index_found]
        for __ in pz_list:
            _ramal, _pz = __.split(".")
            content = m_ramales[_ramal]["Conexion"][int(_pz)].split(",")
            content.remove(_ + ".0")
            m_ramales[_ramal]["Conexion"][int(_pz)] = ",".join(content)

    return (
        m_ramales,
        ramal,
        [np.array(conexionHacia)[index], np.array(conexionDesde)[index]],
    )


# Esta es ala que hasta hoy estamos usando, el V4 va a ser un experimento. y esta es la de pyqt5
def simple_geometryV3(m_ramales, ramal, dmax):
    # coordenadas y nombre de pozo final de todos los ramales
    x_end, y_end, pz_end = np.array([(m_ramales[_]["X"][-1], m_ramales[_]["Y"][-1], m_ramales[_]["Pozo"][-1]) for _ in ramal]).T
    x_end = x_end.astype(float)
    y_end = y_end.astype(float)
    # coordenadas y nombres de pozos generales
    xyPz = [(m_ramales[_]["X"], m_ramales[_]["Y"], m_ramales[_]["Pozo"]) for _ in ramal]
    x_arr, y_arr, pz_arr = np.concatenate(xyPz, axis=1)
    x_arr = x_arr.astype(float)
    y_arr = y_arr.astype(float)

    # interseccion de pozos finales y pozos generales
    xyCoords = np.array([x_arr, y_arr]).T
    xyEndCoords = np.array([x_end, y_end]).T
    c = distance.cdist(xyEndCoords, xyCoords, "euclidean")
    rows, cols = np.where(c <= dmax)
    conexionDesde = []
    conexionHacia = []
    for pz_index in range(len(pz_end)):
        pz_pos = np.where(rows == pz_index)
        join_index = cols[pz_pos]
        a = pz_arr[join_index]  # pozos que llegan
        pz = pz_end[pz_index]
        b = list(a[a != pz])  # pozos que recibe

        if len(b) == 0:
            _pz, _pos = pz.split(".")
            m_ramales[_pz]["Conexion"][int(_pos)] = None
        else:
            if len(b) == 1:
                conexionDesde.append([pz])
                conexionHacia.append(b[0])

                # INDICES
                _pzDesde, _posDesde = b[0].split(".")
                _pzHacia, _posHacia = pz.split(".")

                # COORDENADAS PROMEDIO
                _x, _y = (
                    (m_ramales[_pzDesde]["X"][int(_posDesde)] + m_ramales[_pzHacia]["X"][int(_posHacia)]) / 2.0,
                    (m_ramales[_pzDesde]["Y"][int(_posDesde)] + m_ramales[_pzHacia]["Y"][int(_posHacia)]) / 2.0,
                )

                # DESDE
                content = m_ramales[_pzDesde]["Conexion"][int(_posDesde)]
                if content != None:
                    content = content.split(",")
                    new_content = np.unique([pz] + content)
                else:
                    new_content = [pz]
                m_ramales[_pzDesde]["Conexion"][int(_posDesde)] = ",".join(new_content)
                m_ramales[_pzDesde]["X"][int(_posDesde)] = _x
                m_ramales[_pzDesde]["Y"][int(_posDesde)] = _y

                # HACIA
                content = m_ramales[_pzHacia]["Conexion"][int(_posHacia)]
                if content != None:
                    content = content.split(",")
                    new_content = np.unique(b + content)
                else:
                    new_content = b
                m_ramales[_pzHacia]["Conexion"][int(_posHacia)] = ",".join(new_content)
                m_ramales[_pzHacia]["X"][int(_posHacia)] = _x
                m_ramales[_pzHacia]["Y"][int(_posHacia)] = _y

            else:
                len_obj = np.array([len(m_ramales[_.split(".")[0]]["Pozo"]) for _ in b])
                pos_obj = np.array([int(_.split(".")[1]) for _ in b]) + 1
                indexDesde = list(np.where(len_obj == pos_obj)[0])
                indexHacia = list(set(range(len(pos_obj))).difference(set(indexDesde)))

                # estos es como tener el aso de len(b) == 0
                if len(indexHacia) == 0:
                    _pzHacia, _posHacia = pz.split(".")
                    m_ramales[_pzHacia]["Conexion"][int(_posHacia)] = None
                    continue

                # COORDENADAS
                x_temp, y_temp = [], []

                # HACIA
                arrDesde = [pz] + list(np.array(b)[indexDesde])

                _pzHacia, _posHacia = np.array(b)[indexHacia[0]].split(".")
                content = m_ramales[_pzHacia]["Conexion"][int(_posHacia)]

                if content != None:
                    content = content.split(",")
                    new_content = np.unique(arrDesde + content)
                else:
                    new_content = arrDesde

                m_ramales[_pzHacia]["Conexion"][int(_posHacia)] = ",".join(new_content)

                x_temp.append(m_ramales[_pzHacia]["X"][int(_posHacia)])
                y_temp.append(m_ramales[_pzHacia]["Y"][int(_posHacia)])
                conexionDesde.append(list(new_content))

                # DESDE
                for _ in arrDesde:
                    _pz, _pos = _.split(".")
                    content = m_ramales[_pz]["Conexion"][int(_pos)]
                    if content != None:
                        content = content.split(",")
                        new_content = np.unique(list(np.array(b)[indexHacia]) + content)
                    else:
                        new_content = list(np.array(b)[indexHacia])
                    m_ramales[_pz]["Conexion"][int(_pos)] = ",".join(new_content)
                    x_temp.append(m_ramales[_pz]["X"][int(_pos)])
                    y_temp.append(m_ramales[_pz]["Y"][int(_pos)])
                conexionHacia.append(new_content[0])

                # MODIFICAR COORDENADAS
                arr = list(arrDesde) + list(np.array(b)[indexHacia])
                x_m, y_m = np.mean(x_temp), np.mean(y_temp)
                for _ in arr:
                    _pz, _pos = _.split(".")
                    m_ramales[_pz]["X"][int(_pos)] = x_m
                    m_ramales[_pz]["Y"][int(_pos)] = y_m

    # IDENTIFICAR POZOS DE DERIVACION
    remove_ramal = [_ for _ in m_ramales.keys() if m_ramales[_]["Derivacion"][0] == "Derivacion"]
    ramal_modificado = [_ for _ in ramal if _ not in remove_ramal]
    if len(ramal_modificado) > 0:
        x_array, y_array, pz_array = [], [], []
        [
            (
                x_array.append(m_ramales[_]["X"]),
                y_array.append(m_ramales[_]["Y"]),
                pz_array.append(m_ramales[_]["Pozo"]),
            )
            for _ in m_ramales.keys()
            if _ not in remove_ramal
        ]
        x_array = np.concatenate(x_array)
        y_array = np.concatenate(y_array)
        pz_array = np.concatenate(pz_array)
        coords_array = list(zip(x_array, y_array))

        for _ in remove_ramal:
            x_derivador = m_ramales[_]["X"][0]
            y_derivador = m_ramales[_]["Y"][0]
            coords_derivador = np.array([[x_derivador, y_derivador]])
            d = distance.cdist(coords_derivador, coords_array)
            index = np.argmin(d)
            _ramal, _pz = pz_array[index].split(".")

            m_ramales[_]["X"][0] = m_ramales[_ramal]["X"][int(_pz)]
            m_ramales[_]["Y"][0] = m_ramales[_ramal]["Y"][int(_pz)]
            m_ramales[_ramal]["Derivacion"][int(_pz)] = "Derivacion"
            m_ramales[_ramal]["Obs"][int(_pz)] = "Derivacion Pluvial a Ramal " + str(_)

    # REMOVER LOS REPETIDOS
    uniques, uniq_idx, counts = np.unique(conexionHacia, return_index=True, return_counts=True)
    index = sorted(uniq_idx)

    # REMOVER POZOS QUE LLEGAN A POZOS EXISTENTES SIMULTANEAMENTE
    index_repeat = np.where(np.sum(distance.cdist(xyEndCoords, xyEndCoords, "euclidean") <= dmax, axis=1) > 1)
    for _ in pz_end[index_repeat]:
        _ramal, _pz = _.split(".")

        if not m_ramales[_ramal]["Conexion"][int(_pz)]:
            continue

        intersection_array = np.array(m_ramales[_ramal]["Conexion"][int(_pz)].split(","))
        ramales_check, pzs_check = pp_char_split(intersection_array, _split=".")

        for ramal_check, pz_check in zip(ramales_check, pzs_check):
            # ramal_check, pz_check = m_ramales[_ramal]['Conexion'][int(_pz)].split('.')
            ramal_len = len(m_ramales[ramal_check]["Conexion"]) - 1
            if ramal_len == int(pz_check):
                # remove from conexionHacia
                index_remove1 = np.char.equal(conexionHacia, _).nonzero()[0]
                [index.remove(_rev) for _rev in index_remove1]

                content = m_ramales[_ramal]["Conexion"][-1].split(", ")
                remove_from = ".".join([ramal_check, pz_check])
                content.remove(remove_from)
                if len(content) == 0:
                    m_ramales[_ramal]["Conexion"][int(_pz)] = None

    conexion = np.concatenate([m_ramales[_]["Conexion"] for _ in ramal.keys()])
    conexion_no_none = conexion[np.where(conexion)]
    # REMOVE 0 PZ FROM DERIVACION
    for _ in remove_ramal:
        index_remove = np.where(np.char.find(conexion_no_none.astype(str), _ + ".0") != -1)
        index_found = np.where(conexion == conexion_no_none[index_remove])
        pz_list = pz_array[index_found]
        for __ in pz_list:
            _ramal, _pz = __.split(".")
            content = m_ramales[_ramal]["Conexion"][int(_pz)].split(",")
            content.remove(_ + ".0")
            m_ramales[_ramal]["Conexion"][int(_pz)] = ",".join(content)

    if len(conexionHacia) > 0 or len(conexionDesde) > 0:
        # return m_ramales, ramal, [np.array(conexionHacia)[index], [np.array(conexionHacia)[index],operator.itemgetter(*index)(conexionDesde)]]
        return (
            m_ramales,
            ramal,
            [np.array(conexionHacia)[index], [conexionDesde[_] for _ in index]],
        )
    else:
        return m_ramales, ramal, [np.array([]), []]


def simple_geometryV4(m_ramales, ramal, dmax):
    # coordenadas y nombre de pozo final de todos los ramales
    x_end, y_end, pz_end = np.array([(m_ramales[_]["X"][-1], m_ramales[_]["Y"][-1], m_ramales[_]["Pozo"][-1]) for _ in ramal]).T
    x_end = x_end.astype(float)
    y_end = y_end.astype(float)
    # coordenadas y nombres de pozos generales
    xyPz = [(m_ramales[_]["X"], m_ramales[_]["Y"], m_ramales[_]["Pozo"]) for _ in ramal]
    x_arr, y_arr, pz_arr = np.concatenate(xyPz, axis=1)
    x_arr = x_arr.astype(float)
    y_arr = y_arr.astype(float)

    # interseccion de pozos finales y pozos generales
    xyCoords = np.array([x_arr, y_arr]).T
    xyEndCoords = np.array([x_end, y_end]).T
    c = distance.cdist(xyEndCoords, xyCoords, "euclidean")
    rows, cols = np.where(c <= dmax)
    conexionDesde = []
    conexionHacia = []
    for pz_index in range(len(pz_end)):
        pz_pos = np.where(rows == pz_index)
        join_index = cols[pz_pos]
        a = pz_arr[join_index]
        pz = pz_end[pz_index]
        b = list(a[a != pz])

        if len(b) == 0:
            _pz, _pos = pz.split(".")
            m_ramales[_pz]["Conexion"][int(_pos)] = None
        else:
            if len(b) == 1:
                conexionDesde.append([pz])
                conexionHacia.append(b[0])

                # INDICES
                _pzDesde, _posDesde = b[0].split(".")
                _pzHacia, _posHacia = pz.split(".")

                # COORDENADAS PROMEDIO
                _x, _y = (
                    (m_ramales[_pzDesde]["X"][int(_posDesde)] + m_ramales[_pzHacia]["X"][int(_posHacia)]) / 2.0,
                    (m_ramales[_pzDesde]["Y"][int(_posDesde)] + m_ramales[_pzHacia]["Y"][int(_posHacia)]) / 2.0,
                )

                # DESDE
                content = m_ramales[_pzDesde]["Conexion"][int(_posDesde)]
                if content != None:
                    content = content.split(",")
                    new_content = np.unique([pz] + content)
                else:
                    new_content = [pz]
                m_ramales[_pzDesde]["Conexion"][int(_posDesde)] = ",".join(new_content)
                m_ramales[_pzDesde]["X"][int(_posDesde)] = _x
                m_ramales[_pzDesde]["Y"][int(_posDesde)] = _y

                # HACIA
                content = m_ramales[_pzHacia]["Conexion"][int(_posHacia)]
                if content != None:
                    content = content.split(",")
                    new_content = np.unique(b + content)
                else:
                    new_content = b
                m_ramales[_pzHacia]["Conexion"][int(_posHacia)] = ",".join(new_content)
                m_ramales[_pzHacia]["X"][int(_posHacia)] = _x
                m_ramales[_pzHacia]["Y"][int(_posHacia)] = _y

            else:
                len_obj = np.array([len(m_ramales[_.split(".")[0]]["Pozo"]) for _ in b])
                pos_obj = np.array([int(_.split(".")[1]) for _ in b]) + 1
                indexDesde = list(np.where(len_obj == pos_obj)[0])
                indexHacia = list(set(range(len(pos_obj))).difference(set(indexDesde)))

                # COORDENADAS
                x_temp, y_temp = [], []

                # HACIA
                arrDesde = [pz] + list(np.array(b)[indexDesde])
                _pzHacia, _posHacia = np.array(b)[indexHacia[0]].split(".")
                content = m_ramales[_pzHacia]["Conexion"][int(_posHacia)]

                if content != None:
                    content = content.split(",")
                    new_content = np.unique(arrDesde + content)
                else:
                    new_content = arrDesde

                m_ramales[_pzHacia]["Conexion"][int(_posHacia)] = ",".join(new_content)

                x_temp.append(m_ramales[_pzHacia]["X"][int(_posHacia)])
                y_temp.append(m_ramales[_pzHacia]["Y"][int(_posHacia)])
                conexionDesde.append(list(new_content))

                # DESDE
                for _ in arrDesde:
                    _pz, _pos = _.split(".")
                    content = m_ramales[_pz]["Conexion"][int(_pos)]
                    if content != None:
                        content = content.split(",")
                        new_content = np.unique(list(np.array(b)[indexHacia]) + content)
                    else:
                        new_content = list(np.array(b)[indexHacia])
                    m_ramales[_pz]["Conexion"][int(_pos)] = ",".join(new_content)
                    x_temp.append(m_ramales[_pz]["X"][int(_pos)])
                    y_temp.append(m_ramales[_pz]["Y"][int(_pos)])
                conexionHacia.append(new_content[0])

                # MODIFICAR COORDENADAS
                arr = list(arrDesde) + list(np.array(b)[indexHacia])
                x_m, y_m = np.mean(x_temp), np.mean(y_temp)
                for _ in arr:
                    _pz, _pos = _.split(".")
                    m_ramales[_pz]["X"][int(_pos)] = x_m
                    m_ramales[_pz]["Y"][int(_pos)] = y_m

    # IDENTIFICAR POZOS DE DERIVACION
    remove_ramal = [_ for _ in m_ramales.keys() if m_ramales[_]["Derivacion"][0] == "Derivacion"]
    ramal_modificado = [_ for _ in ramal if _ not in remove_ramal]
    if len(ramal_modificado) > 0:
        x_array, y_array, pz_array = [], [], []
        [
            (
                x_array.append(m_ramales[_]["X"]),
                y_array.append(m_ramales[_]["Y"]),
                pz_array.append(m_ramales[_]["Pozo"]),
            )
            for _ in m_ramales.keys()
            if _ not in remove_ramal
        ]
        x_array = np.concatenate(x_array)
        y_array = np.concatenate(y_array)
        pz_array = np.concatenate(pz_array)
        coords_array = list(zip(x_array, y_array))

        for _ in remove_ramal:
            x_derivador = m_ramales[_]["X"][0]
            y_derivador = m_ramales[_]["Y"][0]
            coords_derivador = np.array([[x_derivador, y_derivador]])
            d = distance.cdist(coords_derivador, coords_array)
            index = np.argmin(d)
            _ramal, _pz = pz_array[index].split(".")

            m_ramales[_]["X"][0] = m_ramales[_ramal]["X"][int(_pz)]
            m_ramales[_]["Y"][0] = m_ramales[_ramal]["Y"][int(_pz)]
            m_ramales[_ramal]["Derivacion"][int(_pz)] = "Derivacion"
            m_ramales[_ramal]["Obs"][int(_pz)] = "Derivacion Pluvial a Ramal " + str(_)

    # REMOVER LOS REPETIDOS
    uniques, uniq_idx, counts = np.unique(conexionHacia, return_index=True, return_counts=True)
    index = sorted(uniq_idx)

    # REMOVER POZOS QUE LLEGAN A POZOS EXISTENTES SIMULTANEAMENTE
    index_repeat = np.where(np.sum(distance.cdist(xyEndCoords, xyEndCoords, "euclidean") <= dmax, axis=1) > 1)
    for _ in pz_end[index_repeat]:
        _ramal, _pz = _.split(".")

        intersection_array = np.array(m_ramales[_ramal]["Conexion"][int(_pz)].split(","))
        ramales_check, pzs_check = pp_char_split(intersection_array, _split=".")

        for ramal_check, pz_check in zip(ramales_check, pzs_check):
            # ramal_check, pz_check = m_ramales[_ramal]['Conexion'][int(_pz)].split('.')
            ramal_len = len(m_ramales[ramal_check]["Conexion"]) - 1
            if ramal_len == int(pz_check):
                # remove from conexionHacia
                index_remove1 = np.char.equal(conexionHacia, _).nonzero()[0]
                [index.remove(_rev) for _rev in index_remove1]

                content = m_ramales[_ramal]["Conexion"][-1].split(", ")
                remove_from = ".".join([ramal_check, pz_check])
                content.remove(remove_from)
                if len(content) == 0:
                    m_ramales[_ramal]["Conexion"][int(_pz)] = None

    conexion = np.concatenate([m_ramales[_]["Conexion"] for _ in ramal.keys()])
    conexion_no_none = conexion[np.where(conexion)]
    # REMOVE 0 PZ FROM DERIVACION
    for _ in remove_ramal:
        index_remove = np.where(np.char.find(conexion_no_none.astype(str), _ + ".0") != -1)
        index_found = np.where(conexion == conexion_no_none[index_remove])
        pz_list = pz_array[index_found]
        for __ in pz_list:
            _ramal, _pz = __.split(".")
            content = m_ramales[_ramal]["Conexion"][int(_pz)].split(",")
            content.remove(_ + ".0")
            m_ramales[_ramal]["Conexion"][int(_pz)] = ",".join(content)

    return (
        m_ramales,
        ramal,
        [np.array(conexionHacia)[index], np.array(conexionDesde)[index]],
    )


def simple_geometry_MP(m_ramales, ramal, n_cpu, dmax):
    if len(ramal) == 1:
        p4, p5 = [], []
        return m_ramales, ramal, [p4, p5]
    else:
        iter = [",".join(map(str, comb)) for comb in combinations(ramal, 2)]
        manager = Manager()
        p = manager.list()
        coords = manager.list()
        func1 = partial(iter_func, m_ramales, dmax, p, coords)
        pool = Pool(processes=n_cpu)
        pool.map(func1, iter)
        p1 = [item for item in p if item]
        iter1 = list(combinations(p1, 2))
        iter2 = {k: v for k, v in enumerate([set(i).intersection(set(j)) for i, j in iter1]) if v != set()}
        iter3 = del_duplicate_dict({k: v for k, v in zip(range(len(iter1)), [np.unique(iter1[i]) for i in range(len(iter1))]) if k in iter2.keys()})
        p2 = [list(list(iter3.values())[i]) for i in range(len(list(iter3.values())))]
        p3 = list(
            filter(
                None,
                [i for i in p1 if set(np.unique(p2)).intersection(set(i)) == set()] + p2,
            )
        )
        coords_dict = clean_dict(p1, p3, coords)
        p4, p5 = [], []
        for i in range(len(p3)):
            for j in range(len(p3[i])):
                if int(p3[i][j].split(".")[1]) + 1 == len(m_ramales[p3[i][j].split(".")[0]]["Conexion"]):
                    temp_remove = p3[i][:]
                    temp_remove.remove(m_ramales[p3[i][j].split(".")[0]]["Pozo"][int(p3[i][j].split(".")[1])])
                    temp2 = [k for k in temp_remove if len(m_ramales[k.split(".")[0]]["Conexion"]) != int(k.split(".")[1]) + 1]
                    m_ramales[p3[i][j].split(".")[0]]["Conexion"].__setitem__(int(p3[i][j].split(".")[1]), "".join(temp2))
                    m_ramales[p3[i][j].split(".")[0]]["X"].__setitem__(int(p3[i][j].split(".")[1]), coords_dict[p3[i][j]][0])
                    m_ramales[p3[i][j].split(".")[0]]["Y"].__setitem__(int(p3[i][j].split(".")[1]), coords_dict[p3[i][j]][1])
                else:
                    temp_remove = p3[i][:]
                    temp_remove.remove(m_ramales[p3[i][j].split(".")[0]]["Pozo"][int(p3[i][j].split(".")[1])])
                    m_ramales[p3[i][j].split(".")[0]]["Conexion"].__setitem__(int(p3[i][j].split(".")[1]), ",".join(temp_remove))
                    m_ramales[p3[i][j].split(".")[0]]["X"].__setitem__(int(p3[i][j].split(".")[1]), coords_dict[p3[i][j]][0])
                    m_ramales[p3[i][j].split(".")[0]]["Y"].__setitem__(int(p3[i][j].split(".")[1]), coords_dict[p3[i][j]][1])
                    (p4.append(p3[i][j]), p5.append(temp_remove))

        del temp2, temp_remove
        return m_ramales, ramal, [p4, p5]


"#######################################################################################################################"
"ASIGNAR ELEVACIONES"
"#######################################################################################################################"


def raster2z_func(m_ramales, raster, iter1):
    src_filename = raster
    src_ds = gdal.Open(src_filename)
    gt = src_ds.GetGeoTransform()
    rb = src_ds.GetRasterBand(1)
    px = np.floor((m_ramales[iter1]["X"] - gt[0]) / gt[1])
    py = np.floor((m_ramales[iter1]["Y"] - gt[3]) / gt[5])
    return [
        iter1,
        np.round([float(rb.ReadAsArray(pxx, pyy, 1, 1)) for pxx, pyy in zip(px, py)], 4),
    ]


def raster2Z1(raster, mx, my, gt=None):
    """
    :param raster: Nombre del raster
    :param mx: lista de coordenadas este
    :param my: lista de coordenadas norte
    :return:
    """
    # check for raster or string type
    if not isinstance(raster, gdal.Dataset):
        src_filename = raster
        src_ds = gdal.Open(src_filename)
        gt = src_ds.GetGeoTransform()
    else:
        src_ds = raster
    rb = src_ds.GetRasterBand(1)
    px, py = np.floor((mx - gt[0]) / gt[1]), np.floor((my - gt[3]) / gt[5])
    return np.round([float(rb.ReadAsArray(int(pxx), int(pyy), 1, 1)) for pxx, pyy in zip(px, py)], 3)


def raster2Z2(raster, mx, my, src_filename=None):
    """
    :param raster: Nombre del raster
    :param mx: lista de coordenadas este
    :param my: lista de coordenadas norte
    :return:
    """
    if not isinstance(raster, np.ndarray):
        src_filename = rasterio.open(raster)
        x_lim, y_lim, res_x, res_y = (
            src_filename.bounds.left,
            src_filename.bounds.top,
            src_filename.transform.a,
            src_filename.transform.e,
        )
        rb = src_filename.read(1)
    else:
        rb = raster
        x_lim, y_lim, res_x, res_y = (
            src_filename.bounds.left,
            src_filename.bounds.top,
            src_filename.transform.a,
            src_filename.transform.e,
        )

    px, py = np.floor((mx - x_lim) / res_x), np.floor((my - y_lim) / res_y)
    return np.round(rb[(py.astype(int), px.astype(int))].astype(float), 3)


def get_elev_raster(m_ramales, ramal, raster):
    """

    :param m_ramales:
    :param raster: GeoTiff
    :return:
    """

    # get raster open and read as array
    src_ds = gdal.Open(raster)
    gt = src_ds.GetGeoTransform()
    for i in ramal.values():
        # indice para modificar los tramos nuevos unicamente
        index = np.char.equal(m_ramales[i]["Estado"], "nuevo").nonzero()[0]
        if index.size > 0:
            x = m_ramales[i]["X"]
            y = m_ramales[i]["Y"]
            m_ramales[i]["Z"] = np.round(raster2Z1(raster=src_ds, mx=x, my=y, gt=gt), 4)
            # m_ramales[i]["Z"] = np.round(np.array(convert_utm_to_ellipsoidal(x, y, m_ramales[i]["Z"])), 4)  # borrar

    return (m_ramales, ramal)


def get_elev_raster_MP(m_ramales, ramal, n_cpu, raster):
    iter_v = sorted(ramal.keys())
    func1 = partial(raster2z_func, m_ramales, raster)
    pool = Pool(processes=n_cpu)
    p = pool.map(func1, iter_v)
    for i in p:
        m_ramales[i[0]]["Z"] = i[1]
    return m_ramales, ramal


def join_raster(elev_file, path_out, rRes, nan=np.nan):
    files_to_mosaic = elev_file
    # merge raster files
    options = gdal.WarpOptions(
        options=["COMPRESS=LZW", "TILED=YES"],
        xRes=rRes,
        yRes=rRes,
        dstNodata=nan,
        resampleAlg=gdal.GRA_CubicSpline,
    )
    g = gdal.Warp(
        path_out + os.path.sep + "join.tif",
        files_to_mosaic,
        format="GTiff",
        options=options,
    )
    g = None  # Close file and flush to disk
    del g


def get_delimiter(file_path, bytes=4096):
    sniffer = csv.Sniffer()
    data = open(file_path, "r").read(bytes)
    delimiter = sniffer.sniff(data).delimiter
    return delimiter


def get_xyz_from_files(elev_file, source_in, m_ramales=None):
    """
    get xyz tree from a set of elevation (xyz) files not cut to m_ramales buffer

    :param elev_file:
    :return:
    """

    if m_ramales:
        # create mask
        df = pd.DataFrame(m_ramales).T
        mask_lines = gpd.GeoDataFrame(df)
        mask_lines["geometry"] = 0

        for row, geom in enumerate(zip(mask_lines["X"], mask_lines["Y"])):
            mask_lines.geometry.iloc[row] = LineString(zip(geom[0], geom[1]))
        mask_lines.set_geometry("geometry", inplace=True)
        polygons = mask_lines.buffer(10, cap_style=3).dissolve().explode()
    else:
        # get shapefile
        m_ramales_shp = gpd.read_file(source_in)
        polygons = gpd.GeoDataFrame(m_ramales_shp.buffer(10, cap_style=3), columns=["geometry"]).dissolve().explode()

    files = elev_file
    if not isinstance(files, list):
        files = [files]

    x_array = []
    y_array = []
    z_array = []
    for file in files:
        try:
            x, y, z = np.load(file, allow_pickle=True).T
        except:
            delimiter = get_delimiter(file, bytes=4096)
            x, y, z = np.loadtxt(file, delimiter=delimiter, dtype=object).T

        for geom in polygons.geometry:
            polygon = np.array(geom.exterior.coords.xy).T
            if x.size > 0:
                # get points inside polygon
                points = np.array([x, y]).copy()
                index_in = nb_is_inside_parallel(points, polygon.copy())
                del points

                x_array.append(x[index_in])
                y_array.append(y[index_in])
                z_array.append(z[index_in])
                del index_in
            else:
                x_array.append(x)
                y_array.append(y)
                z_array.append(z)

        del x, y, z

    _x = np.concatenate(x_array)
    del x_array
    _y = np.concatenate(y_array)
    del y_array
    _z = np.concatenate(z_array)
    del z_array
    coords = np.array([_x, _y, _z]).T
    del _x, _y, _z

    path_out = m_ramales_shp.split(os.path.sep)[0] + os.path.sep + r"03_ELEVACION" + os.path.sep + "01_XYZ"
    if not os.path.exists(path_out):
        os.makedirs(path_out)

    np.savetxt(path_out + os.path.sep + "join.csv", coords)
    np.save(path_out + os.path.sep + "join.npy", coords)

    del coords


def get_tree_from_xyz(xyz_file):
    # get coordinates arrays
    try:
        x_coords, y_coords, z_coords = np.load(xyz_file).T
    except:
        x_coords, y_coords, z_coords = np.load(xyz_file, allow_pickle=True).T

    x_coords, y_coords = coords_transform(x_coords, y_coords, ProjFrom="epsg:32717", ProjTo=crs_utm_epsg)  # borrar
    # init tree search
    xy_coords = np.array([x_coords, y_coords]).T
    tree = spatial.KDTree(xy_coords)

    del x_coords, y_coords, xy_coords
    return (tree, z_coords)


def get_elev_xyz(m_ramales, ramal, xyz_file, n_cpu=6, npoints=2):
    """
    :param m_ramales:
    :param ramal:
    :param elev_file:
    :param n_cpu:
    :return:
    """

    if isinstance(xyz_file, str):
        tree, z_coords = get_tree_from_xyz(xyz_file)
    else:
        tree, z_coords = xyz_file

    # loop over ramal
    for i in ramal.values():
        # get ramal coordinates
        x = m_ramales[i]["X"]
        y = m_ramales[i]["Y"]
        # get ramal points
        coords = np.array([x, y]).T
        # get ramal points indexes
        d_array, index_array = tree.query(coords, k=npoints, workers=n_cpu)
        if npoints > 1:
            # get ramal points elevations
            m_ramales[i]["Z"] = np.round(z_coords[index_array].mean(axis=1), 4)
        else:
            m_ramales[i]["Z"] = np.round(z_coords[index_array], 4)

    return m_ramales, ramal, (tree, z_coords)


def xyz2Z(tree_xyz, x, y, n_cpu=6, npoints=2):
    tree, z_coords = tree_xyz

    # get points
    coords = np.array([x, y]).T
    # get points indexes
    d_array, index_array = tree.query(coords, k=npoints, workers=n_cpu)
    if npoints > 1:
        # get points elevations
        return z_coords[index_array].mean(axis=1)
    else:
        return z_coords[index_array]


def get_elevation_from_countour_Linear(path):
    gdf = gpd.read_file(path, engine="pyogrio")
    coords = gdf.geometry.get_coordinates(index_parts=False, include_z=True).to_numpy()
    x_buff, y_buff, z_buff = coords.T[0], coords.T[1], coords.T[2]

    # Perform linear interpolation
    data_array = np.array([x_buff, y_buff]).T
    z_Linear = LinearNDInterpolator(data_array, z_buff, fill_value=np.nan, rescale=True)

    # Predict elevation values for each sewer pipe
    for i in ramal.values():
        x_predict = m_ramales[i]["X"]
        y_predcit = m_ramales[i]["Y"]
        m_ramales[i]["Z"] = np.round(z_Linear(x_predict, y_predcit), 3)

    return m_ramales, ramal


def get_elevation_from_countour_Linear_borrar(path, x_predict, y_predcit):
    gdf = gpd.read_file(path, engine="pyogrio")
    coords = gdf.geometry.get_coordinates(index_parts=False, include_z=True).to_numpy()
    x_buff, y_buff, z_buff = coords.T[0], coords.T[1], coords.T[2]

    # Perform linear interpolation
    data_array = np.array([x_buff, y_buff]).T
    z_Linear = LinearNDInterpolator(data_array, z_buff, fill_value=np.nan, rescale=True)

    return np.round(z_Linear(x_predict, y_predcit), 3)


def get_elev_source(elev_file):
    elev_file_type = [_.split(os.path.sep)[-1].split(".")[-1] for _ in elev_file]

    if np.unique(elev_file_type) in ["npy", "txt", "csv"]:
        elev_file = path_proy + r"03_ELEVACION" + os.path.sep + r"01_XYZ" + os.path.sep + "join.npy"
        _type = "." + elev_file_type[0]
        if not os.path.exists(elev_file):
            get_xyz_from_files(elev_file, source_in)
        elev_file = get_tree_from_xyz(elev_file)

    elif np.unique(elev_file_type) in ["tif", "tiff", "geotiff"]:
        elev_file = path_proy + r"03_ELEVACION" + os.path.sep + r"00_RASTER" + os.path.sep + "join.tif"
        _type = ".tif"
        if not os.path.exists(elev_file):
            join_raster(
                elev_file,
                path_proy + r"03_ELEVACION" + os.path.sep + r"00_RASTER",
                0.5,
                nan=np.nan,
            )

    elif np.unique(elev_file_type) in ["shp", "gpkg"]:
        _type = "." + str(np.unique(elev_file_type)[0])
        elev_file = path_proy + r"03_ELEVACION" + os.path.sep + r"02_VECTOR" + os.path.sep + "join" + _type

    else:
        print("NO ELEVATION FILE")
        elev_file = None

    return elev_file, _type


def get_elev_values(m_ramales, ramal, elev_source, elev_file_type, n_max_ramal):
    n_max_ramal = 5000
    if elev_file_type in [".tif"]:
        if len(ramal) > n_max_ramal:
            n_cpu = int(max(2.0, round(len(ramal) / n_max_ramal, 0) + 1))
            m_ramales, ramal = get_elev_raster_MP(m_ramales, ramal, n_cpu, raster=elev_source)
            return m_ramales, ramal
        else:
            m_ramales, ramal = get_elev_raster(m_ramales, ramal, raster=elev_source)
            return m_ramales, ramal
    elif elev_file_type in [".npy"]:
        m_ramales, ramal, tree_xyz = get_elev_xyz(m_ramales, ramal, xyz_file=elev_source)
        return m_ramales, ramal, tree_xyz

    elif elev_file_type in [".shp", ".gpkg", "dxf"]:
        m_ramales, ramales = get_elevation_from_countour_Linear(elev_source)
        return m_ramales, ramal


"#######################################################################################################################"
"OBTENER LONGITUDES"
"#######################################################################################################################"


def dist2d_vector(x_v, y_v):
    return ((x_v[1:] - x_v[:-1]) ** 2 + (y_v[1:] - y_v[:-1]) ** 2) ** 0.5


def get_len(m_ramales, ramal):
    """

    :param m_ramales:
    :param ramal:
    :return:
    """
    for i in ramal.values():
        m_ramales[i]["L"] = np.round(np.insert(dist2d_vector(m_ramales[i]["X"], m_ramales[i]["Y"]), 0, 0), 2)
        m_ramales[i]["LT"] = np.cumsum(m_ramales[i]["L"])
    return (m_ramales, ramal)


"#######################################################################################################################"
"ASIGNAR PENDIENTES NATURALES"
"#######################################################################################################################"


def diff_z(z_v):
    return z_v[1:] - z_v[:-1]


def Smin(material, m_ramales, i=None, j=None):
    s_min = itemgetter(*material)(pendiente_minima_pypiper)

    if i and len(material) > 1 and not j:
        s_min = np.array(s_min)
        # check for minimal slope given by the seccion shape
        index_min_seccion = np.isin(m_ramales[i]["Seccion"], pendiente_minima_pypiper["seccion"]).nonzero()[0]
        if index_min_seccion.size > 0:
            s_min[index_min_seccion] = np.array([0.004] * index_min_seccion.size)

        # check for minimal slope determine by usuario
        index_min_usuario = np.logical_not(np.isnan(m_ramales[i]["S_min"])).nonzero()[0]
        if index_min_usuario.size > 0:
            s_min[index_min_usuario] = m_ramales[i]["S_min"][index_min_usuario]

        return s_min

    elif j and i:
        # if not isinstance(j, (list, np.ndarray, tuple)):
        #     j = [j]
        #
        # try:
        #     j = np.concatenate(j)
        # except:
        #     pass
        #
        # # check for minimal slope for material
        # s_min = np.array(itemgetter(*m_ramales[i]["Material"])(pendiente_minima_pypiper))
        #
        # # check for minimal slope given by the seccion shape
        # index_min_seccion = np.isin(m_ramales[i]["Seccion"], pendiente_minima_pypiper["seccion"]).nonzero()[0]
        # if index_min_seccion.size > 0:
        #     s_min[index_min_seccion] = np.array([0.005] * index_min_seccion.size)
        #
        # # check for minimal slope determine by usuario
        # index_min_usuario = np.logical_not(np.isnan(m_ramales[i]["S_min"])).nonzero()[0]
        # if index_min_usuario.size > 0:
        #     s_min[index_min_usuario] = m_ramales[i]["S_min"][index_min_usuario]
        #
        # return np.array(s_min)[j]

        cond_usuario = np.invert(np.isnan(m_ramales[i]["S_min"][j])).nonzero()[0]
        if len(cond_usuario) > 0:
            return m_ramales[i]["S_min"][j]

        else:
            if np.isscalar(s_min):
                return np.array([s_min] * len(material))
            else:
                return np.array(s_min)

    else:
        try:
            s_min = np.concatenate(s_min)
        except:
            pass

        return np.array(s_min)


def Smin_original(material, m_ramales, i=None, j=None):
    # pendiente_minima_pypiper = {'PVC': 0.004, 'PVC-1MPa': 0.004, 'PEAD': 0.004, 'PRFV': 0.005, 'HS': 0.01, 'HA': 0.01, 'HD': 0.01}
    s_min = itemgetter(*material)(pendiente_minima_pypiper)
    # if np.isscalar(s_min):
    #     s_min = np.array([s_min])
    # else:
    #     s_min = np.array(s_min)
    # f = operator.itemgetter(*material)
    # s_min = f(pendiente_minima_pypiper)
    # [Smin[_] for _ in material]
    # list(map(pendiente_minima_pypiper.get, material))

    if i and len(material) > 1 and not j:
        index_min = np.logical_not(np.isnan(m_ramales[i]["S_min"])).nonzero()[0]
        # CHECK FOR LOCAL MINIMUM SLOPE
        if index_min.size > 0:
            s_min = np.array(s_min)
            s_min[index_min] = m_ramales[i]["S_min"][index_min]
        return np.array(s_min)

    elif j and i:
        cond = np.invert(np.isnan(m_ramales[i]["S_min"][j])).nonzero()[0]
        if len(cond) > 0:
            return m_ramales[i]["S_min"][j]
        else:
            if np.isscalar(s_min):
                return np.array([s_min] * len(material))
            else:
                return np.array(s_min)

    else:
        return s_min


def Smin_does_not_work(material, m_ramales, i=None, j=None):
    """
    Calculate the minimum slope (s_min) for given materials considering user-specified slopes and section handling.

    Parameters:
    material (list or str): A list of materials or a single material.
    m_ramales (dict): A dictionary containing information about different ramales.
    i (int, optional): The index of the specific ramal in the m_ramales dictionary.
    j (int or list of ints, optional): The index or list of indices within the arrays in the specific ramal.

    Returns:
    np.ndarray: An array of minimum slopes for the specified materials.
    """
    # Ensure material is a list
    if isinstance(material, str):
        material = [material]

    # Case 1: If we have a (i) ramal number but not specific positions in the array (j)
    if i and not j and len(material) > 1:
        # Retrieve the minimum slope for the given materials from the dictionary
        s_material = np.array(itemgetter(*m_ramales[i]["Material"])(pendiente_minima_pypiper))

        # Set s_min_seccion to 0.4 if the section is in the specified list, otherwise use s_material
        s_min_seccion = np.where(
            np.isin(m_ramales[i]["Seccion"], pendiente_minima_pypiper["seccion"]),
            0.004,
            s_material,
        )

        # Get the minimum values between s_min_seccion and s_material
        s_min = np.min([s_min_seccion, s_material], axis=0)

        # Replace any non-zero values from user-specified slopes (s_min_usuario)
        s_min_usuario = np.nan_to_num(m_ramales[i]["S_min"])
        s_min = np.where(s_min_usuario != 0, s_min_usuario, s_min)

        # Replace non zero values of user oblige slope
        s_user = np.nan_to_num(m_ramales[i]["S_user"])
        s_min = np.where(s_user != 0, s_user, s_min)

        return s_min

    # Case 2: If we have a (i) ramal number and specific positions in the array (j)
    elif i and j:
        if not isinstance(j, (list, np.ndarray, tuple)):
            j = [j]
            s_material = np.array([itemgetter(*m_ramales[i]["Material"][j])(pendiente_minima_pypiper)])
            s_material = np.array([s_material.item()])
        else:
            s_material = np.array(itemgetter(*m_ramales[i]["Material"][j])(pendiente_minima_pypiper))
            if len(j) == 1 and not isinstance(j, tuple):
                s_material = [s_material.item()]

        # Set s_min_seccion to 0.4 if the section is in the specified list, otherwise use s_material
        s_min_seccion = np.where(
            np.isin(m_ramales[i]["Seccion"][j], pendiente_minima_pypiper["seccion"]),
            0.004,
            s_material,
        )

        # Get the minimum values between s_min_seccion and s_material
        s_min = np.min([s_min_seccion, s_material], axis=0)

        # Replace any non-zero values from user-specified slopes (s_min_usuario)
        s_min_usuario = np.nan_to_num(m_ramales[i]["S_min"][j])
        s_min = np.where(s_min_usuario != 0, s_min_usuario, s_min)

        # Replace non zero values of user oblige slope
        s_user = np.nan_to_num(m_ramales[i]["S_user"][j])
        s_min = np.where(s_user != 0, s_user, s_min)

        return s_min

    # Case 3: If neither i nor j are specified
    else:
        # Retrieve the minimum slope for the given materials from the dictionary
        s_min = np.array(itemgetter(*material)(pendiente_minima_pypiper))
        return s_min


def get_slope(m_ramales, ramal):
    for i in ramal.values():
        # indice para modificar los tramos nuevos unicamente
        index = np.char.equal(m_ramales[i]["Estado"], "nuevo").nonzero()[0]

        if index.size > 0:
            m_ramales[i]["L"][0] = 1
            a = -np.round(
                np.true_divide(np.insert(diff_z(m_ramales[i]["Z"]), 0, 0), m_ramales[i]["L"]),
                3,
            )
            m_ramales[i]["L"][0] = 0
            m_ramales[i]["S"] = np.asarray([0.0] * len(a))
            for j in set(m_ramales[i]["Material"]):
                index_v = np.where(m_ramales[i]["Material"] == j)
                s = a[index_v]

                # get slope min from material
                smin_material = Smin([j], m_ramales)

                # get slope min for user min
                smin_user = np.nan_to_num(m_ramales[i]["S_min"])
                smin_user = smin_user[index_v]
                smin = np.where((smin_user != 0) & (smin_user < smin_material), smin_user, smin_material)

                # min slope
                s = np.where(s < smin, smin, s)

                # # get slope for user
                # s_user = np.nan_to_num(m_ramales[i]['S_user'])
                # s_user = s_user[index_v]
                # s = np.where(s_user != 0, s_user, s)

                # assing slope
                np.put(m_ramales[i]["S"], index_v, s)

            # # #CHECK FOR LOCAL MINIMUM SLOPE
            # index_min = np.where(m_ramales[i]['S_min'] == m_ramales[i]['S_min'])[0]
            # if index_min.size > 0:
            #     np.put(m_ramales[i]['S'], index_min, m_ramales[i]['S_min'][index_min])

        # this make sure that the D_init is not nana due to zero slope pipes
        index_existente = np.char.equal(m_ramales[i]["Estado"], "existente").nonzero()[0]
        if index_existente.size > 0:
            index_change = (m_ramales[i]["S"] <= 0).nonzero()[0]
            if index_change.size > 0:
                np.put(m_ramales[i]["S"], index_change, 0.001)

    return m_ramales, ramal


"#######################################################################################################################"
"ASIGNAR RUGOSIDAD"
"#######################################################################################################################"


def roughness_mat(material, roughness="manning"):
    # rugosidad_pypiper = {
    f = operator.itemgetter(*material)
    return f(rugosidad_pypiper[roughness])


def get_roughness(m_ramales, ramal, roughness="manning"):
    """

    :param m_ramales:
    :param ramal:
    :return:
    """
    for i in ramal.values():
        # indice para modificar los tramos nuevos unicamente
        index = np.char.equal(m_ramales[i]["Estado"], "nuevo").nonzero()[0]
        if index.size > 0:
            m_ramales[i]["Rug"] = np.asarray(roughness_mat(m_ramales[i]["Material"], roughness))
    return m_ramales, ramal


"#######################################################################################################################"
"SUMATORIA DE CAUDALES"
"#######################################################################################################################"


def filterTheDict(dictObj, callback):
    newDict = dict()
    for key, value in dictObj.items():
        if callback((key, value)):
            newDict[key] = value
    return newDict


# @profile
def get_q(m_ramales, ramal, q_dict, qmin=2.5):
    q_dict.index = q_dict["pz"]
    q_pz = {"q_san": {}, "q_pluvial": {}}
    q_remove = {k: [] for k in q_dict.index}

    for i in ramal.values():
        try:
            pz_index = m_ramales[i]["Pozo"]

            q_san_arr = q_dict.loc[pz_index]["q_san"].to_numpy().astype(float)
            index_nan = np.isnan(q_san_arr)
            q_san_arr[index_nan] = 0
            q_pz["q_san"][i] = dict(zip(pz_index, q_san_arr))

            q_plu_arr = q_dict.loc[pz_index]["q_pluvial"].to_numpy().astype(float)
            index_nan = np.isnan(q_plu_arr)
            q_plu_arr[index_nan] = 0
            q_pz["q_pluvial"][i] = dict(zip(pz_index, q_plu_arr))

            # if q_pz['q_san'][i][0] < qmin:  #     if m_ramales[i]['Conexion'][-1] is not None:  #         for _ in m_ramales[i]['Conexion'][-1].split(','):  #             q_remove[_].append(q_pz['q_san'][i][0])  #     q_pz['q_san'][i][0] = qmin
        except:
            print("Error: ", i)
            empty_flow = np.array([0] * len(pz_index)).astype(float)
            q_pz["q_pluvial"][i] = empty_flow
            empty_flow[0] = qmin
            q_pz["q_san"][i] = empty_flow

    return q_pz


# get edge cumulative flow
def get_edge_cumulative_flow(G, start_node, end_node):
    # Start with the flow value of the edge itself
    edge_flow = G.edges[start_node, end_node]["flow"]
    # Add the cumulative flow of the start node
    cumulative_flow = get_cumulative_flow(G, start_node)
    # The cumulative flow for the edge is the sum of the start node's cumulative flow and the edge's flow
    return cumulative_flow + edge_flow


# get node cumulative flow
def get_cumulative_flow(G, node, visited=None):
    if visited is None:
        visited = set()

    # Avoid revisiting nodes
    if node in visited:
        return 0
    visited.add(node)

    # Base flow is the flow at the node itself
    base_flow = G.nodes[node]["flow"] if "flow" in G.nodes[node] else 0
    cumulative_flow = base_flow

    # Add the flow from each incoming edge
    for pred in G.predecessors(node):
        edge_flow = G.edges[pred, node]["flow"] if "flow" in G.edges[pred, node] else 0
        cumulative_flow += get_cumulative_flow(G, pred, visited.copy()) + edge_flow

    return cumulative_flow


# Initialize a new approach using numpy
def correct_first_true_sequence(values):
    # Convert to numpy array if not already one
    if not isinstance(values, np.ndarray):
        values = np.array(values)

    # Identify where the values change from False to True or True to False
    changes = np.diff(values)
    first_true_index = np.argmax(values == True)  # Index of first True value

    # If there's no True value, return the original
    if values[first_true_index] == False:
        return values

    # Find the first False after the first True
    post_true_changes = np.where(changes[first_true_index:] == True)[0]

    if len(post_true_changes) > 0:
        end_index = post_true_changes[0] + first_true_index + 1
    else:
        end_index = len(values)

    # Set the identified range to True, everything else to False
    result = np.zeros_like(values, dtype=bool)
    result[first_true_index:end_index] = True
    return result


# @profile
def get_flowsum(m_ramales, ramal, q_v, flow_type="q_comb", qmin=2.5):
    q_san = q_v["q_san"]
    q_pluvial = q_v["q_pluvial"]

    for i in ramal.values():
        base_array = m_ramales[i]["Pozo"]
        try:
            q_pluvial_series = q_pluvial.index.to_series().astype(str)
            substring = rf"^{i}\."

            pluvial_index = q_pluvial_series.str.contains(substring, regex=True)
            pluvial_index = correct_first_true_sequence(pluvial_index)
            q_pluvial_values = q_pluvial[pluvial_index]

            if np.any(base_array == q_pluvial_series[pluvial_index].to_numpy()):
                q_pluvial_values_shift = q_pluvial_values.shift().fillna(0)
                m_ramales[i]["q_pluvial"] = q_pluvial_values_shift.astype(float).to_numpy()
            else:
                print("error flow:", i)
                m_ramales[i]["q_pluvial"] = np.zeros(len(m_ramales[i]["Pozo"]))

        except:
            print("error flow:", i)
            m_ramales[i]["q_pluvial"] = np.zeros(len(m_ramales[i]["Pozo"]))

        try:
            q_san_series = q_san.index.to_series().astype(str)
            substring = rf"^{i}\."
            sanitario_index = q_san_series.str.contains(substring, regex=True)
            sanitario_index = correct_first_true_sequence(sanitario_index)
            q_san_values = q_san[sanitario_index]
            if np.any(base_array == q_san_series[sanitario_index].to_numpy()):
                q_san_values_shift = q_san_values.shift().fillna(0)
                m_ramales[i]["q_san"] = q_san_values_shift.astype(float).to_numpy()
            else:
                print("error flow:", i)
                m_ramales[i]["q_san"] = np.zeros(len(m_ramales[i]["Pozo"]))

        except:
            print("error flow:", i)
            m_ramales[i]["q_san"] = np.zeros(len(m_ramales[i]["Pozo"]))

    # Create a directed graph
    G = nx.DiGraph()
    df = m_ramales2df(m_ramales)

    # Iterate over the DataFrame rows
    for connection, row in df.iterrows():
        # Skip rows where the index is an empty string
        if connection == "":
            continue

        # Parse the source and target nodes from the index
        source, target = connection.split("-")

        # Add nodes and edge to the graph
        G.add_node(source)
        G.add_node(target)

        if flow_type == ["q_san"]:
            flow_val = row["q_san"]
        elif flow_type == ["q_pluvial"]:
            flow_val = row["q_pluvial"]
        else:
            flow_val = row["q_san"] + row["q_pluvial"]

        G.add_edge(source, target, flow=flow_val)

    # Calculate cumulative flow for each node
    cumulative_flows_edges = {str(start) + "-" + str(end): get_edge_cumulative_flow(G, start, end) for start, end in G.edges}
    df_q_accu = pd.DataFrame(
        cumulative_flows_edges.values(),
        index=cumulative_flows_edges.keys(),
        columns=["q_accu"],
    )
    df["q_accu"] = 0
    df.loc[df_q_accu.index, "q_accu"] = df_q_accu["q_accu"]

    for index, s in df.groupby("Ramal")["q_accu"]:
        if flow_type in ["q_san", "q_comb"]:
            m_ramales[index]["q_accu"] = np.where(s.to_numpy() < qmin, qmin, s.to_numpy())
        else:
            m_ramales[index]["q_accu"] = s.to_numpy()

    # var_temp = var0[:].copy()
    # var_q_san = {key: [] for key in m_ramales.keys()}
    # var_q_pluvial = {key: [] for key in m_ramales.keys()}
    # while len(var_temp) > 0:
    #     var_temp1 = []
    #     for i in var_temp:
    #         dir = list(m_ramales[i]['Conexion'][-1:])[0]
    #         if dir is not None and dir != '':
    #             arr = np.array(dir.split(','))
    #             r_array, pos_array = pp_char_split(arr, _split='.')
    #             for r, pos in zip(r_array, pos_array):
    #                 # r, pos = dir.split('.')
    #                 #SANITARIO
    #                 if q_remove.get(str(r) + '.' + str(pos)) is not None:
    #                     q_remove_val = - qmin + np.sum(q_remove[str(r) + '.' + str(pos)])
    #                 else:
    #                     q_remove_val = - qmin
    #                 q_temp_san = np.sum(m_ramales[i]['q_san']) - np.sum(var_q_san[i]) + q_remove_val
    #                 q_temp1_san = m_ramales[r]['q_san'][int(pos) + 1]
    #                 m_ramales[r]['q_san'][int(pos) + 1] = q_temp_san + q_temp1_san
    #                 var_q_san[i].append(q_temp_san)
    #
    #
    #                 #PLUVIAL
    #                 q_temp_pluvial = np.sum(m_ramales[i]['q_pluvial']) - np.sum(var_q_pluvial[i])
    #                 q_temp1_pluvial = m_ramales[r]['q_pluvial'][int(pos) + 1]
    #                 m_ramales[r]['q_pluvial'][int(pos) + 1] = q_temp_pluvial + q_temp1_pluvial
    #                 var_q_pluvial[i].append(q_temp_pluvial)
    #
    #                 var_temp1.append(r)
    #
    #     var_temp = np.unique(var_temp1[:])
    #
    # for i in ramal.keys():
    #     derivador_index = np.where(m_ramales[i]['Derivacion'] == 'Derivacion')[0]
    #     q_pluvial_accu = np.cumsum(m_ramales[i]['q_pluvial'])
    #
    #     if len(derivador_index) != len(q_pluvial_accu):
    #         for _derivador in derivador_index:
    #             _derivador = _derivador + 1
    #             qi = q_pluvial_accu[_derivador]
    #             q_left = np.array([0] * (_derivador))
    #             q_rigth = np.array([qi] * (len(q_pluvial_accu) - _derivador))
    #             q_derivacion = np.concatenate([q_left, q_rigth])
    #             q_pluvial_accu = q_pluvial_accu - q_derivacion
    #
    #             #ASIGNAR CAUDAL PLUVIAL PARA DERIVACION
    #             ramal_descarga = m_ramales[i]['Obs'][_derivador - 1].split(' ')[-1]
    #             m_ramales[ramal_descarga]['q_pluvial'][0] = qi
    #             m_ramales[ramal_descarga]['q_accu'] = np.cumsum(m_ramales[ramal_descarga]['q_pluvial'])
    #
    #
    #     _tipo = [_.lower() for _ in  m_ramales[i]['Tipo']]
    #     index_combinado = np.char.equal(_tipo , 'combinado').nonzero()[0]
    #     index_sanitario = np.char.equal(_tipo , 'sanitario').nonzero()[0]
    #     index_pluvial = np.char.equal(_tipo , 'pluvial').nonzero()[0]
    #
    #     if index_sanitario.size > 0:
    #         q_accu = np.cumsum(m_ramales[i]['q_san'])
    #
    #     elif index_pluvial.size > 0:
    #         q_accu = q_pluvial_accu
    #
    #     elif index_combinado.size > 0:
    #         q_accu = q_pluvial_accu + np.cumsum(m_ramales[i]['q_san'])
    #
    #     m_ramales[i]['q_accu'] = q_accu

    return m_ramales, ramal


"#######################################################################################################################"
"DIMENSIONAMIENTO DE DIAMETRO INTERNO Y EXTERNO"
"#######################################################################################################################"


def seccion_str2float(arr, return_b=False):
    """

    :param arr: array of string mix of circular and rectangular sections
    :return: array of diameter of circular sections and heigth dimensions of rectangular sections
    """
    arr = np.array(arr)
    # split base and heigth when possible
    b, h = pp_char_split(arr, _split="x")
    # get circular and rectangular indexes
    circular_index = np.char.equal(h, "0").nonzero()[0]
    rectangular_index = np.char.not_equal(h, "0").nonzero()[0]
    # zeros array
    out = np.zeros(shape=len(b), dtype=float)
    # fill zeros array
    out[circular_index] = b[circular_index].astype(float)
    if return_b:
        out[rectangular_index] = b[rectangular_index].astype(float)
    else:
        out[rectangular_index] = h[rectangular_index].astype(float)

    return out


def seccion_remplazar_dimension(arr, D_necesario):
    """

    :param arr: string array of circular and rectangular sections
    :param D_necesario: minimum size for section
    :return: modify section array with circular and rectangular sections replaced
    """
    # split base and heigth when possible
    b, h = pp_char_split(arr, _split="x")
    # get circular and rectangular indexes
    circular_index = np.char.equal(h, "0").nonzero()[0]
    rectangular_index = np.array(list(set(range(len(b))).difference(set(circular_index))), dtype=int)
    # boolean filter as np.where
    circular_seccion = b[circular_index].astype(float)
    circular_seccion[circular_seccion < D_necesario] = D_necesario
    # boolean filter as np.where
    rectangular_seccion = h[rectangular_index].astype(float)
    rectangular_seccion[rectangular_seccion < D_necesario] = D_necesario
    # replace changed values in original array
    b[circular_index] = circular_seccion
    h[rectangular_index] = rectangular_seccion
    # join B and H by 'x'
    return np.array(["x".join(_) if _[1] != "0" else _[0] for _ in zip(b, h)], dtype=str)


def seccion_init(q, manning, pendiente, seccion="circular"):
    """

    :param q: Caudal tramo (L/s)
    :param n: Coeficiente de mannig
    :param S: Pendiente (m/m)
    :return:
    """
    if seccion in ["circular"]:
        return (q / 1000.0 * manning / (0.3117 * pendiente ** (1.0 / 2.0))) ** (3.0 / 8.0)

    if seccion in ["rectangular"]:
        # #asumiendo que la base es dos veces el calado
        # y_array = (((q /1000) * manning) / ((pendiente ** 0.5) * (2 ** (1/3)))) ** (3/8)
        # #seccion eficiente
        # b_min = y_array * 2
        # b_min = ((q / 1000) * 0.765) ** (2 / 5)
        b_min = ((q / 1000) * 0.35) ** (2 / 5)
        b_min = np.where(b_min >= par_basicos(seccion_min=1), b_min, par_basicos(seccion_min=1))
        b_array = np.around(b_min, decimals=1)

        try:
            y_array = np.array(
                [
                    opt.brentq(
                        rectangular_SPLL_root,
                        0.001,
                        b_array[_] * 5,
                        xtol=1e-3,
                        args=(b_array[_], pendiente[_], manning[_], q[_]),
                    )
                    for _ in range(len(b_array))
                ]
            )
        except:
            # print('Error: def seccion_init - seccion rectangular ')
            y_array = np.array(
                [
                    opt.root(
                        rectangular_SPLL_root,
                        0.05,
                        args=(b_array[_], pendiente[_], manning[_], q[_]),
                        method="hybr",
                    ).x[0]
                    for _ in range(len(b_array))
                ]
            )
        y_array = np.where(y_array >= par_basicos(seccion_min=1), y_array, par_basicos(seccion_min=1))

        return b_array, y_array


def seccion_menor_mayor(seccion_init_array):
    (
        """
    :param seccion_init_array:   array de dimensiones de secciones sin ordenar
    :return: array con seccion esde mayor a menor
    """
        ""
    )
    seccion_init_array = seccion_init_array.astype(float)
    if len(seccion_init_array) > 2:
        a = seccion_init_array.copy()
        for k in np.where(a[0:-1] / a[1:] > 1)[0]:
            a[k:][a[k:] <= a[k:][0]] = a[k:][0]
        return a
    else:
        return seccion_init_array


def diameter_translate(D_in, material_out):
    """
    Transforma el diametro D_in a su equivalente en el material_out
    :param D_in:
    :param material_out:
    :return:
    """
    if not isinstance(D_in, (list, np.ndarray)):
        # array diametro externo
        d_ext_array_out = D_ext(material_out)
        # get closet size in material_out from D_in in material_in
        closet_index = np.argmin(np.abs((D_in / d_ext_array_out) - 1))
        # D_out size
        D_out = d_ext_array_out[closet_index]
        return D_out
    else:
        D_out_array = []
        for D_in_pos, material_out_pos in zip(D_in, material_out):
            # array diametro externo
            d_ext_array_out = D_ext(material_out_pos)
            # get closet size in material_out from D_in in material_in
            closet_index = np.argmin(np.abs((D_in_pos / d_ext_array_out) - 1))
            # D_out size
            D_out_array.append(d_ext_array_out[closet_index])
        return np.array(D_out_array)


def get_metodo_constructivo_max_diamenter(i, index_seccion, m_ramales, key):
    # Iterate through each "metodo_constructivo" and its maximum diameter
    for (
        metodo_constructivo,
        max_diameter_metodo_constructivo,
    ) in diametro_interno_externo_pypiper["metodo_constructivo_diameter_max"].items():
        # Create a filter for the current "metodo_constructivo"
        metodo_constructivo_filter = m_ramales[i]["metodo_constructivo"][index_seccion] == metodo_constructivo

        # Get the relevant indices in the original array
        original_indices = np.where(metodo_constructivo_filter)[0]

        # Apply the filter to get the relevant section of the array
        metodo_constructivo_array = m_ramales[i][key][index_seccion].astype(float)[original_indices]

        # Identify indices where the diameter exceeds the maximum allowed diameter
        change_limit_diameter_index = np.where(metodo_constructivo_array > max_diameter_metodo_constructivo)[0]

        # Replace the values in the original array if any values exceed the limit
        if change_limit_diameter_index.size > 0:
            metodo_constructivo_array[change_limit_diameter_index] = max_diameter_metodo_constructivo
            new_array_change = m_ramales[i][key][index_seccion].copy()
            np.put(
                new_array_change,
                original_indices[change_limit_diameter_index],
                metodo_constructivo_array[change_limit_diameter_index].astype(str),
            )

            # Use np.put to update the original array with the modified values
            m_ramales[i][key][index_seccion] = new_array_change


def D_ext(material):
    return np.asarray(sorted(diametro_interno_externo_pypiper[material].keys()))


def D_ext_float(i, m_ramales):
    D_ext = np.zeros(shape=len(m_ramales[i]["Seccion"]))
    secciones = np.unique(m_ramales[i]["Seccion"])
    for seccion in secciones:
        index_seccion = np.char.equal(m_ramales[i]["Seccion"], seccion).nonzero()[0]
        if seccion in ["circular"]:
            D_ext[index_seccion] = m_ramales[i]["D_ext"][index_seccion]
        if seccion in ["rectangular"]:
            b_arr, h_arr = pp_char_split(m_ramales[i]["D_int"][index_seccion], _split="x")
            b_arr, h_arr = b_arr.astype(float), h_arr.astype(float)
            # D_ext[index_seccion] = b_arr
            D_ext[index_seccion] = h_arr
    return D_ext


def D_ext_string(i, m_ramales):
    D_ext = np.zeros(shape=len(m_ramales[i]["Seccion"]), dtype="U256")
    secciones = np.unique(m_ramales[i]["Seccion"])
    for seccion in secciones:
        index_seccion = np.char.equal(m_ramales[i]["Seccion"], seccion).nonzero()[0]
        if seccion in ["circular"]:
            D_ext[index_seccion] = (m_ramales[i]["D_ext"][index_seccion].astype(float) * 1000).astype(int).astype(str)
        elif seccion in ["rectangular"]:
            b_arr, h_arr = pp_char_split(m_ramales[i]["D_int"][index_seccion], _split="x")
            b_arr, h_arr = b_arr.astype(float) * 1000, h_arr.astype(float) * 1000
            D_ext[index_seccion] = np.array(["x".join(_) for _ in np.array(list(zip(b_arr.astype(int), h_arr.astype(int)))).astype(str)])
    return D_ext


def D_int(D_v, material):
    return itemgetter(*D_v)(diametro_interno_externo_pypiper[material])


def D_inter_sizing_fromPz(i, _pz):
    """
    Returns the internal sizing from pz position to end of array
    """
    # "DIMENSIONAR DIAMETRO INTERNO"
    for j in list(set(m_ramales[i]["Material"][int(_pz) + 1 :])):
        Dmin_int = D_ext(j)
        index_v = np.where(m_ramales[i]["Material"] == j)[0]
        index_v1 = np.array(index_v >= int(_pz) + 1).nonzero()[0]
        index_v2 = index_v[index_v1]
        D_init_temp = m_ramales[i]["D_init"][index_v2]
        index_v3 = np.searchsorted(Dmin_int, D_init_temp)
        np.put(m_ramales[i]["D_int"], index_v2, Dmin_int[index_v3])


def D_inter_sizing(m_ramales, i, index_seccion, seccion="circular"):
    # ToDo: como hacemos para  modificar la seccion a rectangular  cuando no hay diametros suficientemente grande

    # If the section is circular, process the internal diameters for the given branch ('i') of a network

    # make a copy to reset if change the material  of some indexes
    ramal_copy = m_ramales[i].copy()
    if seccion == "circular":
        # Extract the initial internal diameters for the given section indices and convert them to floats
        D_init_circular = m_ramales[i]["D_int"][index_seccion].astype(float)
        # Get a unique set of materials for the given section indices
        materiales = set(m_ramales[i]["Material"][index_seccion])
        count = 0
        # Initialize the condition for while loop to false to enter the loop
        cond = False
        while not cond and count < 10:
            count = count + 1
            # Iterate over each unique material
            for j in materiales:
                # Set the condition to True. It will be set to False later if a condition is not met.
                cond = True
                # Get the minimum internal diameter for the current material 'j'
                Dmin_int = D_ext(j)
                # Find indices where the material type matches the current material 'j'
                index_material = np.where(m_ramales[i]["Material"][index_seccion] == j)
                # Search for the positions in the sorted array where D_init_circular should be inserted
                index_diametro = np.searchsorted(Dmin_int, D_init_circular[index_material])
                try:
                    # Try to assign the diameter values based on the searchsorted indices
                    D_int = Dmin_int[index_diametro]
                except Exception as e:
                    # probar si el diametro teorico mayor a  diametro fisico es mucho mas grande en un 20%, si es mas del 20% entonces sii continuar con buscar otro diametro mas grande en otro material
                    index_chnage_material = [pos for _, pos in zip(index_diametro, index_material[0]) if _ >= len(Dmin_int)]
                    if np.isclose(D_init_circular[index_chnage_material], Dmin_int[-1], rtol=0.2).all():
                        change_index_close = (index_diametro == Dmin_int.size).nonzero()[0]
                        index_diametro[change_index_close] = Dmin_int.size - 1
                        D_int = Dmin_int[index_diametro]
                    else:
                        # If the material is one of these ['PVC', 'PEAD', 'PRFV'], change the material to 'HA'
                        if j in ["PVC", "PEAD", "PRFV", "HS", "PVC-1MPa"]:
                            m_ramales[i] = ramal_copy
                            # current_max_diameter = np.max(Dmin_int)
                            # max_diameters = {_:list(diametro_interno_externo_pypiper[_])[-1] for _ in diametro_interno_externo_pypiper if  _ != j}
                            # max_diameters = pd.DataFrame(max_diameters.values(), index= max_diameters.keys(), columns=['D'])
                            # max_diameters.sort_values('D', inplace=True)
                            # print(f"********************\nRamal {i} tiene diametro teorico mayor a los diametros disponibles\n********************")

                            np.put(m_ramales[i]["Material"], index_chnage_material, ["HA"] * len(index_chnage_material))
                            np.put(m_ramales[i]["Seccion"], index_chnage_material, ["rectangular"] * len(index_chnage_material))

                            s = m_ramales[i]["S"]
                            smin_material = Smin([j], m_ramales)
                            s = np.where(s < smin_material, smin_material, s)
                            smin_user = Smin([j], m_ramales, i=i, j=index_chnage_material)
                            if smin_user.size > 0:
                                smin_user_index = np.invert(np.isnan(smin_user)).nonzero()[0]
                                s[smin_user_index] = smin_user[smin_user_index]

                            np.put(m_ramales[i]["S"], index_chnage_material, s)
                            # Update the set of materials since it has been changed
                            materiales = set(m_ramales[i]["Material"][index_seccion])
                            # Reset condition to False to re-enter the loop and process the new material 'HA'
                            cond = False
                            break
                        else:
                            sys.exit(f"Ramal {j} tiene diametro teorico mayor a los diametros disponibles")
                # Update the indices of the section where the material was found
                index_insert = index_seccion[index_material]
                # Update the internal diameters in the main array with the calculated diameters
                np.put(m_ramales[i]["D_int"], index_insert, D_int)


def predict_inside_diameters(diameter_dict, materials, new_outside_diameters):
    """
    Efficiently fits a polynomial to the diameter data for each unique material and predicts inside diameters for new outside diameters.

    :param diameter_dict: Dictionary of diameter data for different materials.
    :param materials: Array of materials corresponding to the new outside diameters.
    :param new_outside_diameters: Array of new outside diameters to predict inside diameters for.
    :return: Array of predicted inside diameters.
    """
    new_outside_diameters = new_outside_diameters.astype(float)
    predictions = np.empty(len(new_outside_diameters))
    unique_materials = np.unique(materials)

    for material in unique_materials:
        # Indices where current material is present
        index_material = np.where(materials == material)[0]

        # Extracting diameter data for the material
        diameter_data = diameter_dict.get(material, None)
        if diameter_data is None:
            predictions[index_material] = np.nan  # Material not found
            continue

        # Extracting outside and inside diameters from the dictionary
        outside_diameters = np.array(list(diameter_data.keys())).astype(float)
        inside_diameters = np.array(list(diameter_data.values())).astype(float)

        # Fitting a polynomial (3rd degree) to the data
        coefficients = np.polyfit(outside_diameters, inside_diameters, 3)
        polynomial = np.poly1d(coefficients)

        # Valid range for diameters
        min_value, max_value = np.min(outside_diameters), np.max(outside_diameters)
        min_value, max_value = float(min_value), float(max_value)
        # Vectorized prediction for all diameters of the current material
        valid_indices = (new_outside_diameters[index_material] >= min_value) & (new_outside_diameters[index_material] <= max_value)
        invalid_indices = ~valid_indices

        # Predicting inside diameters
        predictions[index_material[valid_indices]] = polynomial(new_outside_diameters[index_material[valid_indices]])
        predictions[index_material[invalid_indices]] = np.nan  # Outside diameter out of range

        predictions[0] = predictions[1]  # to avoid error in sising
    return predictions


def get_sizing_int(m_ramales, ramal, xy_inter, ramal_value=None):
    """
    todavia se necesita modificar lo que hacen la derivacion para que acpete canales

    :param m_ramales:
    :param ramal:
    :param xy_inter:
    :return:
    """

    # DERIVACION
    derivacion_list = []
    for i in ramal.values():
        derivacion_index = np.where(m_ramales[i]["Derivacion"] == "Derivacion")[0]
        if len(derivacion_index) != len(m_ramales[i]["Derivacion"]) and len(derivacion_index) > 0:
            derivacion_list.append([str(i) + "." + str(_) for _ in derivacion_index])
    try:
        derivacion_list = np.concatenate(derivacion_list)
        ramal_derivacion_arr, pz_derivacion_arr = np.array([np.array(_.split(".")) for _ in derivacion_list]).T
    except:
        derivacion_list = np.array([])
        ramal_derivacion_arr, pz_derivacion_arr = [], []

    # check for specific ramal
    if ramal_value:
        lista_ramales = [ramal_value]
    else:
        lista_ramales = ramal.values()
    # dimensionamiento de secciones
    for i in lista_ramales:
        # check for new ramales
        index_new = np.char.equal(m_ramales[i]["Estado"], "nuevo").nonzero()[0]
        index_existing = np.char.equal(m_ramales[i]["Estado"], "existente").nonzero()[0]
        if index_new.size > 0:
            # indexar tipos de seccion
            secciones = np.unique(m_ramales[i]["Seccion"])

            empty_array = np.zeros(shape=len(m_ramales[i]["Estado"]), dtype="U256")
            m_ramales[i]["D_int"] = empty_array.copy()
            for seccion in secciones:
                index_seccion = np.char.equal(m_ramales[i]["Seccion"], seccion).nonzero()[0]
                if seccion in ["circular"]:
                    # array de diametros calculados
                    d_init_v = np.round(
                        seccion_init(
                            m_ramales[i]["q_accu"][index_seccion],
                            m_ramales[i]["Rug"][index_seccion],
                            m_ramales[i]["S"][index_seccion],
                            seccion,
                        ),
                        3,
                    )
                    nan_check = np.isnan(d_init_v).nonzero()[0]
                    if len(nan_check) > 0:
                        print("error", i)
                        sys.exit("Hay valores Nan en def -> get_sizing_int")

                    # diametro minimo segun requerimientos de usuario
                    D_min = m_ramales[i]["D_min"][index_seccion]

                    # diametro minimo segun parametros basicos
                    D_min = np.where(D_min > 0, D_min, par_basicos(D_min=1))

                    # array de diametros minimos definitivos
                    d_init_v = np.where(d_init_v <= D_min, D_min, d_init_v)

                    # verificacion que el diametro vaya de mayor a menor
                    m_ramales[i]["D_int"][index_seccion] = seccion_menor_mayor(d_init_v)

                    # dimensionar diametro interno
                    D_inter_sizing(m_ramales, i, index_seccion, "circular")

                    # modificar diametros asociados a metodos constructivosd-int
                    get_metodo_constructivo_max_diamenter(i, index_seccion, m_ramales, "D_int")

                    # verificacion de que los diametros del ramal vayan de menor a mayor despues del dimensionamiento interno
                    d_int_array_sort = seccion_menor_mayor(m_ramales[i]["D_int"][index_seccion])

                    # equivalencia de diametros entre materiales pvc y hs
                    d_int_translate = diameter_translate(d_int_array_sort, m_ramales[i]["Material"][index_seccion])

                    # asignar diametros equivalentes y transformados a array de diametro interno
                    m_ramales[i]["D_int"][index_seccion] = d_int_translate

                elif seccion in ["rectangular"]:
                    # array de diametros minimos
                    rec_init_b, rec_init_y = np.round(
                        seccion_init(
                            m_ramales[i]["q_accu"][index_seccion],
                            m_ramales[i]["Rug"][index_seccion],
                            m_ramales[i]["S"][index_seccion],
                            seccion,
                        ),
                        3,
                    )

                    # dimensionar para que quede h/D < valor predeterminado
                    rec_init_y = np.around(rec_init_y / 0.05) * 0.05
                    # diametro minimo segun requerimientos de usuario
                    y_min = m_ramales[i]["D_min"][index_seccion]
                    y_min_nan_index = np.isnan(y_min).nonzero()[0]
                    y_min[y_min_nan_index] = 0
                    rec_init_y = np.where(rec_init_y >= y_min, rec_init_y, y_min)

                    b_min = np.round(y_min / 1.5, 1)
                    rec_init_b = np.where(rec_init_b >= b_min, rec_init_b, b_min)

                    # verificar que vaya de menor a mayor la dimension h y b
                    rec_init_y = seccion_menor_mayor(rec_init_y)
                    rec_init_b = seccion_menor_mayor(rec_init_b)

                    # join BxY
                    string_array = np.stack([rec_init_b, rec_init_y], axis=1).astype(str)
                    rectangular_seccion = np.array(["x".join(_) for _ in string_array])
                    # set internal section
                    m_ramales[i]["D_int"][index_seccion] = rectangular_seccion

            # modificar diametros de derivacion
            if i in ramal_derivacion_arr:
                index_pos = np.where(ramal_derivacion_arr == i)
                ramal_arr, pz_arr = (
                    ramal_derivacion_arr[index_pos],
                    pz_derivacion_arr[index_pos],
                )

                for _pz, _ramal in zip(pz_arr, ramal_arr):
                    # "DIMENSIONAMIENTO DIAMETRO INICIAL"
                    d_init_derivacion = np.round(
                        seccion_init(
                            m_ramales[i]["q_accu"][int(_pz) + 1 :],
                            m_ramales[i]["Rug"][int(_pz) + 1 :],
                            m_ramales[i]["S"][int(_pz) + 1 :],
                        ),
                        3,
                    )
                    D_min_derivacion = m_ramales[i]["D_min"][int(_pz) + 1 :]
                    D_min_derivacion = np.where(
                        D_min_derivacion > par_basicos(D_min=1),
                        D_min_derivacion,
                        par_basicos(D_min=1),
                    )
                    d_init_derivacion = np.where(
                        d_init_derivacion <= D_min_derivacion,
                        D_min_derivacion,
                        d_init_derivacion,
                    )

                    m_ramales[i]["D_init"][int(_pz) + 1 :] = d_init_derivacion
                    m_ramales[i]["D_int"][int(_pz) + 1 :] = np.asarray([0.0] * len(d_init_derivacion))

                    # "VERIFICACION QUE DIAMETRO DE RAMAL VAYA DE MENOR A MAYOR"
                    if len(d_init_derivacion) > 1:
                        a = d_init_derivacion[:]
                        for k in np.where(a[0:-1] / a[1:] > 1)[0]:
                            a[k:][a[k:] <= a[k:][0]] = a[k:][0]
                        d_init_derivacion = a[:]
                        m_ramales[i]["D_init"][int(_pz) + 1 :] = d_init_derivacion
                        m_ramales[i]["D_int"][int(_pz) + 1 :] = np.asarray([0.0] * len(d_init_derivacion))

                    # "DIMENSIONAR DIAMETRO INTERNO"
                    D_inter_sizing_fromPz(m_ramales, i, _pz)

                    # IGUALAR DIAMETRO DE ALCANTARILLADO COMBINADO CON LA DESCARGA PLUVIAL
                    D_min_anterior = m_ramales[i]["D_int"][int(_pz)]
                    ramal_derivacion = m_ramales[i]["Obs"][int(_pz)].split(" ")[-1]
                    m_ramales[ramal_derivacion]["D_min"] = np.array([D_min_anterior] * len(m_ramales[ramal_derivacion]["D_min"]))

        # get int size for existing pipes
        if index_existing.size > 0:
            # indexar tipos de seccion
            secciones = np.unique(m_ramales[i]["Seccion"])
            # empty_array = np.zeros(shape=len(m_ramales[i]['Estado'])).astype('U256')
            empty_array = np.zeros(shape=len(m_ramales[i]["Estado"]), dtype="U256")
            m_ramales[i]["D_int"] = empty_array.copy()
            for seccion in secciones:
                index_seccion = np.char.equal(m_ramales[i]["Seccion"], seccion).nonzero()[0]
                if seccion in ["circular"]:
                    m_ramales[i]["D_ext"][0] = m_ramales[i]["D_ext"][1]
                    # array de diametros calculados
                    d_init_v = predict_inside_diameters(
                        diametro_interno_externo_pypiper,
                        m_ramales[i]["Material"][index_seccion],
                        m_ramales[i]["D_ext"][index_seccion],
                    )

                    # fill nan values
                    filtro_nan = np.isnan(d_init_v)
                    try:
                        d_init_v[filtro_nan.nonzero()] = m_ramales[i]["D_ext"][filtro_nan.nonzero()].astype(float)
                    except:
                        print("error:get_sizing_int")

                    # aqui no se hace niguna correcion porque son diametros existentes
                    m_ramales[i]["D_int"][index_seccion] = d_init_v

                elif seccion in ["rectangular"]:
                    # # array de diametros minimos
                    # rec_init_b, rec_init_y = np.round(seccion_init(m_ramales[i]['q_accu'][index_seccion], m_ramales[i]['Rug'][index_seccion], m_ramales[i]['S'][index_seccion], seccion), 3)
                    #
                    # # join BxY
                    # string_array = np.stack([rec_init_b, rec_init_y], axis=1).astype(str)
                    # rectangular_seccion = np.array(['x'.join(_) for _ in string_array])
                    # set internal section
                    m_ramales[i]["D_int"][index_seccion] = m_ramales[i]["D_ext"][index_seccion]

    # Conexiones
    conexionHacia, conexionDesde = xy_inter
    xy_inter1 = [k.split(".")[0] for k in conexionHacia]
    # verificar que los diametros de los afluentes sean menor o igual al efluente
    for k in ramal.values():
        # check for new ramales
        index_new = np.char.equal(m_ramales[k]["Estado"], "nuevo").nonzero()[0]
        if k in xy_inter1 and index_new.size > 0:
            # identificar la posicion de los pozos que entran al ramal
            iter1 = np.char.equal(xy_inter1, k).nonzero()

            iter2 = [xy_inter[1][_] for _ in iter1[0]]
            for m, n in zip(xy_inter[0][iter1], iter2):
                # ramales que llegan a tramo K en el pozo M
                ramal_arr, pz_arr = np.array([np.array(_.split(".")) for _ in n]).T
                secciones = np.array([m_ramales[_]["Seccion"][int(__)] for _, __ in zip(ramal_arr, pz_arr)])

                condicion_circular = secciones == "circular"
                indice_circular = condicion_circular.nonzero()[0]
                condicion_rectangular = secciones == "rectangular"
                indice_rectangular = condicion_rectangular.nonzero()[0]

                _ramal = m.split(".")[0]
                _pz = int(m.split(".")[1]) + 1

                if indice_circular.size > 0:
                    pz_arr_circular = pz_arr[indice_circular]
                    ramal_arr_circular = ramal_arr[indice_circular]
                    # diametros internos de ramales d ellegada
                    D_in_array = [m_ramales[_]["D_int"][int(__)] for _, __ in zip(ramal_arr_circular, pz_arr_circular)]

                    # check for not ciruclar section
                    D_in_array = seccion_str2float(D_in_array)
                    D_max = np.max(D_in_array)

                    # dimensionar diametro interno
                    materiales = set(m_ramales[_ramal]["Material"][_pz:])
                    for material in materiales:
                        # equivalencia de diametros de PVC y HS
                        D_max_translate = diameter_translate(D_max, material_out=material)
                        # tamaño de diametro
                        Dmin_int = D_ext(material)
                        index_diametro = np.where(Dmin_int >= D_max_translate)[0][0]
                        D_necesario = Dmin_int[index_diametro]

                        if _ramal in ramal_derivacion_arr:
                            index_pos = np.where(ramal_derivacion_arr == _ramal)
                            index_pz_pos = np.sort(pz_derivacion_arr[index_pos].astype(int))
                            derivacion_pos = (index_pz_pos > _pz).nonzero()[0]
                            if derivacion_pos.size > 0:
                                pz_start = _pz
                                pz_end = index_pz_pos[derivacion_pos[0]]
                                index_v = np.where(m_ramales[_ramal]["Material"] == material)[0]
                                index_v1 = np.where((index_v >= pz_start) & (index_v <= pz_end))[0]
                                cond = (m_ramales[_ramal]["D_int"][index_v1] < D_necesario).nonzero()[0]
                                index_v2 = index_v1[cond]
                                m_ramales[_ramal]["D_int"][index_v2] = D_necesario
                            else:
                                pz_start = _pz
                                pz_end = len(m_ramales[_ramal]["Pozo"]) - 1
                                index_v = np.where(m_ramales[_ramal]["Material"] == material)[0]
                                index_v1 = np.where((index_v >= pz_start) & (index_v <= pz_end))[0]
                                cond = (m_ramales[_ramal]["D_int"][index_v1] < D_necesario).nonzero()[0]
                                index_v2 = index_v[cond]
                                m_ramales[_ramal]["D_int"][index_v2] = D_necesario

                        else:
                            # get float array from interal section string array
                            d_int_array = seccion_str2float(m_ramales[_ramal]["D_int"])

                            index_material = np.where(m_ramales[_ramal]["Material"] == material)[0]
                            index_foward = np.where(index_material >= _pz)[0]
                            index_map = index_material[index_foward]
                            cond = (d_int_array[index_map] < D_necesario).nonzero()[0]
                            index_change = index_map[cond]

                            seccion_necesaria = seccion_remplazar_dimension(m_ramales[_ramal]["D_int"][index_change], D_necesario)
                            m_ramales[_ramal]["D_int"][index_change] = seccion_necesaria

    return m_ramales, ramal


def get_sizing_ext(m_ramales, ramal, ramal_value=None):
    # check for specific ramal
    if ramal_value:
        lista_ramales = [ramal_value]
    else:
        lista_ramales = ramal.values()

    for i in lista_ramales:
        # indice para modificar los tramos nuevos unicamente
        index = np.char.equal(m_ramales[i]["Estado"], "nuevo").nonzero()[0]
        if index.size > 0:
            m_ramales[i]["D_ext"] = np.zeros(shape=len(m_ramales[i]["D_int"])).astype("U256")
            secciones_array = m_ramales[i]["Seccion"].copy()
            secciones = np.unique(secciones_array)

            for seccion in secciones:
                index_seccion = np.char.equal(secciones_array, seccion).nonzero()[0]
                materiales = set(m_ramales[ramal[i]]["Material"][index_seccion])

                if seccion in ["circular"]:
                    for material in materiales:
                        index_material = np.where(m_ramales[i]["Material"][index_seccion] == material)[0]
                        index_seccion_material = index_seccion[index_material]

                        seccion_interior = m_ramales[i]["D_int"][index_seccion_material].astype(float).copy()
                        D_ext_v = D_int(seccion_interior, material)
                        # modificar diametros asociados a metodos constructivos
                        get_metodo_constructivo_max_diamenter(i, index_seccion, m_ramales, "D_ext")
                        np.put(m_ramales[i]["D_ext"], index_seccion_material, D_ext_v)

                elif seccion in ["rectangular"]:
                    for material in materiales:
                        index_material = np.where(m_ramales[i]["Material"][index_seccion] == material)[0]
                        index_seccion_material = index_seccion[index_material]

                        seccion_interior = m_ramales[i]["D_int"][index_seccion_material]
                        np.put(
                            m_ramales[i]["D_ext"],
                            index_seccion_material,
                            seccion_interior,
                        )

        else:
            m_ramales[i]["D_ext"][0] = m_ramales[i]["D_ext"][1]

    return m_ramales, ramal


"#######################################################################################################################"
"SECCION LLENA"
"#######################################################################################################################"


def Q_SLL(D_int, S, Rug, Seccion):
    q_sll_arr = np.zeros(D_int.shape[0])
    secciones = np.unique(Seccion)

    for _seccion in secciones:
        seccion_index = np.char.equal(Seccion, _seccion).nonzero()

        if _seccion in ["circular"]:
            q_sll_arr[seccion_index] = 0.312 / Rug[seccion_index] * D_int[seccion_index].astype(float) ** (8.0 / 3.0) * abs(S[seccion_index]) ** (1.0 / 2.0) * 1000.0

        elif _seccion in ["rectangular"]:
            b_arr, h_arr = pp_char_split(D_int[seccion_index], _split="x")
            b_arr, h_arr = b_arr.astype(float), h_arr.astype(float)
            Rh = (b_arr * h_arr) / (b_arr + (2 * h_arr))
            _A = h_arr * b_arr

            # VELOCIDAD
            _V = ((Rh ** (2.0 / 3.0)) * (S[seccion_index] ** (1.0 / 2.0))) / Rug[seccion_index]
            q_sll_arr[seccion_index] = 1000 * _V * _A  # multiplicado por 1000 para tener L/s

    return q_sll_arr


def V_SLL(D_int, S, Rug, Seccion):
    v_sll_arr = np.zeros(D_int.shape[0])
    secciones = np.unique(Seccion)

    for _seccion in secciones:
        seccion_index = np.char.equal(Seccion, _seccion).nonzero()

        if _seccion in ["circular"]:
            v_sll_arr[seccion_index] = 0.397 / Rug[seccion_index] * D_int[seccion_index].astype(float) ** (2.0 / 3.0) * abs(S[seccion_index]) ** (1.0 / 2.0)

        elif _seccion in ["rectangular"]:
            b_arr, h_arr = pp_char_split(D_int[seccion_index], _split="x")
            b_arr, h_arr = b_arr.astype(float), h_arr.astype(float)
            Rh = (b_arr * h_arr) / (b_arr + (2 * h_arr))
            v_sll_arr[seccion_index] = ((Rh ** (2.0 / 3.0)) * (abs(S[seccion_index]) ** (1.0 / 2.0))) / Rug[seccion_index]

    return v_sll_arr


def get_SLL(m_ramales, ramal, ramal_value=None):
    # check for specific ramal
    if ramal_value:
        lista_ramales = [ramal_value]
    else:
        lista_ramales = ramal.values()

    for i in lista_ramales:
        m_ramales[i]["Q_SLL"] = np.round(
            Q_SLL(
                m_ramales[i]["D_int"],
                m_ramales[i]["S"],
                m_ramales[i]["Rug"],
                m_ramales[i]["Seccion"],
            ),
            2,
        )
        m_ramales[i]["V_SLL"] = np.round(
            V_SLL(
                m_ramales[i]["D_int"],
                m_ramales[i]["S"],
                m_ramales[i]["Rug"],
                m_ramales[i]["Seccion"],
            ),
            2,
        )
    return m_ramales, ramal


"#######################################################################################################################"
"SECCION PARCIALMENTE LLENA"
"#######################################################################################################################"


def rectangular_SPLL_minimize(y_arr, b_arr, S, Rug, q_accu):
    q_model = (((((b_arr * y_arr) / (b_arr + (2 * y_arr))) ** (2.0 / 3.0)) * (S ** (1.0 / 2.0))) / Rug) * (y_arr * b_arr)
    ssq_residuals = np.sum((q_model - (q_accu / 1000.0)) ** 2)
    return ssq_residuals


def ang_SPLL_minimize(ang_v, q_accu, Q_SLL_v):
    model = (ang_v / 360.0 - np.sin(np.radians(ang_v)) / (2 * np.pi)) * (1 - 360 * np.sin(np.radians(ang_v)) / (2 * np.pi * ang_v)) ** (2.0 / 3.0)
    return model - (q_accu / Q_SLL_v)


def rectangular_SPLL_root(y_arr, b_arr, S, Rug, q_accu):
    q_model = (((((b_arr * y_arr) / (b_arr + (2 * y_arr))) ** (2.0 / 3.0)) * (S ** (1.0 / 2.0))) / Rug) * (y_arr * b_arr)
    return q_model - (q_accu / 1000.0)


def ang_SPLL_root(ang_v, q_accu, Q_SLL_v):
    model = (ang_v / 360.0 - np.sin(np.radians(ang_v)) / (2 * np.pi)) * (1 - 360 * np.sin(np.radians(ang_v)) / (2 * np.pi * ang_v)) ** (2.0 / 3.0)
    return model - (q_accu / Q_SLL_v)


def v_rectangular_SPLL(Rh, S, Rug):
    return ((Rh ** (2.0 / 3.0)) * (S ** (1.0 / 2.0))) / Rug


def v_SPLL(ang_v):
    return (1 - 360.0 * np.sin(np.radians(ang_v)) / (2 * np.pi * ang_v)) ** (2.0 / 3.0)


def h_SPLL(ang_v):
    return 0.5 * (1 - np.cos(np.radians(ang_v / 2.0)))


def get_SPLL(m_ramales, ramal, ramal_value=None):
    """
     funcion que halla las raices de las ecucaiones de secciones circulares (ang) y rectangulares (y)

    :param m_ramales:
    :param ramal:
    :param i:
    :return:
    """
    if ramal_value:
        lista_ramales = [ramal_value]
    else:
        lista_ramales = ramal.values()

    for i in lista_ramales:
        empty_array = np.zeros(shape=len(m_ramales[i]["Pozo"]), dtype=float)
        # crear arrays vacios para llenar con un index
        m_ramales[i]["ang"] = empty_array.copy()
        m_ramales[i]["q/Q"] = empty_array.copy()
        m_ramales[i]["h/D"] = empty_array.copy()
        m_ramales[i]["v/V"] = empty_array.copy()
        m_ramales[i]["h"] = empty_array.copy()
        m_ramales[i]["v"] = empty_array.copy()

        Seccion = m_ramales[i]["Seccion"]
        secciones = np.unique(Seccion)
        # modificar los ceros en el caudal para evitar errores en la minimizacion
        q_accu_array = m_ramales[i]["q_accu"].copy()
        cond_q_accu = m_ramales[i]["q_accu"] == 0
        cond_q_accu_invertida = np.invert(cond_q_accu)
        q_accu_array[cond_q_accu] = 0.001

        for _seccion in secciones:
            seccion_index = np.char.equal(Seccion, _seccion).nonzero()[0]
            if _seccion in ["circular"]:
                seccion_index_circular = np.trim_zeros(seccion_index)
                # find roots
                try:
                    ang_v = np.array(
                        [
                            opt.brentq(
                                ang_SPLL_root,
                                1,
                                10000,
                                xtol=1e-3,
                                args=(q_accu_array[_], m_ramales[i]["Q_SLL"][_]),
                            )
                            for _ in seccion_index_circular
                        ]
                    )
                except Exception as e:
                    ang_v = np.array(
                        [
                            opt.root(
                                ang_SPLL_root,
                                1,
                                args=(q_accu_array[_], m_ramales[i]["Q_SLL"][_]),
                                method="hybr",
                            ).x[0]
                            for _ in seccion_index_circular
                        ]
                    )

                ang_v[ang_v >= 360] = 360
                # Llenar arrays de resultados hidraulicos
                cond_fix_zero = cond_q_accu_invertida[seccion_index_circular]
                m_ramales[i]["ang"][seccion_index_circular] = ang_v * cond_fix_zero
                m_ramales[i]["q/Q"][seccion_index_circular] = (
                    np.round(
                        m_ramales[i]["q_accu"][seccion_index_circular] / m_ramales[i]["Q_SLL"][seccion_index_circular],
                        3,
                    )
                    * cond_fix_zero
                )
                m_ramales[i]["h/D"][seccion_index_circular] = np.round(h_SPLL(ang_v), 3) * cond_fix_zero
                m_ramales[i]["v/V"][seccion_index_circular] = np.round(v_SPLL(ang_v), 3) * cond_fix_zero
                m_ramales[i]["h"][seccion_index_circular] = (
                    np.round(
                        m_ramales[i]["h/D"][seccion_index_circular] * m_ramales[i]["D_int"][seccion_index_circular].astype(float),
                        3,
                    )
                    * cond_fix_zero
                )
                m_ramales[i]["v"][seccion_index_circular] = (
                    np.round(
                        m_ramales[i]["v/V"][seccion_index_circular] * m_ramales[i]["V_SLL"][seccion_index_circular],
                        3,
                    )
                    * cond_fix_zero
                )

            elif _seccion in ["rectangular"]:
                # indice de seccion rectangular del tramo i
                seccion_index_rectangular = np.trim_zeros(seccion_index)
                # base y altura de la seccion, por defecto son str
                b_arr, h_arr = pp_char_split(m_ramales[i]["D_int"][seccion_index_rectangular], _split="x")
                b_arr, h_arr = b_arr.astype(float), h_arr.astype(float)
                b_v = np.zeros(shape=len(m_ramales[i]["D_int"]))
                b_v[seccion_index_rectangular] = b_arr
                # find root
                try:
                    y_arr = np.array(
                        [
                            opt.brentq(
                                rectangular_SPLL_root,
                                0.001,
                                b_v[_] * 5,
                                xtol=1e-3,
                                args=(
                                    b_v[_],
                                    m_ramales[i]["S"][_],
                                    m_ramales[i]["Rug"][_],
                                    q_accu_array[_],
                                ),
                            )
                            for _ in seccion_index_rectangular
                        ]
                    )
                except:
                    y_arr = np.array(
                        [
                            opt.root(
                                rectangular_SPLL_root,
                                0.05,
                                args=(
                                    b_v[_],
                                    m_ramales[i]["S"][_],
                                    m_ramales[i]["Rug"][_],
                                    q_accu_array[_],
                                ),
                                method="hybr",
                            ).x[0]
                            for _ in seccion_index_rectangular
                        ]
                    )

                # Radio hidraulico, pendiente, rugosidad,
                Rh = (b_arr * y_arr) / (b_arr + (2 * y_arr))
                S = m_ramales[i]["S"][seccion_index_rectangular]
                Rug = m_ramales[i]["Rug"][seccion_index_rectangular]
                # Velocidad de seccion parcialmente llena
                v = v_rectangular_SPLL(Rh, S, Rug)
                # Llenar arrays de resultados hidraulicos
                m_ramales[i]["q/Q"][seccion_index_rectangular] = np.round(
                    m_ramales[i]["q_accu"][seccion_index_rectangular] / m_ramales[i]["Q_SLL"][seccion_index_rectangular],
                    3,
                )
                m_ramales[i]["h/D"][seccion_index_rectangular] = y_arr / h_arr
                m_ramales[i]["v/V"][seccion_index_rectangular] = np.round(v / m_ramales[i]["V_SLL"][seccion_index_rectangular], 3)
                m_ramales[i]["h"][seccion_index_rectangular] = np.round(y_arr, 3)
                m_ramales[i]["v"][seccion_index_rectangular] = np.round(v, 3)

    return m_ramales, ramal


"######################################################################################################################"
"DIMENSIONAMIENTO SECCION PARCIALMENTE LLENA"
"######################################################################################################################"


def check_in_out_size(m_ramales, ramal, xy_inter, xy_inter1):
    # Conexiones
    conexionHacia, conexionDesde = xy_inter

    for k in ramal.values():
        # check for new ramales
        index_new = np.char.equal(m_ramales[k]["Estado"], "nuevo").nonzero()[0]
        if k in xy_inter1 and index_new.size > 0:
            # identificar la posicion de los pozos que entran al ramal
            iter1 = np.char.equal(xy_inter1, k).nonzero()[0]
            conexionHacia_index, conexionDesde_index = conexionHacia[iter1], [conexionDesde[_] for _ in iter1]

            for m, n in zip(conexionHacia_index, conexionDesde_index):
                # ramales que llegan a tramo k en el pozo m
                ramal_arr, pz_arr = np.array([np.array(_.split(".")) for _ in n]).T

                secciones = np.array([m_ramales[_]["Seccion"][int(__)] for _, __ in zip(ramal_arr, pz_arr)])
                condicion_circular = secciones == "circular"
                indice_circular = condicion_circular.nonzero()[0]
                condicion_rectangular = secciones == "rectangular"
                indice_rectangular = condicion_rectangular.nonzero()[0]

                _ramal = m.split(".")[0]
                _pz = int(m.split(".")[1]) + 1

                if indice_circular.size > 0:
                    ramal_arr_circular, pz_arr_circular = ramal_arr[indice_circular], pz_arr[indice_circular]
                    # diametros internos de los ramales de llegada
                    D_in_array = [m_ramales[_]["D_int"][int(__)] for _, __ in zip(ramal_arr_circular, pz_arr_circular)]
                    # check for not ciruclar section
                    D_in_array = seccion_str2float(D_in_array)
                    D_max = np.max(D_in_array)

                    _ramal = m.split(".")[0]
                    _pz = int(m.split(".")[1]) + 1
                    # "dimensionar diametro interno"
                    materiales = set(m_ramales[_ramal]["Material"][_pz:])
                    for material in materiales:
                        # transformacion y equivalencia entre diametro de pvc y hs
                        D_max_translate = diameter_translate(D_max, material_out=material)

                        # get diameter size
                        Dmin_int = D_ext(material)
                        index_diametro = np.where(Dmin_int >= D_max_translate)[0][0]
                        D_necesario = Dmin_int[index_diametro]

                        # get float array from interal section string array
                        d_int_array = seccion_str2float(m_ramales[_ramal]["D_int"])

                        index_material = np.where(m_ramales[_ramal]["Material"] == material)[0]
                        index_foward = np.where(index_material >= _pz)[0]
                        index_map = index_material[index_foward]
                        cond = (d_int_array[index_map] < D_necesario).nonzero()[0]
                        index_change = index_map[cond]

                        seccion_necesaria = seccion_remplazar_dimension(m_ramales[_ramal]["D_int"][index_change], D_necesario)
                        m_ramales[_ramal]["D_int"][index_change] = seccion_necesaria


def get_sizing_SPLL(m_ramales, ramal, xy_inter):
    # Conexiones
    conexionHacia, conexionDesde = xy_inter

    # get Froude values
    m_ramales, ramal = hydraulic_conditions(m_ramales, ramal)

    # map_calado_dict = {"critico": 0.70, "sub-critico": 0.75, "super-critico": 0.7, "": 0.75, }

    # # ubicar tramos con h/d >= valor predeterminado
    # h_D_dict = {ii: np.where(m_ramales[ii]["h/D"] >= par_basicos(h_D_max=1))[0] for ii in ramal.values() if len(np.where(m_ramales[ii]["h/D"] >= par_basicos(h_D_max=1))[0]) > 0 and "nuevo" in m_ramales[ii]["Estado"]}
    h_D_dict = get_h_D_dict(m_ramales)

    #  ramales donde existen conexiones de otros ramales
    xy_inter1 = [k.split(".")[0] for k in conexionHacia]

    cont = 0
    while len(h_D_dict) > 0 and cont < 100:
        for i in h_D_dict.keys():
            # check for new ramales
            index_new = np.char.equal(m_ramales[i]["Estado"], "nuevo").nonzero()[0]
            index_existing = np.char.equal(m_ramales[i]["Estado"], "existente").nonzero()[0]
            if index_new.size > 0:
                # indexar tipos de seccion
                secciones = np.unique(m_ramales[i]["Seccion"])
                for seccion in secciones:
                    index_seccion = np.char.equal(m_ramales[i]["Seccion"], seccion).nonzero()[0]
                    if seccion in ["circular"]:
                        materiales = set(m_ramales[i]["Material"][index_seccion])
                        for material in materiales:
                            # indice de tramos con h/D => Valor predeterminado
                            index_change = np.intersect1d(h_D_dict[i], index_seccion)
                            # selecionar indice de material similar
                            index_material = np.where(m_ramales[i]["Material"][index_change] == material)[0]
                            # cuando se cambia material para disminuir velocidad este indice queda vacio, entonces si pasa esto solo se continua el for loop
                            if len(index_material) == 0:
                                seccion_control = False
                                continue
                            # array de diametros del material
                            Dmin_int = D_ext(material)
                            # diametros a modificar
                            index_map_to_otiginal = index_change[index_material]
                            D_old = m_ramales[i]["D_int"][index_map_to_otiginal].copy()

                            # diametros modificados
                            index_search = np.searchsorted(Dmin_int, D_old) + 1

                            if np.max(index_search) < Dmin_int.size:
                                D_new = Dmin_int[index_search]
                                np.put(m_ramales[i]["D_int"], index_map_to_otiginal, D_new)
                                seccion_control = False
                            else:
                                # print("aqui", i)

                                index_change_seccion = np.where(index_search >= Dmin_int.size)[0]
                                index_change_seccion = index_map_to_otiginal[index_change_seccion]
                                m_ramales[i]["Material"][index_change_seccion] = "HA"
                                m_ramales[i]["Seccion"][index_change_seccion] = "rectangular"
                                m_ramales[i]["ang"][index_change_seccion] = 0
                                seccion_control = True

                                break

                        # break for loop if a section is changed
                        if seccion_control:
                            break
                        # "verificacion que diametro de ramal vaya de menor a mayor"
                        d_int_array = seccion_menor_mayor(m_ramales[i]["D_int"][index_seccion])
                        # transformacion y equivalencia entre diametro de pvc y hs
                        d_int_translate = diameter_translate(d_int_array, m_ramales[i]["Material"][index_seccion])
                        # asignar diametros equivalentes a array de diametro interno
                        m_ramales[i]["D_int"][index_seccion] = d_int_translate

                    elif seccion in ["rectangular"]:
                        # indice de tramos con h/D => Valor predeterminado
                        index_change = np.intersect1d(h_D_dict[i], index_seccion)

                        # array de dimensiones del canal
                        b_array, h_array = pp_char_split(m_ramales[i]["D_ext"], _split="x")
                        b_array, h_array = b_array.astype(float), h_array.astype(float)
                        # cantidades necesaria para dimensionar calado
                        pendiente = m_ramales[i]["S"]
                        manning = m_ramales[i]["Rug"]
                        q = m_ramales[i]["q_accu"]

                        # obtener el calado
                        try:
                            y_array = np.array(
                                [
                                    opt.brentq(
                                        rectangular_SPLL_root,
                                        0.001,
                                        b_array[_] * 5,
                                        xtol=1e-3,
                                        args=(
                                            b_array[_],
                                            pendiente[_],
                                            manning[_],
                                            q[_],
                                        ),
                                    )
                                    for _ in index_change
                                ]
                            )
                        except Exception as e:
                            y_array = np.array(
                                [
                                    opt.root(
                                        rectangular_SPLL_root,
                                        0.05,
                                        args=(
                                            b_array[_],
                                            pendiente[_],
                                            manning[_],
                                            q[_],
                                        ),
                                        method="hybr",
                                    ).x[0]
                                    for _ in index_change
                                ]
                            )

                        # previus_heigth = h_array[index_change].copy()
                        previus_heigth = h_array.copy()
                        if len(index_change) > 0:
                            froude_number = pd.Series(m_ramales[i]["Froude"]).map(map_calado_dict).to_numpy()
                            factor = 1 + (1 - froude_number)
                            # nuevo seccion de canal (h)
                            h_array[index_change] = np.round(y_array * factor[index_change] / 0.05) * 0.05 + 0.10
                            tol = tol = 1e-6
                            resize_index = np.nonzero(h_array[index_change] <= (previus_heigth[index_change] + tol))[0]

                            if len(resize_index) > 0:
                                map_index = index_change[resize_index]
                                # h_array[map_index] = h_array[map_index] + 0.05
                                h_array[map_index] = previus_heigth[map_index] + 0.05

                            # verificar que vaya de menor a mayor la dimension h y b
                            h_array[index_seccion] = seccion_menor_mayor(h_array[index_seccion])
                            b_array[index_seccion] = seccion_menor_mayor(b_array[index_seccion])

                            # join BxY
                            string_array = np.stack([b_array, h_array], axis=1).astype(str)
                            rectangular_seccion = np.array(["x".join(_) for _ in string_array])
                            # set internal section
                            m_ramales[i]["D_int"][index_seccion] = rectangular_seccion[index_seccion]

            if index_existing.size > 0:
                print("Pass")

        # verificar que los diametros de los afluentes sean menor o igual al efluente
        check_in_out_size(m_ramales, ramal, xy_inter, xy_inter1)

        # "asignar diametros externos, caudal y velocidad seccion llena, dimensionamiento en seccion parcialmente llena"
        m_ramales, ramal = get_sizing_ext(m_ramales, ramal)
        m_ramales, ramal = get_SLL(m_ramales, ramal)
        m_ramales, ramal = get_SPLL(m_ramales, ramal)

        h_D_dict = get_h_D_dict(m_ramales)

        cont = cont + 1

    if cont >= 20:
        print(h_D_dict)
        sys.exit("error def get_sizing_SPLL")

    return m_ramales, ramal


def get_h_D_dict(m_ramales):
    map_calado_dict = {"critico": 0.65, "sub-critico": 0.65, "super-critico": 0.65, "": 0.65, }
    is_close_percentage = 0.05

    h_D_dict = {}
    for ii in m_ramales.keys():
        if "nuevo" in m_ramales[ii]["Estado"]:
            Froude_value = m_ramales[ii]["Froude"]  # Get the Froude value
            h_D_max = pd.Series(Froude_value).map(map_calado_dict).to_numpy()  # Map Froude to h/D threshold

            h_D_values = m_ramales[ii]["h/D"]
            # condition = (h_D_values >= h_D_max) | (np.isclose(h_D_values, h_D_max, atol=h_D_max * is_close_percentage ))
            condition = np.invert((h_D_values <= h_D_max) | (np.isclose(h_D_values, h_D_max, rtol=is_close_percentage)))

            h_D_dict[ii] = np.where(condition)[0]

            # Only keep entries where there are any matching values
            if len(h_D_dict[ii]) == 0:
                del h_D_dict[ii]

    return h_D_dict


"######################################################################################################################"
"ASIGNAR ELEVACIONES Y ALTURAS DE POZO "
"######################################################################################################################"


def get_pz_init(m_ramales, ramal):
    for i in ramal.values():
        if not np.any(np.char.equal(m_ramales[i]["Estado"], "nuevo")):
            continue

        # Ground elevations
        m_ramales[i]["ZTI"] = np.insert(m_ramales[i]["Z"][0:-1], 0, 0)
        m_ramales[i]["ZTF"] = np.insert(m_ramales[i]["Z"][1:], 0, 0)

        # Get external section dimensions
        seccion_externa = seccion_str2float(m_ramales[i]["D_ext"])

        # Calculate elevation changes due to slope
        dif_z = np.cumsum(m_ramales[i]["L"] * m_ramales[i]["S"])

        # Initial calculations
        elevacion_tapa_inicial = m_ramales[i]["Z"][0]
        cobertura_minima = par_basicos(h_min=True)

        # Minimum depths calculations
        min_cover_depth = np.where(np.logical_and(~np.isnan(m_ramales[i]["cobertura_min"]), m_ramales[i]["cobertura_min"] > 0), m_ramales[i]["cobertura_min"], cobertura_minima)

        min_manhole_depth = min_cover_depth + seccion_externa

        # Initial bottom elevation and depths
        zfondo_inicial = elevacion_tapa_inicial - min_manhole_depth[0]
        zfondo_v = zfondo_inicial - dif_z

        # Set initial elevations
        m_ramales[i]["ZFI"] = np.insert(zfondo_v[0:-1], 0, 0)
        m_ramales[i]["ZFF"] = np.insert(zfondo_v[1:], 0, 0)
        m_ramales[i]["HI"] = m_ramales[i]["ZTI"] - m_ramales[i]["ZFI"]
        m_ramales[i]["HF"] = m_ramales[i]["ZTF"] - m_ramales[i]["ZFF"]
        m_ramales[i]["SALTO"] = np.zeros_like(m_ramales[i]["HI"])

        # update elvations
        m_ramales = w_TFP(i, m_ramales)

    return m_ramales, ramal


def w_TFP(i, m_ramales):
    """
    Calcula alturas y elevaciones modificadas de pozos según las pendientes,
    considerando tanto Pozo_hmin como cobertura_min
    """
    dif_z = np.cumsum(m_ramales[i]["L"] * m_ramales[i]["S"])

    if isinstance(m_ramales[i].get("ZTI"), np.ndarray):
        zfondo_v = m_ramales[i]["ZFI"][1] - dif_z - np.cumsum(m_ramales[i]["SALTO"])
    else:
        seccion_altura = seccion_str2float(m_ramales[i]["D_ext"])

        # Considerar el máximo entre cobertura_min y Pozo_hmin
        cobertura_min = np.where((m_ramales[i]["cobertura_min"] <= 0.0) | np.isnan(m_ramales[i]["cobertura_min"]), par_basicos(h_min=1), m_ramales[i]["cobertura_min"])

        pozo_hmin = m_ramales[i]["Pozo_hmin"]
        initial_depth = np.where(~np.isnan(pozo_hmin), np.maximum(pozo_hmin, cobertura_min), cobertura_min)

        zfondo_v = (m_ramales[i]["ZTI"][1] - initial_depth[1] - seccion_altura[1]) - dif_z
    m_ramales[i]["ZFI"] = np.insert(zfondo_v[0:-1], 0, 0)
    m_ramales[i]["ZFF"] = np.insert(zfondo_v[1:], 0, 0)
    m_ramales[i]["HI"] = m_ramales[i]["ZTI"] - m_ramales[i]["ZFI"]
    m_ramales[i]["HF"] = m_ramales[i]["ZTF"] - m_ramales[i]["ZFF"]

    # Identify points that need adjustment using isclose
    # pozo_hmin = np.roll(np.nan_to_num(m_ramales[i]['Pozo_hmin']), 1)
    pozo_hmin = np.insert(np.nan_to_num(m_ramales[i]["Pozo_hmin"][:-1]), 0, 0)
    mask_adjust = ~np.isclose(m_ramales[i]["HI"], pozo_hmin, rtol=1e-2) & (m_ramales[i]["HI"] < pozo_hmin)
    mask_adjust[0] = False
    if np.any(mask_adjust):
        adjust_indices = np.where(mask_adjust)[0]
        for idx in adjust_indices:
            new_bottom = m_ramales[i]["ZTI"][idx] - pozo_hmin[idx]
            downstream_dif = np.cumsum(m_ramales[i]["L"][idx:] * m_ramales[i]["S"][idx:])
            new_bottom_profile = new_bottom - downstream_dif

            m_ramales[i]["ZFI"][idx:] = np.insert(new_bottom_profile[:-1], 0, new_bottom)
            m_ramales[i]["ZFF"][idx:] = new_bottom_profile
            m_ramales[i]["HI"][idx:] = m_ramales[i]["ZTI"][idx:] - m_ramales[i]["ZFI"][idx:]
            m_ramales[i]["HF"][idx:] = m_ramales[i]["ZTF"][idx:] - m_ramales[i]["ZFF"][idx:]

    salto = m_ramales[i]["HI"][1:] - m_ramales[i]["HF"][:-1]
    salto[0] = 0
    m_ramales[i]["SALTO"][1:] = salto
    return m_ramales


def check_existing_pz(m_ramales, ramal, xy_inter):
    val_break = np.sum([len(m_ramales[_]["Pozo"]) for _ in m_ramales.keys()]) * 20
    # revisar la llegada de ramales nuevo a existentes
    for i in ramal.values():
        # indice para modificar los tramos nuevos unicamente
        index = np.char.equal(m_ramales[i]["Estado"], "nuevo").nonzero()[0]
        derivacion = m_ramales[i]["Derivacion"][-1]
        if index.size > 0 and not derivacion:
            # check for conection From and To existing pz
            conexionDesde, conexionHacia = m_ramales[i]["Conexion"][[0, -1]]

            if conexionHacia is not None:
                checkHacia = [_ for _ in conexionHacia.split(",") if "existente" in m_ramales[_.split(".")[0]]["Estado"]]
                if len(checkHacia) == 0:
                    conexionHacia = None
                else:
                    conexionHacia = ",".join(checkHacia)
            else:
                checkHacia = []

            if conexionDesde is not None:
                checkDesde = [_ for _ in conexionDesde.split(",") if "existente" in m_ramales[_.split(".")[0]]["Estado"]]
                if len(checkDesde) == 0:
                    conexionDesde = None
                else:
                    conexionDesde = ",".join(checkDesde)
            else:
                checkDesde = []

            check_list = checkDesde + checkHacia
            if len(check_list) > 0:
                # case 1: conexionDesde: None, conexionHacia: existing
                if conexionDesde is None and conexionHacia is not None:
                    # get minimum elevation in conexionHacia  pz
                    conexionHacia_Pz = conexionHacia.split(",")
                    min_elevation_pz = []
                    for pz in conexionHacia_Pz:
                        _ramal, _pos = pz.split(".")
                        min_elevation_pz.append(m_ramales[_ramal]["ZFI"][int(_pos) + 1])
                    min_elevation_index = np.argmin(min_elevation_pz)
                    min_elevation_pz = np.min(min_elevation_pz)

                    # compare minimun elevation to m_ramales[i][ZFF][-1], if min elevation is below m_ramales[i][ZFF][-1] do nothing
                    if min_elevation_pz > m_ramales[i]["ZFF"][-1]:
                        cond_cont = 0
                        # 2 es el número de tramos que se permite modificar para llegar a la elevacion del pozo existente
                        cond_len = len(m_ramales[i]["ZFF"]) - 1
                        cond_pos = cond_len
                        while cond_cont < cond_len:
                            # compare minimun elevation to m_ramales[i][ZFF][-1], if min elevation is below m_ramales[i][ZFF][-1] do nothing
                            if min_elevation_pz > m_ramales[i]["ZFF"][-1]:
                                # diferencia de altura simepre se compara con el último tramo porque ya se modificó las laturas en W_TFP
                                if cond_cont == 0:
                                    # diferencia de altura disponible entre la elevacion de inicio del ultimo tramo y la elevacion del pozo existente
                                    diff_z = m_ramales[i]["ZFI"][-1] - min_elevation_pz
                                    # availbale slope
                                    s_disponible = np.round((diff_z / m_ramales[i]["L"][cond_pos]), 3) - 0.001
                                else:
                                    # diferencia de elevacion necesaria a disminuir
                                    diff_z_necesaria = m_ramales[i]["ZFF"][-1] - min_elevation_pz
                                    # disminucion de pendiente en tramo cond_pos
                                    s_necesaria = np.round(
                                        (diff_z_necesaria / m_ramales[i]["L"][cond_pos]),
                                        3,
                                    )
                                    # available slope
                                    s_disponible = m_ramales[i]["S"][cond_pos] - abs(s_necesaria)
                                # decidir si se usa la pendinete dipsonible o la minima
                                try:
                                    smin = Smin(
                                        [m_ramales[i]["Material"][cond_pos]],
                                        m_ramales,
                                        i=i,
                                        j=cond_pos,
                                    )
                                    s_new = s_disponible if s_disponible > smin else smin
                                except:
                                    print("error check_existing_pz")

                                # asignar pendiente
                                m_ramales[i]["S"][cond_pos] = s_new

                                # actualziar elevaciones y profunidades
                                m_ramales = w_TFP(i, m_ramales)
                                # m_ramales = update_elevations(i, m_ramales, cond_pos)

                                # actualizar contador de condicion
                                cond_cont = cond_cont + 1
                                cond_pos = cond_pos - 1

                            # si la elevacion del pozo existente es menor a la del ramal nuevo, entonces temrinar while loop
                            if min_elevation_pz < m_ramales[i]["ZFF"][-1]:
                                # la condicion de la tuberia nueva llegar por encima a la tuberia existente se cumple, modificar contador para salir del while loop
                                cond_cont = cond_len
                                if cond_cont > 2:
                                    print(
                                        "REVISAR TRAMO POR COBERTURAS MINIMAS: ",
                                        m_ramales[i]["Ramal"][0],
                                    )
                            else:
                                if cond_cont >= 3:
                                    diff_val = min_elevation_pz - m_ramales[i]["ZFF"][-1]
                                    print(
                                        "ERROR:",
                                        m_ramales[i]["Ramal"],
                                        " esta mas abajo que ",
                                        conexionHacia_Pz[min_elevation_index],
                                        f"({round(diff_val, 3)} m)",
                                    )
                                    shp_out(m_ramales, ramal, project_name)
                                    cad_profile_out(
                                        m_ramales,
                                        ramal,
                                        project_name,
                                        elev_source=elev_source,
                                        step=5,
                                    )

                                    sys.exit("ERROR")

                # case 2: conexionDesde: existing, conexionHacia: None
                elif conexionDesde is not None and conexionHacia is None:
                    # get minimum elevation in conexionDesde  pz
                    conexionDesde_Pz = conexionDesde.split(",")
                    min_elevation_pz = []
                    for pz in conexionDesde_Pz:
                        _ramal, _pos = pz.split(".")
                        min_elevation_pz.append(m_ramales[_ramal]["ZFF"][int(_pos)])
                    min_elevation_pz = np.min(min_elevation_pz)

                    # check if elevation is already the same
                    if m_ramales[i]["ZFI"][1] <= min_elevation_pz:
                        continue

                    # asignar elevacion minima a inicio de pozo
                    m_ramales[i]["ZFI"][1] = min_elevation_pz
                    # revisar la pendiente disponible entre el pozo inicial y final del tramo m_ramales[i][1]
                    diff_z = m_ramales[i]["ZFI"][1] - m_ramales[i]["ZFF"][1]
                    s_disponible = np.round((diff_z / m_ramales[i]["L"][1]), 3) - 0.001
                    smin = Smin([m_ramales[i]["Material"][1]], m_ramales, i=i, j=1)
                    smin_usuario = np.nan_to_num(m_ramales[i]["S_min"][1])
                    smin = np.max([smin_usuario, smin[0]])

                    s_new = s_disponible if s_disponible > smin else smin

                    # asignar pendiente
                    m_ramales[i]["S"][1] = s_new
                    # m_ramales = w_TFP(i, m_ramales)
                    # update elevations
                    m_ramales = update_elevations(i, m_ramales, 1)

                    # 'OPTIMIZAR: DISMINUIR ALTURA DE EXCAVACION MODIFICANDO PENDIENTES'
                    m_ramales = get_opt_S1(i, m_ramales, val_break)
                    # # 'OPTIMIZAR: REVISAR ALTURA MINIMA DE EXCAVACION MODIFICANDO PENDIENTES'
                    m_ramales = get_opt_S2(i, m_ramales, val_break)

                # case 3: conexionDesde: existing, conexionHacia: existing
                elif conexionDesde is not None and conexionHacia is not None:
                    # get minimum elevation in conexionDesde
                    conexionDesde_Pz = conexionDesde.split(",")
                    min_elevation_Desde = []
                    for pz in conexionDesde_Pz:
                        _ramal, _pos = pz.split(".")
                        min_elevation_Desde.append(m_ramales[_ramal]["ZFF"][int(_pos)])
                    min_elevation_Desde = np.min(min_elevation_Desde)

                    # check if elevation is already the same
                    if m_ramales[i]["ZFI"][1] == min_elevation_Desde:
                        continue
                    # asignar la elevacion de pozo inicial
                    m_ramales[i]["ZFI"][1] = min_elevation_Desde

                    # revisar si el primer tramo nuevo se conecta a una tuberia existente o a un ramal nuevo
                    if len(m_ramales[i]["Tramo"]) == 2:
                        min_ramal, min_pz = conexionHacia.split(".")
                        if min_pz == "0":
                            min_pz = int(min_pz) + 1
                            diff_z = m_ramales[i]["ZFI"][1] - m_ramales[min_ramal]["ZFI"][min_pz]
                        else:
                            min_pz = int(min_pz)
                            diff_z = m_ramales[i]["ZFI"][1] - m_ramales[min_ramal]["ZFF"][min_pz]
                        existing_check = True
                    else:
                        diff_z = m_ramales[i]["ZFI"][1] - m_ramales[i]["ZFF"][1]
                        existing_check = False

                    # revisar si la elevacion del tramo existente del inicio no cambia de signo la pendiente del primero tramo nuevo
                    s_disponible = np.round(diff_z / m_ramales[i]["L"][1], 3) - 0.001
                    smin = Smin([m_ramales[i]["Material"][1]], m_ramales)
                    smin_usuario = np.nan_to_num(m_ramales[i]["S_min"][1])
                    smin = np.max([smin_usuario, smin])
                    s_new = s_disponible if s_disponible > smin else smin

                    # asignar pendiente nueva
                    m_ramales[i]["S"][1] = s_new
                    # update elevations
                    # m_ramales = w_TFP(i, m_ramales)
                    m_ramales = update_elevations(i, m_ramales, 1)

                    # revisar si el cambio de pendiente no afecta aguas abajo
                    if diff_z > 0 and s_new > smin:
                        # 'OPTIMIZAR: DISMINUIR ALTURA DE EXCAVACION MODIFICANDO PENDIENTES'
                        m_ramales = get_opt_S1(i, m_ramales, val_break)
                        # 'OPTIMIZAR: REVISAR ALTURA MINIMA DE EXCAVACION MODIFICANDO PENDIENTES'
                        m_ramales = get_opt_S2(i, m_ramales, val_break)
                    else:
                        if not existing_check:
                            # 'OPTIMIZAR: DISMINUIR ALTURA DE EXCAVACION MODIFICANDO PENDIENTES'
                            m_ramales = get_opt_S1(i, m_ramales, val_break)
                        else:
                            # si se conecta directo a un ramal existente no es posible modificar los tramos nuevos agua abajo
                            print(
                                "ERROR:",
                                m_ramales[i]["Ramal"],
                                " esta mas abajo que ",
                                min_ramal + "." + str(min_pz),
                            )
                            shp_out(m_ramales, ramal, project_name)
                            cad_profile_out(
                                m_ramales,
                                ramal,
                                project_name,
                                elev_source=elev_source,
                                step=5,
                            )
                            sys.exit("ERROR")

                    # get minimum elevation in ConexionHacia
                    conexionHacia_Pz = conexionHacia.split(",")
                    min_elevation_Hacia = []
                    for pz in conexionHacia_Pz:
                        _ramal, _pos = pz.split(".")
                        if _pos == "0":
                            _pos = int(_pos) + 1
                            min_elevation_Hacia.append(m_ramales[_ramal]["ZFI"][_pos])
                        else:
                            _pos = int(_pos)
                            min_elevation_Hacia.append(m_ramales[_ramal]["ZFF"][_pos])
                    min_elevation_index = np.argmin(min_elevation_Hacia)
                    min_elevation_Hacia = np.min(min_elevation_Hacia)

                    # compare minimun elevation to m_ramales[i][ZFF][-1]
                    if min_elevation_Hacia > m_ramales[i]["ZFF"][-1]:
                        # diferencia de altura
                        diff_z = m_ramales[i]["ZFI"][-1] - min_elevation_Hacia
                        # availbale slope
                        s_disponible = np.round(diff_z / m_ramales[i]["L"][-1], 3) - 0.001
                        smin = Smin([m_ramales[i]["Material"][-1]], m_ramales)
                        s_new = s_disponible if s_disponible > smin else smin
                        # asginar nueva pendiente
                        m_ramales[i]["S"][-1] = s_new
                        # update elevations
                        # m_ramales = w_TFP(i, m_ramales)
                        m_ramales = update_elevations(i, m_ramales, len(m_ramales[i]["S"]) - 1)
                        # si la diferencia de altura es negativa o si la pendiente es igual a smin, entonces hay que modificar la pendiente de los tramos anteriores
                        if diff_z > 0 and s_new > smin:
                            pass
                        else:
                            # modificar las pendientes aguas abajo para modificar el ramal nuevo
                            "OPTIMIZAR: DISMINUIR ALTURA DE EXCAVACION MODIFICANDO PENDIENTES"
                            m_ramales = get_opt_S1(i, m_ramales, val_break)

                            if min_elevation_Hacia > m_ramales[i]["ZFF"][-1]:
                                # modificar fisicamente los tramos siguientes
                                print(
                                    "ERROR:",
                                    m_ramales[i]["Ramal"],
                                    " esta mas abajo que ",
                                    conexionHacia_Pz[min_elevation_index],
                                )
                                shp_out(m_ramales, ramal, project_name)
                                cad_profile_out(
                                    m_ramales,
                                    ramal,
                                    project_name,
                                    elev_source=elev_source,
                                    step=5,
                                )
                                sys.exit("ERROR")

    # "dimensionar secciones"
    m_ramales, ramal = get_sizing_int(m_ramales, ramal, xy_inter)
    m_ramales, ramal = get_sizing_ext(m_ramales, ramal)
    m_ramales, ramal = get_SLL(m_ramales, ramal)
    m_ramales, ramal = get_SPLL(m_ramales, ramal)
    m_ramales, ramal = get_sizing_SPLL(m_ramales, ramal, xy_inter)

    return m_ramales, ramal


def check_pz_list(m_ramales, xy_inter):
    conexionHacia, conexionDesde = xy_inter
    c = []
    name = []
    for i, j in zip(conexionHacia, conexionDesde):
        estados = [m_ramales[_.split(".")[0]]["Estado"][int(_.split(".")[1])] for _ in j]

        derivacion = [m_ramales[_.split(".")[0]]["Derivacion"][-1] for _ in i.split(",")]
        if True in derivacion:
            c.append(100)
            name.append("Es una derivacion!")
            continue

        if not "nuevo" in estados:
            c.append(100)
            name.append("Es un tramo existente!")
            continue

        ramalHacia, pzHacia = i.split(".")
        elevacionHacia = m_ramales[ramalHacia]["ZFI"][int(pzHacia) + 1]

        elevacionDesde = []
        for posDesde in j:
            ramalDesde, pzDesde = posDesde.split(".")
            elevacionDesde.append(m_ramales[ramalDesde]["ZFF"][int(pzDesde)])
        elevacionDesde = np.min(elevacionDesde)
        elevacionDiff = elevacionDesde - elevacionHacia

        c.append(elevacionDiff)
        name.append("elevacion desde " + ",".join(j) + " menor a " + i + " (" + str(round(elevacionDiff, 3)) + "m )")

    # temp = np.where(np.asarray(c) < 0)[0]

    c = np.asarray(c)
    # Tolerance set to 1 millimeter level (assuming the unit is meters)
    tolerance = 2e-3  # Negative 2 mm in meters

    # Find indices where values are negative and not close to zero within the specified tolerance
    temp = np.where((c < -tolerance) & ~np.isclose(c, 0, atol=tolerance))[0]

    return temp, [name[_] for _ in temp]


def check_pz_fix(m_ramales, ramal, temp, xy_inter):
    round_slope_value = 0.001
    conexionHacia, conexionDesde = xy_inter

    # sort order to avoid error of check pz depth before changing depth before the current point
    new_index_temp = np.argsort(conexionHacia[temp])
    temp = temp[new_index_temp]

    for m in temp:
        n = conexionHacia[m].split(".")
        # "verificar salto en pozo de llegada"
        i, index_v = n[0], int(n[1]) + 1

        # check if existing state
        if "nuevo" in np.unique(m_ramales[i]["Estado"]):
            # salto para alcanzar el fondo de la tuberia que llega
            elevacionDesde = []
            for posDesde in conexionDesde[m]:
                ramalDesde, pzDesde = posDesde.split(".")
                elevacionDesde.append(m_ramales[ramalDesde]["ZFF"][int(pzDesde)])
            elevacionDesde = np.min(elevacionDesde)
            # check if elevacionDesde esta mas abajo que el pozo ZFI
            if m_ramales[i]["ZFI"][index_v] <= elevacionDesde:
                continue

            s_disponible = (((min(m_ramales[i]["ZFI"][index_v], elevacionDesde)) - m_ramales[i]["ZFF"][index_v]) / m_ramales[i]["L"][index_v]) - 0.001
            s_temp = np.around(s_disponible, decimals=3)
            s_min = Smin(m_ramales[i]["Material"], m_ramales, i)
            # elevaciones iniciales
            ZFF_old = m_ramales[i]["ZFF"].copy()

            if s_temp >= s_min[index_v]:
                # manhole jump

                # update slope
                m_ramales[i]["S"][index_v] = s_temp
                # temporal ZFF elevation
                ZFF_temp = m_ramales[i]["ZFF"][index_v] + (m_ramales[i]["L"][index_v] * m_ramales[i]["S"][index_v])
                # update manhole jump
                m_ramales[i]["SALTO"][index_v] = np.abs(
                    np.round(
                        (m_ramales[i]["ZFI"][index_v] - ZFF_temp) + m_ramales[i]["SALTO"][index_v],
                        3,
                    )
                )
                # update ZFF elevation
                m_ramales[i]["ZFI"][index_v] = ZFF_temp
                # update manhole depths
                m_ramales[i]["HI"] = m_ramales[i]["ZTI"] - m_ramales[i]["ZFI"]
                m_ramales[i]["HF"] = m_ramales[i]["ZTF"] - m_ramales[i]["ZFF"]

                # "dimensionar secciones"
                m_ramales, ramal = get_sizing_int(m_ramales, ramal, xy_inter, i)
                m_ramales, ramal = get_sizing_ext(m_ramales, ramal, i)
                m_ramales, ramal = get_SLL(m_ramales, ramal, i)
                m_ramales, ramal = get_SPLL(m_ramales, ramal, i)
                m_ramales, ramal = get_sizing_SPLL(m_ramales, ramal, xy_inter)

            else:
                # modify slope of trench

                # asginar pendinete minima a tramo
                m_ramales[i]["S"][index_v] = s_min[index_v]
                # salto para alcanzar el fondo de la tuberia que llega
                elevacionDesde = []
                for posDesde in conexionDesde[m]:
                    ramalDesde, pzDesde = posDesde.split(".")
                    elevacionDesde.append(m_ramales[ramalDesde]["ZFF"][int(pzDesde)])
                elevacionDesde = np.min(elevacionDesde)
                dif_h = m_ramales[i]["ZFI"][index_v] - elevacionDesde

                # asginar salto
                # m_ramales[i]['SALTO'][index_v] = np.abs(np.round(dif_h + m_ramales[i]['SALTO'][index_v], 3))
                m_ramales[i]["SALTO"][index_v] = np.round(dif_h, 3)
                # ASIGNAR ELEVACION INICIAL MINIMA A TRAMO
                m_ramales[i]["ZFI"][index_v] = elevacionDesde

                # update elevations
                m_ramales = update_elevations(i, m_ramales, index_v)

                # decrease slope in next trenches to return to same elevation in n+1  manholes
                m_ramales = balance_slope_next_trench(ZFF_old, i, m_ramales, index_v, round_slope_value, s_min)

                # decrease jumps in next trenches to return to same elevation in posterior manholes
                m_ramales = balance_jump_next_trench(i, m_ramales, index_v)
                # ZFF_old = m_ramales[i]['ZFF']

                # "DIMENSIONAR SECCIONES"
                m_ramales, ramal = get_sizing_int(m_ramales, ramal, xy_inter, i)
                m_ramales, ramal = get_sizing_ext(m_ramales, ramal, i)
                m_ramales, ramal = get_SLL(m_ramales, ramal, i)
                m_ramales, ramal = get_SPLL(m_ramales, ramal, i)
                m_ramales, ramal = get_sizing_SPLL(m_ramales, ramal, xy_inter)

    return m_ramales, ramal


def check_starting_pz(m_ramales, ramal, xy_inter):
    x = [m_ramales[_]["X"] for _ in ramal]
    y = [m_ramales[_]["Y"] for _ in ramal]
    pz = [m_ramales[_]["Pozo"] for _ in ramal]

    x = np.concatenate(x)
    y = np.concatenate(y)
    pz = np.concatenate(pz)

    points = np.array([x, y]).T
    # Calculate distances between all points
    distances = distance_matrix(points, points)

    # Set diagonal to infinity (so points don't match with themselves)
    np.fill_diagonal(distances, np.inf)

    # get distances < 0.1
    pos_arr1, pos_arr2 = np.where(distances < 0.01)
    df = pd.DataFrame(np.array([pz[pos_arr1], pz[pos_arr2]]).T)

    # 1. Filter rows where either column ends with '.0'
    mask1 = df.iloc[:, 0].astype(str).str.endswith(".0") | df.iloc[:, 1].astype(str).str.endswith(".0")
    df1 = df[mask1]
    # 2. Filter rows where either column does not start with 'E'
    mask2 = ~df1.iloc[:, 0].astype(str).str.startswith("E") | ~df1.iloc[:, 1].astype(str).str.startswith("E")
    df2 = df1[mask2]
    # 3. Filter rows where both columns don't end with '.0'
    mask3 = ~(df2.iloc[:, 0].astype(str).str.endswith(".0") & df2.iloc[:, 1].astype(str).str.endswith(".0"))
    df_res = df2[mask3]

    for pos, tup in df_res.iterrows():
        pz1, pz2 = tup
        pz1_ramal, pz1_pos = pz1.split(".")
        pz2_ramal, pz2_pos = pz2.split(".")

        pz1_pos = int(pz1_pos) if int(pz1_pos) > 0 else 1
        pz2_pos = int(pz2_pos) if int(pz2_pos) > 0 else 1

        pz1_tramo = m_ramales[pz1_ramal]["Tramo"][pz1_pos].split("-")
        pz2_tramo = m_ramales[pz2_ramal]["Tramo"][pz2_pos].split("-")

        pz2_index = np.array(pz2_tramo) == pz2
        pz1_index = np.array(pz1_tramo) == pz1

        pz1_elev = np.array([m_ramales[pz1_ramal]["ZFI"][pz1_pos], m_ramales[pz1_ramal]["ZFF"][pz1_pos]])[pz1_index][0]
        pz2_elev = np.array([m_ramales[pz2_ramal]["ZFI"][pz2_pos], m_ramales[pz2_ramal]["ZFF"][pz2_pos]])[pz2_index][0]

        if len(m_ramales[pz2_ramal]["Conexion"]) - 1 == int(pz2_pos) and not pz2.endswith(".0"):
            # check if the conection if actually to another ramal, and the pz1 is just a starting pz
            conexion_list = [_ for _ in m_ramales[pz2_ramal]["Conexion"] if _]
            conexion_cond = []
            for pz_list in conexion_list:
                for pz_int in pz_list.split(","):
                    pz_int_ramal, pz_int_pos = pz_int.split(".")
                    if pz_int != pz1 and len(m_ramales[pz_int_ramal]["Conexion"]) - 1 != int(pz_int_pos):
                        conexion_cond.append(pz_int)
            if len(conexion_cond) > 0 and pz1.endswith(".0"):
                continue

            # revisar si el pozo que llega no esta por debajo
            if pz2_elev < pz1_elev:
                m_ramales[pz1_ramal]["ZFI"][1] = pz2_elev
                # revisar la pendiente disponible entre el pozo inicial y final del tramo m_ramales[i][1]
                diff_z = m_ramales[pz1_ramal]["ZFI"][1] - m_ramales[pz1_ramal]["ZFF"][1]
                s_disponible = np.round((diff_z / m_ramales[pz1_ramal]["L"][1]), 3) - 0.001
                smin = Smin([m_ramales[pz1_ramal]["Material"][1]], m_ramales, i=pz1_ramal, j=1)
                if isinstance(smin, (float, int)):
                    smin = [smin]
                smin_usuario = np.nan_to_num(m_ramales[pz1_ramal]["S_min"][1])
                smin = np.max([smin_usuario, smin[0]])
                s_new = s_disponible if s_disponible > smin else smin

                m_ramales[pz1_ramal]["S"][1] = s_new
                # actualziar elevaciones y profunidades
                m_ramales = w_TFP(pz1_ramal, m_ramales)
            continue

        if len(m_ramales[pz1_ramal]["Conexion"]) - 1 == int(pz1_pos) and not pz1.endswith(".0"):
            # check if the conection if actually to another ramal, and the pz1 is just a starting pz
            conexion_list = [_ for _ in m_ramales[pz1_ramal]["Conexion"] if _]
            conexion_cond = []
            for pz_list in conexion_list:
                for pz_int in pz_list.split(","):
                    pz_int_ramal, pz_int_pos = pz_int.split(".")
                    if pz_int != pz2 and len(m_ramales[pz_int_ramal]["Conexion"]) - 1 != int(pz_int_pos):
                        conexion_cond.append(pz_int)
            if len(conexion_cond) > 0 and pz2.endswith(".0"):
                continue

            # revisar si el pozo que llega no esta por debajo
            if pz1_elev < pz2_elev:
                m_ramales[pz2_ramal]["ZFI"][1] = pz1_elev
                # revisar la pendiente disponible entre el pozo inicial y final del tramo m_ramales[i][1]
                diff_z = m_ramales[pz2_ramal]["ZFI"][1] - m_ramales[pz2_ramal]["ZFF"][1]
                s_disponible = np.round((diff_z / m_ramales[pz2_ramal]["L"][1]), 3) - 0.001
                smin = Smin([m_ramales[pz2_ramal]["Material"][1]], m_ramales, i=pz2_ramal, j=1)
                if isinstance(smin, (float, int)):
                    smin = [smin]
                smin_usuario = np.nan_to_num(m_ramales[pz2_ramal]["S_min"][1])
                smin = np.max([smin_usuario, smin[0]])
                s_new = s_disponible if s_disponible > smin else smin

                m_ramales[pz2_ramal]["S"][1] = s_new
                # actualziar elevaciones y profunidades
                m_ramales = w_TFP(pz2_ramal, m_ramales)
            continue

        # check wich pz is the starting pz
        if pz1.endswith(".0") and pz1_elev < pz2_elev:  # and len(m_ramales[pz2_ramal]['Ramal']) - 1 == pz2_pos:
            m_ramales[pz1_ramal]["ZFI"][1] = pz2_elev

            # revisar la pendiente disponible entre el pozo inicial y final del tramo m_ramales[i][1]
            diff_z = m_ramales[pz1_ramal]["ZFI"][1] - m_ramales[pz1_ramal]["ZFF"][1]
            s_disponible = np.round((diff_z / m_ramales[pz1_ramal]["L"][1]), 3) - 0.001
            smin = Smin([m_ramales[pz1_ramal]["Material"][1]], m_ramales, i=pz1_ramal, j=1)
            if isinstance(smin, (float, int)):
                smin = [smin]
            smin_usuario = np.nan_to_num(m_ramales[pz1_ramal]["S_min"][1])
            smin = np.max([smin_usuario, smin[0]])
            s_new = s_disponible if s_disponible > smin else smin

            # s_new = (m_ramales[pz1_ramal]['ZFI'][1] - m_ramales[pz1_ramal]['ZFF'][1]) / m_ramales[pz1_ramal]['L'][1]
            m_ramales[pz1_ramal]["S"][1] = s_new
            # actualziar elevaciones y profunidades
            m_ramales = w_TFP(pz1_ramal, m_ramales)

        if pz2.endswith(".0") and pz2_elev < pz1_elev:  # and  len(m_ramales[pz1_ramal]['Ramal']) - 1 ==  pz1_pos:
            m_ramales[pz2_ramal]["ZFI"][1] = pz1_elev

            # revisar la pendiente disponible entre el pozo inicial y final del tramo m_ramales[i][1]
            diff_z = m_ramales[pz2_ramal]["ZFI"][1] - m_ramales[pz2_ramal]["ZFF"][1]
            s_disponible = np.round((diff_z / m_ramales[pz2_ramal]["L"][1]), 3) - 0.001
            smin = Smin([m_ramales[pz2_ramal]["Material"][1]], m_ramales, i=pz2_ramal, j=1)
            if isinstance(smin, (float, int)):
                smin = [smin]
            smin_usuario = np.nan_to_num(m_ramales[pz2_ramal]["S_min"][1])
            smin = np.max([smin_usuario, smin[0]])
            s_new = s_disponible if s_disponible > smin else smin

            # s_new = (m_ramales[pz2_ramal]['ZFI'][1] - m_ramales[pz2_ramal]['ZFF'][1]) / m_ramales[pz2_ramal]['L'][1]
            m_ramales[pz2_ramal]["S"][1] = s_new
            # actualziar elevaciones y profunidades
            m_ramales = w_TFP(pz2_ramal, m_ramales)

    # dimensionar secciones
    m_ramales, ramal = get_sizing_int(m_ramales, ramal, xy_inter)
    m_ramales, ramal = get_sizing_ext(m_ramales, ramal)
    m_ramales, ramal = get_SLL(m_ramales, ramal)
    m_ramales, ramal = get_SPLL(m_ramales, ramal)
    m_ramales, ramal = get_sizing_SPLL(m_ramales, ramal, xy_inter)

    return m_ramales, ramal


def check_pz(m_ramales, ramal, xy_inter):
    # check elevation  for pz , keep starting pz  in higer elevaction than passing pz
    m_ramales, ramal = check_starting_pz(m_ramales, ramal, xy_inter)

    # check for levels of new and existing ramales
    m_ramales, ramal = check_existing_pz(m_ramales, ramal, xy_inter)

    # conexionHacia, conexionDesde = xy_inter
    n_max = 15

    # index for ramales reaching below elevation to other ramal
    temp, names = check_pz_list(m_ramales, xy_inter)
    cont = 0
    while len(temp) > 0:
        cont = cont + 1
        print("cont check_pz: ", cont)
        # modifiy slopes to fix elevation issues
        m_ramales, ramal = check_pz_fix(m_ramales, ramal, temp, xy_inter)

        # index for ramales reaching below elevation to other ramal
        temp, names = check_pz_list(m_ramales, xy_inter)

        if cont > n_max:
            print("REVISAR:", names)
            # shp_out(m_ramales, ramal, project_name)
            cad_profile_out(m_ramales, ramal, project_name, elev_source=elev_source, step=5)

            a = (
                pd.Series(names)
                .str.split("menor a", expand=True)[1]
                .str.replace("(", "")
                .str.replace(")", "")
                .str.replace(" ", "")
                .str.replace("m", "")
                .str.split("-", expand=True)
            )
            _ramal_pz = a[0].str.split(".", expand=True)
            _ramal_list = _ramal_pz[0]
            _pz_list = _ramal_pz[1].astype(int)
            h_list = np.ceil(a[1].astype(float) / 0.05) * 0.05
            e_dict = {}
            for _ramal, _pz, _h in zip(_ramal_list, _pz_list, h_list):
                max_array = np.max(
                    np.array(
                        np.array(
                            [
                                pd.Series(m_ramales[_ramal]["HF"]).shift(0).fillna(0).to_numpy(),
                                pd.Series(m_ramales[_ramal]["HI"]).shift(-1).fillna(0).to_numpy(),
                            ]
                        ).T
                    ),
                    axis=1,
                )
                h_max = max_array[_pz]
                e_dict[_ramal + "." + str(_pz)] = {"Pozo_hmin": round(h_max + _h, 2) + 0.05}
            print("*" * 100)
            print(e_dict)
            print("*" * 100)

            sys.exit("ERROR: def check_pz")

    m_ramales = check_depth_jump_consistency(m_ramales)

    return m_ramales, ramal


# check for trench depth after chek_pz function
def check_pz_overfitting(m_ramales, xy_inter):
    conexionHacia, conexionDesde = xy_inter
    for conexionHacia_value, conexionDesde_value in zip(conexionHacia, conexionDesde):
        # obtener zff de pozos que llegan hacia el pozo ConexionHacia
        zff_min_conexionHacia = np.min([m_ramales[_.split(".")[0]]["ZFF"][-1] for _ in conexionDesde_value])

        _ramal, _pz = conexionHacia_value.split(".")
        # obtener zff de pozo del mismo ramal que llega a pozo ConexionHacia
        if int(_pz) == 0:
            zff_previus_trench = zff_min_conexionHacia
        else:
            zff_previus_trench = m_ramales[_ramal]["ZFF"][int(_pz)]

        # ------------------------------------------------------------------------------------
        # obtener zfi del tramo siguiente de pozo ConexionHacia
        zfi_next_trench = m_ramales[_ramal]["ZFI"][int(_pz) + 1]
        # revisar si la elevacion ZFF del tramo anterior y la elevacion ZFI del tramo posterior son similares
        if np.isclose(zff_previus_trench, zfi_next_trench):
            continue
        # revisar si la elevacion ZFI del tramo posterior y la elevacion ZFF de los tramos que llegan al pozo son similares
        if np.isclose(zff_min_conexionHacia, zfi_next_trench):
            continue

        # get next trench elevation ZFF and check if new elevation causes diferent slope, if not continue
        zff_next_trench = m_ramales[_ramal]["ZFF"][int(_pz) + 1]
        length_trench = m_ramales[_ramal]["L"][int(_pz) + 1]
        slope_next_trench = m_ramales[_ramal]["S"][int(_pz) + 1]
        new_temp_slope = round(((zff_min_conexionHacia - zff_next_trench) / length_trench) - 0.001, 3)

        if new_temp_slope == slope_next_trench:
            continue

        # if this creates diferent slope, assume the new slope and iterate
        new_temp_zfi = np.round(zff_next_trench + (length_trench * new_temp_slope), 3)
        new_temp1_zfi = np.round(np.min([zff_min_conexionHacia, zff_previus_trench, new_temp_zfi]), 3)

        new_slope = round(((new_temp1_zfi - zff_next_trench) / length_trench) - 0.001, 3)
        new_zfi = np.round(zff_next_trench + (length_trench * new_slope), 3)
        m_ramales[_ramal]["ZFI"][int(_pz) + 1] = new_zfi
        m_ramales[_ramal]["S"][int(_pz) + 1] = new_slope

    return m_ramales


"######################################################################################################################"
"OPTIMIZACION: EXCAVACIONES "
"######################################################################################################################"


def opt_S1(i, m_ramales):
    """
    i:          Ramal
    m_ramales:  Diccionario de ramales

    Funcion para minimizar la excavacion a recubirmiento minimo de tubo + diametro externo + temp
    """

    # Valor maximo de diferencia entre la znaja minima y la zanja calculada
    temp = np.max(m_ramales[i]["L"]) * (0.06 / 100)
    # array de la pendiente minima segun el material
    smin = Smin(m_ramales[i]["Material"], m_ramales, i)
    # indices de las alturas finales (HF) donde se cumple la condicion (recubirmiento minimo de tubo + diametro externo + temp)
    seccion_altura = seccion_str2float(m_ramales[i]["D_ext"])
    cobertura_minima = par_basicos(h_min=True)
    # Minimum depths calculations
    min_cover_depth = np.where(np.logical_and(~np.isnan(m_ramales[i]["cobertura_min"]), m_ramales[i]["cobertura_min"] > 0), m_ramales[i]["cobertura_min"], cobertura_minima)
    min_manhole_depth = min_cover_depth + seccion_altura + temp

    a = np.where(m_ramales[i]["HF"] > min_manhole_depth)
    # indices de donde la pendientes es mayor a la pendiente minima
    b = np.where(m_ramales[i]["S"] > smin)
    # indice de los tramos que tienen una profunidad mayor a la minima y que tienen pendiente mayor a la minima
    index_v1, a_ind, b_ind = np.intersect1d(a, b, return_indices=True)

    if index_v1.any():
        # pendinete minima para lograr altura de zanja minima
        c = np.around(
            (m_ramales[i]["ZFI"][index_v1] - (m_ramales[i]["ZTF"][index_v1] - (min_manhole_depth - temp)[index_v1])) / m_ramales[i]["L"][index_v1],
            decimals=3,
        )
        c = np.where(c > smin[index_v1], c, smin[index_v1])
        return index_v1, c
    else:
        return [], []


def opt_S2(i, m_ramales):
    """
    Funcion para profundizar los pozos hasta valor minimmo
    """

    temp = np.max(m_ramales[i]["L"]) * (0.06 / 100)
    smin = Smin(m_ramales[i]["Material"], m_ramales, i)

    seccion_altura = seccion_str2float(m_ramales[i]["D_ext"])
    # initial depth
    initial_depth = par_basicos(h_min=1) if m_ramales[i]["cobertura_min"][0] <= 0.0 or np.isnan(m_ramales[i]["cobertura_min"][0]) else m_ramales[i]["cobertura_min"][0]
    # minimun dpeth for trench
    hmin = initial_depth + seccion_altura - temp

    # indices de las alturas finales (HF) donde se cumple la condicion (recubirmiento minimo de tubo + diametro externo + temp)
    cobertura_minima = par_basicos(h_min=True)
    # Minimum depths calculations
    min_cover_depth = np.where(np.logical_and(~np.isnan(m_ramales[i]["cobertura_min"]), m_ramales[i]["cobertura_min"] > 0), m_ramales[i]["cobertura_min"], cobertura_minima)
    min_manhole_depth = min_cover_depth + seccion_altura - temp

    index_v1 = np.where(m_ramales[i]["HF"] < min_manhole_depth)[0]
    index_v1 = index_v1[index_v1 > 0]
    if index_v1.any():
        c = np.around(
            (m_ramales[i]["ZFI"][index_v1] - (m_ramales[i]["ZTF"][index_v1] - (min_manhole_depth + temp)[index_v1])) / m_ramales[i]["L"][index_v1],
            decimals=3,
        )
        c = np.where(c > smin[index_v1], c, smin[index_v1])
        return index_v1, c
    else:
        return index_v1, []


def opt_S3(i, m_ramales):
    # definir altura de pozos considerando el Tramo_Min y Pozo_Min
    Pozo_Min = np.roll(m_ramales[i]["Pozo_hmin"], 1)
    index_pz = np.where(Pozo_Min > m_ramales[i]["HI"])[0]
    index_pz = index_pz[index_pz != 0]

    if len(index_pz) > 0:
        # CREAR SALTO
        m_ramales[i]["SALTO"] = np.asarray([0.0] * len(m_ramales[i]["S"]))

        Salto_Fit = Pozo_Min[index_pz] - m_ramales[i]["HI"][index_pz]
        temp_ZFI = m_ramales[i]["ZFI"][index_pz] - Salto_Fit

        # S_Fit = (temp_ZFI - m_ramales[i]["ZFF"][index_pz]) / m_ramales[i]["L"][index_pz]
        # S_Fit = np.round(np.where(S_Fit - 0.001 > smin[index_pz], S_Fit - 0.001, smin[index_pz]), 3)

        diff_z = temp_ZFI - m_ramales[i]["ZFF"][index_pz]
        s_disponible = np.round((diff_z / m_ramales[i]["L"][index_pz]), 3) - 0.001
        smin = Smin(m_ramales[i]["Material"], m_ramales, i=i)[index_pz]

        if isinstance(smin, (float, int)):
            smin = [smin]
        smin_usuario = np.nan_to_num(m_ramales[i]["S_min"][index_pz])
        smin = np.max([smin_usuario, smin], axis=0)
        S_Fit = np.where(s_disponible > smin, s_disponible, smin)

        new_ZFI = m_ramales[i]["ZFF"][index_pz] + (S_Fit * m_ramales[i]["L"][index_pz])
        m_ramales[i]["SALTO"][index_pz] = m_ramales[i]["ZFI"][index_pz] - new_ZFI
        m_ramales[i]["ZFI"][index_pz] = new_ZFI
        m_ramales[i]["S"][index_pz] = S_Fit
        m_ramales[i]["HI"] = m_ramales[i]["ZTI"] - m_ramales[i]["ZFI"]
        m_ramales[i]["HF"] = m_ramales[i]["ZTF"] - m_ramales[i]["ZFF"]

        # idx_temp = np.where(S_Fit == smin[index_pz])[0]
        idx_temp = np.where(S_Fit == smin)[0]
        index_v3 = index_pz[idx_temp]
        salto_residual = Pozo_Min[index_v3] - m_ramales[i]["HI"][index_v3]

        return index_v3, salto_residual, m_ramales
    else:
        return [], [], m_ramales


def opt_S4(i, m_ramales, index_v3, salto_residual):
    len_array = len(m_ramales[i]["ZFI"])

    for _index, _h in zip(index_v3, salto_residual):
        if _index < len_array - 1:
            # APLICAR SALTO
            m_ramales[i]["SALTO"][_index] = _h

            # PENDIENTE MINIMA
            s_actual = m_ramales[i]["S"][_index]
            smin = Smin(m_ramales[i]["Material"], m_ramales, i)[_index]

            if isinstance(smin, (float, int)):
                smin = [smin]
            smin_usuario = np.nan_to_num(m_ramales[i]["S_min"][_index])
            try:
                smin = np.max([smin_usuario, smin], axis=0)
            except:
                smin = np.max(np.concatenate([[smin_usuario], smin]), axis=0)
                
            s_final = np.max([s_actual, smin])

            m_ramales[i]["S"][_index] = s_final
            # MODIFICAR ELEVACION FONDO INICIAL Y FINAL
            m_ramales[i]["ZFI"][_index] = m_ramales[i]["ZFI"][_index] - _h
            m_ramales[i]["ZFF"][_index] = m_ramales[i]["ZFI"][_index] - m_ramales[i]["L"][_index] * s_final

            # VERIFICAR SI ELEVACION DE FONDO FINAL TRAMO I ES MAYOR A ELEVACION FONDO INICIAL TRAMO I + 1
            if m_ramales[i]["ZFI"][_index + 1] > m_ramales[i]["ZFF"][_index]:
                m_ramales[i]["ZFI"][_index + 1] = m_ramales[i]["ZFF"][_index]
                m_ramales[i]["SALTO"][_index + 1] = 0
                # MODIFICAR ALTURA DE POZOS
                m_ramales[i]["HI"] = m_ramales[i]["ZTI"] - m_ramales[i]["ZFI"]
                m_ramales[i]["HF"] = m_ramales[i]["ZTF"] - m_ramales[i]["ZFF"]
            else:
                # MODIFICAR ALTURA DE POZOS
                m_ramales[i]["HI"] = m_ramales[i]["ZTI"] - m_ramales[i]["ZFI"]
                m_ramales[i]["HF"] = m_ramales[i]["ZTF"] - m_ramales[i]["ZFF"]
                break

            for pos in range(_index + 1, len_array):
                s_necesaria = (m_ramales[i]["ZFI"][pos] - m_ramales[i]["ZFF"][pos]) / m_ramales[i]["L"][pos]
                s_min = Smin(m_ramales[i]["Material"], m_ramales, i)[pos]
                s_final = np.max([s_necesaria, s_min])
                m_ramales[i]["S"][pos] = s_final

                if (s_necesaria < s_min) and (pos < len_array - 1):
                    # MODIFICAR ELEVACION FONDO INICIAL Y FINAL
                    m_ramales[i]["ZFF"][pos] = m_ramales[i]["ZFI"][pos] - m_ramales[i]["L"][pos] * s_final

                    # VERIFICAR SI ELEVACION DE FONDO FINAL TRAMO I ES MAYOR A ELEVACION FONDO INICIAL TRAMO I + 1
                    if m_ramales[i]["ZFI"][pos + 1] > m_ramales[i]["ZFF"][pos]:
                        m_ramales[i]["ZFI"][pos + 1] = m_ramales[i]["ZFF"][pos]
                        m_ramales[i]["SALTO"][pos + 1] = 0
                        # MODIFICAR ALTURA DE POZOS
                        m_ramales[i]["HI"] = m_ramales[i]["ZTI"] - m_ramales[i]["ZFI"]
                        m_ramales[i]["HF"] = m_ramales[i]["ZTF"] - m_ramales[i]["ZFF"]
                    else:
                        # MODIFICAR PENDIENTE  Y ALTURA DE POZOS
                        m_ramales[i]["HI"] = m_ramales[i]["ZTI"] - m_ramales[i]["ZFI"]
                        m_ramales[i]["HF"] = m_ramales[i]["ZTF"] - m_ramales[i]["ZFF"]
                        break
                else:
                    # MODIFICAR ELEVACION FONDO INICIAL Y FINAL
                    m_ramales[i]["ZFF"][pos] = m_ramales[i]["ZFI"][pos] - m_ramales[i]["L"][pos] * s_final
                    m_ramales[i]["HI"] = m_ramales[i]["ZTI"] - m_ramales[i]["ZFI"]
                    m_ramales[i]["HF"] = m_ramales[i]["ZTF"] - m_ramales[i]["ZFF"]
                    break

        elif _index == len_array - 1:
            # APLICAR SALTO
            m_ramales[i]["SALTO"][_index] = _h

            # PENDIENTE MINIMA
            s_actual = m_ramales[i]["S"][_index]
            s_min = Smin(m_ramales[i]["Material"], m_ramales, i)[_index]
            s_final = np.max([s_actual, s_min])
            m_ramales[i]["S"][_index] = s_final

            # MODIFICAR ELEVACION FONDO INICIAL Y FINAL
            m_ramales[i]["ZFI"][_index] = m_ramales[i]["ZFI"][_index] - _h
            m_ramales[i]["ZFF"][_index] = m_ramales[i]["ZFI"][_index] - m_ramales[i]["L"][_index] * s_final

            break

        else:
            print("break")
            break

    return m_ramales


def get_opt_S(m_ramales, ramal, xy_inter):
    val_break = np.sum([len(m_ramales[_]["Pozo"]) for _ in m_ramales.keys()]) * 100

    n = 0
    n_count = np.sum([1 for _, __ in enumerate(m_ramales.values()) if __["Estado"][0] in ["nuevo"]])
    for i in ramal.values():
        index = np.char.equal(m_ramales[i]["Estado"], "nuevo").nonzero()[0]
        if index.size > 0:
            n = n + 1
            # print(
            #     f"\rprogreso get_opt_S: {round((n / n_count) * 100, 2)}%",
            #     end="",
            #     flush=True,
            # )

            # update elvations
            m_ramales = w_TFP(i, m_ramales)

            # 'optimizar: disminuir altura de excavacion modificando pendientes'
            m_ramales = get_opt_S1(i, m_ramales, val_break)
            m_ramales, ramal = get_sizing_int(m_ramales, ramal, xy_inter, i)
            m_ramales, ramal = get_sizing_ext(m_ramales, ramal, i)
            m_ramales, ramal = get_SLL(m_ramales, ramal, i)
            m_ramales, ramal = get_SPLL(m_ramales, ramal, i)
            m_ramales, ramal = get_sizing_SPLL(m_ramales, ramal, xy_inter)

            # 'optimizar: revisar altura minima de excavacion modificando pendientes'
            m_ramales = get_opt_S2(i, m_ramales, val_break)
            m_ramales, ramal = get_sizing_int(m_ramales, ramal, xy_inter, i)
            m_ramales, ramal = get_sizing_ext(m_ramales, ramal, i)
            m_ramales, ramal = get_SLL(m_ramales, ramal, i)
            m_ramales, ramal = get_SPLL(m_ramales, ramal, i)
            m_ramales, ramal = get_sizing_SPLL(m_ramales, ramal, xy_inter)

            # 'optimizar: profundizar los pozos necesarios de la columna pozo_min mediante saltos en los pozos'
            index_v3, salto_residual, m_ramales = opt_S3(i, m_ramales)
            m_ramales, ramal = get_sizing_int(m_ramales, ramal, xy_inter, i)
            m_ramales, ramal = get_sizing_ext(m_ramales, ramal, i)
            m_ramales, ramal = get_SLL(m_ramales, ramal, i)
            m_ramales, ramal = get_SPLL(m_ramales, ramal, i)
            m_ramales, ramal = get_sizing_SPLL(m_ramales, ramal, xy_inter)

            # 'optimizar: profundizar los pozos necesarios de la columna pozo_min mediante profundizacion del tramo anterior'
            if len(index_v3) > 0:
                m_ramales = opt_S4(i, m_ramales, index_v3, salto_residual)
                m_ramales, ramal = get_sizing_int(m_ramales, ramal, xy_inter, i)
                m_ramales, ramal = get_sizing_ext(m_ramales, ramal, i)
                m_ramales, ramal = get_SLL(m_ramales, ramal, i)
                m_ramales, ramal = get_SPLL(m_ramales, ramal, i)
                m_ramales, ramal = get_sizing_SPLL(m_ramales, ramal, xy_inter)

    print(
        f"\n",
        end="",
        flush=True,
    )
    return m_ramales, ramal


def get_opt_S2(i, m_ramales, val_break):
    "OPTIMIZAR: REVISAR ALTURA MINIMA DE EXCAVACION MODIFICANDO PENDIENTES"
    cont = -1
    index_v2, c1 = opt_S2(i, m_ramales)
    for j in range(len(index_v2)):
        while len(c1) != 0:
            m_ramales[i]["S"][index_v2[j]] = c1[j]
            m_ramales = w_TFP(i, m_ramales)
            index_v2, c1 = opt_S2(i, m_ramales)
            cont = cont + 1
            if cont > len(index_v2) + val_break:
                # print("break 2!", i)
                break
        break
    return m_ramales


def get_opt_S1(i, m_ramales, val_break):
    cont = -1
    # 'OPTIMIZAR: DISMINUIR ALTURA DE EXCAVACION MODIFICANDO PENDIENTES'
    index_v1, c = opt_S1(i, m_ramales)
    for j in range(len(index_v1)):
        while len(c) != 0:
            m_ramales[i]["S"][index_v1[j]] = c[j]
            m_ramales = w_TFP(i, m_ramales)
            index_v1, c = opt_S1(i, m_ramales)
            cont = cont + 1
            if cont > len(index_v1) + val_break:
                # print("break 1!", index_v1, i)
                break
        break
    return m_ramales


def get_opt_S_thread(args):
    """Process individual ramal with original logic"""
    i, shared_m_ramales, shared_ramal, xy_inter, val_break = args

    index = np.char.equal(shared_m_ramales[i]["Estado"], "nuevo").nonzero()[0]

    if index.size > 0:
        # 'OPTIMIZAR: DISMINUIR ALTURA DE EXCAVACION MODIFICANDO PENDIENTES'
        shared_m_ramales = get_opt_S1(i, shared_m_ramales, val_break)
        shared_m_ramales, shared_ramal = get_sizing_int(shared_m_ramales, shared_ramal, xy_inter, i)
        shared_m_ramales, shared_ramal = get_sizing_ext(shared_m_ramales, shared_ramal, i)
        shared_m_ramales, shared_ramal = get_SLL(shared_m_ramales, shared_ramal, i)
        shared_m_ramales, shared_ramal = get_SPLL(shared_m_ramales, shared_ramal, i)
        shared_m_ramales, shared_ramal = get_sizing_SPLL(shared_m_ramales, shared_ramal, xy_inter)

        # 'OPTIMIZAR: REVISAR ALTURA MINIMA DE EXCAVACION MODIFICANDO PENDIENTES'
        shared_m_ramales = get_opt_S2(i, shared_m_ramales, val_break)
        shared_m_ramales, shared_ramal = get_sizing_int(shared_m_ramales, shared_ramal, xy_inter, i)
        shared_m_ramales, shared_ramal = get_sizing_ext(shared_m_ramales, shared_ramal, i)
        shared_m_ramales, shared_ramal = get_SLL(shared_m_ramales, shared_ramal, i)
        shared_m_ramales, shared_ramal = get_SPLL(shared_m_ramales, shared_ramal, i)
        shared_m_ramales, shared_ramal = get_sizing_SPLL(shared_m_ramales, shared_ramal, xy_inter)

        # 'OPTIMIZAR: PROFUNDIZAR LOS POZOS NECESARIOS DE LA COLUMNA POZO_MIN MEDIANTE SALTOS EN LOS POZOS'
        index_v3, salto_residual, shared_m_ramales = opt_S3(i, shared_m_ramales)
        shared_m_ramales, shared_ramal = get_sizing_int(shared_m_ramales, shared_ramal, xy_inter, i)
        shared_m_ramales, shared_ramal = get_sizing_ext(shared_m_ramales, shared_ramal, i)
        shared_m_ramales, shared_ramal = get_SLL(shared_m_ramales, shared_ramal, i)
        shared_m_ramales, shared_ramal = get_SPLL(shared_m_ramales, shared_ramal, i)
        shared_m_ramales, shared_ramal = get_sizing_SPLL(shared_m_ramales, shared_ramal, xy_inter)

        # 'OPTIMIZAR: PROFUNDIZAR LOS POZOS NECESARIOS DE LA COLUMNA Pozo_Min MEDIANTE PROFUNDIZACION DEL TRAMO ANTERIOR'
        if len(index_v3) > 0:
            shared_m_ramales = opt_S4(i, shared_m_ramales, index_v3, salto_residual)
            shared_m_ramales, shared_ramal = get_sizing_int(shared_m_ramales, shared_ramal, xy_inter, i)
            shared_m_ramales, shared_ramal = get_sizing_ext(shared_m_ramales, shared_ramal, i)
            shared_m_ramales, shared_ramal = get_SLL(shared_m_ramales, shared_ramal, i)
            shared_m_ramales, shared_ramal = get_SPLL(shared_m_ramales, shared_ramal, i)
            shared_m_ramales, shared_ramal = get_sizing_SPLL(shared_m_ramales, shared_ramal, xy_inter)


def get_opt_S_MP(m_ramales, ramal, xy_inter, n_cpu=None):
    val_break = np.sum([len(m_ramales[_]["Pozo"]) for _ in m_ramales.keys()])
    n_count = np.sum([1 for _, __ in enumerate(m_ramales.values()) if __["Estado"][0] in ["nuevo"]])

    # Create manager and shared dictionaries
    with Manager() as manager:
        shared_m_ramales = manager.dict(m_ramales)
        shared_ramal = manager.dict(ramal)

        # Prepare work items for parallel processing
        work_items = []
        n = 0
        for i in ramal.values():
            index = np.char.equal(m_ramales[i]["Estado"], "nuevo").nonzero()[0]
            if index.size > 0:
                n += 1
                print(f"\rprogreso get_opt_S: {round((n / n_count) * 100, 2)}%", end="", flush=True)
                work_items.append((i, shared_m_ramales, shared_ramal, xy_inter, val_break))

        # Setup process pool
        n_cpu = n_cpu if n_cpu is not None else (cpu_count() - 1)

        # Process all items in parallel
        with Pool(n_cpu) as pool:
            pool.map(get_opt_S_thread, work_items)

        print(f"\n", end="", flush=True)

        # Return the processed dictionaries
        return dict(shared_m_ramales), dict(shared_ramal)


"######################################################################################################################"
"OPTIMIZACION: VELOCIDAD "
"######################################################################################################################"


def v_max(material):
    f = operator.itemgetter(*material)
    return np.array(f(velocidad_maxima_pypiper))


def compare_velocity(compare_value, max_value, tolerancia_relativa=0.02, tolerancia_absoluta=0.15):
    """
    funcion para obetner las velocidades de tramos que estasn por encima de la velocidad maxima permitida, utilizando logica difusa para
    eliminar valores que no son estrictamente menores pero si son muy cercanos
    :param compare_value:
    :param max_value: valor de refrencia
    :param tolerancia_relativa: porcentaje %
    :param tolerancia_absoluta: valor de diferencia de velocidad (m/s)
    :return:
    """
    # índice de velocidades mayores a la maxima en el tramo
    index_v = np.where(compare_value > max_value)[0]
    # revisar si los resultados de v y v_max estan muy cercanos, si cumple eliminar.
    remove_index = np.isclose(
        compare_value[index_v],
        max_value[index_v],
        rtol=tolerancia_relativa,
        atol=tolerancia_absoluta,
        equal_nan=False,
    ).nonzero()[0]
    index_v = np.delete(index_v, remove_index)
    return index_v


def s_h_SPLL_rectangular(s, b, manning, v, q_accu):
    """

    :param s: pendiente que se va a minimizar, %
    :param b: ancho del canal, m
    :param mannig:
    :param v: velocidad maxima, m/s
    :param q_accu: caudal, L/s
    :return:
    """

    # encontar calado con nueva pendiente
    h = opt.brentq(rectangular_SPLL_root, 0.001, b * 5, xtol=1e-3, args=(b, s, manning, q_accu))
    # calcular la velocidad con la pendiente nueva
    velocity_model = (1 / manning) * (((b * h) / (b + (2 * h))) ** (2 / 3)) * (s ** (1 / 2))
    # calcular el residual de la velocidad simulada y velocidad maxima
    ssq_residuals = np.sum((velocity_model - v) ** 2)
    return ssq_residuals


def s_ang_SPLL_circular(s, manning, d_int, v, q_accu):
    # mirar si el caudal acumulado es cero, se pone un caudal para que funcione la formula
    if q_accu == 0:
        q_accu = 0.001
    # calculo de caudal lleno
    q_lleno = 0.312 / manning * d_int ** (8.0 / 3.0) * s ** (1.0 / 2.0) * 1000.0
    # angulo de la seccion parcialmente llena
    ang_value = opt.brentq(ang_SPLL_root, 0.001, 10000, xtol=1e-3, args=(q_accu, q_lleno))
    # Radio Hidraulico
    Rh = (d_int / 4.0) * (1 - (360 * np.sin(np.radians(ang_value)) / (2 * np.pi * ang_value)))
    # calcular la velocidad con la pendiente nueva
    velocity_model = (1 / manning) * ((Rh) ** (2 / 3)) * (s ** (1 / 2))
    # calcular el residual de la velocidad simulada y velocidad maxima
    ssq_residuals = np.sum((velocity_model - v) ** 2)
    return ssq_residuals


def s_h_SPLL_rectangular_root(s, b, manning, v, q_accu):
    """

    :param s: pendiente que se va a minimizar, %
    :param b: ancho del canal, m
    :param mannig:
    :param v: velocidad maxima, m/s
    :param q_accu: caudal, L/s
    :return:
    """

    # encontar calado con nueva pendiente
    try:
        h = opt.brentq(rectangular_SPLL_root, 0.001, b * 5, xtol=1e-3, args=(b, s, manning, q_accu))
    except:
        h = opt.root(rectangular_SPLL_root, 0.01, args=(b, s, manning, q_accu), method="hybr").x[0]
    # calcular la velocidad con la pendiente nueva
    velocity_model = (1 / manning) * (((b * h) / (b + (2 * h))) ** (2 / 3)) * (s ** (1 / 2))
    return velocity_model - v


def s_ang_SPLL_circular_root(s, manning, d_int, v, q_accu, i):
    # Ensure q_accu is a small positive number
    q_accu = max(q_accu, 1e-6)

    # Prevent extremely small or zero values
    s = max(s, 1e-6)
    manning = max(manning, 1e-6)
    d_int = max(d_int, 1e-6)

    # Calculate full pipe flow
    q_lleno = 0.312 / manning * d_int ** (8.0 / 3.0) * s ** (1.0 / 2.0) * 1000.0

    try:
        # Narrow down the angle search range
        ang_value = opt.brentq(ang_SPLL_root, 0.1, 360, xtol=1e-3, args=(q_accu, q_lleno))

        # Avoid potential division by zero or near-zero values
        if ang_value < 0.1:
            return np.nan

        # Radio Hidraulico with additional protection
        Rh = (d_int / 4.0) * (1 - (360 * np.sin(np.radians(ang_value)) / (2 * np.pi * max(ang_value, 0.1))))

        # Calculate velocity
        velocity_model = (1 / manning) * ((max(Rh, 1e-6)) ** (2 / 3)) * (s ** (1 / 2))

        return velocity_model - v

    except ValueError:
        # Log or handle the specific root-finding failure
        # print(f"Root finding failed for parameters: s={s}, manning={manning}, d_int={d_int}, v={v}, q_accu={q_accu}-tramo {i}")
        return np.nan


def seek_S(seccion_int, rugosidad, material, tipo_seccion, q_accu, pendiente):
    """
    funcion para buscar la pendiente que se asocia a la velocidad maxima permitida

    :param seccion:
    :param ang_v:
    :param Rugosidad:
    :param Material:
    :param tipo_seccion:
    :param h: lamina de agua en m
    :param S: Pendiente en %
    :return:
    """
    index_rectangular = np.trim_zeros(np.char.equal(tipo_seccion, "rectangular").nonzero()[0])
    index_circular = np.trim_zeros(np.char.equal(tipo_seccion, "circular").nonzero()[0])
    secciones = np.unique(tipo_seccion)

    pendiente_maxima = np.zeros(shape=len(tipo_seccion), dtype=float)
    # velocidad maxima de cada elemnto de tramo con base a su material
    v_max_array = v_max(material)

    for seccion in secciones:
        if seccion in ["circular"]:
            # get float values from D_int
            seccion_int_float = seccion_str2float(seccion_int)
            # pendiente maxima
            try:
                pendiente_maxima_circular = np.array(
                    [opt.brentq(s_ang_SPLL_circular_root, 0.005, 10, xtol=1e-3, args=(rugosidad[i], seccion_int_float[i], v_max_array[i], q_accu[i], i)) for i in index_circular]
                )
            except:
                pendiente_maxima_circular = np.array(
                    [
                        opt.root(
                            s_ang_SPLL_circular_root,
                            pendiente[i],
                            args=(rugosidad[i], seccion_int_float[i], v_max_array[i], q_accu[i], i),
                            method="hybr",
                        ).x[0]
                        for i in index_circular
                    ]
                )
            pendiente_maxima[index_circular] = np.around(pendiente_maxima_circular, decimals=3)

        elif seccion in ["rectangular"]:
            # base y altura de la seccion, por defecto son str
            b, h_int = pp_char_split(seccion_int, _split="x")
            b = b.astype(float)
            try:
                pendiente_maxima_rectangular = np.array(
                    [
                        opt.brentq(
                            s_h_SPLL_rectangular_root,
                            0.005,
                            pendiente[i] * 5,
                            xtol=1e-3,
                            args=(b[i], rugosidad[i], v_max_array[i], q_accu[i]),
                        )
                        for i in index_rectangular
                    ]
                )
            except:
                pendiente_maxima_rectangular = np.array(
                    [
                        opt.root(
                            s_h_SPLL_rectangular_root,
                            pendiente[i],
                            args=(b[i], rugosidad[i], v_max_array[i], q_accu[i]),
                            method="hybr",
                        ).x[0]
                        for i in index_rectangular
                    ]
                )
            pendiente_maxima[index_rectangular] = np.around(pendiente_maxima_rectangular, decimals=3)
    return pendiente_maxima


def modificar_material(i, m_ramales, ramal, seccion_minnima_cambio=0.6):
    # Lista de velocidades maximas segun el material para cada material del tramo
    v_max_v = v_max(m_ramales[i]["Material"])
    # indice de velocidades mayores a la maxima en el tramo
    index_v = compare_velocity(m_ramales[i]["v"], v_max_v)
    # trasnformar string a float
    seccion_int_float = seccion_str2float(m_ramales[i]["D_int"])
    # indice de secciones mayores a seccion minima
    index_seccion_mayor_seccion_minima = np.where(seccion_int_float[index_v] >= seccion_minnima_cambio)[0]
    index_seccion_menor_seccion_minima = np.where(seccion_int_float[index_v] < seccion_minnima_cambio)[0]
    index_HA = index_v[index_seccion_mayor_seccion_minima]
    index_HS = index_v[index_seccion_menor_seccion_minima]

    material_existente_HA = np.unique(m_ramales[i]["Material"][index_HA])
    cond_HA = [_ for _ in material_existente_HA if _ not in ["HA"]]

    material_existente_HS = np.unique(m_ramales[i]["Material"][index_HS])
    cond_HS = [_ for _ in material_existente_HS if _ not in ["HS"]]

    if len(cond_HS) == 0 and len(cond_HA) == 0:
        return m_ramales, ramal

    m_ramales[i]["Material"][index_HA] = "HA"
    m_ramales[i]["Material"][index_HS] = "HS"
    m_ramales[i]["Rug"] = np.asarray(roughness_mat(m_ramales[i]["Material"]))

    m_ramales[i]["D_int"][index_HA] = diameter_translate(
        seccion_str2float(m_ramales[i]["D_int"][index_HA]),
        m_ramales[i]["Material"][index_HA],
    )
    m_ramales[i]["D_int"][index_HS] = diameter_translate(
        seccion_str2float(m_ramales[i]["D_int"][index_HS]),
        m_ramales[i]["Material"][index_HS],
    )

    # asignar diametros externos, caudal y velocidad seccion llena, dimensionamiento en seccion parcialmente llena
    m_ramales, ramal = get_sizing_ext(m_ramales, ramal, i)
    m_ramales, ramal = get_SLL(m_ramales, ramal, i)
    m_ramales, ramal = get_SPLL(m_ramales, ramal, i)
    return m_ramales, ramal


def modificar_saltos(i, m_ramales, ramal, xy_inter, h_max=10.0):
    # lista de velocidades maximas segun el material para cada material del tramo
    v_max_v = v_max(m_ramales[i]["Material"])
    # indice de velocidades mayores a la maxima en el tramo
    index_v = compare_velocity(m_ramales[i]["v"], v_max_v)
    # for while cuando hay velocidades
    if len(index_v) != 0:
        while index_v.any():
            # buscar la pendiente maxima para tener una velocidad maxima
            S_target = (
                np.round(
                    seek_S(
                        m_ramales[i]["D_int"],
                        m_ramales[i]["Rug"],
                        m_ramales[i]["Material"],
                        m_ramales[i]["Seccion"],
                        m_ramales[i]["q_accu"],
                        m_ramales[i]["S"],
                    ),
                    3,
                )
                - 0.001
            )
            S_target = np.where(
                S_target > Smin(m_ramales[i]["Material"], m_ramales, i),
                S_target,
                Smin(m_ramales[i]["Material"], m_ramales, i),
            )
            # calcular nuevo fondo inicial de pozo (ZFF) considerando las pendientes maximas
            ZFI_new = m_ramales[i]["ZFF"][index_v] + (m_ramales[i]["L"][index_v] * S_target[index_v])
            # calcular salto necesario para alcanzar la pendiente maxima necesaria
            salto = np.round(m_ramales[i]["ZFI"][index_v] - ZFI_new, 3)
            # verificar que salto generado no sea mayor a h_max
            salto = np.where(salto > h_max, 0, salto)
            # calcular el nuevo fondo inicial desde los nuevos saltos
            ZFI_new = m_ramales[i]["ZFI"][index_v] - salto
            # calcular nueva S_target considerando el nuevo ZFI_new
            S_target = np.round((ZFI_new - m_ramales[i]["ZFF"][index_v]) / m_ramales[i]["L"][index_v], 3)
            ZFI_new = m_ramales[i]["ZFF"][index_v] + (m_ramales[i]["L"][index_v] * S_target)
            # asignarn pendiente
            m_ramales[i]["S"][index_v] = S_target

            # check for previus jumps, select biggest
            salto_max = np.max([salto, m_ramales[i]["SALTO"][index_v]], axis=0)
            # check if salto array is already the same, so not posible to change it further
            if list(salto_max) == list(m_ramales[i]["SALTO"][index_v]):
                break
            # asignar salto nuevo maximo
            m_ramales[i]["SALTO"][index_v] = np.round(salto_max, 3)
            # set new ZFI
            m_ramales[i]["ZFI"][index_v] = ZFI_new
            m_ramales[i]["HI"] = m_ramales[i]["ZTI"] - m_ramales[i]["ZFI"]
            m_ramales[i]["HF"] = m_ramales[i]["ZTF"] - m_ramales[i]["ZFF"]

            # asignar diametros externos, caudal y velocidad seccion llena, dimensionamiento en seccion parcialmente llena
            m_ramales, ramal = get_sizing_int(m_ramales, ramal, xy_inter, i)
            m_ramales, ramal = get_sizing_ext(m_ramales, ramal, i)
            m_ramales, ramal = get_SLL(m_ramales, ramal, i)
            m_ramales, ramal = get_SPLL(m_ramales, ramal, i)
            m_ramales, ramal = get_sizing_SPLL(m_ramales, ramal, xy_inter)
            # buscar tramos con velocidad mayor a v_max y que no tengan la pendiente minima o el salto maximo
            index_v = compare_velocity(m_ramales[i]["v"], v_max_v)
            # revisar tramos disponibles para modificar
            tramos_disponibles_cambio = np.intersect1d(
                np.where(m_ramales[i]["S"] > Smin(m_ramales[i]["Material"], m_ramales, i))[0],
                np.where(m_ramales[i]["SALTO"] < h_max)[0],
            )
            index_v = np.intersect1d(tramos_disponibles_cambio, index_v)

    return m_ramales, ramal


def get_rugosidad_canal(caso, h, b, k, response=None):
    """

    :param caso: tipo de rugosidad artificial
    :param h: Lamina libre de agua, m
    :param b: Base de canal, m
    :param k: Altura de rugosidad, m
    :return: array de valores de rugosidad de manning artificial
    """

    coeficientes_rugosidad = {
        0: ["dados", 52, -5.1, -0.8],
        1: ["barras_continuas", 47.5, -1.2, 0.1],
        2: ["barras_cortadas", 54.2, -2.1, 0.33],
        3: ["v_invertida", 85.8, -3.9, -0.8],
        4: ["doble_zig_zag", 116.1, -6.1, -1.2],
    }

    map_casos = {
        "dados": 0,
        "barras_continuas": 1,
        "barras_cortadas": 2,
        "v_invertida": 3,
        "doble_zig_zag": 4,
    }

    try:
        caso = np.array(itemgetter(*caso)(map_casos))
    except:
        pass

    # array de posibles valores de los bloques
    tipo, coef_a, coef_b, coef_c = np.array(itemgetter(*caso)(coeficientes_rugosidad)).T
    coef_a, coef_b, coef_c = (
        coef_a.astype(float),
        coef_b.astype(float),
        coef_c.astype(float),
    )
    rugosidad_Chezy = 1000 / (coef_a + coef_b * (h / k) + coef_c * (b / h))
    # Radio hidraulico
    Rh = (b * h) / (b + 2 * h)
    # Chezy to Mannig
    rugosidad_mannig = (Rh ** (1 / 6)) / rugosidad_Chezy
    check_value = np.where(rugosidad_mannig < 0)[0]
    while len(check_value) > 0:
        k[check_value] = k[check_value] + 0.025
        rugosidad_Chezy = 1000 / (coef_a + coef_b * (h / k) + coef_c * (b / h))
        # Radio hidraulico
        Rh = (b * h) / (b + 2 * h)
        # Chezy to Mannig
        rugosidad_mannig = (Rh ** (1 / 6)) / rugosidad_Chezy
        check_value = np.where(rugosidad_mannig < 0)[0]

    if response == None:
        return np.round(rugosidad_mannig, 4)
    else:
        if isinstance(tipo, str):
            return np.round(rugosidad_mannig, 4), np.array(["".join([_tipo, "-", "{:.3f}".format(_k), "m"]) for _tipo, _k in zip([tipo], k)]).astype("U256")
        else:
            return np.round(rugosidad_mannig, 4), np.array(["".join([_tipo, "-", "{:.3f}".format(_k), "m"]) for _tipo, _k in zip(tipo, k)]).astype("U256")


def modificar_seccion_rugosidad(i, m_ramales, ramal, seccion_minima_rectangular, xy_inter):
    # lista de velocidades maximas segun el material para cada material del tramo
    v_max_v = v_max(m_ramales[i]["Material"])
    index_v = compare_velocity(m_ramales[i]["v"], v_max_v)
    # transformar secciones de string a float
    seccion_int = seccion_str2float(m_ramales[i]["D_int"])
    # indices de tramos  rectangulares existentes
    index_seccion_rectangular_existente = np.char.equal("rectangular", m_ramales[i]["Seccion"]).nonzero()[0]
    # indice de tramos posibles para convertir en canal
    index_seccion_rectangular_nueva = np.where(seccion_int >= seccion_minima_rectangular)[0]
    # indice de tramos que necesitan ser rectangulares para poner rugosidad artificial
    no_rectangular_seccion_yet = np.setdiff1d(index_seccion_rectangular_nueva, index_seccion_rectangular_existente)
    need_tobe_rectangular_seccion = np.intersect1d(index_v, no_rectangular_seccion_yet)

    # revisar si hay secciones para cambiar
    if len(need_tobe_rectangular_seccion) == 0 and index_seccion_rectangular_nueva.size == 0:
        return m_ramales, ramal

    # convertir tramos en canales rectangulares y de material HA
    m_ramales[i]["Seccion"][need_tobe_rectangular_seccion] = "rectangular"
    m_ramales[i]["Material"][need_tobe_rectangular_seccion] = "HA"
    m_ramales[i]["Rug"] = np.asarray(roughness_mat(m_ramales[i]["Material"]))

    # asignar diametros externos, caudal y velocidad seccion llena, dimensionamiento en seccion parcialmente llena
    m_ramales, ramal = get_sizing_int(m_ramales, ramal, xy_inter, i)
    m_ramales, ramal = get_sizing_ext(m_ramales, ramal, i)
    m_ramales, ramal = get_SLL(m_ramales, ramal, i)
    m_ramales, ramal = get_SPLL(m_ramales, ramal, i)
    m_ramales, ramal = get_sizing_SPLL(m_ramales, ramal, xy_inter)

    # índice de velocidades mayores a la maxima en el tramo despues de cambiar a seccion recntangular
    index_v = compare_velocity(m_ramales[i]["v"], v_max_v)
    # intersectar las secciones rectangulares y las velocidades mayores al maximo
    index_seccion_rectangular_existente = np.char.equal("rectangular", m_ramales[i]["Seccion"]).nonzero()[0]
    need_tobe_rectangular_seccion = np.intersect1d(index_v, index_seccion_rectangular_existente)
    # valores iniciales
    s = 0.05
    caso = 0
    caso_rugosidad = np.full(shape=len(m_ramales[i]["h"]), fill_value=caso, dtype=int)
    s = np.full(shape=len(m_ramales[i]["h"]), fill_value=s, dtype=float)
    while len(index_v) > 0 and len(need_tobe_rectangular_seccion) > 0:
        # indexar arrays originales
        caso_rugosidad_new = caso_rugosidad[need_tobe_rectangular_seccion]
        s_new = s[need_tobe_rectangular_seccion]
        # get h y b from channel seccion
        try:
            b, h_int = np.array([np.array(_.split("x")).astype(float) for _ in m_ramales[i]["D_int"][need_tobe_rectangular_seccion]]).T
        except:
            print()
        h = m_ramales[i]["h"][need_tobe_rectangular_seccion]

        # check for condition (h/s) <= 3
        cond = (h / s_new) <= 3
        cond = cond.nonzero()[0]
        if len(cond) > 0:
            # remover el valor que no cumple la condicion
            s_new[cond] = s_new[cond] - 0.025
            # modificar la rugosidad de los tramos que no cumplen la velocidad
            caso_rugosidad_new[cond] = caso_rugosidad_new[cond] + 1
            if np.max(caso_rugosidad) > 4:
                print(
                    "Velocidad maxima en tramo: ",
                    m_ramales[i]["Tramo"][need_tobe_rectangular_seccion[cond]],
                )
                sys.exit("ERROR")

        # modificar rugosidad de canal
        rugosidad_value_array, rugosidad_tipo_array = get_rugosidad_canal(caso_rugosidad_new, h, b, s_new, response=True)
        mannig_array = m_ramales[i]["Rug"].copy()
        mannig_array[need_tobe_rectangular_seccion] = rugosidad_value_array
        m_ramales[i]["Rug"] = mannig_array

        # asignar diametros externos, caudal y velocidad seccion llena, dimensionamiento en seccion parcialmente llena
        m_ramales, ramal = get_SLL(m_ramales, ramal, i)
        m_ramales, ramal = get_SPLL(m_ramales, ramal, i)

        # modificar arrays originales
        caso_rugosidad[need_tobe_rectangular_seccion] = caso_rugosidad_new
        s[need_tobe_rectangular_seccion] = s_new

        # modificar Rugosidad de m_ramales
        rugosidad_string = m_ramales[i]["Rugosidad"].copy()
        rugosidad_string[need_tobe_rectangular_seccion] = rugosidad_tipo_array
        m_ramales[i]["Rugosidad"] = rugosidad_string

        # índice de velocidades mayores a la maxima en el tramo
        index_v = compare_velocity(m_ramales[i]["v"], v_max_v)
        if len(index_v) > 0:
            s[need_tobe_rectangular_seccion] = s[need_tobe_rectangular_seccion] + 0.025
            index_seccion_rectangular_existente = np.char.equal("rectangular", m_ramales[i]["Seccion"]).nonzero()[0]
            need_tobe_rectangular_seccion = np.intersect1d(index_v, index_seccion_rectangular_existente)

    # asignar diametros externos, caudal y velocidad seccion llena, dimensionamiento en seccion parcialmente llena (redimensionar canales por aumento de lámina de agua por rugosidad articial)
    m_ramales, ramal = get_sizing_int(m_ramales, ramal, xy_inter, i)
    m_ramales, ramal = get_sizing_ext(m_ramales, ramal, i)
    m_ramales, ramal = get_SLL(m_ramales, ramal, i)
    m_ramales, ramal = get_SPLL(m_ramales, ramal, i)
    m_ramales, ramal = get_sizing_SPLL(m_ramales, ramal, xy_inter)

    return m_ramales, ramal


def modificar_pendiente_reducir_saltos(h_max, i, m_ramales, ramal, xy_inter):
    # indicar los indices de los tramos que tiene velocidad menor a la maxima y tiene un salto mayor a cero
    index_velocidad_menor = np.where(m_ramales[i]["v"] < v_max(m_ramales[i]["Material"]))[0]
    index_salto = np.where(m_ramales[i]["SALTO"] > 0)[0]
    index_change_slope = np.intersect1d(index_velocidad_menor, index_salto)
    if len(index_change_slope) > 0:
        # buscar la pendiente maxima para tener una velocidad maxima
        pendiente_maxima_hidraulica = np.round(
            seek_S(
                m_ramales[i]["D_int"],
                m_ramales[i]["Rug"],
                m_ramales[i]["Material"],
                m_ramales[i]["Seccion"],
                m_ramales[i]["q_accu"],
                m_ramales[i]["S"],
            ),
            3,
        )
        # buscar la pendiente maxima que pueda existir fisicamente
        # profundidad inicial minima
        hi_min = par_basicos(1) + seccion_str2float(m_ramales[i]["D_ext"])
        # elevacion maxima de fondo inicial ZFI
        ZFI_minima = m_ramales[i]["ZTI"] - hi_min
        # obtener la pendiente fisica maxima
        pendiente_maxima_fisica = np.round((ZFI_minima - m_ramales[i]["ZFF"]) / m_ramales[i]["L"], 3)
        # revisar para pendiente minima
        pendiente_maxima_fisica = np.where(
            pendiente_maxima_fisica < m_ramales[i]["S"],
            m_ramales[i]["S"],
            pendiente_maxima_fisica,
        )
        # pendiente maxima
        pendiente_maxima = np.min([pendiente_maxima_hidraulica, pendiente_maxima_fisica], axis=0) - 0.001
        # encontrar donde la pendiente maxima obtenida es mayor a la pendinete actual
        cond = (pendiente_maxima - m_ramales[i]["S"]) > 0.001
        cond = cond.nonzero()[0]
        cond = np.intersect1d(cond, index_change_slope)
        if len(cond) == 0:
            return m_ramales, ramal

        # calcular nuevo fondo inicial de pozo (ZFF) considerando las pendientes maximas
        ZFI_new = m_ramales[i]["ZFF"][cond] + (m_ramales[i]["L"][cond] * pendiente_maxima[cond])
        # calcular salto la necesario para alcanzar la pendiente maxima necesaria
        diferencia_salto = np.round(ZFI_new - m_ramales[i]["ZFI"][cond], 3)
        # limitar la diferencia de salto al h_max inicial
        diferencia_salto = np.where(diferencia_salto > h_max, h_max, diferencia_salto)
        # modificar profunidad de salto
        salto = m_ramales[i]["SALTO"].copy()
        # salto[cond] = m_ramales[i]['SALTO'][cond] - diferencia_salto
        salto[cond] = np.min([m_ramales[i]["SALTO"][cond], diferencia_salto], axis=0)
        # asignar salto nuevo maximo
        m_ramales[i]["SALTO"] = np.round(salto, 3)
        # set new ZFI
        m_ramales[i]["ZFI"][cond] = ZFI_new
        m_ramales[i]["HI"] = m_ramales[i]["ZTI"] - m_ramales[i]["ZFI"]
        m_ramales[i]["HF"] = m_ramales[i]["ZTF"] - m_ramales[i]["ZFF"]
        # modificar las pendientes
        m_ramales = w_TFP(i, m_ramales)
        # asignar diametros externos, caudal y velocidad seccion llena, dimensionamiento en seccion parcialmente llena
        m_ramales, ramal = get_sizing_int(m_ramales, ramal, xy_inter, i)
        m_ramales, ramal = get_sizing_ext(m_ramales, ramal, i)
        m_ramales, ramal = get_SLL(m_ramales, ramal, i)
        m_ramales, ramal = get_SPLL(m_ramales, ramal, i)
        m_ramales, ramal = get_sizing_SPLL(m_ramales, ramal, xy_inter)

    return m_ramales, ramal


def opt_V(i, m_ramales, ramal, xy_inter):
    # revisar si m_ramales tiene la llave SALTO
    if "SALTO" not in list(m_ramales[i].keys()):
        m_ramales[i]["SALTO"] = np.zeros(shape=len(m_ramales[i]["S"]), dtype=float)

    # diametro minimo para cambiar de hormigon simple a hormigon armado
    seccion_minnima_cambio = 0.6
    # salto maximo para reducir velocidad
    h_max = 2.5
    # diametro minimo para cambiar de tuberia a canal, diametro maximo para poner tuberia de
    seccion_minima_rectangular = 0.2

    # primer intento: cambiar el material de plastico a hormigon para reducir la velocidad
    m_ramales, ramal = modificar_material(i, m_ramales, ramal, seccion_minnima_cambio)

    # segundo intento: hacer salto para modificar pendiente
    m_ramales, ramal = modificar_saltos(i, m_ramales, ramal, xy_inter, h_max)

    # tercer intento: cambiar el tipo de seccion a canal
    m_ramales, ramal = modificar_seccion_rugosidad(i, m_ramales, ramal, seccion_minima_rectangular, xy_inter)

    # cuarto interno: reducir saltos y profunidades corrigiendo pendiente
    # m_ramales, ramal = modificar_pendiente_reducir_saltos(h_max, i, m_ramales, ramal, xy_inter)

    # falta hacer 5 intento, cambiar a pvc de presion las que sea sanitarios con velcoidad alta

    return m_ramales, ramal


def get_opt_V(m_ramales, ramal, xy_inter):
    for i in ramal.values():
        "OPTIMIZAR: CREAR SALTOS PARA REDUCIR VELOCIDAD"
        # indice para modificar los tramos nuevos unicamente
        index = np.char.equal(m_ramales[i]["Estado"], "nuevo").nonzero()[0]
        if index.size > 0:
            m_ramales, ramal = opt_V(i, m_ramales, ramal, xy_inter)
    return m_ramales, ramal


def get_opt_V_thread(m_ramales, ramal, xy_inter, i):
    "OPTIMIZAR: CREAR SALTOS PARA REDUCIR VELOCIDAD"
    m_ramales, ramal = opt_V(i, m_ramales, ramal, xy_inter)
    return m_ramales[i]


def get_opt_V_MP(m_ramales, ramal, xy_inter, n_cpu):
    iter_v = sorted(ramal.keys())
    func1 = partial(get_opt_V_thread, m_ramales, ramal, xy_inter)
    pool = Pool(processes=n_cpu)
    p = pool.map(func1, iter_v)
    for i in p:
        m_ramales[i["Ramal"][0]] = i
    return m_ramales, ramal


"######################################################################################################################"
"COMPROBACIONES HIDRAULICAS"
"######################################################################################################################"


def get_tension_tractiva(m_ramales, j):
    """

    :param m_ramales:
    :param j:
    :return: Tension Tractiva en Pascales, minimo 0.6 sanitario o 1 en pluvial
    """
    Seccion = m_ramales[j]["Seccion"]
    secciones = np.unique(Seccion)
    tension_tractiva = np.zeros(shape=len(Seccion))
    # gravedad
    gravedad = 9.81
    # densidad agua
    densidad_agua = 1000

    for _seccion in secciones:
        seccion_index = np.char.equal(Seccion, _seccion).nonzero()[0]
        if _seccion in ["circular"]:
            seccion_index_circular = np.trim_zeros(seccion_index)
            d_int_array = seccion_str2float(m_ramales[j]["D_int"][seccion_index_circular])
            angle_radians = np.radians(m_ramales[j]["ang"][seccion_index_circular])
            Rh_circular = (1 - (np.sin(angle_radians) / angle_radians)) * (d_int_array / 4.0)
            tension_tractiva_circular = densidad_agua * gravedad * m_ramales[j]["S"][seccion_index_circular] * Rh_circular
            tension_tractiva[seccion_index_circular] = tension_tractiva_circular

        elif _seccion in ["rectangular"]:
            # indice de seccion rectangular del tramo j
            seccion_index_rectangular = np.trim_zeros(seccion_index)
            # base y altura de la seccion, por defecto son str
            b_arr, h_arr = pp_char_split(m_ramales[j]["D_int"][seccion_index_rectangular], _split="x")
            b_arr, h_arr = b_arr.astype(float), h_arr.astype(float)
            b_v = np.zeros(shape=len(m_ramales[j]["D_int"]))
            b_v[seccion_index_rectangular] = b_arr
            # vector de calado de agua en el canal rectangular
            y_arr = m_ramales[j]["h"][seccion_index_rectangular]
            # Radio hidraulico
            Rh_rectangular = (b_arr * y_arr) / (b_arr + (2 * y_arr))
            tension_tractiva_rectangular = densidad_agua * gravedad * m_ramales[j]["S"][seccion_index_rectangular] * Rh_rectangular
            tension_tractiva[seccion_index_rectangular] = tension_tractiva_rectangular

    return tension_tractiva


def get_froude_number(m_ramales, j):
    # gravedad
    g = 9.81
    # Froude number
    froude = m_ramales[j]["v"] / (g * m_ramales[j]["h"]) ** 0.5
    froude_string = np.empty(shape=len(froude), dtype="U256")
    # asignar tipo de flujo
    froude_string[np.where(froude == 1)[0]] = "critico"
    froude_string[np.where(froude < 1)[0]] = "sub-critico"
    froude_string[np.where(froude > 1)[0]] = "super-critico"

    return froude_string


def get_reynolds_number(m_ramales, j):
    """

    :param m_ramales:
    :param j:
    :return: numero de reynolds
    """
    Seccion = m_ramales[j]["Seccion"]
    secciones = np.unique(Seccion)
    reynolds = np.zeros(shape=len(Seccion))
    reynolds_string = np.empty(shape=len(reynolds), dtype="U256")
    # viscocidad cinematica
    kv = 1.004 * 10**-6

    for _seccion in secciones:
        seccion_index = np.char.equal(Seccion, _seccion).nonzero()[0]
        if _seccion in ["circular"]:
            seccion_index_circular = np.trim_zeros(seccion_index)
            d_int_array = seccion_str2float(m_ramales[j]["D_int"][seccion_index_circular])
            angle_radians = np.radians(m_ramales[j]["ang"][seccion_index_circular])
            Rh_circular = (1 - (np.sin(angle_radians) / angle_radians)) * (d_int_array / 4.0)
            reynolds_circular = m_ramales[j]["v"][seccion_index_circular] * Rh_circular / kv
            reynolds[seccion_index_circular] = reynolds_circular

        elif _seccion in ["rectangular"]:
            # índice de seccion rectangular del tramo j
            seccion_index_rectangular = np.trim_zeros(seccion_index)
            # base y altura de la seccion, por defecto son str
            b_arr, h_arr = pp_char_split(m_ramales[j]["D_int"][seccion_index_rectangular], _split="x")
            b_arr, h_arr = b_arr.astype(float), h_arr.astype(float)
            b_v = np.zeros(shape=len(m_ramales[j]["D_int"]))
            b_v[seccion_index_rectangular] = b_arr
            # vector de calado de agua en el canal rectangular
            y_arr = m_ramales[j]["h"][seccion_index_rectangular]
            # Radio hidraulico
            Rh_rectangular = (b_arr * y_arr) / (b_arr + (2 * y_arr))
            reynolds_rectangular = m_ramales[j]["v"][seccion_index_rectangular] * Rh_rectangular / kv
            reynolds[seccion_index_rectangular] = reynolds_rectangular

    # asignar tipo de flujo
    reynolds_string[np.where(reynolds < 2300)[0]] = "laminar"
    reynolds_string[np.intersect1d(np.where(reynolds <= 2300)[0], np.where(reynolds >= 2900)[0])] = "transicion"
    reynolds_string[np.where(reynolds > 2900)[0]] = "turbulento"

    return reynolds_string


def indice_abrasion(m_ramales, j):
    porcentaje_sedimentos = 0.15
    return (m_ramales[j]["v"] * porcentaje_sedimentos * m_ramales[j]["h"]) / (seccion_str2float(m_ramales[j]["D_ext"]) * m_ramales[j]["Rug"])


def hydraulic_conditions(m_ramales, ramal):
    """

    :param m_ramales:
    :param ramal:
    :return:
    """
    for i in ramal.values():
        # tension tractiva
        m_ramales[i]["Tension"] = get_tension_tractiva(m_ramales, i)
        # numero de froude
        m_ramales[i]["Froude"] = get_froude_number(m_ramales, i)
        # numero de reynolds
        m_ramales[i]["Reynolds"] = get_reynolds_number(m_ramales, i)
        # indice de desgaste
        m_ramales[i]["indice_abrasion"] = indice_abrasion(m_ramales, i)  # perdidas de carga en flujo

    return m_ramales, ramal


def force_format_diameter(m_ramales, ramal):
    """

    :param m_ramales:
    :param ramal:
    :return:
    """
    for i in ramal.values():
        # force correct format to D_ext
        m_ramales[i]["D_ext"] = round_floats_in_string(m_ramales[i]["D_ext"], decimal_places=3)
        m_ramales[i]["D_int"] = round_floats_in_string(m_ramales[i]["D_int"], decimal_places=3)

    return m_ramales, ramal


"######################################################################################################################"
"SHP OUT, DXF OUT "
"######################################################################################################################"


def qml2file():
    string = """
         <!DOCTYPE qgis PUBLIC 'http://mrcc.com/qgis.dtd' 'SYSTEM'>
<qgis readOnly="0" styleCategories="LayerConfiguration|Symbology|Labeling|Fields|Legend" version="3.34.1-Prizren" labelsEnabled="1">
  <flags>
    <Identifiable>1</Identifiable>
    <Removable>1</Removable>
    <Searchable>1</Searchable>
    <Private>0</Private>
  </flags>
  <renderer-v2 enableorderby="0" type="categorizedSymbol" attr="Seccion" forceraster="0" referencescale="-1" symbollevels="0">
    <categories>
      <category symbol="0" type="string" label="circular" value="circular" uuid="{27866238-6c2d-4926-920f-ac406a28beb3}" render="true"/>
      <category symbol="1" type="string" label="rectangular" value="rectangular" uuid="{a20fd1b8-99d5-4290-a1d3-5da45026179c}" render="true"/>
      <category symbol="2" type="string" label="" value="" uuid="{4a2c249a-881b-490d-8ca2-f3ae3fe8aa60}" render="true"/>
    </categories>
    <symbols>
      <symbol alpha="1" type="line" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="0">
        <data_defined_properties>
          <Option type="Map">
            <Option type="QString" value="" name="name"/>
            <Option name="properties"/>
            <Option type="QString" value="collection" name="type"/>
          </Option>
        </data_defined_properties>
        <layer pass="0" id="{f2171ebb-a20f-48b3-a09e-54ef992a6794}" class="MarkerLine" enabled="1" locked="0">
          <Option type="Map">
            <Option type="QString" value="4" name="average_angle_length"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="average_angle_map_unit_scale"/>
            <Option type="QString" value="MM" name="average_angle_unit"/>
            <Option type="QString" value="3" name="interval"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="interval_map_unit_scale"/>
            <Option type="QString" value="MM" name="interval_unit"/>
            <Option type="QString" value="0" name="offset"/>
            <Option type="QString" value="0" name="offset_along_line"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_along_line_map_unit_scale"/>
            <Option type="QString" value="MM" name="offset_along_line_unit"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
            <Option type="QString" value="MM" name="offset_unit"/>
            <Option type="bool" value="true" name="place_on_every_part"/>
            <Option type="QString" value="SegmentCenter" name="placements"/>
            <Option type="QString" value="0" name="ring_filter"/>
            <Option type="QString" value="1" name="rotate"/>
          </Option>
          <data_defined_properties>
            <Option type="Map">
              <Option type="QString" value="" name="name"/>
              <Option name="properties"/>
              <Option type="QString" value="collection" name="type"/>
            </Option>
          </data_defined_properties>
          <symbol alpha="1" type="marker" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="@0@0">
            <data_defined_properties>
              <Option type="Map">
                <Option type="QString" value="" name="name"/>
                <Option name="properties"/>
                <Option type="QString" value="collection" name="type"/>
              </Option>
            </data_defined_properties>
            <layer pass="0" id="{2e65d832-2d03-4503-99f9-90f7de9288d3}" class="FilledMarker" enabled="1" locked="0">
              <Option type="Map">
                <Option type="QString" value="0" name="angle"/>
                <Option type="QString" value="43,131,186,255" name="color"/>
                <Option type="QString" value="1" name="horizontal_anchor_point"/>
                <Option type="QString" value="filled_arrowhead" name="name"/>
                <Option type="QString" value="0,0" name="offset"/>
                <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
                <Option type="QString" value="MM" name="offset_unit"/>
                <Option type="QString" value="diameter" name="scale_method"/>
                <Option type="QString" value="3" name="size"/>
                <Option type="QString" value="3x:0,0,0,0,0,0" name="size_map_unit_scale"/>
                <Option type="QString" value="MM" name="size_unit"/>
                <Option type="QString" value="1" name="vertical_anchor_point"/>
              </Option>
              <data_defined_properties>
                <Option type="Map">
                  <Option type="QString" value="" name="name"/>
                  <Option type="Map" name="properties">
                    <Option type="Map" name="size">
                      <Option type="bool" value="true" name="active"/>
                      <Option type="QString" value="CASE&#xd;&#xa;  WHEN &quot;D_ext&quot; LIKE '%x%' THEN&#xd;&#xa;    sqrt(to_real(left(&quot;D_ext&quot;, strpos(&quot;D_ext&quot;, 'x') - 1))) * 3&#xd;&#xa;  ELSE&#xd;&#xa;    sqrt(to_real(&quot;D_ext&quot;)) * 5&#xd;&#xa;END" name="expression"/>
                      <Option type="int" value="3" name="type"/>
                    </Option>
                  </Option>
                  <Option type="QString" value="collection" name="type"/>
                </Option>
              </data_defined_properties>
              <symbol alpha="1" type="fill" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="@@0@0@0">
                <data_defined_properties>
                  <Option type="Map">
                    <Option type="QString" value="" name="name"/>
                    <Option name="properties"/>
                    <Option type="QString" value="collection" name="type"/>
                  </Option>
                </data_defined_properties>
                <layer pass="0" id="{5f1d114b-d9ef-49e9-acc7-4926684d21c5}" class="SimpleFill" enabled="1" locked="0">
                  <Option type="Map">
                    <Option type="QString" value="3x:0,0,0,0,0,0" name="border_width_map_unit_scale"/>
                    <Option type="QString" value="43,131,186,255" name="color"/>
                    <Option type="QString" value="miter" name="joinstyle"/>
                    <Option type="QString" value="0,0" name="offset"/>
                    <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
                    <Option type="QString" value="MM" name="offset_unit"/>
                    <Option type="QString" value="35,35,35,255" name="outline_color"/>
                    <Option type="QString" value="solid" name="outline_style"/>
                    <Option type="QString" value="0" name="outline_width"/>
                    <Option type="QString" value="MM" name="outline_width_unit"/>
                    <Option type="QString" value="solid" name="style"/>
                  </Option>
                  <data_defined_properties>
                    <Option type="Map">
                      <Option type="QString" value="" name="name"/>
                      <Option name="properties"/>
                      <Option type="QString" value="collection" name="type"/>
                    </Option>
                  </data_defined_properties>
                </layer>
              </symbol>
            </layer>
          </symbol>
        </layer>
        <layer pass="0" id="{8980af69-e003-4ba3-b691-16c00256a6c5}" class="SimpleLine" enabled="1" locked="0">
          <Option type="Map">
            <Option type="QString" value="0" name="align_dash_pattern"/>
            <Option type="QString" value="square" name="capstyle"/>
            <Option type="QString" value="5;2" name="customdash"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="customdash_map_unit_scale"/>
            <Option type="QString" value="MM" name="customdash_unit"/>
            <Option type="QString" value="0" name="dash_pattern_offset"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="dash_pattern_offset_map_unit_scale"/>
            <Option type="QString" value="MM" name="dash_pattern_offset_unit"/>
            <Option type="QString" value="0" name="draw_inside_polygon"/>
            <Option type="QString" value="bevel" name="joinstyle"/>
            <Option type="QString" value="43,131,186,255" name="line_color"/>
            <Option type="QString" value="solid" name="line_style"/>
            <Option type="QString" value="0.6" name="line_width"/>
            <Option type="QString" value="MM" name="line_width_unit"/>
            <Option type="QString" value="0" name="offset"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
            <Option type="QString" value="MM" name="offset_unit"/>
            <Option type="QString" value="0" name="ring_filter"/>
            <Option type="QString" value="0" name="trim_distance_end"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="trim_distance_end_map_unit_scale"/>
            <Option type="QString" value="MM" name="trim_distance_end_unit"/>
            <Option type="QString" value="0" name="trim_distance_start"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="trim_distance_start_map_unit_scale"/>
            <Option type="QString" value="MM" name="trim_distance_start_unit"/>
            <Option type="QString" value="0" name="tweak_dash_pattern_on_corners"/>
            <Option type="QString" value="0" name="use_custom_dash"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="width_map_unit_scale"/>
          </Option>
          <data_defined_properties>
            <Option type="Map">
              <Option type="QString" value="" name="name"/>
              <Option type="Map" name="properties">
                <Option type="Map" name="outlineWidth">
                  <Option type="bool" value="true" name="active"/>
                  <Option type="QString" value="CASE&#xd;&#xa;  WHEN &quot;D_ext&quot; LIKE '%x%' THEN&#xd;&#xa;    sqrt(to_real(left(&quot;D_ext&quot;, strpos(&quot;D_ext&quot;, 'x') - 1)))&#xd;&#xa;  ELSE&#xd;&#xa;    sqrt(to_real(&quot;D_ext&quot;)) * 1.25&#xd;&#xa;END" name="expression"/>
                  <Option type="int" value="3" name="type"/>
                </Option>
              </Option>
              <Option type="QString" value="collection" name="type"/>
            </Option>
          </data_defined_properties>
        </layer>
        <layer pass="0" id="{e8de49c9-d072-487d-ab3f-f91c06082f27}" class="MarkerLine" enabled="1" locked="0">
          <Option type="Map">
            <Option type="QString" value="4" name="average_angle_length"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="average_angle_map_unit_scale"/>
            <Option type="QString" value="MM" name="average_angle_unit"/>
            <Option type="QString" value="3" name="interval"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="interval_map_unit_scale"/>
            <Option type="QString" value="MM" name="interval_unit"/>
            <Option type="QString" value="0" name="offset"/>
            <Option type="QString" value="0" name="offset_along_line"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_along_line_map_unit_scale"/>
            <Option type="QString" value="MM" name="offset_along_line_unit"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
            <Option type="QString" value="MM" name="offset_unit"/>
            <Option type="bool" value="true" name="place_on_every_part"/>
            <Option type="QString" value="LastVertex|FirstVertex|InnerVertices" name="placements"/>
            <Option type="QString" value="0" name="ring_filter"/>
            <Option type="QString" value="1" name="rotate"/>
          </Option>
          <data_defined_properties>
            <Option type="Map">
              <Option type="QString" value="" name="name"/>
              <Option name="properties"/>
              <Option type="QString" value="collection" name="type"/>
            </Option>
          </data_defined_properties>
          <symbol alpha="1" type="marker" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="@0@2">
            <data_defined_properties>
              <Option type="Map">
                <Option type="QString" value="" name="name"/>
                <Option name="properties"/>
                <Option type="QString" value="collection" name="type"/>
              </Option>
            </data_defined_properties>
            <layer pass="0" id="{062adcbc-c023-4909-ba48-3875ea1a4cde}" class="FilledMarker" enabled="1" locked="0">
              <Option type="Map">
                <Option type="QString" value="0" name="angle"/>
                <Option type="QString" value="43,131,186,255" name="color"/>
                <Option type="QString" value="1" name="horizontal_anchor_point"/>
                <Option type="QString" value="circle" name="name"/>
                <Option type="QString" value="0,0" name="offset"/>
                <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
                <Option type="QString" value="MM" name="offset_unit"/>
                <Option type="QString" value="diameter" name="scale_method"/>
                <Option type="QString" value="2" name="size"/>
                <Option type="QString" value="3x:0,0,0,0,0,0" name="size_map_unit_scale"/>
                <Option type="QString" value="MM" name="size_unit"/>
                <Option type="QString" value="1" name="vertical_anchor_point"/>
              </Option>
              <data_defined_properties>
                <Option type="Map">
                  <Option type="QString" value="" name="name"/>
                  <Option type="Map" name="properties">
                    <Option type="Map" name="size">
                      <Option type="bool" value="true" name="active"/>
                      <Option type="QString" value="CASE&#xd;&#xa;  WHEN &quot;D_ext&quot; LIKE '%x%' THEN&#xd;&#xa;    sqrt(to_real(left(&quot;D_ext&quot;, strpos(&quot;D_ext&quot;, 'x') - 1))) * 2&#xd;&#xa;  ELSE&#xd;&#xa;    sqrt(to_real(&quot;D_ext&quot;)) * 3&#xd;&#xa;END" name="expression"/>
                      <Option type="int" value="3" name="type"/>
                    </Option>
                  </Option>
                  <Option type="QString" value="collection" name="type"/>
                </Option>
              </data_defined_properties>
              <symbol alpha="1" type="fill" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="@@0@2@0">
                <data_defined_properties>
                  <Option type="Map">
                    <Option type="QString" value="" name="name"/>
                    <Option name="properties"/>
                    <Option type="QString" value="collection" name="type"/>
                  </Option>
                </data_defined_properties>
                <layer pass="0" id="{4e7cc66f-7bc4-4549-959d-e619c68cc739}" class="SimpleFill" enabled="1" locked="0">
                  <Option type="Map">
                    <Option type="QString" value="3x:0,0,0,0,0,0" name="border_width_map_unit_scale"/>
                    <Option type="QString" value="43,131,186,255" name="color"/>
                    <Option type="QString" value="bevel" name="joinstyle"/>
                    <Option type="QString" value="0,0" name="offset"/>
                    <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
                    <Option type="QString" value="MM" name="offset_unit"/>
                    <Option type="QString" value="35,35,35,255" name="outline_color"/>
                    <Option type="QString" value="solid" name="outline_style"/>
                    <Option type="QString" value="0" name="outline_width"/>
                    <Option type="QString" value="MM" name="outline_width_unit"/>
                    <Option type="QString" value="solid" name="style"/>
                  </Option>
                  <data_defined_properties>
                    <Option type="Map">
                      <Option type="QString" value="" name="name"/>
                      <Option name="properties"/>
                      <Option type="QString" value="collection" name="type"/>
                    </Option>
                  </data_defined_properties>
                </layer>
              </symbol>
            </layer>
          </symbol>
        </layer>
      </symbol>
      <symbol alpha="1" type="line" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="1">
        <data_defined_properties>
          <Option type="Map">
            <Option type="QString" value="" name="name"/>
            <Option name="properties"/>
            <Option type="QString" value="collection" name="type"/>
          </Option>
        </data_defined_properties>
        <layer pass="0" id="{f2171ebb-a20f-48b3-a09e-54ef992a6794}" class="MarkerLine" enabled="1" locked="0">
          <Option type="Map">
            <Option type="QString" value="4" name="average_angle_length"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="average_angle_map_unit_scale"/>
            <Option type="QString" value="MM" name="average_angle_unit"/>
            <Option type="QString" value="3" name="interval"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="interval_map_unit_scale"/>
            <Option type="QString" value="MM" name="interval_unit"/>
            <Option type="QString" value="0" name="offset"/>
            <Option type="QString" value="0" name="offset_along_line"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_along_line_map_unit_scale"/>
            <Option type="QString" value="MM" name="offset_along_line_unit"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
            <Option type="QString" value="MM" name="offset_unit"/>
            <Option type="bool" value="true" name="place_on_every_part"/>
            <Option type="QString" value="SegmentCenter" name="placements"/>
            <Option type="QString" value="0" name="ring_filter"/>
            <Option type="QString" value="1" name="rotate"/>
          </Option>
          <data_defined_properties>
            <Option type="Map">
              <Option type="QString" value="" name="name"/>
              <Option name="properties"/>
              <Option type="QString" value="collection" name="type"/>
            </Option>
          </data_defined_properties>
          <symbol alpha="1" type="marker" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="@1@0">
            <data_defined_properties>
              <Option type="Map">
                <Option type="QString" value="" name="name"/>
                <Option name="properties"/>
                <Option type="QString" value="collection" name="type"/>
              </Option>
            </data_defined_properties>
            <layer pass="0" id="{2e65d832-2d03-4503-99f9-90f7de9288d3}" class="FilledMarker" enabled="1" locked="0">
              <Option type="Map">
                <Option type="QString" value="0" name="angle"/>
                <Option type="QString" value="255,255,191,255" name="color"/>
                <Option type="QString" value="1" name="horizontal_anchor_point"/>
                <Option type="QString" value="filled_arrowhead" name="name"/>
                <Option type="QString" value="0,0" name="offset"/>
                <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
                <Option type="QString" value="MM" name="offset_unit"/>
                <Option type="QString" value="diameter" name="scale_method"/>
                <Option type="QString" value="3" name="size"/>
                <Option type="QString" value="3x:0,0,0,0,0,0" name="size_map_unit_scale"/>
                <Option type="QString" value="MM" name="size_unit"/>
                <Option type="QString" value="1" name="vertical_anchor_point"/>
              </Option>
              <data_defined_properties>
                <Option type="Map">
                  <Option type="QString" value="" name="name"/>
                  <Option type="Map" name="properties">
                    <Option type="Map" name="size">
                      <Option type="bool" value="true" name="active"/>
                      <Option type="QString" value="CASE&#xd;&#xa;  WHEN &quot;D_ext&quot; LIKE '%x%' THEN&#xd;&#xa;    sqrt(to_real(left(&quot;D_ext&quot;, strpos(&quot;D_ext&quot;, 'x') - 1))) * 3&#xd;&#xa;  ELSE&#xd;&#xa;    sqrt(to_real(&quot;D_ext&quot;)) * 5&#xd;&#xa;END" name="expression"/>
                      <Option type="int" value="3" name="type"/>
                    </Option>
                  </Option>
                  <Option type="QString" value="collection" name="type"/>
                </Option>
              </data_defined_properties>
              <symbol alpha="1" type="fill" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="@@1@0@0">
                <data_defined_properties>
                  <Option type="Map">
                    <Option type="QString" value="" name="name"/>
                    <Option name="properties"/>
                    <Option type="QString" value="collection" name="type"/>
                  </Option>
                </data_defined_properties>
                <layer pass="0" id="{5f1d114b-d9ef-49e9-acc7-4926684d21c5}" class="SimpleFill" enabled="1" locked="0">
                  <Option type="Map">
                    <Option type="QString" value="3x:0,0,0,0,0,0" name="border_width_map_unit_scale"/>
                    <Option type="QString" value="255,255,191,255" name="color"/>
                    <Option type="QString" value="miter" name="joinstyle"/>
                    <Option type="QString" value="0,0" name="offset"/>
                    <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
                    <Option type="QString" value="MM" name="offset_unit"/>
                    <Option type="QString" value="35,35,35,255" name="outline_color"/>
                    <Option type="QString" value="solid" name="outline_style"/>
                    <Option type="QString" value="0" name="outline_width"/>
                    <Option type="QString" value="MM" name="outline_width_unit"/>
                    <Option type="QString" value="solid" name="style"/>
                  </Option>
                  <data_defined_properties>
                    <Option type="Map">
                      <Option type="QString" value="" name="name"/>
                      <Option name="properties"/>
                      <Option type="QString" value="collection" name="type"/>
                    </Option>
                  </data_defined_properties>
                </layer>
              </symbol>
            </layer>
          </symbol>
        </layer>
        <layer pass="0" id="{8980af69-e003-4ba3-b691-16c00256a6c5}" class="SimpleLine" enabled="1" locked="0">
          <Option type="Map">
            <Option type="QString" value="0" name="align_dash_pattern"/>
            <Option type="QString" value="square" name="capstyle"/>
            <Option type="QString" value="5;2" name="customdash"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="customdash_map_unit_scale"/>
            <Option type="QString" value="MM" name="customdash_unit"/>
            <Option type="QString" value="0" name="dash_pattern_offset"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="dash_pattern_offset_map_unit_scale"/>
            <Option type="QString" value="MM" name="dash_pattern_offset_unit"/>
            <Option type="QString" value="0" name="draw_inside_polygon"/>
            <Option type="QString" value="bevel" name="joinstyle"/>
            <Option type="QString" value="255,255,191,255" name="line_color"/>
            <Option type="QString" value="solid" name="line_style"/>
            <Option type="QString" value="0.6" name="line_width"/>
            <Option type="QString" value="MM" name="line_width_unit"/>
            <Option type="QString" value="0" name="offset"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
            <Option type="QString" value="MM" name="offset_unit"/>
            <Option type="QString" value="0" name="ring_filter"/>
            <Option type="QString" value="0" name="trim_distance_end"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="trim_distance_end_map_unit_scale"/>
            <Option type="QString" value="MM" name="trim_distance_end_unit"/>
            <Option type="QString" value="0" name="trim_distance_start"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="trim_distance_start_map_unit_scale"/>
            <Option type="QString" value="MM" name="trim_distance_start_unit"/>
            <Option type="QString" value="0" name="tweak_dash_pattern_on_corners"/>
            <Option type="QString" value="0" name="use_custom_dash"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="width_map_unit_scale"/>
          </Option>
          <data_defined_properties>
            <Option type="Map">
              <Option type="QString" value="" name="name"/>
              <Option type="Map" name="properties">
                <Option type="Map" name="outlineWidth">
                  <Option type="bool" value="true" name="active"/>
                  <Option type="QString" value="CASE&#xd;&#xa;  WHEN &quot;D_ext&quot; LIKE '%x%' THEN&#xd;&#xa;    sqrt(to_real(left(&quot;D_ext&quot;, strpos(&quot;D_ext&quot;, 'x') - 1)))&#xd;&#xa;  ELSE&#xd;&#xa;    sqrt(to_real(&quot;D_ext&quot;)) * 1.25&#xd;&#xa;END" name="expression"/>
                  <Option type="int" value="3" name="type"/>
                </Option>
              </Option>
              <Option type="QString" value="collection" name="type"/>
            </Option>
          </data_defined_properties>
        </layer>
        <layer pass="0" id="{e8de49c9-d072-487d-ab3f-f91c06082f27}" class="MarkerLine" enabled="1" locked="0">
          <Option type="Map">
            <Option type="QString" value="4" name="average_angle_length"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="average_angle_map_unit_scale"/>
            <Option type="QString" value="MM" name="average_angle_unit"/>
            <Option type="QString" value="3" name="interval"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="interval_map_unit_scale"/>
            <Option type="QString" value="MM" name="interval_unit"/>
            <Option type="QString" value="0" name="offset"/>
            <Option type="QString" value="0" name="offset_along_line"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_along_line_map_unit_scale"/>
            <Option type="QString" value="MM" name="offset_along_line_unit"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
            <Option type="QString" value="MM" name="offset_unit"/>
            <Option type="bool" value="true" name="place_on_every_part"/>
            <Option type="QString" value="LastVertex|FirstVertex|InnerVertices" name="placements"/>
            <Option type="QString" value="0" name="ring_filter"/>
            <Option type="QString" value="1" name="rotate"/>
          </Option>
          <data_defined_properties>
            <Option type="Map">
              <Option type="QString" value="" name="name"/>
              <Option name="properties"/>
              <Option type="QString" value="collection" name="type"/>
            </Option>
          </data_defined_properties>
          <symbol alpha="1" type="marker" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="@1@2">
            <data_defined_properties>
              <Option type="Map">
                <Option type="QString" value="" name="name"/>
                <Option name="properties"/>
                <Option type="QString" value="collection" name="type"/>
              </Option>
            </data_defined_properties>
            <layer pass="0" id="{062adcbc-c023-4909-ba48-3875ea1a4cde}" class="FilledMarker" enabled="1" locked="0">
              <Option type="Map">
                <Option type="QString" value="0" name="angle"/>
                <Option type="QString" value="255,255,191,255" name="color"/>
                <Option type="QString" value="1" name="horizontal_anchor_point"/>
                <Option type="QString" value="circle" name="name"/>
                <Option type="QString" value="0,0" name="offset"/>
                <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
                <Option type="QString" value="MM" name="offset_unit"/>
                <Option type="QString" value="diameter" name="scale_method"/>
                <Option type="QString" value="2" name="size"/>
                <Option type="QString" value="3x:0,0,0,0,0,0" name="size_map_unit_scale"/>
                <Option type="QString" value="MM" name="size_unit"/>
                <Option type="QString" value="1" name="vertical_anchor_point"/>
              </Option>
              <data_defined_properties>
                <Option type="Map">
                  <Option type="QString" value="" name="name"/>
                  <Option type="Map" name="properties">
                    <Option type="Map" name="size">
                      <Option type="bool" value="true" name="active"/>
                      <Option type="QString" value="CASE&#xd;&#xa;  WHEN &quot;D_ext&quot; LIKE '%x%' THEN&#xd;&#xa;    sqrt(to_real(left(&quot;D_ext&quot;, strpos(&quot;D_ext&quot;, 'x') - 1))) * 2&#xd;&#xa;  ELSE&#xd;&#xa;    sqrt(to_real(&quot;D_ext&quot;)) * 3&#xd;&#xa;END" name="expression"/>
                      <Option type="int" value="3" name="type"/>
                    </Option>
                  </Option>
                  <Option type="QString" value="collection" name="type"/>
                </Option>
              </data_defined_properties>
              <symbol alpha="1" type="fill" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="@@1@2@0">
                <data_defined_properties>
                  <Option type="Map">
                    <Option type="QString" value="" name="name"/>
                    <Option name="properties"/>
                    <Option type="QString" value="collection" name="type"/>
                  </Option>
                </data_defined_properties>
                <layer pass="0" id="{4e7cc66f-7bc4-4549-959d-e619c68cc739}" class="SimpleFill" enabled="1" locked="0">
                  <Option type="Map">
                    <Option type="QString" value="3x:0,0,0,0,0,0" name="border_width_map_unit_scale"/>
                    <Option type="QString" value="255,255,191,255" name="color"/>
                    <Option type="QString" value="bevel" name="joinstyle"/>
                    <Option type="QString" value="0,0" name="offset"/>
                    <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
                    <Option type="QString" value="MM" name="offset_unit"/>
                    <Option type="QString" value="35,35,35,255" name="outline_color"/>
                    <Option type="QString" value="solid" name="outline_style"/>
                    <Option type="QString" value="0" name="outline_width"/>
                    <Option type="QString" value="MM" name="outline_width_unit"/>
                    <Option type="QString" value="solid" name="style"/>
                  </Option>
                  <data_defined_properties>
                    <Option type="Map">
                      <Option type="QString" value="" name="name"/>
                      <Option name="properties"/>
                      <Option type="QString" value="collection" name="type"/>
                    </Option>
                  </data_defined_properties>
                </layer>
              </symbol>
            </layer>
          </symbol>
        </layer>
      </symbol>
      <symbol alpha="1" type="line" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="2">
        <data_defined_properties>
          <Option type="Map">
            <Option type="QString" value="" name="name"/>
            <Option name="properties"/>
            <Option type="QString" value="collection" name="type"/>
          </Option>
        </data_defined_properties>
        <layer pass="0" id="{f2171ebb-a20f-48b3-a09e-54ef992a6794}" class="MarkerLine" enabled="1" locked="0">
          <Option type="Map">
            <Option type="QString" value="4" name="average_angle_length"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="average_angle_map_unit_scale"/>
            <Option type="QString" value="MM" name="average_angle_unit"/>
            <Option type="QString" value="3" name="interval"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="interval_map_unit_scale"/>
            <Option type="QString" value="MM" name="interval_unit"/>
            <Option type="QString" value="0" name="offset"/>
            <Option type="QString" value="0" name="offset_along_line"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_along_line_map_unit_scale"/>
            <Option type="QString" value="MM" name="offset_along_line_unit"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
            <Option type="QString" value="MM" name="offset_unit"/>
            <Option type="bool" value="true" name="place_on_every_part"/>
            <Option type="QString" value="SegmentCenter" name="placements"/>
            <Option type="QString" value="0" name="ring_filter"/>
            <Option type="QString" value="1" name="rotate"/>
          </Option>
          <data_defined_properties>
            <Option type="Map">
              <Option type="QString" value="" name="name"/>
              <Option name="properties"/>
              <Option type="QString" value="collection" name="type"/>
            </Option>
          </data_defined_properties>
          <symbol alpha="1" type="marker" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="@2@0">
            <data_defined_properties>
              <Option type="Map">
                <Option type="QString" value="" name="name"/>
                <Option name="properties"/>
                <Option type="QString" value="collection" name="type"/>
              </Option>
            </data_defined_properties>
            <layer pass="0" id="{2e65d832-2d03-4503-99f9-90f7de9288d3}" class="FilledMarker" enabled="1" locked="0">
              <Option type="Map">
                <Option type="QString" value="0" name="angle"/>
                <Option type="QString" value="215,25,28,255" name="color"/>
                <Option type="QString" value="1" name="horizontal_anchor_point"/>
                <Option type="QString" value="filled_arrowhead" name="name"/>
                <Option type="QString" value="0,0" name="offset"/>
                <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
                <Option type="QString" value="MM" name="offset_unit"/>
                <Option type="QString" value="diameter" name="scale_method"/>
                <Option type="QString" value="3" name="size"/>
                <Option type="QString" value="3x:0,0,0,0,0,0" name="size_map_unit_scale"/>
                <Option type="QString" value="MM" name="size_unit"/>
                <Option type="QString" value="1" name="vertical_anchor_point"/>
              </Option>
              <data_defined_properties>
                <Option type="Map">
                  <Option type="QString" value="" name="name"/>
                  <Option type="Map" name="properties">
                    <Option type="Map" name="size">
                      <Option type="bool" value="true" name="active"/>
                      <Option type="QString" value="CASE&#xd;&#xa;  WHEN &quot;D_ext&quot; LIKE '%x%' THEN&#xd;&#xa;    sqrt(to_real(left(&quot;D_ext&quot;, strpos(&quot;D_ext&quot;, 'x') - 1))) * 3&#xd;&#xa;  ELSE&#xd;&#xa;    sqrt(to_real(&quot;D_ext&quot;)) * 5&#xd;&#xa;END" name="expression"/>
                      <Option type="int" value="3" name="type"/>
                    </Option>
                  </Option>
                  <Option type="QString" value="collection" name="type"/>
                </Option>
              </data_defined_properties>
              <symbol alpha="1" type="fill" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="@@2@0@0">
                <data_defined_properties>
                  <Option type="Map">
                    <Option type="QString" value="" name="name"/>
                    <Option name="properties"/>
                    <Option type="QString" value="collection" name="type"/>
                  </Option>
                </data_defined_properties>
                <layer pass="0" id="{5f1d114b-d9ef-49e9-acc7-4926684d21c5}" class="SimpleFill" enabled="1" locked="0">
                  <Option type="Map">
                    <Option type="QString" value="3x:0,0,0,0,0,0" name="border_width_map_unit_scale"/>
                    <Option type="QString" value="215,25,28,255" name="color"/>
                    <Option type="QString" value="miter" name="joinstyle"/>
                    <Option type="QString" value="0,0" name="offset"/>
                    <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
                    <Option type="QString" value="MM" name="offset_unit"/>
                    <Option type="QString" value="35,35,35,255" name="outline_color"/>
                    <Option type="QString" value="solid" name="outline_style"/>
                    <Option type="QString" value="0" name="outline_width"/>
                    <Option type="QString" value="MM" name="outline_width_unit"/>
                    <Option type="QString" value="solid" name="style"/>
                  </Option>
                  <data_defined_properties>
                    <Option type="Map">
                      <Option type="QString" value="" name="name"/>
                      <Option name="properties"/>
                      <Option type="QString" value="collection" name="type"/>
                    </Option>
                  </data_defined_properties>
                </layer>
              </symbol>
            </layer>
          </symbol>
        </layer>
        <layer pass="0" id="{8980af69-e003-4ba3-b691-16c00256a6c5}" class="SimpleLine" enabled="1" locked="0">
          <Option type="Map">
            <Option type="QString" value="0" name="align_dash_pattern"/>
            <Option type="QString" value="square" name="capstyle"/>
            <Option type="QString" value="5;2" name="customdash"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="customdash_map_unit_scale"/>
            <Option type="QString" value="MM" name="customdash_unit"/>
            <Option type="QString" value="0" name="dash_pattern_offset"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="dash_pattern_offset_map_unit_scale"/>
            <Option type="QString" value="MM" name="dash_pattern_offset_unit"/>
            <Option type="QString" value="0" name="draw_inside_polygon"/>
            <Option type="QString" value="bevel" name="joinstyle"/>
            <Option type="QString" value="215,25,28,255" name="line_color"/>
            <Option type="QString" value="solid" name="line_style"/>
            <Option type="QString" value="0.6" name="line_width"/>
            <Option type="QString" value="MM" name="line_width_unit"/>
            <Option type="QString" value="0" name="offset"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
            <Option type="QString" value="MM" name="offset_unit"/>
            <Option type="QString" value="0" name="ring_filter"/>
            <Option type="QString" value="0" name="trim_distance_end"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="trim_distance_end_map_unit_scale"/>
            <Option type="QString" value="MM" name="trim_distance_end_unit"/>
            <Option type="QString" value="0" name="trim_distance_start"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="trim_distance_start_map_unit_scale"/>
            <Option type="QString" value="MM" name="trim_distance_start_unit"/>
            <Option type="QString" value="0" name="tweak_dash_pattern_on_corners"/>
            <Option type="QString" value="0" name="use_custom_dash"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="width_map_unit_scale"/>
          </Option>
          <data_defined_properties>
            <Option type="Map">
              <Option type="QString" value="" name="name"/>
              <Option type="Map" name="properties">
                <Option type="Map" name="outlineWidth">
                  <Option type="bool" value="true" name="active"/>
                  <Option type="QString" value="CASE&#xd;&#xa;  WHEN &quot;D_ext&quot; LIKE '%x%' THEN&#xd;&#xa;    sqrt(to_real(left(&quot;D_ext&quot;, strpos(&quot;D_ext&quot;, 'x') - 1)))&#xd;&#xa;  ELSE&#xd;&#xa;    sqrt(to_real(&quot;D_ext&quot;)) * 1.25&#xd;&#xa;END" name="expression"/>
                  <Option type="int" value="3" name="type"/>
                </Option>
              </Option>
              <Option type="QString" value="collection" name="type"/>
            </Option>
          </data_defined_properties>
        </layer>
        <layer pass="0" id="{e8de49c9-d072-487d-ab3f-f91c06082f27}" class="MarkerLine" enabled="1" locked="0">
          <Option type="Map">
            <Option type="QString" value="4" name="average_angle_length"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="average_angle_map_unit_scale"/>
            <Option type="QString" value="MM" name="average_angle_unit"/>
            <Option type="QString" value="3" name="interval"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="interval_map_unit_scale"/>
            <Option type="QString" value="MM" name="interval_unit"/>
            <Option type="QString" value="0" name="offset"/>
            <Option type="QString" value="0" name="offset_along_line"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_along_line_map_unit_scale"/>
            <Option type="QString" value="MM" name="offset_along_line_unit"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
            <Option type="QString" value="MM" name="offset_unit"/>
            <Option type="bool" value="true" name="place_on_every_part"/>
            <Option type="QString" value="LastVertex|FirstVertex|InnerVertices" name="placements"/>
            <Option type="QString" value="0" name="ring_filter"/>
            <Option type="QString" value="1" name="rotate"/>
          </Option>
          <data_defined_properties>
            <Option type="Map">
              <Option type="QString" value="" name="name"/>
              <Option name="properties"/>
              <Option type="QString" value="collection" name="type"/>
            </Option>
          </data_defined_properties>
          <symbol alpha="1" type="marker" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="@2@2">
            <data_defined_properties>
              <Option type="Map">
                <Option type="QString" value="" name="name"/>
                <Option name="properties"/>
                <Option type="QString" value="collection" name="type"/>
              </Option>
            </data_defined_properties>
            <layer pass="0" id="{062adcbc-c023-4909-ba48-3875ea1a4cde}" class="FilledMarker" enabled="1" locked="0">
              <Option type="Map">
                <Option type="QString" value="0" name="angle"/>
                <Option type="QString" value="215,25,28,255" name="color"/>
                <Option type="QString" value="1" name="horizontal_anchor_point"/>
                <Option type="QString" value="circle" name="name"/>
                <Option type="QString" value="0,0" name="offset"/>
                <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
                <Option type="QString" value="MM" name="offset_unit"/>
                <Option type="QString" value="diameter" name="scale_method"/>
                <Option type="QString" value="2" name="size"/>
                <Option type="QString" value="3x:0,0,0,0,0,0" name="size_map_unit_scale"/>
                <Option type="QString" value="MM" name="size_unit"/>
                <Option type="QString" value="1" name="vertical_anchor_point"/>
              </Option>
              <data_defined_properties>
                <Option type="Map">
                  <Option type="QString" value="" name="name"/>
                  <Option type="Map" name="properties">
                    <Option type="Map" name="size">
                      <Option type="bool" value="true" name="active"/>
                      <Option type="QString" value="CASE&#xd;&#xa;  WHEN &quot;D_ext&quot; LIKE '%x%' THEN&#xd;&#xa;    sqrt(to_real(left(&quot;D_ext&quot;, strpos(&quot;D_ext&quot;, 'x') - 1))) * 2&#xd;&#xa;  ELSE&#xd;&#xa;    sqrt(to_real(&quot;D_ext&quot;)) * 3&#xd;&#xa;END" name="expression"/>
                      <Option type="int" value="3" name="type"/>
                    </Option>
                  </Option>
                  <Option type="QString" value="collection" name="type"/>
                </Option>
              </data_defined_properties>
              <symbol alpha="1" type="fill" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="@@2@2@0">
                <data_defined_properties>
                  <Option type="Map">
                    <Option type="QString" value="" name="name"/>
                    <Option name="properties"/>
                    <Option type="QString" value="collection" name="type"/>
                  </Option>
                </data_defined_properties>
                <layer pass="0" id="{4e7cc66f-7bc4-4549-959d-e619c68cc739}" class="SimpleFill" enabled="1" locked="0">
                  <Option type="Map">
                    <Option type="QString" value="3x:0,0,0,0,0,0" name="border_width_map_unit_scale"/>
                    <Option type="QString" value="215,25,28,255" name="color"/>
                    <Option type="QString" value="bevel" name="joinstyle"/>
                    <Option type="QString" value="0,0" name="offset"/>
                    <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
                    <Option type="QString" value="MM" name="offset_unit"/>
                    <Option type="QString" value="35,35,35,255" name="outline_color"/>
                    <Option type="QString" value="solid" name="outline_style"/>
                    <Option type="QString" value="0" name="outline_width"/>
                    <Option type="QString" value="MM" name="outline_width_unit"/>
                    <Option type="QString" value="solid" name="style"/>
                  </Option>
                  <data_defined_properties>
                    <Option type="Map">
                      <Option type="QString" value="" name="name"/>
                      <Option name="properties"/>
                      <Option type="QString" value="collection" name="type"/>
                    </Option>
                  </data_defined_properties>
                </layer>
              </symbol>
            </layer>
          </symbol>
        </layer>
      </symbol>
    </symbols>
    <source-symbol>
      <symbol alpha="1" type="line" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="0">
        <data_defined_properties>
          <Option type="Map">
            <Option type="QString" value="" name="name"/>
            <Option name="properties"/>
            <Option type="QString" value="collection" name="type"/>
          </Option>
        </data_defined_properties>
        <layer pass="0" id="{f2171ebb-a20f-48b3-a09e-54ef992a6794}" class="MarkerLine" enabled="1" locked="0">
          <Option type="Map">
            <Option type="QString" value="4" name="average_angle_length"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="average_angle_map_unit_scale"/>
            <Option type="QString" value="MM" name="average_angle_unit"/>
            <Option type="QString" value="3" name="interval"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="interval_map_unit_scale"/>
            <Option type="QString" value="MM" name="interval_unit"/>
            <Option type="QString" value="0" name="offset"/>
            <Option type="QString" value="0" name="offset_along_line"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_along_line_map_unit_scale"/>
            <Option type="QString" value="MM" name="offset_along_line_unit"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
            <Option type="QString" value="MM" name="offset_unit"/>
            <Option type="bool" value="true" name="place_on_every_part"/>
            <Option type="QString" value="SegmentCenter" name="placements"/>
            <Option type="QString" value="0" name="ring_filter"/>
            <Option type="QString" value="1" name="rotate"/>
          </Option>
          <data_defined_properties>
            <Option type="Map">
              <Option type="QString" value="" name="name"/>
              <Option name="properties"/>
              <Option type="QString" value="collection" name="type"/>
            </Option>
          </data_defined_properties>
          <symbol alpha="1" type="marker" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="@0@0">
            <data_defined_properties>
              <Option type="Map">
                <Option type="QString" value="" name="name"/>
                <Option name="properties"/>
                <Option type="QString" value="collection" name="type"/>
              </Option>
            </data_defined_properties>
            <layer pass="0" id="{2e65d832-2d03-4503-99f9-90f7de9288d3}" class="FilledMarker" enabled="1" locked="0">
              <Option type="Map">
                <Option type="QString" value="0" name="angle"/>
                <Option type="QString" value="255,255,255,255" name="color"/>
                <Option type="QString" value="1" name="horizontal_anchor_point"/>
                <Option type="QString" value="filled_arrowhead" name="name"/>
                <Option type="QString" value="0,0" name="offset"/>
                <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
                <Option type="QString" value="MM" name="offset_unit"/>
                <Option type="QString" value="diameter" name="scale_method"/>
                <Option type="QString" value="3" name="size"/>
                <Option type="QString" value="3x:0,0,0,0,0,0" name="size_map_unit_scale"/>
                <Option type="QString" value="MM" name="size_unit"/>
                <Option type="QString" value="1" name="vertical_anchor_point"/>
              </Option>
              <data_defined_properties>
                <Option type="Map">
                  <Option type="QString" value="" name="name"/>
                  <Option type="Map" name="properties">
                    <Option type="Map" name="size">
                      <Option type="bool" value="true" name="active"/>
                      <Option type="QString" value="CASE&#xd;&#xa;  WHEN &quot;D_ext&quot; LIKE '%x%' THEN&#xd;&#xa;    sqrt(to_real(left(&quot;D_ext&quot;, strpos(&quot;D_ext&quot;, 'x') - 1))) * 3&#xd;&#xa;  ELSE&#xd;&#xa;    sqrt(to_real(&quot;D_ext&quot;)) * 5&#xd;&#xa;END" name="expression"/>
                      <Option type="int" value="3" name="type"/>
                    </Option>
                  </Option>
                  <Option type="QString" value="collection" name="type"/>
                </Option>
              </data_defined_properties>
              <symbol alpha="1" type="fill" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="@@0@0@0">
                <data_defined_properties>
                  <Option type="Map">
                    <Option type="QString" value="" name="name"/>
                    <Option name="properties"/>
                    <Option type="QString" value="collection" name="type"/>
                  </Option>
                </data_defined_properties>
                <layer pass="0" id="{5f1d114b-d9ef-49e9-acc7-4926684d21c5}" class="SimpleFill" enabled="1" locked="0">
                  <Option type="Map">
                    <Option type="QString" value="3x:0,0,0,0,0,0" name="border_width_map_unit_scale"/>
                    <Option type="QString" value="255,255,255,255" name="color"/>
                    <Option type="QString" value="miter" name="joinstyle"/>
                    <Option type="QString" value="0,0" name="offset"/>
                    <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
                    <Option type="QString" value="MM" name="offset_unit"/>
                    <Option type="QString" value="35,35,35,255" name="outline_color"/>
                    <Option type="QString" value="solid" name="outline_style"/>
                    <Option type="QString" value="0" name="outline_width"/>
                    <Option type="QString" value="MM" name="outline_width_unit"/>
                    <Option type="QString" value="solid" name="style"/>
                  </Option>
                  <data_defined_properties>
                    <Option type="Map">
                      <Option type="QString" value="" name="name"/>
                      <Option name="properties"/>
                      <Option type="QString" value="collection" name="type"/>
                    </Option>
                  </data_defined_properties>
                </layer>
              </symbol>
            </layer>
          </symbol>
        </layer>
        <layer pass="0" id="{8980af69-e003-4ba3-b691-16c00256a6c5}" class="SimpleLine" enabled="1" locked="0">
          <Option type="Map">
            <Option type="QString" value="0" name="align_dash_pattern"/>
            <Option type="QString" value="square" name="capstyle"/>
            <Option type="QString" value="5;2" name="customdash"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="customdash_map_unit_scale"/>
            <Option type="QString" value="MM" name="customdash_unit"/>
            <Option type="QString" value="0" name="dash_pattern_offset"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="dash_pattern_offset_map_unit_scale"/>
            <Option type="QString" value="MM" name="dash_pattern_offset_unit"/>
            <Option type="QString" value="0" name="draw_inside_polygon"/>
            <Option type="QString" value="bevel" name="joinstyle"/>
            <Option type="QString" value="255,255,255,255" name="line_color"/>
            <Option type="QString" value="solid" name="line_style"/>
            <Option type="QString" value="0.6" name="line_width"/>
            <Option type="QString" value="MM" name="line_width_unit"/>
            <Option type="QString" value="0" name="offset"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
            <Option type="QString" value="MM" name="offset_unit"/>
            <Option type="QString" value="0" name="ring_filter"/>
            <Option type="QString" value="0" name="trim_distance_end"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="trim_distance_end_map_unit_scale"/>
            <Option type="QString" value="MM" name="trim_distance_end_unit"/>
            <Option type="QString" value="0" name="trim_distance_start"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="trim_distance_start_map_unit_scale"/>
            <Option type="QString" value="MM" name="trim_distance_start_unit"/>
            <Option type="QString" value="0" name="tweak_dash_pattern_on_corners"/>
            <Option type="QString" value="0" name="use_custom_dash"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="width_map_unit_scale"/>
          </Option>
          <data_defined_properties>
            <Option type="Map">
              <Option type="QString" value="" name="name"/>
              <Option type="Map" name="properties">
                <Option type="Map" name="outlineWidth">
                  <Option type="bool" value="true" name="active"/>
                  <Option type="QString" value="CASE&#xd;&#xa;  WHEN &quot;D_ext&quot; LIKE '%x%' THEN&#xd;&#xa;    sqrt(to_real(left(&quot;D_ext&quot;, strpos(&quot;D_ext&quot;, 'x') - 1)))&#xd;&#xa;  ELSE&#xd;&#xa;    sqrt(to_real(&quot;D_ext&quot;)) * 1.25&#xd;&#xa;END" name="expression"/>
                  <Option type="int" value="3" name="type"/>
                </Option>
              </Option>
              <Option type="QString" value="collection" name="type"/>
            </Option>
          </data_defined_properties>
        </layer>
        <layer pass="0" id="{e8de49c9-d072-487d-ab3f-f91c06082f27}" class="MarkerLine" enabled="1" locked="0">
          <Option type="Map">
            <Option type="QString" value="4" name="average_angle_length"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="average_angle_map_unit_scale"/>
            <Option type="QString" value="MM" name="average_angle_unit"/>
            <Option type="QString" value="3" name="interval"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="interval_map_unit_scale"/>
            <Option type="QString" value="MM" name="interval_unit"/>
            <Option type="QString" value="0" name="offset"/>
            <Option type="QString" value="0" name="offset_along_line"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_along_line_map_unit_scale"/>
            <Option type="QString" value="MM" name="offset_along_line_unit"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
            <Option type="QString" value="MM" name="offset_unit"/>
            <Option type="bool" value="true" name="place_on_every_part"/>
            <Option type="QString" value="LastVertex|FirstVertex|InnerVertices" name="placements"/>
            <Option type="QString" value="0" name="ring_filter"/>
            <Option type="QString" value="1" name="rotate"/>
          </Option>
          <data_defined_properties>
            <Option type="Map">
              <Option type="QString" value="" name="name"/>
              <Option name="properties"/>
              <Option type="QString" value="collection" name="type"/>
            </Option>
          </data_defined_properties>
          <symbol alpha="1" type="marker" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="@0@2">
            <data_defined_properties>
              <Option type="Map">
                <Option type="QString" value="" name="name"/>
                <Option name="properties"/>
                <Option type="QString" value="collection" name="type"/>
              </Option>
            </data_defined_properties>
            <layer pass="0" id="{062adcbc-c023-4909-ba48-3875ea1a4cde}" class="FilledMarker" enabled="1" locked="0">
              <Option type="Map">
                <Option type="QString" value="0" name="angle"/>
                <Option type="QString" value="255,255,255,255" name="color"/>
                <Option type="QString" value="1" name="horizontal_anchor_point"/>
                <Option type="QString" value="circle" name="name"/>
                <Option type="QString" value="0,0" name="offset"/>
                <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
                <Option type="QString" value="MM" name="offset_unit"/>
                <Option type="QString" value="diameter" name="scale_method"/>
                <Option type="QString" value="2" name="size"/>
                <Option type="QString" value="3x:0,0,0,0,0,0" name="size_map_unit_scale"/>
                <Option type="QString" value="MM" name="size_unit"/>
                <Option type="QString" value="1" name="vertical_anchor_point"/>
              </Option>
              <data_defined_properties>
                <Option type="Map">
                  <Option type="QString" value="" name="name"/>
                  <Option type="Map" name="properties">
                    <Option type="Map" name="size">
                      <Option type="bool" value="true" name="active"/>
                      <Option type="QString" value="CASE&#xd;&#xa;  WHEN &quot;D_ext&quot; LIKE '%x%' THEN&#xd;&#xa;    sqrt(to_real(left(&quot;D_ext&quot;, strpos(&quot;D_ext&quot;, 'x') - 1))) * 2&#xd;&#xa;  ELSE&#xd;&#xa;    sqrt(to_real(&quot;D_ext&quot;)) * 3&#xd;&#xa;END" name="expression"/>
                      <Option type="int" value="3" name="type"/>
                    </Option>
                  </Option>
                  <Option type="QString" value="collection" name="type"/>
                </Option>
              </data_defined_properties>
              <symbol alpha="1" type="fill" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="@@0@2@0">
                <data_defined_properties>
                  <Option type="Map">
                    <Option type="QString" value="" name="name"/>
                    <Option name="properties"/>
                    <Option type="QString" value="collection" name="type"/>
                  </Option>
                </data_defined_properties>
                <layer pass="0" id="{4e7cc66f-7bc4-4549-959d-e619c68cc739}" class="SimpleFill" enabled="1" locked="0">
                  <Option type="Map">
                    <Option type="QString" value="3x:0,0,0,0,0,0" name="border_width_map_unit_scale"/>
                    <Option type="QString" value="255,255,255,255" name="color"/>
                    <Option type="QString" value="bevel" name="joinstyle"/>
                    <Option type="QString" value="0,0" name="offset"/>
                    <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
                    <Option type="QString" value="MM" name="offset_unit"/>
                    <Option type="QString" value="35,35,35,255" name="outline_color"/>
                    <Option type="QString" value="solid" name="outline_style"/>
                    <Option type="QString" value="0" name="outline_width"/>
                    <Option type="QString" value="MM" name="outline_width_unit"/>
                    <Option type="QString" value="solid" name="style"/>
                  </Option>
                  <data_defined_properties>
                    <Option type="Map">
                      <Option type="QString" value="" name="name"/>
                      <Option name="properties"/>
                      <Option type="QString" value="collection" name="type"/>
                    </Option>
                  </data_defined_properties>
                </layer>
              </symbol>
            </layer>
          </symbol>
        </layer>
      </symbol>
    </source-symbol>
    <colorramp type="gradient" name="[source]">
      <Option type="Map">
        <Option type="QString" value="43,131,186,255" name="color1"/>
        <Option type="QString" value="215,25,28,255" name="color2"/>
        <Option type="QString" value="cw" name="direction"/>
        <Option type="QString" value="0" name="discrete"/>
        <Option type="QString" value="gradient" name="rampType"/>
        <Option type="QString" value="rgb" name="spec"/>
        <Option type="QString" value="0.25;171,221,164,255;rgb;cw:0.5;255,255,191,255;rgb;cw:0.75;253,174,97,255;rgb;cw" name="stops"/>
      </Option>
    </colorramp>
    <rotation/>
    <sizescale/>
  </renderer-v2>
  <selection mode="Default">
    <selectionColor invalid="1"/>
    <selectionSymbol>
      <symbol alpha="1" type="line" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="">
        <data_defined_properties>
          <Option type="Map">
            <Option type="QString" value="" name="name"/>
            <Option name="properties"/>
            <Option type="QString" value="collection" name="type"/>
          </Option>
        </data_defined_properties>
        <layer pass="0" id="{eb6f9095-2b71-4af1-b230-20d737ca4a59}" class="SimpleLine" enabled="1" locked="0">
          <Option type="Map">
            <Option type="QString" value="0" name="align_dash_pattern"/>
            <Option type="QString" value="square" name="capstyle"/>
            <Option type="QString" value="5;2" name="customdash"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="customdash_map_unit_scale"/>
            <Option type="QString" value="MM" name="customdash_unit"/>
            <Option type="QString" value="0" name="dash_pattern_offset"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="dash_pattern_offset_map_unit_scale"/>
            <Option type="QString" value="MM" name="dash_pattern_offset_unit"/>
            <Option type="QString" value="0" name="draw_inside_polygon"/>
            <Option type="QString" value="bevel" name="joinstyle"/>
            <Option type="QString" value="35,35,35,255" name="line_color"/>
            <Option type="QString" value="solid" name="line_style"/>
            <Option type="QString" value="0.26" name="line_width"/>
            <Option type="QString" value="MM" name="line_width_unit"/>
            <Option type="QString" value="0" name="offset"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
            <Option type="QString" value="MM" name="offset_unit"/>
            <Option type="QString" value="0" name="ring_filter"/>
            <Option type="QString" value="0" name="trim_distance_end"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="trim_distance_end_map_unit_scale"/>
            <Option type="QString" value="MM" name="trim_distance_end_unit"/>
            <Option type="QString" value="0" name="trim_distance_start"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="trim_distance_start_map_unit_scale"/>
            <Option type="QString" value="MM" name="trim_distance_start_unit"/>
            <Option type="QString" value="0" name="tweak_dash_pattern_on_corners"/>
            <Option type="QString" value="0" name="use_custom_dash"/>
            <Option type="QString" value="3x:0,0,0,0,0,0" name="width_map_unit_scale"/>
          </Option>
          <data_defined_properties>
            <Option type="Map">
              <Option type="QString" value="" name="name"/>
              <Option name="properties"/>
              <Option type="QString" value="collection" name="type"/>
            </Option>
          </data_defined_properties>
        </layer>
      </symbol>
    </selectionSymbol>
  </selection>
  <labeling type="simple">
    <settings calloutType="simple">
      <text-style fontStrikeout="0" fontWordSpacing="0" forcedBold="0" multilineHeight="1" fontSize="14" fontSizeUnit="Point" legendString="Aa" blendMode="0" fontKerning="1" fontFamily="Arial" isExpression="1" textOpacity="1" forcedItalic="0" fontLetterSpacing="0" fontUnderline="0" capitalization="0" fieldName="coalesce(&quot;Tramo&quot; || '\n', '') ||&#xd;&#xa;CASE WHEN &quot;L&quot; IS NOT NULL THEN 'L: ' || &quot;L&quot; || ' m' || '\n' ELSE '' END ||&#xd;&#xa;CASE WHEN &quot;D_ext&quot; IS NOT NULL THEN 'D: ' || &quot;D_ext&quot; || ' m ' || coalesce(&quot;Material&quot;, '') || '\n' ELSE '' END ||&#xd;&#xa;CASE WHEN &quot;S&quot; IS NOT NULL THEN 'S: ' || round(&quot;S&quot;*100, 3) || '%' || '\n' ELSE '' END ||&#xd;&#xa;CASE WHEN &quot;v&quot; IS NOT NULL THEN 'v: ' || round(&quot;v&quot;, 2) || ' m/s' || '\n' ELSE '' END ||&#xd;&#xa;CASE WHEN &quot;q_accu&quot; IS NOT NULL THEN 'q: ' || round(&quot;q_accu&quot;, 2) || ' L/s' || '\n' ELSE '' END ||&#xd;&#xa;CASE WHEN &quot;h/D&quot; IS NOT NULL THEN 'h/D: ' || round(&quot;h/D&quot;, 3) ELSE '' END&#xd;&#xa;" fontItalic="0" multilineHeightUnit="Percentage" useSubstitutions="0" previewBkgrdColor="255,255,255,255" allowHtml="0" fontSizeMapUnitScale="3x:0,0,0,0,0,0" namedStyle="Regular" textOrientation="horizontal" fontWeight="50" textColor="0,0,0,255">
        <families/>
        <text-buffer bufferDraw="1" bufferColor="255,255,255,255" bufferSizeMapUnitScale="3x:0,0,0,0,0,0" bufferJoinStyle="128" bufferSize="1" bufferOpacity="1" bufferSizeUnits="MM" bufferNoFill="0" bufferBlendMode="0"/>
        <text-mask maskJoinStyle="128" maskOpacity="1" maskSizeUnits="MM" maskedSymbolLayers="" maskSize="0" maskSizeMapUnitScale="3x:0,0,0,0,0,0" maskEnabled="0" maskType="0"/>
        <background shapeRotationType="0" shapeBorderColor="128,128,128,255" shapeSizeMapUnitScale="3x:0,0,0,0,0,0" shapeRadiiMapUnitScale="3x:0,0,0,0,0,0" shapeFillColor="255,255,255,255" shapeRadiiUnit="MM" shapeSizeUnit="MM" shapeBorderWidthUnit="Point" shapeSizeX="0" shapeRadiiX="0" shapeSizeType="0" shapeOffsetMapUnitScale="3x:0,0,0,0,0,0" shapeRotation="0" shapeRadiiY="0" shapeBorderWidthMapUnitScale="3x:0,0,0,0,0,0" shapeJoinStyle="64" shapeBlendMode="0" shapeDraw="0" shapeOffsetX="0" shapeType="0" shapeSizeY="0" shapeOpacity="1" shapeBorderWidth="0" shapeOffsetUnit="MM" shapeOffsetY="0" shapeSVGFile="">
          <symbol alpha="1" type="marker" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="markerSymbol">
            <data_defined_properties>
              <Option type="Map">
                <Option type="QString" value="" name="name"/>
                <Option name="properties"/>
                <Option type="QString" value="collection" name="type"/>
              </Option>
            </data_defined_properties>
            <layer pass="0" id="" class="SimpleMarker" enabled="1" locked="0">
              <Option type="Map">
                <Option type="QString" value="0" name="angle"/>
                <Option type="QString" value="square" name="cap_style"/>
                <Option type="QString" value="133,182,111,255" name="color"/>
                <Option type="QString" value="1" name="horizontal_anchor_point"/>
                <Option type="QString" value="bevel" name="joinstyle"/>
                <Option type="QString" value="circle" name="name"/>
                <Option type="QString" value="0,0" name="offset"/>
                <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
                <Option type="QString" value="MM" name="offset_unit"/>
                <Option type="QString" value="35,35,35,255" name="outline_color"/>
                <Option type="QString" value="solid" name="outline_style"/>
                <Option type="QString" value="0" name="outline_width"/>
                <Option type="QString" value="3x:0,0,0,0,0,0" name="outline_width_map_unit_scale"/>
                <Option type="QString" value="MM" name="outline_width_unit"/>
                <Option type="QString" value="diameter" name="scale_method"/>
                <Option type="QString" value="2" name="size"/>
                <Option type="QString" value="3x:0,0,0,0,0,0" name="size_map_unit_scale"/>
                <Option type="QString" value="MM" name="size_unit"/>
                <Option type="QString" value="1" name="vertical_anchor_point"/>
              </Option>
              <data_defined_properties>
                <Option type="Map">
                  <Option type="QString" value="" name="name"/>
                  <Option name="properties"/>
                  <Option type="QString" value="collection" name="type"/>
                </Option>
              </data_defined_properties>
            </layer>
          </symbol>
          <symbol alpha="1" type="fill" clip_to_extent="1" is_animated="0" frame_rate="10" force_rhr="0" name="fillSymbol">
            <data_defined_properties>
              <Option type="Map">
                <Option type="QString" value="" name="name"/>
                <Option name="properties"/>
                <Option type="QString" value="collection" name="type"/>
              </Option>
            </data_defined_properties>
            <layer pass="0" id="" class="SimpleFill" enabled="1" locked="0">
              <Option type="Map">
                <Option type="QString" value="3x:0,0,0,0,0,0" name="border_width_map_unit_scale"/>
                <Option type="QString" value="255,255,255,255" name="color"/>
                <Option type="QString" value="bevel" name="joinstyle"/>
                <Option type="QString" value="0,0" name="offset"/>
                <Option type="QString" value="3x:0,0,0,0,0,0" name="offset_map_unit_scale"/>
                <Option type="QString" value="MM" name="offset_unit"/>
                <Option type="QString" value="128,128,128,255" name="outline_color"/>
                <Option type="QString" value="no" name="outline_style"/>
                <Option type="QString" value="0" name="outline_width"/>
                <Option type="QString" value="Point" name="outline_width_unit"/>
                <Option type="QString" value="solid" name="style"/>
              </Option>
              <data_defined_properties>
                <Option type="Map">
                  <Option type="QString" value="" name="name"/>
                  <Option name="properties"/>
                  <Option type="QString" value="collection" name="type"/>
                </Option>
              </data_defined_properties>
            </layer>
          </symbol>
        </background>
        <shadow shadowScale="100" shadowOffsetUnit="MM" shadowUnder="0" shadowRadiusMapUnitScale="3x:0,0,0,0,0,0" shadowRadius="1.5" shadowColor="0,0,0,255" shadowOffsetAngle="135" shadowBlendMode="6" shadowRadiusUnit="MM" shadowOffsetMapUnitScale="3x:0,0,0,0,0,0" shadowRadiusAlphaOnly="0" shadowDraw="1" shadowOffsetDist="1" shadowOpacity="0.69999999999999996" shadowOffsetGlobal="1"/>
        <dd_properties>
          <Option type="Map">
            <Option type="QString" value="" name="name"/>
            <Option name="properties"/>
            <Option type="QString" value="collection" name="type"/>
          </Option>
        </dd_properties>
        <substitutions/>
      </text-style>
      <text-format addDirectionSymbol="0" plussign="0" wrapChar="" useMaxLineLengthForAutoWrap="1" placeDirectionSymbol="0" rightDirectionSymbol=">" formatNumbers="0" autoWrapLength="0" multilineAlign="1" decimals="3" reverseDirectionSymbol="0" leftDirectionSymbol="&lt;"/>
      <placement xOffset="0" lineAnchorTextPoint="CenterOfText" labelOffsetMapUnitScale="3x:0,0,0,0,0,0" lineAnchorPercent="0.5" geometryGeneratorType="PointGeometry" offsetUnits="MapUnit" maxCurvedCharAngleOut="-25" preserveRotation="1" lineAnchorClipping="0" overlapHandling="PreventOverlap" placement="2" repeatDistanceMapUnitScale="3x:0,0,0,0,0,0" layerType="LineGeometry" rotationAngle="0" overrunDistanceUnit="MM" yOffset="0" polygonPlacementFlags="2" quadOffset="4" placementFlags="14" repeatDistanceUnits="MM" geometryGenerator="" geometryGeneratorEnabled="0" centroidWhole="0" priority="5" overrunDistanceMapUnitScale="3x:0,0,0,0,0,0" allowDegraded="0" overrunDistance="0" distUnits="MM" lineAnchorType="0" rotationUnit="AngleDegrees" maxCurvedCharAngleIn="25" centroidInside="0" repeatDistance="0" distMapUnitScale="3x:0,0,0,0,0,0" fitInPolygonOnly="0" dist="0" predefinedPositionOrder="TR,TL,BR,BL,R,L,TSR,BSR" offsetType="0"/>
      <rendering unplacedVisibility="0" obstacleType="0" labelPerPart="0" mergeLines="0" fontMaxPixelSize="10000" scaleMax="10000000" zIndex="0" obstacle="1" scaleMin="1" drawLabels="1" minFeatureSize="0" scaleVisibility="0" obstacleFactor="1" limitNumLabels="0" maxNumLabels="2000" fontMinPixelSize="3" upsidedownLabels="0" fontLimitPixelSize="0"/>
      <dd_properties>
        <Option type="Map">
          <Option type="QString" value="" name="name"/>
          <Option name="properties"/>
          <Option type="QString" value="collection" name="type"/>
        </Option>
      </dd_properties>
      <callout type="simple">
        <Option type="Map">
          <Option type="QString" value="pole_of_inaccessibility" name="anchorPoint"/>
          <Option type="int" value="0" name="blendMode"/>
          <Option type="Map" name="ddProperties">
            <Option type="QString" value="" name="name"/>
            <Option name="properties"/>
            <Option type="QString" value="collection" name="type"/>
          </Option>
          <Option type="bool" value="false" name="drawToAllParts"/>
          <Option type="QString" value="0" name="enabled"/>
          <Option type="QString" value="point_on_exterior" name="labelAnchorPoint"/>
          <Option type="QString" value="&lt;symbol alpha=&quot;1&quot; type=&quot;line&quot; clip_to_extent=&quot;1&quot; is_animated=&quot;0&quot; frame_rate=&quot;10&quot; force_rhr=&quot;0&quot; name=&quot;symbol&quot;>&lt;data_defined_properties>&lt;Option type=&quot;Map&quot;>&lt;Option type=&quot;QString&quot; value=&quot;&quot; name=&quot;name&quot;/>&lt;Option name=&quot;properties&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;collection&quot; name=&quot;type&quot;/>&lt;/Option>&lt;/data_defined_properties>&lt;layer pass=&quot;0&quot; id=&quot;{40aecfc0-a511-4ae5-8162-ff8ebeda35ad}&quot; class=&quot;SimpleLine&quot; enabled=&quot;1&quot; locked=&quot;0&quot;>&lt;Option type=&quot;Map&quot;>&lt;Option type=&quot;QString&quot; value=&quot;0&quot; name=&quot;align_dash_pattern&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;square&quot; name=&quot;capstyle&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;5;2&quot; name=&quot;customdash&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;3x:0,0,0,0,0,0&quot; name=&quot;customdash_map_unit_scale&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;MM&quot; name=&quot;customdash_unit&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;0&quot; name=&quot;dash_pattern_offset&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;3x:0,0,0,0,0,0&quot; name=&quot;dash_pattern_offset_map_unit_scale&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;MM&quot; name=&quot;dash_pattern_offset_unit&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;0&quot; name=&quot;draw_inside_polygon&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;bevel&quot; name=&quot;joinstyle&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;60,60,60,255&quot; name=&quot;line_color&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;solid&quot; name=&quot;line_style&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;0.3&quot; name=&quot;line_width&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;MM&quot; name=&quot;line_width_unit&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;0&quot; name=&quot;offset&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;3x:0,0,0,0,0,0&quot; name=&quot;offset_map_unit_scale&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;MM&quot; name=&quot;offset_unit&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;0&quot; name=&quot;ring_filter&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;0&quot; name=&quot;trim_distance_end&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;3x:0,0,0,0,0,0&quot; name=&quot;trim_distance_end_map_unit_scale&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;MM&quot; name=&quot;trim_distance_end_unit&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;0&quot; name=&quot;trim_distance_start&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;3x:0,0,0,0,0,0&quot; name=&quot;trim_distance_start_map_unit_scale&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;MM&quot; name=&quot;trim_distance_start_unit&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;0&quot; name=&quot;tweak_dash_pattern_on_corners&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;0&quot; name=&quot;use_custom_dash&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;3x:0,0,0,0,0,0&quot; name=&quot;width_map_unit_scale&quot;/>&lt;/Option>&lt;data_defined_properties>&lt;Option type=&quot;Map&quot;>&lt;Option type=&quot;QString&quot; value=&quot;&quot; name=&quot;name&quot;/>&lt;Option name=&quot;properties&quot;/>&lt;Option type=&quot;QString&quot; value=&quot;collection&quot; name=&quot;type&quot;/>&lt;/Option>&lt;/data_defined_properties>&lt;/layer>&lt;/symbol>" name="lineSymbol"/>
          <Option type="double" value="0" name="minLength"/>
          <Option type="QString" value="3x:0,0,0,0,0,0" name="minLengthMapUnitScale"/>
          <Option type="QString" value="MM" name="minLengthUnit"/>
          <Option type="double" value="0" name="offsetFromAnchor"/>
          <Option type="QString" value="3x:0,0,0,0,0,0" name="offsetFromAnchorMapUnitScale"/>
          <Option type="QString" value="MM" name="offsetFromAnchorUnit"/>
          <Option type="double" value="0" name="offsetFromLabel"/>
          <Option type="QString" value="3x:0,0,0,0,0,0" name="offsetFromLabelMapUnitScale"/>
          <Option type="QString" value="MM" name="offsetFromLabelUnit"/>
        </Option>
      </callout>
    </settings>
  </labeling>
  <blendMode>0</blendMode>
  <featureBlendMode>0</featureBlendMode>
  <legend showLabelLegend="0" type="default-vector"/>
  <fieldConfiguration>
    <field configurationFlags="NoFlag" name="fid"/>
    <field configurationFlags="NoFlag" name="L"/>
    <field configurationFlags="NoFlag" name="Pozo"/>
    <field configurationFlags="NoFlag" name="Ramal"/>
    <field configurationFlags="NoFlag" name="Estado"/>
    <field configurationFlags="NoFlag" name="ZFF"/>
    <field configurationFlags="NoFlag" name="Seccion"/>
    <field configurationFlags="NoFlag" name="Tramo"/>
    <field configurationFlags="NoFlag" name="D_ext"/>
    <field configurationFlags="NoFlag" name="SALTO"/>
    <field configurationFlags="NoFlag" name="X"/>
    <field configurationFlags="NoFlag" name="Obs"/>
    <field configurationFlags="NoFlag" name="Y"/>
    <field configurationFlags="NoFlag" name="ZFI"/>
    <field configurationFlags="NoFlag" name="D_int"/>
    <field configurationFlags="NoFlag" name="HF"/>
    <field configurationFlags="NoFlag" name="LT"/>
    <field configurationFlags="NoFlag" name="Material"/>
    <field configurationFlags="NoFlag" name="Rug"/>
    <field configurationFlags="NoFlag" name="ZTI"/>
    <field configurationFlags="NoFlag" name="Rugosidad"/>
    <field configurationFlags="NoFlag" name="Fase"/>
    <field configurationFlags="NoFlag" name="Tipo"/>
    <field configurationFlags="NoFlag" name="S"/>
    <field configurationFlags="NoFlag" name="HI"/>
    <field configurationFlags="NoFlag" name="Z"/>
    <field configurationFlags="NoFlag" name="ZTF"/>
    <field configurationFlags="NoFlag" name="Conexion"/>
    <field configurationFlags="NoFlag" name="Pozo_hmin"/>
    <field configurationFlags="NoFlag" name="cobertura_min"/>
    <field configurationFlags="NoFlag" name="D_min"/>
    <field configurationFlags="NoFlag" name="S_min"/>
    <field configurationFlags="NoFlag" name="Derivacion"/>
  </fieldConfiguration>
  <aliases>
    <alias index="0" field="fid" name=""/>
    <alias index="1" field="L" name=""/>
    <alias index="2" field="Pozo" name=""/>
    <alias index="3" field="Ramal" name=""/>
    <alias index="4" field="Estado" name=""/>
    <alias index="5" field="ZFF" name=""/>
    <alias index="6" field="Seccion" name=""/>
    <alias index="7" field="Tramo" name=""/>
    <alias index="8" field="D_ext" name=""/>
    <alias index="9" field="SALTO" name=""/>
    <alias index="10" field="X" name=""/>
    <alias index="11" field="Obs" name=""/>
    <alias index="12" field="Y" name=""/>
    <alias index="13" field="ZFI" name=""/>
    <alias index="14" field="D_int" name=""/>
    <alias index="15" field="HF" name=""/>
    <alias index="16" field="LT" name=""/>
    <alias index="17" field="Material" name=""/>
    <alias index="18" field="Rug" name=""/>
    <alias index="19" field="ZTI" name=""/>
    <alias index="20" field="Rugosidad" name=""/>
    <alias index="21" field="Fase" name=""/>
    <alias index="22" field="Tipo" name=""/>
    <alias index="23" field="S" name=""/>
    <alias index="24" field="HI" name=""/>
    <alias index="25" field="Z" name=""/>
    <alias index="26" field="ZTF" name=""/>
    <alias index="27" field="Conexion" name=""/>
    <alias index="28" field="Pozo_hmin" name=""/>
    <alias index="29" field="cobertura_min" name=""/>
    <alias index="30" field="D_min" name=""/>
    <alias index="31" field="S_min" name=""/>
    <alias index="32" field="Derivacion" name=""/>
  </aliases>
  <splitPolicies>
    <policy field="fid" policy="Duplicate"/>
    <policy field="L" policy="Duplicate"/>
    <policy field="Pozo" policy="Duplicate"/>
    <policy field="Ramal" policy="Duplicate"/>
    <policy field="Estado" policy="Duplicate"/>
    <policy field="ZFF" policy="Duplicate"/>
    <policy field="Seccion" policy="Duplicate"/>
    <policy field="Tramo" policy="Duplicate"/>
    <policy field="D_ext" policy="Duplicate"/>
    <policy field="SALTO" policy="Duplicate"/>
    <policy field="X" policy="Duplicate"/>
    <policy field="Obs" policy="Duplicate"/>
    <policy field="Y" policy="Duplicate"/>
    <policy field="ZFI" policy="Duplicate"/>
    <policy field="D_int" policy="Duplicate"/>
    <policy field="HF" policy="Duplicate"/>
    <policy field="LT" policy="Duplicate"/>
    <policy field="Material" policy="Duplicate"/>
    <policy field="Rug" policy="Duplicate"/>
    <policy field="ZTI" policy="Duplicate"/>
    <policy field="Rugosidad" policy="Duplicate"/>
    <policy field="Fase" policy="Duplicate"/>
    <policy field="Tipo" policy="Duplicate"/>
    <policy field="S" policy="Duplicate"/>
    <policy field="HI" policy="Duplicate"/>
    <policy field="Z" policy="Duplicate"/>
    <policy field="ZTF" policy="Duplicate"/>
    <policy field="Conexion" policy="Duplicate"/>
    <policy field="Pozo_hmin" policy="Duplicate"/>
    <policy field="cobertura_min" policy="Duplicate"/>
    <policy field="D_min" policy="Duplicate"/>
    <policy field="S_min" policy="Duplicate"/>
    <policy field="Derivacion" policy="Duplicate"/>
  </splitPolicies>
  <defaults>
    <default applyOnUpdate="0" field="fid" expression=""/>
    <default applyOnUpdate="0" field="L" expression=""/>
    <default applyOnUpdate="0" field="Pozo" expression=""/>
    <default applyOnUpdate="0" field="Ramal" expression=""/>
    <default applyOnUpdate="0" field="Estado" expression=""/>
    <default applyOnUpdate="0" field="ZFF" expression=""/>
    <default applyOnUpdate="0" field="Seccion" expression=""/>
    <default applyOnUpdate="0" field="Tramo" expression=""/>
    <default applyOnUpdate="0" field="D_ext" expression=""/>
    <default applyOnUpdate="0" field="SALTO" expression=""/>
    <default applyOnUpdate="0" field="X" expression=""/>
    <default applyOnUpdate="0" field="Obs" expression=""/>
    <default applyOnUpdate="0" field="Y" expression=""/>
    <default applyOnUpdate="0" field="ZFI" expression=""/>
    <default applyOnUpdate="0" field="D_int" expression=""/>
    <default applyOnUpdate="0" field="HF" expression=""/>
    <default applyOnUpdate="0" field="LT" expression=""/>
    <default applyOnUpdate="0" field="Material" expression=""/>
    <default applyOnUpdate="0" field="Rug" expression=""/>
    <default applyOnUpdate="0" field="ZTI" expression=""/>
    <default applyOnUpdate="0" field="Rugosidad" expression=""/>
    <default applyOnUpdate="0" field="Fase" expression=""/>
    <default applyOnUpdate="0" field="Tipo" expression=""/>
    <default applyOnUpdate="0" field="S" expression=""/>
    <default applyOnUpdate="0" field="HI" expression=""/>
    <default applyOnUpdate="0" field="Z" expression=""/>
    <default applyOnUpdate="0" field="ZTF" expression=""/>
    <default applyOnUpdate="0" field="Conexion" expression=""/>
    <default applyOnUpdate="0" field="Pozo_hmin" expression=""/>
    <default applyOnUpdate="0" field="cobertura_min" expression=""/>
    <default applyOnUpdate="0" field="D_min" expression=""/>
    <default applyOnUpdate="0" field="S_min" expression=""/>
    <default applyOnUpdate="0" field="Derivacion" expression=""/>
  </defaults>
  <constraints>
    <constraint unique_strength="1" constraints="3" notnull_strength="1" field="fid" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="L" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="Pozo" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="Ramal" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="Estado" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="ZFF" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="Seccion" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="Tramo" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="D_ext" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="SALTO" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="X" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="Obs" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="Y" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="ZFI" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="D_int" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="HF" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="LT" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="Material" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="Rug" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="ZTI" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="Rugosidad" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="Fase" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="Tipo" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="S" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="HI" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="Z" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="ZTF" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="Conexion" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="Pozo_hmin" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="cobertura_min" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="D_min" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="S_min" exp_strength="0"/>
    <constraint unique_strength="0" constraints="0" notnull_strength="0" field="Derivacion" exp_strength="0"/>
  </constraints>
  <constraintExpressions>
    <constraint desc="" exp="" field="fid"/>
    <constraint desc="" exp="" field="L"/>
    <constraint desc="" exp="" field="Pozo"/>
    <constraint desc="" exp="" field="Ramal"/>
    <constraint desc="" exp="" field="Estado"/>
    <constraint desc="" exp="" field="ZFF"/>
    <constraint desc="" exp="" field="Seccion"/>
    <constraint desc="" exp="" field="Tramo"/>
    <constraint desc="" exp="" field="D_ext"/>
    <constraint desc="" exp="" field="SALTO"/>
    <constraint desc="" exp="" field="X"/>
    <constraint desc="" exp="" field="Obs"/>
    <constraint desc="" exp="" field="Y"/>
    <constraint desc="" exp="" field="ZFI"/>
    <constraint desc="" exp="" field="D_int"/>
    <constraint desc="" exp="" field="HF"/>
    <constraint desc="" exp="" field="LT"/>
    <constraint desc="" exp="" field="Material"/>
    <constraint desc="" exp="" field="Rug"/>
    <constraint desc="" exp="" field="ZTI"/>
    <constraint desc="" exp="" field="Rugosidad"/>
    <constraint desc="" exp="" field="Fase"/>
    <constraint desc="" exp="" field="Tipo"/>
    <constraint desc="" exp="" field="S"/>
    <constraint desc="" exp="" field="HI"/>
    <constraint desc="" exp="" field="Z"/>
    <constraint desc="" exp="" field="ZTF"/>
    <constraint desc="" exp="" field="Conexion"/>
    <constraint desc="" exp="" field="Pozo_hmin"/>
    <constraint desc="" exp="" field="cobertura_min"/>
    <constraint desc="" exp="" field="D_min"/>
    <constraint desc="" exp="" field="S_min"/>
    <constraint desc="" exp="" field="Derivacion"/>
  </constraintExpressions>
  <expressionfields/>
  <previewExpression>COALESCE( "Material", '&lt;NULL>' )</previewExpression>
  <layerGeometryType>1</layerGeometryType>
</qgis>


         
         """
    return string


def round_floats_in_string(arr, decimal_places=3):
    pattern = r"\d+\.\d+"
    return np.array([re.sub(pattern, lambda x: f"{float(x.group()):.{decimal_places}f}", s) for s in arr])


def shp_out(m_ramales, project_name, EPSG=str(32717), path_out=None):
    """
    Convert a DataFrame of ramal data into a GeoDataFrame with line segments grouped by Ramal,
    save it to a GeoPackage file, and generate a QML style file.

    Parameters:
    -----------
    m_ramales : object
        Input data (e.g., list, dict) to be converted to a DataFrame using m_ramales2df.
    ramal : dict
        Dictionary containing ramal-related data (used to determine columns).
    project_name : str
        Name of the project for file naming and directory structure.
    EPSG : int, optional (default=32717)
        EPSG code for the Coordinate Reference System (e.g., 32717 for UTM Zone 17S).
    path_out : str, optional
        Custom output directory path. If None, uses default project structure.

    Returns:
    --------
    gdf : geopandas.GeoDataFrame
        GeoDataFrame containing line segments for each Ramal.
    """
    # Step 1: Convert input to DataFrame
    df = m_ramales2df(m_ramales).copy()

    # Step 3: Initialize lists to store line segments and their attributes
    lines = []
    attributes = []

    # Step 4: Group the DataFrame by 'Ramal'
    grouped = df.groupby("Ramal")

    # Step 5: Iterate through each Ramal group
    for ramal_id, group in grouped:
        # Validate that X and Y exist for all rows
        if not all(group["X"].notna()) or not all(group["Y"].notna()):
            print(f"Warning: Missing X or Y values in Ramal {ramal_id}. Skipping this group.")
            continue

        # Iterate through consecutive pairs within this Ramal group
        for i in range(len(group) - 1):
            # Get the start and end points for the current segment
            start_point = (group.iloc[i]["X"], group.iloc[i]["Y"])
            end_point = (group.iloc[i + 1]["X"], group.iloc[i + 1]["Y"])

            # Create a LineString for this segment
            line = LineString([start_point, end_point])
            lines.append(line)

            # Collect all columns as attributes for this segment (using the starting row's data)
            segment_attrs = group.iloc[i + 1].to_dict()

            attributes.append(segment_attrs)

    # Step 6: Create a new DataFrame with all attributes
    lines_df = pd.DataFrame(attributes)

    # Step 7: Create a GeoDataFrame with the LineString geometries
    gdf = gpd.GeoDataFrame(lines_df, geometry=lines)

    # Step 8: Round values and set the Coordinate Reference System (CRS)
    gdf = gdf.round(3)  # Round to 3 decimal places as in the original
    gdf = gdf.set_crs(EPSG)
    gdf.to_crs(EPSG)

    # Step 9: Adjust data types (similar to the original function)
    type_dict = type({"casima": "casima"})
    type_none = type(None)
    gdf = gdf.astype({col: (type(gdf[col].iloc[-1]) if type(gdf[col].iloc[-1]) not in [type_dict, type_none] else type("str")) for col in gdf.columns if col not in ["geometry"]})

    # Step 10: Remove 'D_init' column if it exists
    try:
        gdf.pop("D_init")
    except:
        pass

    # Step 11: Define output path
    if path_out is None:
        path_out = f"PROYECTO_{project_name}{os.path.sep}00_GIS{os.path.sep}02_OUT{os.path.sep}01_RAMALES{os.path.sep}"
    else:
        # Ensure it ends with separator
        if not path_out.endswith(os.path.sep):
            path_out += os.path.sep
            
    if not os.path.exists(path_out):
        os.makedirs(path_out)

    # Step 12: Save to GeoPackage
    gpkg_full_path = path_out + project_name + ".gpkg"
    gdf.to_file(gpkg_full_path, driver="GPKG", layer=project_name)

    # Step 13: Create QML file
    qml_out = path_out + f"{project_name}.qml"
    if "qml2file" in globals():
        qml_file = qml2file()
    else:
        qml_file = ""  # Fallback to empty string if qml2file is not available

    with open(qml_out, "w", encoding="utf-8") as f:
        f.write(qml_file)

    return gdf


def ang_cuadrante(ang, cuadrante):
    if cuadrante == 90:
        return 90 - ang
    if cuadrante == 270:
        return 90 - ang
    if cuadrante == 0 or cuadrante == 180:
        return ang


def ang_coords(x_v, y_v):
    y_v, x_v = np.asarray(y_v), np.asarray(x_v)
    N_S_E_W = {(1, 1): 0, (-1, 1): 90, (-1, -1): 180, (1, -1): 270, (0, 1): 0, (1, 0): 0, (0, -1): 0}
    f = operator.itemgetter(*zip(np.sign(x_v[1:] - x_v[:-1]), np.sign(y_v[1:] - y_v[:-1])))
    ang = abs(np.degrees(np.arctan(np.true_divide(y_v[1:] - y_v[:-1], x_v[1:] - x_v[:-1]))))
    ang2 = np.vectorize(ang_cuadrante)
    return ang2(ang, f(N_S_E_W)) + f(N_S_E_W), f(N_S_E_W)


def cuadrante_mat(cuadrante):
    N_S_E_W = {0: (1, 1), 90: (-1, 1), 180: (-1, -1), 270: (1, -1)}
    if isinstance(cuadrante, int):
        cuadrante = [cuadrante]
    f = operator.itemgetter(*cuadrante)
    return f(N_S_E_W)


def ang_vector(x_v, y_v):
    dx = x_v[1:] - x_v[:-1]
    dy = y_v[1:] - y_v[:-1]
    angles = np.abs(np.degrees(np.arctan(np.true_divide(dy, dx))))
    signs = list(zip(np.sign(dx), np.sign(dy)))
    return angles, signs


def remove_adjacent(L):
    # CODIGO OBSOLETO
    return [L[i] for i in range(len(L)) if i == 0 or L[i - 1] != L[i]]


def get_coords(x, y, step, min_distance=1.6):
    min_distance = min_distance * 1.5
    min_distance = max(min_distance, 2)  # estas distancia tiene que ser mayor al ancho del pozo
    abs_array = np.insert(np.cumsum(dist2d_vector(x, y)), 0, 0)
    range_array = np.arange(step, np.max(abs_array), step)

    abs_out = []
    x_out = []
    y_out = []

    ang, cuadrante = ang_vector(x, y)
    for i in range(len(abs_array) - 1):
        index = np.where(np.logical_and((range_array > abs_array[i]), (range_array < abs_array[i + 1])))[0]
        if i == 0:
            x_abs = np.concatenate(
                [
                    [x[i]],
                    x[0] + range_array[index] * np.cos(np.radians(ang[i])) * cuadrante[i][0],
                    [x[i + 1]],
                ]
            )
            y_abs = np.concatenate(
                [
                    [y[i]],
                    y[0] + range_array[index] * np.sin(np.radians(ang[i])) * cuadrante[i][1],
                    [y[i + 1]],
                ]
            )
            abs_abs = np.concatenate([[abs_array[i]], range_array[index], [abs_array[i + 1]]])

            if index.size > 0:
                index_remove = np.where(np.diff(abs_abs) < min_distance)
                abs_abs = np.delete(abs_abs, index_remove)
                y_abs = np.delete(y_abs, index_remove)
                x_abs = np.delete(x_abs, index_remove)

            abs_out.append(abs_abs)
            x_out.append(x_abs)
            y_out.append(y_abs)

        else:
            abs_scale = range_array[index] - abs_out[i - 1][-1]
            x_abs = np.concatenate(
                [
                    x[i] + abs_scale * np.cos(np.radians(ang[i])) * cuadrante[i][0],
                    [x[i + 1]],
                ]
            )
            y_abs = np.concatenate(
                [
                    y[i] + abs_scale * np.sin(np.radians(ang[i])) * cuadrante[i][1],
                    [y[i + 1]],
                ]
            )
            abs_abs = np.concatenate([range_array[index], [abs_array[i + 1]]])

            index_remove = np.where(np.diff(abs_abs) < min_distance)[0]
            if (abs_abs[0] - abs_out[i - 1][-1]) < min_distance and index.size > 0:
                if index_remove.size > 0:
                    index_remove = sorted(list(index_remove) + [0])
                else:
                    index_remove = [0]

            abs_abs = np.delete(abs_abs, index_remove)
            y_abs = np.delete(y_abs, index_remove)
            x_abs = np.delete(x_abs, index_remove)

            abs_out.append(abs_abs)
            x_out.append(x_abs)
            y_out.append(y_abs)

    return np.concatenate(abs_out), np.concatenate(x_out), np.concatenate(y_out)


def get_profile_raster(m_ramales, ramal, raster, step, skip_existing=True):
    # get raster open and read as array
    src_ds = gdal.Open(raster)
    gt = src_ds.GetGeoTransform()

    m_profile = {}
    for i in ramal.values():
        if skip_existing:
            cond = m_ramales[i]["Estado"][0] == "nuevo"
        else:
            cond = True

        if cond:
            abs_out, x_out, y_out = get_coords(
                m_ramales[ramal[i]]["X"],
                m_ramales[ramal[i]]["Y"],
                step=step,
                min_distance=par_dxf(heigth_dat_hidraulicos=1),
            )
            z_out = np.round(raster2Z1(raster=src_ds, mx=x_out, my=y_out, gt=gt), 4)

            # z_out = np.array(convert_utm_to_ellipsoidal(x_out, y_out, z_out))  # borrar
            m_profile[i] = [x_out, y_out, abs_out, z_out]

    return m_profile


def get_profile_xyz(m_ramales, ramal, xyz_file, step, n_cpu=1, npoints=2):
    if isinstance(xyz_file, str):
        tree, z_coords = get_tree_from_xyz(xyz_file)
    else:
        tree, z_coords = xyz_file

    m_profile = {}
    for i in ramal.values():
        # get profile coordinates
        abs_v, x_v, y_v = get_coords(
            m_ramales[ramal[i]]["X"],
            m_ramales[ramal[i]]["Y"],
            step=step,
            min_distance=par_dxf(heigth_dat_hidraulicos=1),
        )
        # get ramal points
        coords = np.array([x_v, y_v]).T
        # get ramal points indexes
        d_array, index_array = tree.query(coords, k=npoints, workers=n_cpu)
        if npoints > 1:
            # get ramal points elevations
            z_v = np.round(z_coords[index_array].mean(axis=1), 4)  # z_v = np.round(np.array(convert_utm_to_ellipsoidal(x_v, y_v, z_v)), 4)  # borrar
        else:
            z_v = np.round(z_coords[index_array], 4)  # z_v = np.round(np.array(convert_utm_to_ellipsoidal(x_v, y_v, z_v)), 4)  # borrar
        # append to profile array
        m_profile[i] = [x_v, y_v, abs_v, z_v]
    return m_profile


def get_profile_vector(m_ramales, ramal, vector, step):
    gdf = gpd.read_file(vector, engine="pyogrio")
    coords = gdf.geometry.get_coordinates(index_parts=False, include_z=True).to_numpy()
    x_buff, y_buff, z_buff = coords.T[0], coords.T[1], coords.T[2]

    # Perform linear interpolation
    data_array = np.array([x_buff, y_buff]).T
    z_Linear = LinearNDInterpolator(data_array, z_buff, fill_value=np.nan, rescale=True)

    m_profile = {}
    for i in ramal.values():
        abs_out, x_out, y_out = get_coords(
            m_ramales[ramal[i]]["X"],
            m_ramales[ramal[i]]["Y"],
            step=step,
            min_distance=par_dxf(heigth_dat_hidraulicos=1),
        )
        z_out = np.round(z_Linear(x_out, y_out), 4)
        m_profile[i] = [x_out, y_out, abs_out, z_out]

    return m_profile


def get_ancho_pozo(i, m_ramales):
    D_ext = D_ext_float(i, m_ramales)
    D_ext[0] = D_ext[1]
    ancho_pozo = np.where(
        D_ext < par_dxf(ancho_pozo_limite=1),
        par_dxf(ancho_pozo_menor_limite=1),
        np.around(D_ext + par_dxf(ancho_pozo_mayor_limite=1), decimals=1) / 2.0,
    )
    ancho_pozo = np.where(
        np.insert(
            np.insert(np.abs(m_ramales[i]["ZFI"][2:] - m_ramales[i]["ZFF"][1:-1]), 0, 0),
            -1,
            0,
        )
        > 0,
        par_dxf(ancho_pozo_menor_limite=1) * 2,
        ancho_pozo,
    )
    return ancho_pozo


def get_profile_tuberia(m_ramales, ramal):
    prog_dict_base, elev_dict_base = {}, {}
    prog_dict_tapa, elev_dict_tapa = {}, {}
    for i in ramal.values():
        # "ABSCISAS"
        prog = m_ramales[i]["LT"]
        # FLOAT DIAMETER VALUES
        D_ext = D_ext_float(i, m_ramales)
        D_ext[0] = D_ext[1]
        # "ANCHO DE POZO"
        ancho_pozo = get_ancho_pozo(i, m_ramales)
        temp_prog1 = prog - ancho_pozo
        temp_prog2 = prog + ancho_pozo
        # 'ABSCISA BASE Y TAPA'
        prog_temp_base = np.vstack((temp_prog1, temp_prog1, temp_prog2))
        prog_temp_tapa = np.vstack((temp_prog1, temp_prog1, temp_prog2, temp_prog2))
        # "ELEVACION BASE"
        elev_temp_base = np.vstack(
            (
                m_ramales[i]["ZFF"][1:-1],
                m_ramales[i]["ZFI"][2:],
                m_ramales[i]["ZFI"][2:],
            )
        )
        c1 = np.asarray([m_ramales[i]["ZFI"][1]] * 3).reshape(-1, 1)
        c2 = np.asarray([m_ramales[i]["ZFF"][-1]] * 3).reshape(-1, 1)
        elev_temp_base = np.concatenate((c1, elev_temp_base, c2), axis=1)
        # "ELEVACION TAPA"
        elev_FF1 = np.asarray(m_ramales[i]["ZFF"][1:-1] + D_ext[1:-1])
        elev_TF1 = np.asarray(m_ramales[i]["ZTF"][1:-1])
        elev_FI2 = np.asarray(m_ramales[i]["ZFI"][2:] + D_ext[2:])
        elev_temp_tapa = np.vstack((elev_FF1, elev_TF1, elev_TF1, elev_FI2))
        c3 = np.asarray(
            [
                m_ramales[i]["ZFI"][1],
                m_ramales[i]["ZTI"][1],
                m_ramales[i]["ZTI"][1],
                m_ramales[i]["ZFI"][1] + D_ext[1],
            ]
        ).reshape(-1, 1)
        c4 = np.asarray(
            [
                m_ramales[i]["ZFF"][-1] + D_ext[-1],
                m_ramales[i]["ZTF"][-1],
                m_ramales[i]["ZTF"][-1],
                m_ramales[i]["ZFF"][-1],
            ]
        ).reshape(-1, 1)
        elev_temp_tapa = np.hstack((c3, elev_temp_tapa, c4))
        # "GENERAR DICCIONARIOS"
        a, b = prog_temp_base.shape
        p_elev_base, p_prog_base = np.asarray([]), np.asarray([])
        p_elev_tapa, p_prog_tapa = np.asarray([]), np.asarray([])
        for j in range(b):
            p_prog_base = np.concatenate((p_prog_base, prog_temp_base[:, j]), axis=0)
            p_elev_base = np.concatenate((p_elev_base, elev_temp_base[:, j]), axis=0)
            p_prog_tapa = np.concatenate((p_prog_tapa, prog_temp_tapa[:, j]), axis=0)
            p_elev_tapa = np.concatenate((p_elev_tapa, elev_temp_tapa[:, j]), axis=0)
        prog_dict_base[i] = p_prog_base
        elev_dict_base[i] = p_elev_base
        prog_dict_tapa[i] = p_prog_tapa
        elev_dict_tapa[i] = p_elev_tapa
    return [prog_dict_base, elev_dict_base], [prog_dict_tapa, elev_dict_tapa]


def get_h_abcisas(m_ramales, ramal, t_base, terreno, skip_existing=False):
    abscisa_dict = {}
    elevacion_dict = {}
    corte_dict = {}

    for i in ramal.values():
        if skip_existing:
            cond = m_ramales[i]["Estado"][0] == "nuevo"
        else:
            cond = True

        if cond:
            index_3 = list(range(2, (len(t_base[0][i])), 3))
            index_1 = list(range(0, (len(t_base[0][i])), 3))
            abs_ZFI = t_base[0][i][index_1][1:]
            abs_ZFF = t_base[0][i][index_3][:-1]
            lista = list(zip(abs_ZFF, abs_ZFI))
            lista_z = list(zip(m_ramales[i]["ZFI"][1:], m_ramales[i]["ZFF"][1:]))
            abs_terreno = terreno[i][2]
            z_vector = []
            pos = 0

            for j, k in zip(lista, lista_z):
                index = np.where((abs_terreno > j[0]) & (abs_terreno < j[1]))[0]
                if len(index) > 0:
                    # abscisas entre pozos
                    abs_array = abs_terreno[index]
                    # pendiente entre tramos
                    s = (k[0] - k[1]) / (j[-1] - j[0])
                    if pos == 0:
                        # asignar elevacion de abscisas
                        elev_abs = k[0] - (abs_array - j[0]) * s
                        z_vector.append(np.concatenate([[k[0]], elev_abs, [k[1]]]))
                    else:
                        # asignar elevacion de abscisas
                        elev_abs = k[0] - (abs_array - j[0]) * s
                        z_vector.append(np.concatenate([elev_abs, [k[1]]]))
                else:
                    if pos == 0:
                        z_vector.append(np.concatenate([[k[0]], [k[1]]]))
                    else:
                        z_vector.append(np.concatenate([[k[1]]]))
                pos = pos + 1

            corte_vector = terreno[i][3] - np.concatenate(z_vector)
            abscisa_dict[i] = abs_terreno
            elevacion_dict[i] = np.concatenate(z_vector)
            corte_dict[i] = corte_vector

    return abscisa_dict, elevacion_dict, corte_dict


# LINETYPES = ['CONTINUOUS', 'CENTER', 'CENTERX2', 'CENTER2','DASHED', 'DASHEDX2', 'DASHED2', 'PHANTOM', 'PHANTOMX2','PHANTOM2', 'DASHDOT', 'DASHDOTX2', 'DASHDOT2', 'DOT','DOTX2', 'DOT2', 'DIVIDE', 'DIVIDEX2', 'DIVIDE2',]

LINETYPES = {"sanitario": "CONTINUOUS", "pluvial": "PHANTOM", "combinado": "DASHDOT"}
LINECOLOR = {
    "sanitario": 10,
    "pluvial": 30,
    "combinado": 15,
    "existente": 102,
    "interferencia": 6,
}
LAYER = {
    "sanitario": "00_SANITARIO",
    "pluvial": "01_PLUVIAL",
    "combinado": "02_COMBINADO",
    "existente": "03_EXISTENTE",
}
LINEWEIGHT = {"sanitario": 40, "pluvial": 40, "combinado": 40, "existente": 20}
BLOQUE_POZO = {
    "sanitario": "B_SAN",
    "pluvial": "B_PLU",
    "combinado": "B_COMB",
    "existente": "B_EXISTENTE",
}


def par_dxf(
    sep_pf=0,
    sep_v=0,
    esc_V=0,
    id_p1=0,
    heigth_pozo_id=0,
    sep_pozo_id=0,
    rec_dat=0,
    heigth_dat_hidraulicos=0,
    heigth_dat_hidraulicos_perfil=0,
    ancho_pozo_menor_limite=0,
    ancho_pozo_mayor_limite=0,
    ancho_pozo_limite=0,
):
    if sep_pf != 0:
        return 100
    if esc_V != 0:
        return 10
    if sep_v != 0:
        return 25
    if id_p1 != 0:
        # return 4.5
        return par_dxf(heigth_pozo_id=1) * 1.9

    if sep_pozo_id != 0:
        return 25
    if heigth_pozo_id != 0:
        return 2.0
    if rec_dat != 0:
        return 11
    if heigth_dat_hidraulicos != 0:
        return 2.0
    if heigth_dat_hidraulicos_perfil != 0:
        return 1.8
    if ancho_pozo_menor_limite != 0:
        return 0.45
    if ancho_pozo_mayor_limite != 0:
        return 0.5
    if ancho_pozo_limite != 0:
        return 0.5

    # if sep_pf != 0:  #     return 25  # if esc_V != 0:  #     return 1  # if sep_v != 0:  #     return 6.25  # if id_p1 != 0:  #     return 1.5  # if sep_pozo_id != 0:  #     return 25  # if heigth_pozo_id != 0:  #     return 0.65  # if rec_dat != 0:  #     return 2.5  # if heigth_dat_hidraulicos != 0:  #     return 0.4  # if ancho_pozo_menor_limite != 0:  #     return 0.45  # if ancho_pozo_mayor_limite != 0:  #     return 0.5  # if ancho_pozo_limite != 0:  #     return 0.5


def calculate_segment_midpoints(start_distance, end_distance, segment_length=700):
    # List to store the midpoints of each segment
    midpoints = []

    # Current start point for the segments
    current_start = start_distance

    while current_start + segment_length <= end_distance:
        # Calculate the end of the current segment
        current_end = current_start + segment_length

        # Calculate the midpoint of the current segment
        midpoint = (current_start + current_end) / 2
        midpoints.append(midpoint)

        # Update the start for the next segment
        current_start = current_end

    # Handle the last segment if it's shorter than the standard segment length
    if current_start < end_distance:
        # Calculate the midpoint of the last, shorter segment
        midpoint = (current_start + end_distance) / 2
        midpoints.append(midpoint)

    return midpoints


def find_similar_numbers(arr1, arr2, tolerance=0.01):
    # Reshape arrays for broadcasting
    arr1_col = arr1.reshape(-1, 1)
    arr2_row = arr2.reshape(1, -1)

    # Calculate absolute differences
    differences = np.abs(arr1_col - arr2_row)

    # Find pairs within tolerance
    similar_pairs = np.argwhere(differences <= tolerance)

    # Extract indices
    indices_arr1 = similar_pairs[:, 0]
    # indices_arr2 = similar_pairs[:, 1]

    return indices_arr1


def update_tuple_in_list(list_of_tuples, index, item_index, new_value):
    # Get the tuple you want to modify
    old_tuple = list_of_tuples[index]

    # Create a new tuple with the updated value
    new_tuple = old_tuple[:item_index] + (new_value,) + old_tuple[item_index + 1 :]

    # Replace the old tuple with the new one
    list_of_tuples[index] = new_tuple


def get_text_entities_from_dxf(dxf_file_path):
    doc = ezdxf.readfile(dxf_file_path)
    msp = doc.modelspace()

    text_entities = []
    counter = 1
    for entity in msp:
        if entity.dxftype() in ["TEXT", "MTEXT"]:
            content = entity.dxf.text if entity.dxftype() == "TEXT" else entity.text
            insert = entity.dxf.insert

            text_entities.append({"number": counter, "content": content, "coordinates": (insert.x, insert.y)})

            counter += 1
    return text_entities


def get_repeated_intervals(arr):
    arr = np.array(arr)
    diff = np.diff(np.concatenate(([True], arr[1:] != arr[:-1], [True])))
    starts = np.where(diff)[0][::2]
    ends = np.where(diff)[0][1::2] - 1
    return [(start, end) for start, end in zip(starts, ends) if end > start]


def cad_profile_out(
    m_ramales, ramal, project_name, elev_source, step, fromEPSG=None, variable_list=None, add_street_names_osm=True, additional_profile_list=None
):
    df = m_ramales2df(m_ramales)
    keep_draw_pz_dict = encontrar_pozos_identicos(m_ramales, df, return_replace_dict=True)
    remove_draw_pz_dict = reverse_dictionary(keep_draw_pz_dict)

    # preparar datos de perfil terreno y tuberia
    terreno = elev_source.get_profile_m_ramales(m_ramales, step, skip_existing=True, adjust_elevation=True)


    t_base, t_tapa = get_profile_tuberia(m_ramales, ramal)
    dat_abs, dat_elev, dat_corte = get_h_abcisas(m_ramales, ramal, t_base, terreno, skip_existing=True)

    # "propiedades de lineas y texto"
    dict1 = {"layer": "00_TERRENO", "color": 64, "lineweight": 30, "ltscale": 5}
    dict1_ = {"layer": "00_TERRENO_PLATAFORMA", "color": 30, "lineweight": 30, "ltscale": 5, "linetype": "DASHDOT"}
    dict2 = {"layer": "01_TUBERIA", "color": 150, "lineweight": 35}
    dict_existente = {
        "layer": "01_TUBERIA_EXISTENTE",
        "linetype": "DASHDOT",
        "color": 102,
        "lineweight": 30,
        "ltscale": 2.5,
    }
    dict3 = {"layer": "05_CAJETIN", "color": 41, "lineweight": 25}
    dict4 = {"layer": "03_GRILLA", "color": 9}
    dict5 = {
        "style": "Letra_Arial",
        "layer": "04_DATOS_GRILLA",
        "color": 7,
        "rotation": 90,
        "height": par_dxf(heigth_dat_hidraulicos_perfil=1),
    }
    dict6 = {
        "style": "Letra_Arial",
        "layer": "02_ATTR",
        "color": 11,
        "height": par_dxf(heigth_pozo_id=1),
    }
    dict7 = {
        "layer": "02_ATTR",
        "linetype": "DASHDOT2",
        "color": 11,
        "lineweight": 30,
        "ltscale": 5,
    }
    dict8 = {
        "style": "Letra_Arial",
        "layer": "04_DATOS_GRILLA",
        "color": 7,
        "height": par_dxf(heigth_dat_hidraulicos_perfil=1),
    }
    dict9 = {
        "layer": "04_INTERFERENCIAS_EXISTENTES",
        "color": 40,
        "lineweight": 40,
        "ltscale": 2,
        "linetype": "DASHDOT2",
    }
    dict10 = {
        "layer": "04_CONEXIONES",
        "color": 8,
        "lineweight": 40,
        "ltscale": 2,
        "linetype": "DASHDOT2",
    }
    dict11 = {
        "style": "Letra_Arial",
        "layer": "05_DATOS_GRILLA",
        "color": 7,
        "rotation": 90,
        "height": par_dxf(heigth_dat_hidraulicos_perfil=1),
    }

    # crear modelo en dxf
    doc = ezdxf.new("R2010", setup=True)

    APPID = "PyPiper"
    try:
        doc.appids.add(APPID)
    except:
        # APPID already exists
        pass

    msp = doc.modelspace()
    appsettings.show_lineweight(doc=doc, state=True)
    doc.units = ezdxf.units.M
    doc.styles.new("Letra_Arial", dxfattribs={"font": "arial.ttf"})

    mleaderstyle = doc.mleader_styles.duplicate_entry("Standard", "EZDXF")
    mleaderstyle.set_mtext_style("Letra_Arial")
    mleaderstyle.set_dxf_attrib("arrow_head_size", par_dxf(heigth_dat_hidraulicos_perfil=1))
    mleaderstyle.dxf.char_height = par_dxf(heigth_dat_hidraulicos_perfil=1)
    mleaderstyle.dxf.landing_gap_size = 0.5

    # Create a block with a cross and a centered circle
    block_EntrySymbol = doc.blocks.new(name="EntrySymbol")
    size = 0.1 * par_dxf(esc_V=1)  # Size of the cross arms
    block_EntrySymbol.add_line((-size, 0), (size, 0), dxfattribs=dict10)  # Horizontal line
    block_EntrySymbol.add_line((0, -size), (0, size), dxfattribs=dict10)  # Vertical line
    block_EntrySymbol.add_circle((0, 0), radius=0.05 * par_dxf(esc_V=1), dxfattribs=dict10)  # Circle at the center with a radius of 0.1

    cont = -1

    # Initialize an empty list
    dist = []
    # Iterate over the values of the dictionary 'ramal'
    for v in ramal.values():
        try:
            # Append the last element of the third item (assuming it's a list) of each 'v' to 'dist'
            dist.append(terreno[v][2][-1])
        except:
            dist.append(0)

    abscisa_lista = []
    elevacion_lista = []
    ramal_lista = []



    for i in ramal.values():
        tuberia_type = np.unique(m_ramales[i]["Estado"]).item()
        try:
            interference_elev_min = [np.min(_["bottom_elevation"]) for _ in pd.DataFrame(m_ramales[i])["Interferencia"].dropna()]
        except:
            interference_elev_min = []
        elev_min = np.min(np.concatenate([m_ramales[i]["ZFF"][1:], interference_elev_min]))

        elev_max = np.max(m_ramales[i]["ZTI"][1:])

        cont = cont + 1
        abs1 = 0 if cont == 0 else cont * par_dxf(sep_pf=1) + np.sum(dist[:cont])

        if tuberia_type in ["existente"]:
            continue

        abscisa_terreno = terreno[i][2] + abs1
        abscisa_t_base = t_base[0][i] + abs1
        abscisa_t_tapa = t_tapa[0][i] + abs1
        abscisa_id_pozo = m_ramales[i]["LT"] + abs1

        factor_sep = 2.4
        # cajetin
        N1 = elev_min * par_dxf(esc_V=1) - 2 * par_dxf(sep_v=1)
        N2 = elev_min * par_dxf(esc_V=1) - factor_sep * par_dxf(sep_v=1) - factor_sep * par_dxf(rec_dat=1)
        N3 = N2 - 1.3 * par_dxf(rec_dat=1)
        N4 = N3 - par_dxf(rec_dat=1)
        N5 = N4 - par_dxf(rec_dat=1)
        N6 = N5 - par_dxf(rec_dat=1)

        # longtiud adicional para poner datos de la grilla a donde se conectan
        aditional_distance = par_dxf(heigth_dat_hidraulicos_perfil=1)
        caj1 = [
            (-par_dxf(sep_pf=1) / 2.0 + abs1, N1),
            (np.max(t_base[0][i]) + abs1 + aditional_distance, N1),
            (np.max(t_base[0][i]) + abs1 + aditional_distance, N2),
            (-par_dxf(sep_pf=1) / 2.0 + abs1, N2),
            (-par_dxf(sep_pf=1) / 2.0 + abs1, N1),
        ]
        caj2 = [
            (-par_dxf(sep_pf=1) / 2.0 + abs1, N2),
            (np.max(t_base[0][i]) + abs1 + aditional_distance, N2),
            (np.max(t_base[0][i]) + abs1 + aditional_distance, N3),
            (-par_dxf(sep_pf=1) / 2.0 + abs1, N3),
            (-par_dxf(sep_pf=1) / 2.0 + abs1, N2),
        ]
        caj3 = [
            (-par_dxf(sep_pf=1) / 2.0 + abs1, N3),
            (np.max(t_base[0][i]) + abs1 + aditional_distance, N3),
            (np.max(t_base[0][i]) + abs1 + aditional_distance, N4),
            (-par_dxf(sep_pf=1) / 2.0 + abs1, N4),
            (-par_dxf(sep_pf=1) / 2.0 + abs1, N3),
        ]
        caj4 = [
            (-par_dxf(sep_pf=1) / 2.0 + abs1, N4),
            (np.max(t_base[0][i]) + abs1 + aditional_distance, N4),
            (np.max(t_base[0][i]) + abs1 + aditional_distance, N5),
            (-par_dxf(sep_pf=1) / 2.0 + abs1, N5),
            (-par_dxf(sep_pf=1) / 2.0 + abs1, N4),
        ]
        caj5 = [
            (-par_dxf(sep_pf=1) / 2.0 + abs1, N5),
            (np.max(t_base[0][i]) + abs1 + aditional_distance, N5),
            (np.max(t_base[0][i]) + abs1 + aditional_distance, N6),
            (-par_dxf(sep_pf=1) / 2.0 + abs1, N6),
            (-par_dxf(sep_pf=1) / 2.0 + abs1, N5),
        ]

        # PERFILES
        elevacion_terreno = terreno[i][3] * par_dxf(esc_V=1)
        elevacion_t_base = t_base[1][i] * par_dxf(esc_V=1)
        elevacion_t_tapa = t_tapa[1][i] * par_dxf(esc_V=1)

        # LINEA IDENTIFICACION DE POZO"
        elevacion_id_pozo_0 = np.asarray([N6] * len(m_ramales[i]["LT"]))
        elevacion_id_pozo_1 = ((np.append(m_ramales[i]["ZTI"][1:], m_ramales[i]["ZTF"][-1])) * par_dxf(esc_V=1)) + par_dxf(sep_pozo_id=1) / 2.0

        # GRILLA
        elevacion_id_pozo_2 = np.asarray([elev_min] * len(elevacion_terreno)) * par_dxf(esc_V=1) - 2 * par_dxf(sep_v=1)
        elevacion_id_pozo_4 = np.asarray(
            -np.sort(
                -np.arange(
                    round(elev_min, 0) - (par_dxf(sep_v=1) / par_dxf(esc_V=1)),
                    elev_max + (par_dxf(sep_v=1) / par_dxf(esc_V=1)),
                    1,
                )
            )
        ) * par_dxf(esc_V=1)

        elev_max_1 = elevacion_id_pozo_4[0] + 1 * par_dxf(esc_V=1)
        elevacion_id_pozo_4 = np.insert(elevacion_id_pozo_4, 0, elev_max_1)
        elevacion_id_pozo_3 = np.asarray([elev_max_1] * len(elevacion_terreno))

        elevacion_id_pozo_5 = np.asarray([N6] * len(elevacion_terreno))
        elevacion_id_pozo_6 = np.asarray([N2] * len(elevacion_terreno))

        # indetificadores de perfiles
        val0 = abs1 - par_dxf(sep_pf=1) / 2.0
        val1 = abs1 + np.max(m_ramales[i]["LT"]) + par_dxf(id_p1=1) / 2.0
        abscisa_lista.append((val0, val1))
        elevacion_lista.append((N6, elev_max_1))
        ramal_lista.append(i)

        # GENERAR CUPLAS DE LISTAS
        p_TERRENO = list(zip(abscisa_terreno, elevacion_terreno))
        p_TUBERIA_base = list(zip(abscisa_t_base, elevacion_t_base))
        p_TUBERIA_tapa = list(zip(abscisa_t_tapa, elevacion_t_tapa))

        i_linea = list(zip(abscisa_id_pozo, elevacion_id_pozo_0))
        f_linea = list(zip(abscisa_id_pozo, elevacion_id_pozo_1))
        p_LINEA_ID = list(zip(i_linea, f_linea))

        i_grilla_v = list(zip(abscisa_terreno, elevacion_id_pozo_2))
        f_grilla_v = list(zip(abscisa_terreno, elevacion_id_pozo_3))
        p_GRILLA_v = list(zip(i_grilla_v, f_grilla_v))

        i_grilla_v1 = list(zip(abscisa_terreno, elevacion_id_pozo_5))
        f_grilla_v1 = list(zip(abscisa_terreno, elevacion_id_pozo_6))
        p_GRILLA_v1 = list(zip(i_grilla_v1, f_grilla_v1))

        i_grilla_h = list(zip([0 + abs1] * len(elevacion_id_pozo_4), elevacion_id_pozo_4))
        f_grilla_h = list(
            zip(
                [m_ramales[i]["LT"][-1] + abs1] * len(elevacion_id_pozo_4),
                elevacion_id_pozo_4,
            )
        )
        p_GRILLA_h = list(zip(i_grilla_h, f_grilla_h))

        # AGREGAR POLYLINEAS A MODELO
        msp.add_lwpolyline(p_TERRENO, dxfattribs=dict1)

        if tuberia_type in ["existente"]:
            msp.add_lwpolyline(p_TUBERIA_base, dxfattribs=dict_existente)
            msp.add_lwpolyline(p_TUBERIA_tapa, dxfattribs=dict_existente)
        else:
            conexion_grilla_vertical = m_ramales[i]["Conexion"][-1]
            z_conexion_grilla = None
            if conexion_grilla_vertical:
                lowest_elev_grid = []
                lowest_elev_grid_pz = []
                lista_ramal_pz = conexion_grilla_vertical.split(",")
                if len(lista_ramal_pz) > 1:
                    for _ in lista_ramal_pz:
                        grilla_ramal_temp, grilla_pz_temp = _.split(".")
                        pz_start_grid, pz_end_grid = pd.Series(m_ramales[grilla_ramal_temp]["Tramo"]).str.split("-", expand=True).T.to_numpy()

                        index_grid_ZFI = (pz_start_grid == _).nonzero()[0]
                        if index_grid_ZFI.size > 1:
                            lowest_elev_grid.append(m_ramales[grilla_ramal_temp]["ZFI"][index_grid_ZFI].item())
                            lowest_elev_grid_pz.append(_)
                        else:
                            lowest_elev_grid.append(np.nan)
                            lowest_elev_grid_pz.append(_)

                        index_grid_ZFF = (pz_end_grid == _).nonzero()[0]
                        if index_grid_ZFF.size > 0:
                            lowest_elev_grid.append(m_ramales[grilla_ramal_temp]["ZFF"][index_grid_ZFF].item())
                            lowest_elev_grid_pz.append(_)
                        else:
                            lowest_elev_grid.append(np.nan)
                            lowest_elev_grid_pz.append(_)

                    # get lowest value index
                    lowest_value_index = np.argmin(lowest_elev_grid)
                    grilla_ramal, grilla_pz = lista_ramal_pz[lowest_value_index].split(".")

                else:
                    grilla_ramal, grilla_pz = conexion_grilla_vertical.split(".")

                try:
                    z_conexion_grilla = m_ramales[grilla_ramal]["ZFI"][int(grilla_pz) + 1]
                    h_conexion_grilla = m_ramales[grilla_ramal]["HI"][int(grilla_pz) + 1]
                except:
                    z_conexion_grilla = m_ramales[grilla_ramal]["ZFF"][int(grilla_pz)]
                    h_conexion_grilla = m_ramales[grilla_ramal]["HF"][int(grilla_pz)]

                p_TUBERIA_base.append(p_TUBERIA_base[-1])
                update_tuple_in_list(p_TUBERIA_base, -2, 1, z_conexion_grilla * par_dxf(esc_V=1))
                update_tuple_in_list(p_TUBERIA_base, -3, 1, z_conexion_grilla * par_dxf(esc_V=1))
                msp.add_lwpolyline(p_TUBERIA_base, dxfattribs=dict2)
                msp.add_lwpolyline(p_TUBERIA_tapa, dxfattribs=dict2)
            else:
                msp.add_lwpolyline(p_TUBERIA_base, dxfattribs=dict2)
                msp.add_lwpolyline(p_TUBERIA_tapa, dxfattribs=dict2)

        # texto y lineas cajetin
        msp.add_lwpolyline(caj1, dxfattribs=dict3)
        msp.add_lwpolyline(caj2, dxfattribs=dict3)
        msp.add_lwpolyline(caj3, dxfattribs=dict3)
        msp.add_lwpolyline(caj4, dxfattribs=dict3)
        msp.add_lwpolyline(caj5, dxfattribs=dict3)
        msp.add_mtext(
            f"DATOS HIDRAULICOS\n\nRamal: {i}",
            dxfattribs={
                "style": "Letra_Arial",
                "layer": "04_DATOS_GRILLA",
                "color": 41,
                "char_height": par_dxf(heigth_dat_hidraulicos=1) * 1.125,
                "attachment_point": 5,
                "width": par_dxf(sep_pf=1) / 4.0,
                "insert": (abs1 - (par_dxf(sep_pf=1) / 4.0), N1 - par_dxf(rec_dat=1)),
            },
        )

        msp.add_mtext(
            "ABSCISAS",
            dxfattribs={
                "style": "Letra_Arial",
                "layer": "04_DATOS_GRILLA",
                "color": 41,
                "char_height": par_dxf(heigth_dat_hidraulicos=1) * 1.125,
                "attachment_point": 5,
                "width": par_dxf(sep_pf=1) / 4.0,
                "insert": (
                    abs1 - (par_dxf(sep_pf=1) / 4.0),
                    N2 - 0.5 * par_dxf(rec_dat=1),
                ),
            },
        )
        msp.add_mtext(
            "ELEVACION TERRENO",
            dxfattribs={
                "style": "Letra_Arial",
                "layer": "04_DATOS_GRILLA",
                "color": 41,
                "char_height": par_dxf(heigth_dat_hidraulicos=1) * 1.125,
                "attachment_point": 5,
                "width": par_dxf(sep_pf=1) / 4.0,
                "insert": (
                    abs1 - (par_dxf(sep_pf=1) / 4.0),
                    N3 - 0.5 * par_dxf(rec_dat=1),
                ),
            },
        )
        msp.add_mtext(
            "ELEVACION PROYECTO",
            dxfattribs={
                "style": "Letra_Arial",
                "layer": "04_DATOS_GRILLA",
                "color": 41,
                "char_height": par_dxf(heigth_dat_hidraulicos=1) * 1.125,
                "attachment_point": 5,
                "width": par_dxf(sep_pf=1) / 4.0,
                "insert": (
                    abs1 - (par_dxf(sep_pf=1) / 4.0),
                    N4 - 0.5 * par_dxf(rec_dat=1),
                ),
            },
        )
        msp.add_mtext(
            "(+)CORTE \\P" + "(-)RELLENO",
            dxfattribs={
                "style": "Letra_Arial",
                "layer": "04_DATOS_GRILLA",
                "color": 41,
                "char_height": par_dxf(heigth_dat_hidraulicos=1) * 1.125,
                "attachment_point": 5,
                "width": par_dxf(sep_pf=1) / 4.0,
                "insert": (
                    abs1 - (par_dxf(sep_pf=1) / 4.0),
                    N5 - 0.5 * par_dxf(rec_dat=1),
                ),
            },
        )

        # texto y  lineas grilla

        # Find indices where terrain abscissa matches branch lengths
        terrain_to_branch_indices = find_similar_numbers(
            abscisa_terreno - abscisa_terreno[0],  # Normalize terrain abscissa
            m_ramales[i]["LT"],  # Branch lengths
            tolerance=0.25,
        )
        # Identify indices before drops in the branch
        drop_indices = (m_ramales[i]["SALTO"] > 0).nonzero()[0] - 1
        # Calculate indices to skip in the vertical grid
        skip_vertical_grid_indices = terrain_to_branch_indices[drop_indices] + 1
        # Find indices where vertical grid spacing is less than 4 units
        close_vertical_grid_indices = (np.diff(abscisa_terreno - abscisa_terreno[0]) < 4.8).nonzero()[0] + 1
        # Get intersection of skip indices and close grid indices
        skip_vertical_index_vertical = np.intersect1d(skip_vertical_grid_indices, close_vertical_grid_indices)
        too_close_vertical_lines = (np.diff(abscisa_terreno - abscisa_terreno[0]) < aditional_distance).nonzero()[0] + 1

        for m in range(len(p_GRILLA_v)):
            if m == len(p_GRILLA_v) - 1 and z_conexion_grilla:
                msp.add_text(np.round(z_conexion_grilla, 3), dxfattribs=dict11).set_placement((abscisa_terreno[m], N5 + (N4 - N5) * 0.5), align=TextEntityAlignment.TOP_CENTER)
                msp.add_text(np.round(h_conexion_grilla, 3), dxfattribs=dict11).set_placement((abscisa_terreno[m], N6 + (N5 - N6) * 0.5), align=TextEntityAlignment.TOP_CENTER)

            if m in too_close_vertical_lines:
                continue
            msp.add_line(p_GRILLA_v[m][0], p_GRILLA_v[m][1], dxfattribs=dict4)
            msp.add_line(p_GRILLA_v1[m][0], p_GRILLA_v1[m][1], dxfattribs=dict4)
            # aling = TextEntityAlignment.TOP_CENTER if m == len(p_GRILLA_v) - 1 else TextEntityAlignment.BOTTOM_CENTER
            aling = TextEntityAlignment.BOTTOM_CENTER

            val_num = terreno[i][2][m]
            if val_num >= 1000:
                val_num = f"{round(terreno[i][2][m], 2):,}"
                km = val_num.split(",")[0]
                dm = val_num.split(",")[1]
                num_out = km + "+" + dm
            else:
                num_out = "0+" + f"{round(val_num, 2):06,.2f}"

            msp.add_text(num_out, dxfattribs=dict11).set_placement((abscisa_terreno[m], N3 + (N2 - N3) * 0.5), align=aling)
            msp.add_text(np.round(elevacion_terreno[m] / par_dxf(esc_V=1), 3), dxfattribs=dict11).set_placement((abscisa_terreno[m], N4 + (N3 - N4) * 0.5), align=aling)
            if m not in skip_vertical_index_vertical:
                msp.add_text(np.round(dat_elev[i][m], 3), dxfattribs=dict11).set_placement((abscisa_terreno[m], N5 + (N4 - N5) * 0.5), align=aling)
                msp.add_text(np.round(dat_corte[i][m], 3), dxfattribs=dict11).set_placement((abscisa_terreno[m], N6 + (N5 - N6) * 0.5), align=aling)

        for n in range(len(p_GRILLA_h)):
            msp.add_line(p_GRILLA_h[n][0], p_GRILLA_h[n][1], dxfattribs=dict4)
            msp.add_text(str(p_GRILLA_h[n][1][1] / par_dxf(esc_V=1)), dxfattribs=dict8).set_placement(
                (-10 + abs1, p_GRILLA_h[n][1][1]),
                align=TextEntityAlignment.MIDDLE_CENTER,
            )

        multiplier = 1
        # INDETIFICADOR DE POZO
        for j in range(len(p_LINEA_ID)):
            current_id_string = remove_draw_pz_dict.get(m_ramales[i]["Pozo"][j]) if remove_draw_pz_dict.get(m_ramales[i]["Pozo"][j]) else m_ramales[i]["Pozo"][j]
            # tramos muy cortos modifican el angulo del texto para que sea  vertical y no se choquen
            if j != len(p_LINEA_ID) - 1:
                if m_ramales[i]["L"][j + 1] < 10 or m_ramales[i]["L"][j] < 10:
                    elevacion_indentificador_pozo_temp = multiplier * par_dxf(id_p1=1) * 2.2 if m_ramales[i]["L"][j + 1] < 10 else 0
                    multiplier = multiplier * -1
                    msp.add_circle(
                        center=(
                            p_LINEA_ID[j][0][0],
                            (p_LINEA_ID[j][1][1] + elevacion_indentificador_pozo_temp) + par_dxf(id_p1=1),
                        ),
                        radius=par_dxf(id_p1=1),
                        dxfattribs=dict7,
                    )
                    msp.add_text(current_id_string, dxfattribs=dict6).set_placement(
                        (
                            p_LINEA_ID[j][0][0],
                            (p_LINEA_ID[j][1][1] + elevacion_indentificador_pozo_temp) + par_dxf(id_p1=1),
                        ),
                        align=TextEntityAlignment.MIDDLE_CENTER,
                    )
                    new_line = (
                        p_LINEA_ID[j][1][0],
                        p_LINEA_ID[j][1][1] + elevacion_indentificador_pozo_temp,
                    )
                    msp.add_line(p_LINEA_ID[j][0], new_line, dxfattribs=dict7)

                else:
                    msp.add_circle(
                        center=(
                            p_LINEA_ID[j][0][0],
                            p_LINEA_ID[j][1][1] + par_dxf(id_p1=1),
                        ),
                        radius=par_dxf(id_p1=1),
                        dxfattribs=dict7,
                    )
                    msp.add_text(current_id_string, dxfattribs=dict6).set_placement(
                        (p_LINEA_ID[j][0][0], p_LINEA_ID[j][1][1] + par_dxf(id_p1=1)),
                        align=TextEntityAlignment.MIDDLE_CENTER,
                    )
                    msp.add_line(p_LINEA_ID[j][0], p_LINEA_ID[j][1], dxfattribs=dict7)
            else:
                msp.add_circle(
                    center=(
                        p_LINEA_ID[j][0][0],
                        p_LINEA_ID[j][1][1] + par_dxf(id_p1=1),
                    ),
                    radius=par_dxf(id_p1=1),
                    dxfattribs=dict7,
                )
                msp.add_text(current_id_string, dxfattribs=dict6).set_placement(
                    (p_LINEA_ID[j][0][0], p_LINEA_ID[j][1][1] + par_dxf(id_p1=1)),
                    align=TextEntityAlignment.MIDDLE_CENTER,
                )
                msp.add_line(p_LINEA_ID[j][0], p_LINEA_ID[j][1], dxfattribs=dict7)

            if m_ramales[i]["SALTO"][j] > 0:
                msp.add_text(np.round(m_ramales[i]["HI"][j], 3), dxfattribs=dict11).set_placement(
                    (p_LINEA_ID[j - 1][0][0], N6 + (N5 - N6) * 0.5), align=TextEntityAlignment.TOP_CENTER
                )
                msp.add_text(np.round(m_ramales[i]["ZFF"][j], 3), dxfattribs=dict11).set_placement(
                    (p_LINEA_ID[j - 1][0][0], N5 + (N4 - N5) * 0.5), align=TextEntityAlignment.TOP_CENTER
                )

            if m_ramales[i]["Conexion"][j] is not None:
                # connect_string = ','.join([_.replace(_, remove_draw_pz_dict.get(_)) if remove_draw_pz_dict.get(_) else _   for _ in m_ramales[i]["Conexion"][j].split(',')])
                connect_string = m_ramales[i]["Conexion"][j]
                msp.add_text("CONEXION POZO: " + connect_string, dxfattribs=dict5).set_placement((p_LINEA_ID[j][0][0], N1), align=TextEntityAlignment.BOTTOM_LEFT)

                # # agregar conexiones desde hacía pozos  # lista_conexiones_figs = [_.split(".")[0] for _ in m_ramales[i]["Conexion"][j].split(",")]  # elev_pozo_conexion = m_ramales[i]["ZFF"][j]  # for conexion_fig in lista_conexiones_figs:  #     elev_conexion_fig = m_ramales[conexion_fig]["ZFF"][-1]  #     estado_conexion_figs = m_ramales[conexion_fig]["Estado"][-1]  #     if elev_conexion_fig >= elev_pozo_conexion and estado_conexion_figs in ["nuevo"]:  #         msp.add_blockref("EntrySymbol",   (p_LINEA_ID[j][0][0], elev_conexion_fig * par_dxf(esc_V=1)),    dxfattribs={"xscale": 0.75, "yscale": 0.75, "rotation": 45})

            if m_ramales[i]["Obs"][j] != "":
                # remover metodos constructivos porque ya se pone esto en los datos hidraulicos
                metodos_lista = [
                    "mejorar suelo",
                    "Perforacion Horizontal Dirigida",
                    "Tunel",
                    "Reparacion",
                    "Colector",
                    "Zanja Mano",
                ]
                metodos_lista = [_.lower() for _ in metodos_lista]

                obs_text = m_ramales[i]["Obs"][j].lower()
                for metodo in metodos_lista:
                    obs_text = obs_text.replace(metodo, "")

                pz_list = ["pz-b1", "pz-b2", "pz-b3", "pz-b4", "pz-esp", "pz-s1", "pz-s2", "pz-s3"]
                for pz_item in pz_list:
                    obs_text = obs_text.replace(pz_item, "")

                msp.add_text(obs_text, dxfattribs=dict5).set_placement(
                    (p_LINEA_ID[j][0][0] + par_dxf(heigth_dat_hidraulicos_perfil=1) * 1.5, N1),
                    align=TextEntityAlignment.BOTTOM_LEFT,
                )

            # datos hidraulicos
            if j != len(p_LINEA_ID) - 1:
                if variable_list:
                    variable_list_str = [f"{_}:{m_ramales[i][_][j + 1]}" for _ in variable_list if not np.isnan(m_ramales[i][_][j + 1])]
                    if len(variable_list_str) == 0:
                        variable_list_str = ""
                    else:
                        variable_list_str = f"\\P {str(variable_list_str)}".replace("[", "").replace("]", "").replace("'", "")
                else:
                    variable_list_str = ""

                D_ext = D_ext_string(i, m_ramales)
                # msp.add_mtext(
                #     "L: " + str(m_ramales[i]["L"][j + 1]) + " m \\P" + "D: " + D_ext[j + 1] + " mm" + str(m_ramales[i]["Material"][j + 1]) + "\\P" + str("rug: " + str(m_ramales[i]["Rugosidad"][j + 1]) + "\\P" if m_ramales[i]["Seccion"][j + 1] == "rectangular" else "") + "J: " + str(np.round(float(m_ramales[i]["S"][j + 1]) * 100, 1)) + "% \\P" + "q: " + str(np.round(m_ramales[i]["q_accu"][j + 1], 2)) + " L/s \\P" + "v: " + str(m_ramales[i]["v"][j + 1]) + " m/s \\P" + "h/D: " + str(np.round(float(m_ramales[i]["h/D"][j + 1]) * 100, 1)) + "% \\P \\P" + m_ramales[i]["metodo_constructivo"][
                #         j + 1] + variable_list_str, dxfattribs={"line_spacing_factor": 0.85, "style": "Letra_Arial", "layer": "04_DATOS_GRILLA", "color": 150, "char_height": par_dxf(heigth_dat_hidraulicos_perfil=1) * 1.125, "attachment_point": 5, "width": m_ramales[i]["L"][j + 1], "insert": (p_LINEA_ID[j][0][0] + m_ramales[i]["L"][j + 1] / 2.0, N2 + (N1 - N2) / 2.0,), }, )
                # --------------
                units = " mm" if m_ramales[i]["Seccion"][j + 1] in ["circular"] else " m"
                nomenclatura = "D: " if m_ramales[i]["Seccion"][j + 1] in ["circular"] else "S: "
                d_convert = (
                    D_ext[j + 1] if m_ramales[i]["Seccion"][j + 1] in ["circular"] else "x".join((np.array(D_ext[j + 1].split("x")).astype(float).round(2) / 1000).astype(str))
                )
                # current_string = "L: " + str(m_ramales[i]["L"][j + 1]) + " m \\P" + nomenclatura + d_convert + units + str(m_ramales[i]["Material"][j + 1]) + "\\P" + str("rug: " + str(m_ramales[i]["Rugosidad"][j + 1]) + "\\P" if m_ramales[i]["Seccion"][j + 1] == "rectangular" else "") + "J: " + str(np.round(float(m_ramales[i]["S"][j + 1]) * 100, 1)) + "% \\P" + "q: " + str(np.round(m_ramales[i]["q_accu"][j + 1], 2)) + " L/s \\P" + "v: " + str(m_ramales[i]["v"][j + 1]) + " m/s \\P" + "h/D: " + str(np.round(float(m_ramales[i]["h/D"][j + 1]) * 100, 1)) + "% \\P" + " "
                msp.add_mtext(
                    "L: "
                    + str(m_ramales[i]["L"][j + 1])
                    + " m \\P"
                    + nomenclatura
                    + d_convert
                    + units
                    + str(m_ramales[i]["Material"][j + 1])
                    + "\\P"
                    + str("rug: " + str(m_ramales[i]["Rugosidad"][j + 1]) + "\\P" if m_ramales[i]["Seccion"][j + 1] == "rectangular" else "")
                    + "J: "
                    + str(np.round(float(m_ramales[i]["S"][j + 1]) * 100, 1))
                    + "% \\P"
                    + "q: "
                    + str(np.round(m_ramales[i]["q_accu"][j + 1], 2))
                    + " L/s \\P"
                    + "v: "
                    + str(m_ramales[i]["v"][j + 1])
                    + " m/s \\P"
                    + "h/D: "
                    + str(np.round(float(m_ramales[i]["h/D"][j + 1]) * 100, 1))
                    + "% \\P \\P"
                    + m_ramales[i]["metodo_constructivo"][j + 1]
                    + variable_list_str,
                    dxfattribs={
                        "line_spacing_factor": 0.85,
                        "style": "Letra_Arial",
                        "layer": "04_DATOS_GRILLA",
                        "color": 150,
                        "char_height": par_dxf(heigth_dat_hidraulicos_perfil=1) * 1.125,
                        "attachment_point": 5,
                        "width": m_ramales[i]["L"][j + 1],
                        "insert": (
                            p_LINEA_ID[j][0][0] + m_ramales[i]["L"][j + 1] / 2.0,
                            N2 + (N1 - N2) / 2.0,
                        ),
                    },
                )

                # msp.add_mtext(f'\\A1;E{round(m_ramales[i]['X'][j + 1], 2)}\\PN{round(m_ramales[i]['Y'][j + 1], 2)}',  #                             dxfattribs={  #                                 "style": "Letra_Arial",  #                                 "layer": "04_DATOS_GRILLA",  #                                 "color": 150,  #                                 "char_height":1.6,  #                                 "attachment_point": 1,  # 5 = center point  #                                 "width": m_ramales[i]["L"][j + 1],  #                                 "insert": (p_LINEA_ID[j][0][0] - 1.6, elev_max_1),  #                                 "rotation": 90,  #                                 "line_spacing_factor": 0.70,  #                             },  #                         )

        # interferencias
        if "Interferencia" in list(m_ramales[i].keys()):
            list_of_interferences = np.invert(m_ramales[i]["Interferencia"] == None).nonzero()[0]
            for pos_interference in list_of_interferences:
                interference = m_ramales[i]["Interferencia"][pos_interference]

                abscisa_interferences = m_ramales[i]["LT"][pos_interference] - (m_ramales[i]["L"][pos_interference] - interference["length_on_line_from_center"]) + abs1

                for pos_seccion, seccion_ in enumerate(interference["seccion"]):
                    if seccion_ == "circular":
                        elevation_interference = interference["bottom_elevation"][pos_seccion] + interference["D"][pos_seccion] / 2.0
                        obs_interference = (
                            "D="
                            + str(interference["D"][pos_seccion])
                            + " m \\P"
                            + "elev="
                            + str(np.round(interference["bottom_elevation"][pos_seccion], 3))
                            + "\\P"
                            + "pos="
                            + str(
                                round(
                                    interference["length_on_line_from_center"][pos_seccion],
                                    2,
                                )
                            )
                            + "m"
                            + "\\P"
                            + str(interference["obs"][pos_seccion].replace(",", "\\P"))
                        )
                        diameter_interference = interference["D"][pos_seccion]
                        abscisa_interference = abscisa_interferences[pos_seccion]

                        # plot
                        color = 4 if "remover" in obs_interference else 40
                        dict_attr = dict9.copy()
                        dict_attr["color"] = color

                        # msp.add_circle(center=(abscisa_interference, elevation_interference * par_dxf(esc_V=1)), radius=(diameter_interference / 2.0) * par_dxf(esc_V=1), dxfattribs=dict10)

                        # Major axis is now vertical, with the length scaled by n
                        major_axis_length = (diameter_interference / 2.0) * par_dxf(esc_V=1)
                        minor_axis_length = diameter_interference / 2.0  # This remains the radius of the original circle

                        # Add ellipse
                        msp.add_ellipse(
                            center=(
                                abscisa_interference,
                                elevation_interference * par_dxf(esc_V=1),
                            ),
                            major_axis=(
                                0,
                                major_axis_length,
                            ),  # Major axis endpoint, change in y
                            ratio=minor_axis_length / major_axis_length,  # Ratio of minor to major axis, now valid as it will be <= 1
                            dxfattribs=dict_attr,
                        )

                        # add leader
                        target_point = Vec2(
                            (
                                abscisa_interference,
                                elevation_interference * par_dxf(esc_V=1),
                            )
                        )

                        ml_builder = msp.add_multileader_mtext("EZDXF", dxfattribs=dict_attr)
                        ml_builder.context.mtext.line_spacing_factor = 0.70
                        ml_builder.set_leader_properties(color=color, lineweight=1)
                        ml_builder.set_arrow_properties(size=par_dxf(heigth_dat_hidraulicos_perfil=1))
                        ml_builder.set_content(
                            obs_interference,
                            style="Letra_arial",
                            alignment=mleader.TextAlignment.center,
                        )

                        ml_builder.quick_leader(
                            obs_interference,
                            target=target_point,
                            segment1=Vec2.from_deg_angle(0, 14),
                            connection_type=mleader.VerticalConnection.center_overline,
                        )

                    elif seccion_ == "rectangular":
                        elevation_interference = interference["bottom_elevation"][pos_seccion]
                        obs_interference = (
                            "Seccion="
                            + str(interference["b"][pos_seccion])
                            + "x"
                            + str(interference["h"][pos_seccion])
                            + " m \\P"
                            + "elev="
                            + str(np.round(interference["bottom_elevation"][pos_seccion], 3))
                            + "\\P"
                            + "pos="
                            + str(
                                round(
                                    interference["length_on_line_from_center"][pos_seccion],
                                    2,
                                )
                            )
                            + "m "
                            + "\\P"
                            + str(interference["obs"][pos_seccion].replace(",", "\\P"))
                        )
                        abscisa_interference = abscisa_interferences[pos_seccion]
                        b_interference = interference["b"][pos_seccion]
                        h_interference = interference["h"][pos_seccion]

                        # plot
                        interference_points = [
                            (
                                abscisa_interference - (b_interference / 2.0),
                                elevation_interference * par_dxf(esc_V=1),
                            ),
                            (
                                abscisa_interference + (b_interference / 2.0),
                                elevation_interference * par_dxf(esc_V=1),
                            ),
                            (
                                abscisa_interference + (b_interference / 2.0),
                                (elevation_interference + h_interference) * par_dxf(esc_V=1),
                            ),
                            (
                                abscisa_interference - (b_interference / 2.0),
                                (elevation_interference + h_interference) * par_dxf(esc_V=1),
                            ),
                            (
                                abscisa_interference - (b_interference / 2.0),
                                elevation_interference * par_dxf(esc_V=1),
                            ),
                        ]
                        color = 4 if "remover" in obs_interference else 40
                        dict_attr = dict9.copy()
                        dict_attr["color"] = color
                        msp.add_lwpolyline(interference_points, dxfattribs=dict_attr)

                        # add leader
                        target_point = Vec2(
                            (
                                abscisa_interference,
                                (elevation_interference + h_interference / 2.0) * par_dxf(esc_V=1),
                            )
                        )
                        ml_builder = msp.add_multileader_mtext("EZDXF", dxfattribs=dict_attr)
                        ml_builder.context.mtext.line_spacing_factor = 0.70
                        ml_builder.set_leader_properties(color=color, lineweight=1)
                        ml_builder.set_arrow_properties(size=par_dxf(heigth_dat_hidraulicos_perfil=1))
                        ml_builder.set_content(obs_interference, style="Letra_arial", alignment=mleader.TextAlignment.center)

                        ml_builder.quick_leader(
                            obs_interference,
                            target=target_point,
                            segment1=Vec2.from_deg_angle(0, 14),
                            connection_type=mleader.VerticalConnection.center_overline,
                        )

    # "guardar dxf"
    try:
        extents = appsettings.update_extents(doc)
        zoom.center(doc.modelspace(), extents.center, extents.size)
        doc.saveas(project_name + os.path.sep + "1.dxf")

        # PROFILES BOUNDS
        abscisa_start = np.array(abscisa_lista).T[0]
        abscisa_end = np.array(abscisa_lista).T[1]
        elevacion_start = np.array(elevacion_lista).T[0]
        elevacion_end = np.array(elevacion_lista).T[1]
        info_perfil = pd.DataFrame(
            np.array(
                [
                    abscisa_start,
                    abscisa_end,
                    elevacion_start,
                    elevacion_end,
                    ramal_lista,
                ]
            ).T,
            columns=["abscisa_min", "abscisa_max", "elev_min", "elev_max", "ramal"],
        )


    except Exception as e:
        print("error DXF perfil tuberia")
        print(e)
        pass


def download_street_names(m_ramales, utm_crs, buffer_distance=100, ):
    # get pandas dataframe
    df = m_ramales2df(m_ramales)
    X = df["X"]
    Y = df["Y"]
    # Create a CRS object for the UTM CRS
    utm_crs = CRS(utm_crs)
    # Create a transformer to convert UTM to WGS84 (lat/lon)
    transformer = Transformer.from_crs(utm_crs, CRS("EPSG:4326"), always_xy=True)
    # Get the bounds of the area in UTM
    minx, miny = np.min(X), np.min(Y)
    maxx, maxy = np.max(X), np.max(Y)

    # Add buffer to the bounds (in meters)
    minx, miny = minx - buffer_distance, miny - buffer_distance
    maxx, maxy = maxx + buffer_distance, maxy + buffer_distance
    
    # Convert bounds to lat/lon
    lon1, lat1 = transformer.transform(minx, miny)
    lon2, lat2 = transformer.transform(maxx, maxy)
    
    # Assign correctly for (west, south, east, north)
    west = min(lon1, lon2)
    east = max(lon1, lon2)
    south = min(lat1, lat2)
    north = max(lat1, lat2)
    
    # Print for debug
    print(f"west: {west}, east: {east}, south: {south}, north: {north}")

    # Download the street network
    bbox = (west, south, east, north)  # aka (left, bottom, right, top)
    G = ox.graph_from_bbox(
        bbox,
        network_type="all",          # or "drive", "walk", etc.
    )

    # Convert the graph to GeoDataFrame
    streets_gdf = ox.graph_to_gdfs(G, nodes=False, edges=True)
    # Keep only the necessary columns
    streets_gdf = streets_gdf[["name", "geometry"]]
    # Remove unnamed streets
    streets_gdf = streets_gdf[streets_gdf["name"].notna()]
    # Transform the streets GeoDataFrame to UTM CRS
    streets_gdf = streets_gdf.to_crs(utm_crs)
    streets_gdf = streets_gdf.explode()
    streets_gdf.reset_index(inplace=True)

    return streets_gdf


def compare_line_to_polyline(line, polyline):
    # Convert to numpy arrays
    line = np.array(line)
    polyline = np.array(polyline)

    # Create line vector
    line_vector = line[1] - line[0]
    line_normalized = line_vector / np.linalg.norm(line_vector)

    # Create polyline segments
    polyline_segments = np.diff(polyline, axis=0)

    # Normalize polyline segments
    polyline_normalized = polyline_segments / np.linalg.norm(polyline_segments, axis=1)[:, np.newaxis]

    # Compute cosine similarities
    similarities = np.dot(polyline_normalized, line_normalized)

    # Clip values to handle numerical instability
    similarities = np.clip(similarities, -1.0, 1.0)

    # Take absolute values as we're interested in alignment, not direction
    similarities = np.abs(similarities)

    return similarities


def get_street_names_osmnx(abs1, elevacion_id_pozo_4, fromEPSG, i, m_ramales, msp, streets_gdf):
    max_length = np.max(m_ramales[i]["LT"])
    if max_length > 10:
        coords_ramal = np.array([m_ramales[i]["X"], m_ramales[i]["Y"]]).T
        coords_trans_array = np.array(transform_coordinates(coords_ramal.T[0], coords_ramal.T[1], "EPSG:4326", fromEPSG)).T

        streets_coords = streets_gdf.geometry.get_coordinates(index_parts=True)
        streets_coords_index = streets_coords.index.get_level_values(0).to_numpy()
        streets_coords = np.array([streets_coords["x"].to_numpy(), streets_coords["y"].to_numpy()]).T

        street_reverse_names = []
        for j in range(len(coords_trans_array) - 1):
            line_segment = [coords_ramal[j], coords_ramal[j + 1]]
            dist = np.min(distance.cdist(streets_coords, [np.mean(line_segment, axis=0)]), axis=1)
            index_min = np.argmin(dist)

            row = streets_gdf.loc[streets_coords_index[index_min]]
            street_name = row["name"]
            segmnet_street = np.array(row.geometry.xy).T
            cond_similarity = np.mean(compare_line_to_polyline(line_segment, segmnet_street))

            if cond_similarity > 0.9 or cond_similarity < -0.9:
                street_reverse_names.append(street_name)
            else:
                street_reverse_names.append(None)

        # Add the last point
        street_reverse_names.append(street_reverse_names[-1])
        cond = [_ for _ in street_reverse_names if _]
        if cond:
            street_reverse_names = pd.Series([_ if _ else np.nan for _ in street_reverse_names]).ffill().bfill().to_numpy()
            unique_values, index_unique_values = np.unique(street_reverse_names, return_index=True)
            index_street_names = np.sort(index_unique_values)
            if len(street_reverse_names) - 1 not in index_street_names:
                index_street_names = np.append(index_street_names, len(street_reverse_names) - 1)

            new_elev_max = np.max(elevacion_id_pozo_4) + 0.75 * par_dxf(esc_V=1)
            start_abs = 0
            for pos in range(len(index_street_names) - 1):
                try:
                    end_abs = index_street_names[pos + 1]
                except:
                    end_abs = index_street_names[pos]
                mid_abs = np.mean([m_ramales[i]["LT"][start_abs], m_ramales[i]["LT"][end_abs]])
                msp.add_mtext(
                    street_reverse_names[start_abs].upper(),
                    dxfattribs={
                        "style": "Letra_Arial",
                        "layer": "07_DATOS_CALLES",
                        "color": 6,
                        "char_height": par_dxf(heigth_dat_hidraulicos_perfil=1),
                        "attachment_point": 5,
                        "insert": (abs1 + mid_abs, new_elev_max),
                    },
                )
                start_abs = end_abs


def get_street_names_from_dxf(abs1, elevacion_id_pozo_4, i, m_ramales, msp, locations):
    street_coords = np.array([_["coordinates"] for _ in locations])
    street_names = np.array([_["content"] for _ in locations])
    coords_ramal = np.array([m_ramales[i]["X"], m_ramales[i]["Y"]]).T
    dist = distance.cdist(street_coords, coords_ramal)
    min_dist = np.min(dist, axis=0)
    index_min_dist = np.argmin(dist, axis=0)
    mask_index = min_dist < 15
    street_reverse_names = street_names[index_min_dist]

    # Add the last point
    cond = [_ for _ in street_reverse_names if _]
    if cond:
        street_reverse_names = pd.Series([_ if _ else np.nan for _ in street_reverse_names]).ffill().bfill().to_numpy()
        unique_values, index_unique_values = np.unique(street_reverse_names, return_index=True)
        index_street_names = np.sort(index_unique_values)
        if len(street_reverse_names) - 1 not in index_street_names:
            index_street_names = np.append(index_street_names, len(street_reverse_names) - 1)

        new_elev_max = np.max(elevacion_id_pozo_4) + 0.75 * par_dxf(esc_V=1)
        start_abs = 0
        for pos in range(len(index_street_names) - 1):
            try:
                end_abs = index_street_names[pos + 1]
            except:
                end_abs = index_street_names[pos]
            mid_abs = np.mean([m_ramales[i]["LT"][start_abs], m_ramales[i]["LT"][end_abs]])
            msp.add_mtext(
                street_reverse_names[start_abs].upper(),
                dxfattribs={
                    "style": "Letra_Arial",
                    "layer": "07_DATOS_CALLES",
                    "color": 6,
                    "char_height": par_dxf(heigth_dat_hidraulicos_perfil=1),
                    "attachment_point": 5,
                    "insert": (abs1 + mid_abs, new_elev_max),
                },
            )
            start_abs = end_abs


def rotation(a, b, c):
    if b == "0-0":
        if (a < 45) and (a > -45) and (c):
            return "B_90", -1
        if (a < 45) and (a > -45) and (not c):
            return "B_90", 0

        if (a > -90) and (a < -45) and (c):
            return "B_90", -1
        if (a > -90) and (a < -45) and (not c):
            return "B_90", 0

        if (a > 45) and (a < 90) and (c):
            return "B_90", -1
        if (a > 45) and (a < 90) and (not c):
            return "B_270", 0
        else:
            return "B", 0

    if b == "90-90":
        if (a < 45) and (a > -45) and (c):
            return "B_0", 2
        if (a < 45) and (a > -45) and (not c):
            return "B_0", 0

        if (a > -90) and (a < -45) and (c):
            return "B_0", 2
        if (a > -90) and (a < -45) and (not c):
            return "B_180", 0

        if (a > 45) and (a < 90) and (c):
            return "B_0", 2
        if (a > 45) and (a < 90) and (not c):
            return "B_0", 0
        else:
            return "B", 0

    if b == "180-180":
        if (a < 45) and (a > -45) and (c):
            return "B_0", 2
        if (a < 45) and (a > -45) and (not c):
            return "B_90", 0

        if (a > -90) and (a < -45) and (c):
            return "B_0", 2
        if (a > -90) and (a < -45) and (not c):
            return "B_270", 0

        if (a > 45) and (a < 90) and (c):
            return "B_0", 2
        if (a > 45) and (a < 90) and (not c):
            return "B_90", 0
        else:
            return "B", 0

    if b == "270-270":
        if (a < 45) and (a > -45) and (c):
            return "B_90", -1
        if (a < 45) and (a > -45) and (not c):
            return "B_0", 0

        if (a > -90) and (a < -45) and (c):
            return "B_90", -1
        if (a > -90) and (a < -45) and (not c):
            return "B_0", 0

        if (a > 45) and (a < 90) and (c):
            return "B_90", -1
        if (a > 45) and (a < 90) and (not c):
            return "B_180", 0
        else:
            return "B", 0

    if b == "0-90" or b == "0-180" or b == "90-180":
        if c:
            return "B_90", 1
        if not c:
            return "B_0", 0

    if b == "0-270":
        if c:
            return "B_90", -1
        if not c:
            return "B_90", 0

    if b == "90-0" or b == "90-270":
        if c:
            return "B_0", 3
        if not c:
            return "B_90", 0

    if b == "180-0":
        if c:
            return "B_0", 3
        if not c:
            return "B_180", 0

    if b == "180-90":
        if c:
            return "B_0", 2
        if not c:
            return "B_180", 0

    if b == "180-270":
        if c:
            return "B_0", 2
        if not c:
            return "B_90", 0

    if b == "270-0":
        if c:
            return "B_0", 3
        if not c:
            return "B_270", 0

    if b == "270-90":
        if c:
            return "B_90", 1
        if not c:
            return "B_270", 0

    if b == "270-180":
        if c:
            return "B_90", -1
        if not c:
            return "B_270", 0

    else:
        return "B", 0


def move_point(x, y, distance, angle_degrees):
    # Convert angle from degrees to radians
    angle_radians = math.radians(angle_degrees)

    # Calculate the new coordinates
    new_x = x + distance * math.cos(angle_radians)
    new_y = y + distance * math.sin(angle_radians)

    return new_x, new_y


def estimate_text_size(text, text_height):
    # Estimate average character width as 60% of text height
    avg_char_width = text_height * 0.556

    # Split text into lines
    lines = text.split("\\P")

    # Estimate width based on the longest line
    max_line_length = max(len(line) for line in lines)
    estimated_width = max_line_length * avg_char_width

    # Estimate height based on number of lines
    estimated_height = len(lines) * text_height + (len(lines) - 1) * text_height * 0.75

    return estimated_width, estimated_height


def get_exact_text_dimensions(text, style_name, char_height, width=None):
    # Create a temporary MText entity
    mtext = MText()
    mtext.text = text
    mtext.dxf.char_height = char_height
    mtext.dxf.width = width if width else 0  # 0 means no width restriction
    mtext.dxf.style = style_name
    # mtext.dxf.attachment_point = TextEntityAlignment.TOP_LEFT

    # Estimate the extents
    extents = estimate_mtext_extents(mtext)

    return extents[0], extents[1]


def get_extent_from_coords(x_coords, y_coords):
    x_min, x_max = np.min(x_coords), np.max(x_coords)
    y_min, y_max = np.min(y_coords), np.max(y_coords)

    return (x_min, y_min, x_max, y_max)


def calculate_layout_scale(x_coords, y_coords, paper_size=(841, 594), margins=(25, 25)):
    # Get extent from coordinates
    extent = get_extent_from_coords(x_coords, y_coords)

    # Unpack extent and paper size
    x_min, y_min, x_max, y_max = extent
    paper_width, paper_height = paper_size

    # Calculate drawing dimensions
    drawing_width = x_max - x_min
    drawing_height = y_max - y_min

    # Calculate available space on paper
    available_width = paper_width - 2 * margins[0]
    available_height = paper_height - 2 * margins[1]

    # Calculate scale factors for width and height
    scale_width = drawing_width / available_width
    scale_height = drawing_height / available_height

    # Use the larger scale to ensure the drawing fits
    scale = max(scale_width, scale_height)

    # Round up to the nearest whole number
    layout_scale = round(scale, 1)

    return layout_scale, extent


def cad_plane_out_general(m_ramales, ramal, project_name, d_min=None, plot_existente=False):
    # "CREAR MODELO EN DXF"
    doc = ezdxf.new("R2000", setup=True)
    msp = doc.modelspace()
    doc.styles.new("Letra_Arial", dxfattribs={"font": "ARIALN.TTF"})
    appsettings.show_lineweight(doc=doc, state=True)
    doc.units = ezdxf.units.M

    dict2 = {
        "layer": "01_POZO",
        "linetype": "CONTINUOUS",
        "color": 11,
        "lineweight": 30,
        "ltscale": 5,
    }
    # "crear bloques para insertar"
    radio, h_flecha, b_flecha = 1.4, 2.5, 0.65
    d1 = 3.5
    d2 = 10
    d3 = 0.2
    letra = 2

    if not plot_existente:
        # get scale
        x_coords_total = np.concatenate([_["X"] for _ in m_ramales.values() if "nuevo" in _["Estado"]])
        y_coords_total = np.concatenate([_["Y"] for _ in m_ramales.values() if "nuevo" in _["Estado"]])
    else:
        x_coords_total = np.concatenate([_["X"] for _ in m_ramales.values()])
        y_coords_total = np.concatenate([_["Y"] for _ in m_ramales.values()])

    # A1 sheet size in meters
    a1_width_m = 0.636 * 1000
    a1_height_m = 0.569 * 1000
    paper_size_A1 = (a1_width_m, a1_height_m)  # A1 paper size in mm
    margins = (25, 25)
    scale, extent = calculate_layout_scale(x_coords_total, y_coords_total, paper_size_A1, margins)

    min_dist = max(radio * scale * 3, d2 * scale)

    B_SAN = doc.blocks.new(name="B_SAN")
    B_SAN.add_circle(center=(0, 0), radius=radio, dxfattribs=dict2)
    hatch = B_SAN.add_hatch(color=LINECOLOR["sanitario"])
    hatch.paths.add_polyline_path(
        [
            (-h_flecha - radio, 0),
            (-h_flecha - radio, -b_flecha),
            (0 - radio, 0),
            (-h_flecha - radio, b_flecha),
        ],
        is_closed=1,
    )

    B_PLU = doc.blocks.new(name="B_PLU")
    B_PLU.add_circle(center=(0, 0), radius=radio, dxfattribs=dict2)
    hatch = B_PLU.add_hatch(color=LINECOLOR["pluvial"])
    hatch.paths.add_polyline_path(
        [
            (-h_flecha - radio, 0),
            (-h_flecha - radio, -b_flecha),
            (0 - radio, 0),
            (-h_flecha - radio, b_flecha),
        ],
        is_closed=1,
    )

    B_COMB = doc.blocks.new(name="B_COMB")
    B_COMB.add_circle(center=(0, 0), radius=radio, dxfattribs=dict2)
    hatch = B_COMB.add_hatch(color=LINECOLOR["combinado"])
    hatch.paths.add_polyline_path(
        [
            (-h_flecha - radio, 0),
            (-h_flecha - radio, -b_flecha),
            (0 - radio, 0),
            (-h_flecha - radio, b_flecha),
        ],
        is_closed=1,
    )

    B_POZO = doc.blocks.new(name="B_POZO")
    B_POZO.add_circle(center=(0, 0), radius=radio, dxfattribs=dict2)
    B_POZO.add_lwpolyline([(-1.30 * radio, -radio), (-1.30 * radio, radio)], dxfattribs=dict2)

    # bloques de pozos
    B_0 = doc.blocks.new(name="B_0")
    B_0.add_lwpolyline([(0, 0), (d1, d1 - d3), (d2, d1 - d3)], dxfattribs=dict2)
    B_0.add_attdef(
        "POZO",
        (d1, d1),
        dxfattribs={"height": letra, "color": 4, "style": "Letra_Arial"},
    )
    B_0.add_attdef(
        "OBSERVACION",
        (d1, d1 + letra + 2 * d3),
        dxfattribs={"height": letra, "color": 30, "style": "Letra_Arial"},
    )

    B_90 = doc.blocks.new(name="B_90")
    B_90.add_lwpolyline([(0, 0), (-d1, d1 - d3), (-d2, d1 - d3)], dxfattribs=dict2)
    B_90.add_attdef(
        "POZO",
        (-d2, d1),
        dxfattribs={"height": letra, "color": 4, "style": "Letra_Arial"},
    )
    B_90.add_attdef(
        "OBSERVACION",
        (-d2, d1 + letra + 2 * d3),
        dxfattribs={"height": letra, "color": 30, "style": "Letra_Arial"},
    )

    B_180 = doc.blocks.new(name="B_180")
    B_180.add_lwpolyline([(0, 0), (-d1, -d1 + d3), (-d2, -d1 + d3)], dxfattribs=dict2)
    B_180.add_attdef(
        "OBSERVACION",
        (-d2, -d1 + 2 * d3 + letra + letra),
        dxfattribs={"height": letra, "color": 30, "style": "Letra_Arial"},
    )
    B_180.add_attdef(
        "POZO",
        (-d2, -d1 - letra),
        dxfattribs={"height": letra, "color": 4, "style": "Letra_Arial"},
    )

    B_270 = doc.blocks.new(name="B_270")
    B_270.add_lwpolyline([(0, 0), (d1, -d1 + d3), (d2, -d1 + d3)], dxfattribs=dict2)
    B_270.add_attdef(
        "OBSERVACION",
        (d1, -d1 + letra * 0.25),
        dxfattribs={"height": letra, "color": 30, "style": "Letra_Arial"},
    )
    B_270.add_attdef(
        "POZO",
        (d1, -d1 - letra),
        dxfattribs={"height": letra, "color": 4, "style": "Letra_Arial"},
    )

    B = doc.blocks.new(name="B")

    radio, h_flecha, b_flecha, letra = (
        1.4 * scale,
        2.5 * scale,
        0.65 * scale,
        letra * scale,
    )
    for i in ramal.values():
        filtro = seccion_str2float(m_ramales[i]["D_ext"]) >= d_min
        if len(m_ramales[i]["Ramal"][filtro]) > 0:
            if not plot_existente:
                if "existente" in m_ramales[i]["Estado"]:
                    continue

            # propiedades de lineas y texto
            if m_ramales[i]["Tipo"][1]:
                a0 = LAYER[m_ramales[i]["Tipo"][1].lower()]
                a1 = LINECOLOR[m_ramales[i]["Tipo"][1].lower()]
                a2 = LINETYPES[m_ramales[i]["Tipo"][1].lower()]
                a3 = LINEWEIGHT[m_ramales[i]["Tipo"][1].lower()]
                bloque = BLOQUE_POZO[m_ramales[i]["Tipo"][1].lower()]
            else:
                a0 = LAYER["sanitario"]
                a1 = LINECOLOR["sanitario"]
                a2 = LINETYPES["sanitario"]
                a3 = LINEWEIGHT["sanitario"]
                bloque = BLOQUE_POZO["sanitario"]
            dict1 = {
                "layer": a0,
                "color": a1,
                "linetype": a2,
                "lineweight": a3,
                "ltscale": 2.5,
            }

            # PREPARAR DATOS
            coordX, coordY = m_ramales[i]["X"], m_ramales[i]["Y"]
            ang_v, cuadrante = ang_coords(coordX, coordY)
            ang_v = np.insert(ang_v, -1, ang_v[-1])
            L_v = np.round(m_ramales[i]["L"][1:], 3)
            cuadrantes = cuadrante_mat(cuadrante)

            original_rot = ang_v[0]
            # Determine quadrant and adjust rotations
            if 0 <= original_rot < 90:
                leader_rot = original_rot + 90 - 180

            elif 90 <= original_rot < 180:
                leader_rot = original_rot - 90

            elif 180 <= original_rot < 270:
                leader_rot = original_rot - 90 - 180

            else:  # 270 <= original_rot < 360
                leader_rot = original_rot - 90

            if isinstance(cuadrantes[0], int):
                cuadrante1 = [cuadrantes[0], cuadrantes[1]]
                cuadrante_X = cuadrante1[0]
                cuadrante_Y = cuadrante1[1]
                cuadrante = [cuadrante]
            else:
                cuadrante1 = list(zip(*cuadrantes))
                cuadrante_X = cuadrante1[0]
                cuadrante_Y = cuadrante1[1]

            coordX1 = coordX[0:-1] + np.abs((radio * np.cos(np.radians(ang_v[0:-1])))) * cuadrante_X
            coordX2 = coordX[0:-1] + np.abs(((L_v - radio - h_flecha) * np.cos(np.radians(ang_v[0:-1])))) * cuadrante_X

            coordY1 = coordY[0:-1] + np.abs((radio * np.sin(np.radians(ang_v[0:-1])))) * cuadrante_Y
            coordY2 = coordY[0:-1] + np.abs(((L_v - radio - h_flecha) * np.sin(np.radians(ang_v[0:-1])))) * cuadrante_Y

            # PREPARACION DE EJES
            tuberia1 = list(zip(coordX1, coordY1))
            tuberia2 = list(zip(coordX2, coordY2))
            tuberia = list(zip(tuberia1, tuberia2))

            # plot line given state new or existing
            [msp.add_line(tuberia[j][0], tuberia[j][1], dxfattribs=dict1) for j in range(len(tuberia))]

            x_flechas, y_flechas, ang_flechas = coordX[1:], coordY[1:], ang_v[0:-1]
            # plot hatch for pozo given state existing

            [
                msp.add_auto_blockref(
                    bloque,
                    (x_flechas[j], y_flechas[j]),
                    {},
                    dxfattribs={"xscale": scale, "yscale": scale, "rotation": ang_v[j]},
                )
                for j in range(len(x_flechas))
            ]
            msp.add_auto_blockref(
                "B_POZO",
                (coordX[0], coordY[0]),
                {},
                dxfattribs={"xscale": scale, "yscale": scale, "rotation": ang_v[0]},
            )

            for j in range(len(x_flechas)):
                msp.add_auto_blockref(
                    bloque,
                    (x_flechas[j], y_flechas[j]),
                    {},
                    dxfattribs={"xscale": scale, "yscale": scale, "rotation": ang_v[j]},
                )

            msp.add_auto_blockref(
                "B_90" if (cuadrante[0] == 0) or (cuadrante[0] == 270) else "B_0",
                (coordX[0], coordY[0]),
                values={
                    "OBSERVACION": str(m_ramales[i]["Obs"][0]),
                    "POZO": str(m_ramales[i]["Pozo"][0]),
                },
                dxfattribs={"xscale": scale, "yscale": scale, "rotation": leader_rot},
            )

            if not m_ramales[i]["Conexion"][-1]:
                msp.add_auto_blockref(
                    "B_0" if (cuadrante[-1] == 0) or (cuadrante[-1] == 270) else "B_90",
                    (coordX[-1], coordY[-1]),
                    values={
                        "OBSERVACION": str(m_ramales[i]["Obs"][-1]),
                        "POZO": str(m_ramales[i]["Pozo"][-1]),
                    },
                    dxfattribs={"xscale": scale, "yscale": scale, "rotation": 0},
                )

            if len(m_ramales[i]["Pozo"]) > 2:
                dif_ang = np.insert(ang_v[1:] - ang_v[0:-1], 0, 0)
                cuadrante1 = [str(cuadrante[i]) + "-" + str(cuadrante[i + 1]) for i in range(len(cuadrante) - 1)]
                cuadrante1 = np.insert(cuadrante1, 0, cuadrante1[0])
                cuadrante1 = np.insert(cuadrante1, -1, cuadrante1[-1])
                rotation1 = np.vectorize(rotation)
                bloques = rotation1(dif_ang, cuadrante1, m_ramales[i]["Conexion"])

                for k in range(1, len(bloques[0]) - 1):
                    if m_ramales[i]["L"][k] >= min_dist:
                        msp.add_auto_blockref(
                            str(bloques[0][k]),
                            (coordX[k], coordY[k]),
                            values={
                                "OBSERVACION": str(m_ramales[i]["Obs"][k]),
                                "POZO": str(m_ramales[i]["Pozo"][k]),
                            },
                            dxfattribs={
                                "xscale": scale,
                                "yscale": scale,
                                "rotation": leader_rot,
                            },
                        )

    # "guardar dxf"
    extents = appsettings.update_extents(doc)
    zoom.center(doc.modelspace(), extents.center, extents.size)
    doc.saveas("PROYECTO_" + project_name + os.path.sep + "01_DXF" + os.path.sep + "01_OUT" + os.path.sep + "00_PLANTA_GENERAL" + str(project_name) + ".dxf")

    # guardar escala
    text_content = str(scale + 0.05)
    # Specify the path and name of the file
    file_path = "PROYECTO_" + project_name + os.path.sep + "01_DXF" + os.path.sep + "01_OUT" + os.path.sep + "00_PLANTA_GENERAL" + str(project_name) + "_scale.txt"
    # Open the file in write mode and write the string to it
    with open(file_path, "w") as file:
        file.write(text_content)


def add_canal_pozo(doc, radio, separacion_radio_canal, h_flecha=None, b_flecha=None, start=None):
    """
    Create a 'pozo_inicio_canal_pozo' block definition in the specified document.
    The blue filled circle has a radius of 1/3 of the specified radius.
    The line is positioned one radius away from the circle's center and has a length equal to the specified radius.

    :param doc: ezdxf document
    :param radius: float, radius of the main circle (default: 0.5)
    :return: Block definition
    """
    # Add blue filled circle (hatch) with 1/2.5 radius
    small_radius = radio / 2.5

    dict_canal = {
        "layer": "01_PLUVIAL_CANAL_ABIERTO",
        "linetype": "PHANTOM2",
        "color": 5,
        "lineweight": 35,
    }

    if start:
        block_name = "B_POZO_CANAL"
        if block_name in doc.blocks:
            return doc.blocks[block_name]

        block = doc.blocks.new(name=block_name)

        hatch = block.add_hatch(
            color=5,
            dxfattribs={
                "layer": "01_PLUVIAL_CANAL_ABIERTO",
                "linetype": "PHANTOM2",
                "lineweight": 35,
                "elevation": (0, 0, 0),
                "extrusion": (0, 0, 1),
                "pattern_name": "SOLID",
                "solid_fill": 1,
                "associative": 0,
                "hatch_style": 0,
                "pattern_type": 1,
            },
        )
        hatch.paths.add_edge_path().add_ellipse(
            center=(0, 0),
            major_axis=(small_radius, 0),
            ratio=1.0,
            start_angle=0.0,
            end_angle=360.0,
            ccw=True,
        )

        # Add main circle outline
        block.add_circle(
            center=(0, 0),
            radius=small_radius,
            dxfattribs={
                "layer": "01_PLUVIAL_CANAL_ABIERTO",
                "linetype": "PHANTOM2",
                "color": 5,
                "lineweight": 35,
            },
        )

        # Add line
        line_start_x = small_radius * separacion_radio_canal  # One radius away from the circle's center
        line_length = radio
        block.add_line(
            start=(line_start_x, -line_length / 2, 0),
            end=(line_start_x, line_length / 2, 0),
            dxfattribs=dict_canal,
        )

        block.add_attdef(
            tag="pz_name",
            dxfattribs={
                "insert": (0, 0),  # Position doesn't matter since it's invisible
                "height": 0,  # Zero height makes it invisible
                "invisible": True,  # This makes it invisible in the drawing
            },
        )

    else:
        block = doc.blocks.new(name="B_PLU_CANAL")
        hatch_circle = block.add_hatch(
            color=5,
            dxfattribs={
                "layer": "01_PLUVIAL_CANAL_ABIERTO",
                "linetype": "PHANTOM2",
                "lineweight": 35,
                "elevation": (0, 0, 0),
                "extrusion": (0, 0, 1),
                "pattern_name": "SOLID",
                "solid_fill": 1,
                "associative": 0,
                "hatch_style": 0,
                "pattern_type": 1,
            },
        )
        hatch_circle.paths.add_edge_path().add_ellipse(
            center=(0, 0),
            major_axis=(small_radius, 0),
            ratio=1.0,
            start_angle=0.0,
            end_angle=360.0,
            ccw=True,
        )

        block.add_circle(center=(0, 0), radius=small_radius, dxfattribs=dict_canal)
        hatch = block.add_hatch(color=LINECOLOR["pluvial"])
        hatch.paths.add_polyline_path(
            [
                (-h_flecha - small_radius, 0),
                (-h_flecha - small_radius, -b_flecha),
                (-small_radius, 0),
                (-h_flecha - small_radius, b_flecha),
            ],
            is_closed=1,
        )
        block.add_line(start=(-h_flecha - small_radius, 0, 0), end=(-radio - h_flecha, 0, 0), dxfattribs=dict_canal)

        block.add_attdef(
            tag="pz_name",
            dxfattribs={
                "insert": (0, 0),  # Position doesn't matter since it's invisible
                "height": 0,  # Zero height makes it invisible
                "invisible": True,  # This makes it invisible in the drawing
            },
        )

    return block


def decide_pozo_to_keep(df, total_pos):
    pos_arr = df["Pozo"].str.split(".", expand=True).iloc[:, 1].astype(int)

    es_inicial = df["Pozo"].str.endswith(".0")
    es_final = pos_arr == total_pos

    # Caso 1: Un pozo inicial y todos los demás finales
    if es_inicial.sum() == 1 and es_final.sum() == len(es_final) - 1:
        return df[es_inicial]["Pozo"].item()

    # Caso 2: Un tramo intermedio y el resto son iniciales o finales
    es_intermedio = ~(es_inicial | es_final)
    if es_intermedio.sum() == 1:
        return df[es_intermedio]["Pozo"].item()

    # Caso 3: Todos son pozos iniciales o todos son finales
    if es_inicial.all() or es_final.all():
        # Para cada tramo, ver si el pozo está al inicio o al final
        # y usar ZFI o ZFF según corresponda
        elevaciones = []
        for idx, row in df.iterrows():
            if idx in [""]:
                elevaciones.append(row["ZFI"])
            else:
                inicio, fin = idx.split("-")  # el índice es el Tramo (inicio-fin)
                if row["Pozo"] == inicio:
                    elevaciones.append(row["ZFI"])
                else:
                    elevaciones.append(row["ZFF"])

        # Tomar el pozo con la menor elevación
        idx_min = np.argmin(elevaciones)
        return df["Pozo"][idx_min]

    # Caso 4: Buscar pozo repetido en los tramos del índice
    pozos_en_tramos = set()
    for tramo in df.index:
        if tramo in [""]:
            continue
        inicio, fin = tramo.split("-")
        if fin in pozos_en_tramos:  # Si el pozo final ya lo habíamos visto
            return fin  # Este es el pozo repetido
        pozos_en_tramos.add(inicio)
        pozos_en_tramos.add(fin)

    # Caso 5: Pozo con mayor caudal acumulado
    idx_max_q = np.argmax(df["q_accu"].values)
    if (df["q_accu"].values == df["q_accu"].values[idx_max_q]).sum() == 1:
        return df["Pozo"].iloc[idx_max_q]

    # Caso 6: Pozo con menor elevación
    idx_min_z = np.argmin(df["ZFF"].values)
    if (df["ZFF"].values == df["ZFF"].values[idx_min_z]).sum() == 1:
        return df["Pozo"].iloc[idx_min_z]

    # Caso 7: Pozo con mayor longitud de tubería
    idx_max_lt = np.argmax(df["LT"].values)
    return df["Pozo"].iloc[idx_max_lt]  # Siempre retornará un valor


def encontrar_pozos_identicos(m_ramales, df, tolerancia=0.01, return_replace_dict=None):
    """
    Encuentra pozos idénticos o muy cercanos en un DataFrame basado en sus coordenadas XYZ.

    Esta función utiliza un árbol KD para identificar eficientemente puntos cercanos
    y luego aplica lógica adicional para determinar qué pozos mantener y cuáles eliminar
    basándose en su estado (existente o nuevo) y su caudal acumulado (q_accu).

    Args:
    df (pandas.DataFrame): DataFrame con columnas 'X', 'Y', 'Z', 'Pozo', 'Estado', y 'q_accu'.
    tolerancia (float): Distancia máxima para considerar dos pozos como idénticos. Por defecto es 0.01.

    Returns:
    dict: Un diccionario donde las claves son los pozos a mantener y los valores son listas de pozos a eliminar.
    """

    # Crear un árbol KD con las coordenadas XYZ para búsqueda eficiente de vecinos
    tree = cKDTree(df[["X", "Y", "Z"]])

    # El parámetro workers=-1 utiliza todos los núcleos disponibles para paralelizar la búsqueda
    pares = tree.query_ball_point(df[["X", "Y", "Z"]], r=tolerancia, workers=-1)
    remove_list, keep_list = [], []
    # Diccionario para almacenar los resultados: {pozo_a_mantener: [pozos_a_eliminar]}
    keep_draw_pz = {}

    # Iterar sobre cada grupo de pozos cercanos
    for pos, grupo in enumerate(pares):
        # Solo procesar grupos con más de un pozo
        if len(grupo) > 1:
            grupo = np.array(grupo)
            # Crear un sub-DataFrame con los pozos del grupo actual
            new_df = df.iloc[grupo]
            pz_list = new_df["Pozo"].to_numpy()

            cond = [_ for _, __ in enumerate(pz_list) if __.endswith(".0")]
            if len(cond) > 0:
                grupo[cond] += 1
                # Crear un sub-DataFrame con los pozos del grupo actual
                mod_df = df.iloc[grupo]
                cols = new_df.columns.to_numpy()
                q_accu_col = np.where(cols == "q_accu")[0].item()
                ZFF_col = np.where(cols == "ZFF")[0].item()
                ZFI_col = np.where(cols == "ZFI")[0].item()
                new_df.iloc[cond, q_accu_col] = mod_df.iloc[cond]["q_accu"]
                new_df.iloc[cond, ZFF_col] = mod_df.iloc[cond]["ZFF"]
                new_df.iloc[cond, ZFI_col] = mod_df.iloc[cond]["ZFI"]

            total_pos = [m_ramales[_]["Tramo"].size - 1 for _ in new_df["Ramal"].to_list()]
            keep_pz = decide_pozo_to_keep(new_df, total_pos)

            remove_index = np.where(pz_list != keep_pz)[0]
            remove_pz = pz_list[remove_index]
            remove_list.append(remove_pz)
            keep_list.append(keep_pz)
            keep_draw_pz[keep_pz] = remove_pz

    if return_replace_dict:
        return keep_draw_pz
    else:
        return keep_list, remove_list


def reverse_dictionary(original_dict):
    """
    Reverses a dictionary where values are lists.
    For a dictionary like {x: [y, z]}, it returns {y: x, z: x}.
    Args:
    original_dict (dict): The original dictionary to reverse.
    Returns:
    dict: The reversed dictionary.
    """
    reversed_dict = {}
    for key, value_list in original_dict.items():
        for value in value_list:
            reversed_dict[value] = key
    return reversed_dict


# -----------------------------------------------------------


# def create_kdtree(msp):
#     lines = list(msp.query("LINE"))
#     blocks = list(msp.query("INSERT"))
#
#     points = np.array(
#         [(obj.dxf.start.x, obj.dxf.start.y) for obj in lines] + [(obj.dxf.end.x, obj.dxf.end.y) for obj in lines] + [(obj.dxf.insert.x, obj.dxf.insert.y) for obj in blocks]
#     )
#
#     tree = KDTree(points)
#
#     return tree, lines, blocks
#
#
# def get_nearby_objects(tree, point, distance, lines, blocks):
#     indices = tree.query_ball_point(point, distance)
#
#     nearby_lines = set()
#     nearby_blocks = set()
#
#     for idx in indices:
#         if idx < len(lines) * 2:
#             nearby_lines.add(lines[idx // 2])
#         else:
#             nearby_blocks.add(blocks[idx - len(lines) * 2])
#
#     return list(nearby_lines), list(nearby_blocks)
#
#
# def get_transformed_block_corners_old(block_ref, block_def):
#     """
#     Get the transformed corners of a block reference based on its insertion point, scaling, and rotation.
#     Args:
#         block_ref: The block reference entity.
#         block_def: The block definition.
#     Returns:
#         A list of transformed corner points (Vec3 objects).
#     """
#
#     bbox = ezdxf.bbox.extents([_ for _ in ezdxf.disassemble.recursive_decompose(block_def) if _.dxf.dxftype == "ATTDEF"])
#     if not bbox.has_data:
#         return [Vec3(0, 0, 0), Vec3(1, 0, 0), Vec3(1, 1, 0), Vec3(0, 1, 0)]
#     # Get corners in local block coordinate system
#     local_corners = [Vec3(bbox.extmin.x, bbox.extmin.y, 0), Vec3(bbox.extmax.x, bbox.extmin.y, 0), Vec3(bbox.extmax.x, bbox.extmax.y, 0), Vec3(bbox.extmin.x, bbox.extmax.y, 0)]
#     # Create transformation matrix
#     transform = Matrix44.chain(
#         Matrix44.scale(block_ref.dxf.xscale, block_ref.dxf.yscale, 1),
#         Matrix44.z_rotate(block_ref.dxf.rotation * (3.14159265 / 180.0)),
#         Matrix44.translate(block_ref.dxf.insert.x, block_ref.dxf.insert.y, 0),
#     )
#     # Apply transformation to each corner
#     return [transform.transform(corner) for corner in local_corners]
#
#
# def get_transformed_block_corners(block_ref, block_def):
#     """
#     Get the transformed corners of a block reference based on its insertion point, scaling, and rotation.
#     Args:
#         block_ref: The block reference entity.
#         block_def: The block definition.
#     Returns:
#         A list of transformed corner points (Vec3 objects).
#     """
#     # Include all drawable entities (LINE, CIRCLE, POLYLINE, etc.)
#     entities = list(ezdxf.disassemble.recursive_decompose(block_def))
#     if not entities:
#         # Fallback to a small square if no entities are found
#         return [Vec3(0, 0, 0), Vec3(1, 0, 0), Vec3(1, 1, 0), Vec3(0, 1, 0)]
#
#     bbox = ezdxf.bbox.extents(entities)
#     if not bbox.has_data:
#         return [Vec3(0, 0, 0), Vec3(1, 0, 0), Vec3(1, 1, 0), Vec3(0, 1, 0)]
#
#     # Define corners in local block coordinate system
#     local_corners = [
#         Vec3(bbox.extmin.x, bbox.extmin.y, 0),
#         Vec3(bbox.extmax.x, bbox.extmin.y, 0),
#         Vec3(bbox.extmax.x, bbox.extmax.y, 0),
#         Vec3(bbox.extmin.x, bbox.extmax.y, 0),
#     ]
#
#     # Create transformation matrix
#     transform = Matrix44.chain(
#         Matrix44.scale(block_ref.dxf.xscale, block_ref.dxf.yscale, 1),
#         Matrix44.z_rotate(block_ref.dxf.rotation * (3.14159265 / 180.0)),
#         Matrix44.translate(block_ref.dxf.insert.x, block_ref.dxf.insert.y, 0),
#     )
#
#     # Apply transformation to each corner
#     return [transform.transform(corner) for corner in local_corners]
#
# def create_line_buffer_with_shapely(line, buffer_distance):
#     """
#     Create a buffer around a line using Shapely.
#     Args:
#         line: The line entity.
#         buffer_distance (float): The distance to buffer around the line.
#     Returns:
#         A Shapely polygon representing the buffered area around the line.
#     """
#     line_geom = LineString([line.dxf.start, line.dxf.end])
#     return line_geom.buffer(buffer_distance)
#
#
# def rotate_point_block_att(point, angle, origin=(0, 0)):
#     """Rotate a point around a given origin."""
#     ox, oy = origin
#     px, py = point
#     qx = ox + math.cos(angle) * (px - ox) - math.sin(angle) * (py - oy)
#     qy = oy + math.sin(angle) * (px - ox) + math.cos(angle) * (py - oy)
#     return qx, qy
#
# def check_intersection(block_ref, nearby_lines, nearby_blocks, buffer_distance, shrink_distance=0.0):
#     """
#     Check if the block intersects with nearby lines or blocks, logging details.
#
#     Returns:
#         Tuple (bool, bool, list, list): (line_intersection, block_intersection, intersecting_lines, intersecting_blocks)
#     """
#     try:
#         block_def = block_ref.doc.blocks[block_ref.dxf.name]
#         transformed_corners = get_transformed_block_corners(block_ref, block_def)
#
#         if len(transformed_corners) < 3:
#             print(f"Warning: Block {block_ref.dxf.name} has insufficient corners")
#             return False, False, [], []
#
#         block_polygon = Polygon([(p.x, p.y) for p in transformed_corners])
#         if not block_polygon.is_valid:
#             print(f"Warning: Invalid polygon for {block_ref.dxf.name}, attempting fix")
#             block_polygon = block_polygon.buffer(0)
#         if block_polygon.is_empty:
#             print(f"Warning: Empty block polygon for {block_ref.dxf.name}")
#             return False, False, [], []
#
#         # Log bounding box size
#         min_x, min_y, max_x, max_y = block_polygon.bounds
#         print(f"Block {block_ref.dxf.name} bounds: ({min_x:.3f}, {min_y:.3f}) to ({max_x:.3f}, {max_y:.3f})")
#         print(f"  Bounding box size: {max_x - min_x:.3f} x {max_y - min_y:.3f}")
#
#         shrunk_block_polygon = block_polygon
#         if shrink_distance > 0:
#             shrunk_block_polygon = block_polygon.buffer(-shrink_distance)
#             if shrunk_block_polygon.is_empty or not shrunk_block_polygon.is_valid:
#                 print(f"Warning: Shrinking created empty/invalid polygon for {block_ref.dxf.name}")
#                 shrunk_block_polygon = block_polygon
#
#         line_intersection = False
#         block_intersection = False
#         intersecting_lines = []
#         intersecting_blocks = []
#
#         # Check lines
#         for line in nearby_lines:
#             try:
#                 line_buffer = create_line_buffer_with_shapely(line, buffer_distance)
#                 if line_buffer is None or line_buffer.is_empty:
#                     print(f"Warning: Empty buffer for line from ({line.dxf.start.x:.3f}, {line.dxf.start.y:.3f}) "
#                           f"to ({line.dxf.end.x:.3f}, {line.dxf.end.y:.3f})")
#                     continue
#                 if shrunk_block_polygon.intersects(line_buffer):
#                     line_intersection = True
#                     intersecting_lines.append(line)
#             except Exception as e:
#                 print(f"Error checking line from ({line.dxf.start.x:.3f}, {line.dxf.start.y:.3f}) "
#                       f"to ({line.dxf.end.x:.3f}, {line.dxf.end.y:.3f}): {e}")
#                 continue
#
#         # Check blocks
#         for other_block in nearby_blocks:
#             if other_block == block_ref:
#                 continue
#             try:
#                 other_block_def = other_block.doc.blocks[other_block.dxf.name]
#                 other_corners = get_transformed_block_corners(other_block, other_block_def)
#                 if len(other_corners) < 3:
#                     print(f"Warning: Block {other_block.dxf.name} has insufficient corners")
#                     continue
#                 other_polygon = Polygon([(p.x, p.y) for p in other_corners])
#                 if not other_polygon.is_valid:
#                     other_polygon = other_polygon.buffer(0)
#                 if other_polygon.is_empty:
#                     print(f"Warning: Empty polygon for {other_block.dxf.name}")
#                     continue
#                 if shrunk_block_polygon.intersects(other_polygon):
#                     block_intersection = True
#                     intersecting_blocks.append(other_block)
#             except Exception as e:
#                 print(f"Error checking block {other_block.dxf.name} at "
#                       f"({other_block.dxf.insert.x:.3f}, {other_block.dxf.insert.y:.3f}): {e}")
#                 continue
#
#         # Log intersection details
#         if line_intersection:
#             print("Intersecting lines:")
#             for i, line in enumerate(intersecting_lines, 1):
#                 print(f"  Line {i}: Start ({line.dxf.start.x:.3f}, {line.dxf.start.y:.3f}), "
#                       f"End ({line.dxf.end.x:.3f}, {line.dxf.end.y:.3f})")
#         if block_intersection:
#             print("Intersecting blocks:")
#             for i, blk in enumerate(intersecting_blocks, 1):
#                 print(f"  Block {i}: {blk.dxf.name} at ({blk.dxf.insert.x:.3f}, {blk.dxf.insert.y:.3f})")
#
#         return line_intersection, block_intersection, intersecting_lines, intersecting_blocks
#
#     except Exception as e:
#         print(f"Error in check_intersection for block {block_ref.dxf.name}: {e}")
#         return False, False, [], []
#
# def identify_blocks_with_interference(msp, target_block_names, buffer_distance=0.2):
#     tree, lines, blocks, line_indices, block_indices = create_kdtree(msp)
#     blocks_with_interference = []
#     for block_ref in msp.query("INSERT"):
#         if block_ref.dxf.name not in target_block_names:
#             continue
#         center = (block_ref.dxf.insert.x, block_ref.dxf.insert.y)
#         nearby_lines, nearby_blocks = get_nearby_objects(tree, center, 200, lines, blocks, line_indices, block_indices)
#         cond = check_intersection(block_ref, nearby_lines, nearby_blocks, buffer_distance)
#         # Use only the boolean intersection flags
#         if np.sum(cond[:2]) > 0:  # Sum only line_intersection and block_intersection
#             blocks_with_interference.append(block_ref)
#     return blocks_with_interference
#
# def rotate_specific_blocks_to_avoid_intersections(doc, msp, target_block_names, buffer_distance=0.2, rotate_angle=5):
#     """
#     Rotate specific blocks to avoid intersections, with detailed debugging.
#
#     Args:
#         doc: The ezdxf document.
#         msp: The modelspace.
#         target_block_names: List of block names to process.
#         buffer_distance: Distance to buffer around lines.
#         rotate_angle: Angle increment for rotation (degrees).
#
#     Returns:
#         The modified document.
#     """
#     blocks_with_interference = identify_blocks_with_interference(msp, target_block_names, buffer_distance)
#     total_blocks = len(blocks_with_interference)
#     print(f"\nTotal blocks with interference: {total_blocks}")
#
#     if not blocks_with_interference:
#         print("No blocks with interference found.")
#         return doc
#
#     tree, lines, blocks, line_indices, block_indices = create_kdtree(msp)
#     print(f"KDTree created with {len(lines)} lines and {len(blocks)} blocks.")
#
#     for current_block, block_ref in enumerate(blocks_with_interference, 1):
#         sys.stdout.write(f"\rProcessing block {current_block} of {total_blocks}" + " " * 20)
#         sys.stdout.flush()
#         print(f"\n\n=== Processing block {block_ref.dxf.name} (Handle: {block_ref.dxf.handle}) ===")
#
#         # Log block insertion point and original rotation
#         center = (block_ref.dxf.insert.x, block_ref.dxf.insert.y)
#         original_angle = block_ref.dxf.rotation
#         print(f"Insertion point: {center}, Original rotation: {original_angle} degrees")
#
#         # Log block geometry
#         block_def = block_ref.doc.blocks[block_ref.dxf.name]
#         transformed_corners = get_transformed_block_corners(block_ref, block_def)
#         print("Transformed corners:")
#         for i, corner in enumerate(transformed_corners, 1):
#             print(f"  Corner {i}: ({corner.x:.3f}, {corner.y:.3f})")
#
#         block_polygon = Polygon([(p.x, p.y) for p in transformed_corners])
#         print(f"Block polygon valid: {block_polygon.is_valid}, Empty: {block_polygon.is_empty}")
#         if not block_polygon.is_valid:
#             block_polygon = block_polygon.buffer(0)
#             print("  Applied buffer(0) to fix invalid polygon.")
#
#         # Get nearby objects
#         nearby_lines, nearby_blocks = get_nearby_objects(tree, center, 200, lines, blocks, line_indices, block_indices)
#         print(f"Nearby objects: {len(nearby_lines)} lines, {len(nearby_blocks)} blocks")
#         if nearby_lines:
#             print("Sample nearby lines:")
#             for i, line in enumerate(nearby_lines[:3], 1):  # Limit to 3 for brevity
#                 print(f"  Line {i}: Start ({line.dxf.start.x:.3f}, {line.dxf.start.y:.3f}), "
#                       f"End ({line.dxf.end.x:.3f}, {line.dxf.end.y:.3f})")
#         if nearby_blocks:
#             print("Nearby blocks:")
#             for i, blk in enumerate(nearby_blocks, 1):
#                 print(f"  Block {i}: {blk.dxf.name} at ({blk.dxf.insert.x:.3f}, {blk.dxf.insert.y:.3f})")
#
#         # Store original attribute states
#         original_attribs = [(attrib.dxf.insert, attrib.dxf.rotation) for attrib in block_ref.attribs]
#         print(f"Attributes: {len(original_attribs)} found")
#         for i, (pos, rot) in enumerate(original_attribs, 1):
#             print(f"  Attr {i}: Position ({pos.x:.3f}, {pos.y:.3f}), Rotation {rot:.1f}")
#
#         # Try rotations
#         solution_found = False
#         for angle in range(0, 360, rotate_angle):
#             block_ref.dxf.rotation = (original_angle + angle) % 360
#             rotation_angle = math.radians(angle)
#             print(f"\nTrying rotation: {angle} degrees (Total: {block_ref.dxf.rotation:.1f})")
#
#             # Update attributes
#             for attrib in block_ref.attribs:
#                 current_pos = (attrib.dxf.insert.x - block_ref.dxf.insert.x,
#                               attrib.dxf.insert.y - block_ref.dxf.insert.y)
#                 new_pos = rotate_point_block_att(current_pos, rotation_angle)
#                 attrib.dxf.insert = Vec3(new_pos[0] + block_ref.dxf.insert.x,
#                                        new_pos[1] + block_ref.dxf.insert.y,
#                                        attrib.dxf.insert.z)
#                 attrib.dxf.rotation = (attrib.dxf.rotation + angle) % 360
#
#             # Check intersections
#             line_intersection, block_intersection, intersecting_lines, intersecting_blocks = check_intersection(
#                 block_ref, nearby_lines, nearby_blocks, buffer_distance)
#             print(f"Intersection check: Line={line_intersection}, Block={block_intersection}")
#
#             if not (line_intersection or block_intersection):
#                 solution_found = True
#                 print(f"Solution found at {angle} degrees!")
#                 print("Final attribute positions:")
#                 for i, attrib in enumerate(block_ref.attribs, 1):
#                     print(f"  Attr {i}: Position ({attrib.dxf.insert.x:.3f}, "
#                           f"{attrib.dxf.insert.y:.3f}), Rotation {attrib.dxf.rotation:.1f}")
#                 break
#
#         if not solution_found:
#             print(f"\nUnable to place block {block_ref.dxf.name} without intersection.")
#             # Revert to original state
#             block_ref.dxf.rotation = original_angle
#             for attrib, (orig_insert, orig_rotation) in zip(block_ref.attribs, original_attribs):
#                 attrib.dxf.insert = orig_insert
#                 attrib.dxf.rotation = orig_rotation
#             print("Reverted to original state:")
#             print(f"  Rotation: {block_ref.dxf.rotation:.1f} degrees")
#             for i, attrib in enumerate(block_ref.attribs, 1):
#                 print(f"  Attr {i}: Position ({attrib.dxf.insert.x:.3f}, "
#                       f"{attrib.dxf.insert.y:.3f}), Rotation {attrib.dxf.rotation:.1f}")
#
#     sys.stdout.write("\n")
#     print("Processing complete.")
#     return doc



def create_kdtree(msp):
    """
    Create a KDTree for lines and blocks, using line endpoints and block bounding box corners.
    
    Args:
        msp: The ezdxf modelspace.
    
    Returns:
        Tuple: (tree, lines, blocks, line_indices, block_indices)
    """
    lines = list(msp.query("LINE"))
    blocks = list(msp.query("INSERT"))
    
    points = []
    line_indices = []
    block_indices = []
    
    # Add line endpoints
    for i, line in enumerate(lines):
        points.extend([(line.dxf.start.x, line.dxf.start.y), (line.dxf.end.x, line.dxf.end.y)])
        line_indices.extend([i, i])
    
    # Add block bounding box corners
    block_positions = {}  # Track insertion points to detect duplicates
    for i, block in enumerate(blocks):
        block_def = block.doc.blocks[block.dxf.name]
        corners = get_transformed_block_corners(block, block_def)
        points.extend([(p.x, p.y) for p in corners])
        block_indices.extend([i] * len(corners))
        
        # Check for duplicate insertion points
        pos = (block.dxf.insert.x, block.dxf.insert.y)
        if pos in block_positions:
            block_positions[pos].append((block.dxf.name, block.dxf.handle))
        else:
            block_positions[pos] = [(block.dxf.name, block.dxf.handle)]
    
    # Warn about duplicates
    for pos, blocks_at_pos in block_positions.items():
        if len(blocks_at_pos) > 1:
            print(f"Warning: Multiple blocks at position {pos}:")
            for name, handle in blocks_at_pos:
                print(f"  - {name} (Handle: {handle})")
    
    if not points:
        print("Warning: No points found for KDTree, returning empty tree.")
        return KDTree(np.array([[0, 0]])), lines, blocks, [], []
    
    points = np.array(points)
    tree = KDTree(points)
    return tree, lines, blocks, line_indices, block_indices

def get_nearby_objects(tree, point, distance, lines, blocks, line_indices, block_indices):
    """
    Find lines and blocks within a given distance of a point using the KDTree.
    
    Args:
        tree: The KDTree.
        point: Tuple (x, y) of the query point.
        distance: Search radius.
        lines: List of line entities.
        blocks: List of block entities.
        line_indices: Mapping of point indices to line indices.
        block_indices: Mapping of point indices to blocks.
    
    Returns:
        Tuple: (nearby_lines, nearby_blocks)
    """
    if not line_indices and not block_indices:
        return [], []
    
    indices = tree.query_ball_point(point, distance)
    
    nearby_lines = set()
    nearby_blocks = set()
    
    for idx in indices:
        if idx < len(line_indices):
            nearby_lines.add(lines[line_indices[idx]])
        else:
            block_idx = block_indices[idx - len(line_indices)]
            if block_idx < len(blocks):
                nearby_blocks.add(blocks[block_idx])
    
    return list(nearby_lines), list(nearby_blocks)

def get_transformed_block_corners(block_ref, block_def):
    """
    Get the transformed corners of a block reference based on its insertion point, scaling, and rotation.
    
    Args:
        block_ref: The block reference entity.
        block_def: The block definition.
    
    Returns:
        List of Vec3 objects representing transformed corners.
    """
    entities = list(ezdxf.disassemble.recursive_decompose(block_def))
    if not entities:
        print(f"Warning: Block {block_def.name} has no entities, using default 10x10 box.")
        return [Vec3(-5, -5, 0), Vec3(5, -5, 0), Vec3(5, 5, 0), Vec3(-5, 5, 0)]
    
    bbox = ezdxf.bbox.extents(entities)
    if not bbox.has_data:
        print(f"Warning: Block {block_def.name} has no valid extents, using default 10x10 box.")
        return [Vec3(-5, -5, 0), Vec3(5, -5, 0), Vec3(5, 5, 0), Vec3(-5, 5, 0)]
    
    local_corners = [
        Vec3(bbox.extmin.x, bbox.extmin.y, 0),
        Vec3(bbox.extmax.x, bbox.extmin.y, 0),
        Vec3(bbox.extmax.x, bbox.extmax.y, 0),
        Vec3(bbox.extmin.x, bbox.extmax.y, 0),
    ]
    
    transform = Matrix44.chain(
        Matrix44.scale(block_ref.dxf.xscale, block_ref.dxf.yscale, 1),
        Matrix44.z_rotate(block_ref.dxf.rotation * (math.pi / 180.0)),
        Matrix44.translate(block_ref.dxf.insert.x, block_ref.dxf.insert.y, 0),
    )
    
    return [transform.transform(corner) for corner in local_corners]

def create_line_buffer_with_shapely(line, buffer_distance):
    """
    Create a buffer around a line using Shapely.
    
    Args:
        line: The line entity.
        buffer_distance: Distance to buffer around the line.
    
    Returns:
        Shapely polygon representing the buffered area, or None if invalid.
    """
    try:
        line_geom = LineString([(line.dxf.start.x, line.dxf.start.y), (line.dxf.end.x, line.dxf.end.y)])
        if line_geom.is_empty or not line_geom.is_valid:
            return None
        return line_geom.buffer(buffer_distance)
    except Exception as e:
        print(f"Error creating buffer for line from ({line.dxf.start.x:.3f}, {line.dxf.start.y:.3f}) "
              f"to ({line.dxf.end.x:.3f}, {line.dxf.end.y:.3f}): {e}")
        return None

def rotate_point_block_att(point, angle, origin=(0, 0)):
    """
    Rotate a point around a given origin.
    
    Args:
        point: Tuple (x, y) to rotate.
        angle: Rotation angle in radians.
        origin: Tuple (x, y) of the rotation center.
    
    Returns:
        Tuple (x, y) of the rotated point.
    """
    ox, oy = origin
    px, py = point
    qx = ox + math.cos(angle) * (px - ox) - math.sin(angle) * (py - oy)
    qy = oy + math.sin(angle) * (px - ox) + math.cos(angle) * (py - oy)
    return qx, qy

def check_intersection(block_ref, nearby_lines, nearby_blocks, buffer_distance, shrink_distance=0.0):
    """
    Check if the block intersects with nearby lines or blocks, logging distances.
    
    Args:
        block_ref: The block reference entity.
        nearby_lines: List of nearby line entities.
        nearby_blocks: List of nearby block entities.
        buffer_distance: Distance to buffer around lines.
        shrink_distance: Distance to shrink the block polygon.
    
    Returns:
        Tuple: (line_intersection, block_intersection, intersecting_lines, intersecting_blocks)
    """
    try:
        block_def = block_ref.doc.blocks[block_ref.dxf.name]
        transformed_corners = get_transformed_block_corners(block_ref, block_def)
        
        if len(transformed_corners) < 3:
            print(f"Warning: Block {block_ref.dxf.name} has insufficient corners")
            return False, False, [], []
        
        block_polygon = Polygon([(p.x, p.y) for p in transformed_corners])
        if not block_polygon.is_valid:
            print(f"Warning: Invalid polygon for {block_ref.dxf.name}, attempting fix")
            block_polygon = block_polygon.buffer(0)
        if block_polygon.is_empty:
            print(f"Warning: Empty block polygon for {block_ref.dxf.name}")
            return False, False, [], []
        
        min_x, min_y, max_x, max_y = block_polygon.bounds
        print(f"Block {block_ref.dxf.name} bounds: ({min_x:.3f}, {min_y:.3f}) to ({max_x:.3f}, {max_y:.3f})")
        print(f"  Bounding box size: {max_x - min_x:.3f} x {max_y - min_y:.3f}")
        
        shrunk_block_polygon = block_polygon
        if shrink_distance > 0:
            shrunk_block_polygon = block_polygon.buffer(-shrink_distance)
            if shrunk_block_polygon.is_empty or not shrunk_block_polygon.is_valid:
                print(f"Warning: Shrinking created empty/invalid polygon for {block_ref.dxf.name}")
                shrunk_block_polygon = block_polygon
        
        line_intersection = False
        block_intersection = False
        intersecting_lines = []
        intersecting_blocks = []
        
        block_pos = (block_ref.dxf.insert.x, block_ref.dxf.insert.y)
        
        # Check lines
        for line in nearby_lines:
            try:
                line_buffer = create_line_buffer_with_shapely(line, buffer_distance)
                if line_buffer is None or line_buffer.is_empty:
                    print(f"Warning: Empty buffer for line from ({line.dxf.start.x:.3f}, {line.dxf.start.y:.3f}) "
                          f"to ({line.dxf.end.x:.3f}, {line.dxf.end.y:.3f})")
                    continue
                if shrunk_block_polygon.intersects(line_buffer):
                    line_intersection = True
                    intersecting_lines.append(line)
                    # Calculate distance from block center to line
                    line_points = [(line.dxf.start.x, line.dxf.start.y), (line.dxf.end.x, line.dxf.end.y)]
                    line_geom = LineString(line_points)
                    distance = block_polygon.distance(line_geom)
                    print(f"  Line distance: {distance:.3f} meters")
            except Exception as e:
                print(f"Error checking line from ({line.dxf.start.x:.3f}, {line.dxf.start.y:.3f}) "
                      f"to ({line.dxf.end.x:.3f}, {line.dxf.end.y:.3f}): {e}")
                continue
        
        # Check blocks
        for other_block in nearby_blocks:
            if other_block == block_ref:
                continue
            other_pos = (other_block.dxf.insert.x, other_block.dxf.insert.y)
            if abs(other_pos[0] - block_pos[0]) < 0.001 and abs(other_pos[1] - block_pos[1]) < 0.001:
                print(f"Skipping block {other_block.dxf.name} at same position ({other_pos[0]:.3f}, {other_pos[1]:.3f})")
                continue
            try:
                other_block_def = other_block.doc.blocks[other_block.dxf.name]
                other_corners = get_transformed_block_corners(other_block, other_block_def)
                if len(other_corners) < 3:
                    print(f"Warning: Block {other_block.dxf.name} has insufficient corners")
                    continue
                other_polygon = Polygon([(p.x, p.y) for p in other_corners])
                if not other_polygon.is_valid:
                    other_polygon = other_polygon.buffer(0)
                if other_polygon.is_empty:
                    print(f"Warning: Empty polygon for {other_block.dxf.name}")
                    continue
                if shrunk_block_polygon.intersects(other_polygon):
                    block_intersection = True
                    intersecting_blocks.append(other_block)
                    distance = block_polygon.distance(other_polygon)
                    print(f"  Block {other_block.dxf.name} distance: {distance:.3f} meters")
            except Exception as e:
                print(f"Error checking block {other_block.dxf.name} at "
                      f"({other_block.dxf.insert.x:.3f}, {other_block.dxf.insert.y:.3f}): {e}")
                continue
        
        if line_intersection:
            print("Intersecting lines:")
            for i, line in enumerate(intersecting_lines, 1):
                print(f"  Line {i}: Start ({line.dxf.start.x:.3f}, {line.dxf.start.y:.3f}), "
                      f"End ({line.dxf.end.x:.3f}, {line.dxf.end.y:.3f})")
        if block_intersection:
            print("Intersecting blocks:")
            for i, blk in enumerate(intersecting_blocks, 1):
                print(f"  Block {i}: {blk.dxf.name} at ({blk.dxf.insert.x:.3f}, {blk.dxf.insert.y:.3f})")
        
        return line_intersection, block_intersection, intersecting_lines, intersecting_blocks
    
    except Exception as e:
        print(f"Error in check_intersection for block {block_ref.dxf.name}: {e}")
        return False, False, [], []

def identify_blocks_with_interference(msp, target_block_names, buffer_distance=0.01):
    """
    Identify blocks that intersect with lines or other blocks.
    
    Args:
        msp: The ezdxf modelspace.
        target_block_names: List of block names to check.
        buffer_distance: Distance to buffer around lines.
    
    Returns:
        List of block references with intersections.
    """
    tree, lines, blocks, line_indices, block_indices = create_kdtree(msp)
    blocks_with_interference = []
    for block_ref in msp.query("INSERT"):
        if block_ref.dxf.name not in target_block_names:
            continue
        center = (block_ref.dxf.insert.x, block_ref.dxf.insert.y)
        nearby_lines, nearby_blocks = get_nearby_objects(tree, center, 200, lines, blocks, line_indices, block_indices)
        line_intersection, block_intersection, _, _ = check_intersection(block_ref, nearby_lines, nearby_blocks, buffer_distance)
        if line_intersection or block_intersection:
            blocks_with_interference.append(block_ref)
    return blocks_with_interference

def rotate_specific_blocks_to_avoid_intersections(doc, msp, target_block_names, buffer_distance=0.01, rotate_angle=5):
    """
    Rotate specific blocks to avoid intersections, with translation fallback.
    
    Args:
        doc: The ezdxf document.
        msp: The modelspace.
        target_block_names: List of block names to process.
        buffer_distance: Distance to buffer around lines.
        rotate_angle: Angle increment for rotation (degrees).
    
    Returns:
        The modified document.
    """
    blocks_with_interference = identify_blocks_with_interference(msp, target_block_names, buffer_distance)
    total_blocks = len(blocks_with_interference)
    print(f"\nTotal blocks with interference: {total_blocks}")
    
    if not blocks_with_interference:
        print("No blocks with interference found.")
        return doc

    tree, lines, blocks, line_indices, block_indices = create_kdtree(msp)
    print(f"KDTree created with {len(lines)} lines and {len(blocks)} blocks.")

    for current_block, block_ref in enumerate(blocks_with_interference, 1):
        sys.stdout.write(f"\rProcessing block {current_block} of {total_blocks}" + " " * 20)
        sys.stdout.flush()
        print(f"\n\n=== Processing block {block_ref.dxf.name} (Handle: {block_ref.dxf.handle}) ===")

        center = (block_ref.dxf.insert.x, block_ref.dxf.insert.y)
        original_angle = block_ref.dxf.rotation
        print(f"Insertion point: {center}, Original rotation: {original_angle} degrees")

        block_def = block_ref.doc.blocks[block_ref.dxf.name]
        transformed_corners = get_transformed_block_corners(block_ref, block_def)
        print("Transformed corners:")
        for i, corner in enumerate(transformed_corners, 1):
            print(f"  Corner {i}: ({corner.x:.3f}, {corner.y:.3f})")
        
        block_polygon = Polygon([(p.x, p.y) for p in transformed_corners])
        print(f"Block polygon valid: {block_polygon.is_valid}, Empty: {block_polygon.is_empty}")
        if not block_polygon.is_valid:
            block_polygon = block_polygon.buffer(0)
            print("  Applied buffer(0) to fix invalid polygon.")

        nearby_lines, nearby_blocks = get_nearby_objects(tree, center, 200, lines, blocks, line_indices, block_indices)
        print(f"Nearby objects: {len(nearby_lines)} lines, {len(nearby_blocks)} blocks")
        if nearby_lines:
            print("Sample nearby lines:")
            for i, line in enumerate(nearby_lines[:3], 1):
                print(f"  Line {i}: Start ({line.dxf.start.x:.3f}, {line.dxf.start.y:.3f}), "
                      f"End ({line.dxf.end.x:.3f}, {line.dxf.end.y:.3f})")
        if nearby_blocks:
            print("Nearby blocks:")
            for i, blk in enumerate(nearby_blocks[:10], 1):  # Limit for brevity
                print(f"  Block {i}: {blk.dxf.name} at ({blk.dxf.insert.x:.3f}, {blk.dxf.insert.y:.3f})")

        original_attribs = [(attrib.dxf.insert, attrib.dxf.rotation) for attrib in block_ref.attribs]
        print(f"Attributes: {len(original_attribs)} found")
        for i, (pos, rot) in enumerate(original_attribs, 1):
            print(f"  Attr {i}: Position ({pos.x:.3f}, {pos.y:.3f}), Rotation {rot:.1f}")

        solution_found = False
        original_insert = block_ref.dxf.insert

        # Try rotations
        for angle in range(0, 360, rotate_angle):
            block_ref.dxf.rotation = (original_angle + angle) % 360
            rotation_angle = math.radians(angle)
            print(f"\nTrying rotation: {angle} degrees (Total: {block_ref.dxf.rotation:.1f})")

            for attrib in block_ref.attribs:
                current_pos = (attrib.dxf.insert.x - block_ref.dxf.insert.x,
                              attrib.dxf.insert.y - block_ref.dxf.insert.y)
                new_pos = rotate_point_block_att(current_pos, rotation_angle)
                attrib.dxf.insert = Vec3(new_pos[0] + block_ref.dxf.insert.x,
                                       new_pos[1] + block_ref.dxf.insert.y,
                                       attrib.dxf.insert.z)
                attrib.dxf.rotation = (attrib.dxf.rotation + angle) % 360

            line_intersection, block_intersection, intersecting_lines, intersecting_blocks = check_intersection(
                block_ref, nearby_lines, nearby_blocks, buffer_distance)
            print(f"Intersection check: Line={line_intersection}, Block={block_intersection}")
            
            if not (line_intersection or block_intersection):
                solution_found = True
                print(f"Solution found at rotation {angle} degrees!")
                break

        # Try translations if rotation fails
        if not solution_found:
            print("\nNo rotation solution found, trying translations...")
            translation_steps = [
                (0.1, 0), (-0.1, 0), (0, 0.1), (0, -0.1),
                (0.2, 0), (-0.2, 0), (0, 0.2), (0, -0.2)
            ]
            block_ref.dxf.rotation = original_angle
            for attrib, (orig_insert, orig_rotation) in zip(block_ref.attribs, original_attribs):
                attrib.dxf.insert = orig_insert
                attrib.dxf.rotation = orig_rotation

            for dx, dy in translation_steps:
                block_ref.dxf.insert = Vec3(center[0] + dx, center[1] + dy, block_ref.dxf.insert.z)
                print(f"Trying translation: ({dx:.2f}, {dy:.2f})")
                line_intersection, block_intersection, _, _ = check_intersection(
                    block_ref, nearby_lines, nearby_blocks, buffer_distance)
                print(f"Intersection check: Line={line_intersection}, Block={block_intersection}")
                if not (line_intersection or block_intersection):
                    solution_found = True
                    print(f"Solution found at translation ({dx:.2f}, {dy:.2f})!")
                    break
                block_ref.dxf.insert = original_insert

        if not solution_found:
            print(f"\nUnable to place block {block_ref.dxf.name} without intersection.")
            block_ref.dxf.rotation = original_angle
            block_ref.dxf.insert = original_insert
            for attrib, (orig_insert, orig_rotation) in zip(block_ref.attribs, original_attribs):
                attrib.dxf.insert = orig_insert
                attrib.dxf.rotation = orig_rotation
            print("Reverted to original state:")
            print(f"  Rotation: {block_ref.dxf.rotation:.1f} degrees")
            for i, attrib in enumerate(block_ref.attribs, 1):
                print(f"  Attr {i}: Position ({attrib.dxf.insert.x:.3f}, "
                      f"{attrib.dxf.insert.y:.3f}), Rotation {attrib.dxf.rotation:.1f}")

    sys.stdout.write("\n")
    print("Processing complete.")
    return doc



# -----------------------------------------------------------
def add_block_with_attributes(m_ramales, msp, block_name, insert_point, dxf_attribs, attribute_values, i, j, APPID, columna):
    """
    Adds a block reference to the model space and assigns attribute values.
    Args:
    - msp (ezdxf.layouts.Modelspace): The model space where the block will be inserted.
    - block_name (str): The name of the block to insert.
    - insert_point (tuple): The coordinates (x, y) where the block will be inserted.
    - dxf_attribs (dict): A dictionary of DXF attributes for scaling and rotation.
    - attribute_values (dict): A dictionary of attribute tags and their corresponding values.
    """
    # Add the block reference
    block_ref = msp.add_blockref(block_name, insert_point, dxfattribs=dxf_attribs)
    block_ref.set_xdata(APPID, [(1000, f"{i},{m_ramales[i][columna][j]}")])
    # Automatically add attributes from attribute definitions
    attribute_values["pz_name"] = m_ramales[i]["Pozo"][j]
    block_ref.add_auto_attribs(attribute_values)


def cad_plane_out(m_ramales, ramal, scale, project_name):
    df = m_ramales2df(m_ramales)
    keep_draw_pz, remove_draw_pz = encontrar_pozos_identicos(m_ramales, df)
    if len(remove_draw_pz) > 0:
        not_draw_pz = np.unique(np.concatenate([list(_) for _ in remove_draw_pz]))
    else:
        not_draw_pz = np.array([])

    # "crear modelo en dxf"
    doc = ezdxf.new("R2000", setup=True)
    msp = doc.modelspace()
    doc.styles.new("Letra_Arial", dxfattribs={"font": "ARIALN.TTF"})
    appsettings.show_lineweight(doc=doc, state=True)
    doc.units = ezdxf.units.M

    APPID = "PyPiper"
    try:
        doc.appids.add(APPID)
    except:
        # APPID already exists
        pass

    dict2 = {
        "layer": "01_POZO",
        "linetype": "CONTINUOUS",
        "color": 11,
        "lineweight": 30,
        "ltscale": 5,
    }
    dict_existente = {
        "layer": "01_POZO_EXISTENTE",
        "linetype": "DASHDOT",
        "color": 102,
        "lineweight": 30,
        "ltscale": 2.5,
    }
    dict_interferencia = {
        "layer": "02_INTERFERENCIA",
        "linetype": "PHANTOM2",
        "color": 6,
        "lineweight": 50,
        "ltscale": 1,
    }
    dict_canal_abierto = {
        "layer": "01_PLUVIAL_CANAL_ABIERTO",
        "linetype": "PHANTOM2",
        "color": 5,
        "lineweight": 50,
        "ltscale": 1,
    }

    # crear bloques para insertar
    radio, h_flecha, b_flecha = 1.4, 2.5, 0.65
    d1 = 7
    d2 = 15
    d3 = 0.35
    separacion_radio_normal = 1.5
    separacion_radio_canal = 2.5

    letra = par_dxf(heigth_dat_hidraulicos=1)
    letra1 = par_dxf(heigth_pozo_id=1)

    B_SAN = doc.blocks.new(name="B_SAN")
    B_SAN.add_circle(center=(0, 0), radius=radio, dxfattribs=dict2)
    hatch = B_SAN.add_hatch(color=LINECOLOR["sanitario"])
    hatch.paths.add_polyline_path(
        [
            (-h_flecha - radio, 0),
            (-h_flecha - radio, -b_flecha),
            (0 - radio, 0),
            (-h_flecha - radio, b_flecha),
        ],
        is_closed=1,
    )
    # Add invisible attribute definition to the block
    B_SAN.add_attdef(tag="pz_name", dxfattribs={"insert": (0, 0), "height": 0, "invisible": True})

    B_PLU = doc.blocks.new(name="B_PLU")
    B_PLU.add_circle(center=(0, 0), radius=radio, dxfattribs=dict2)
    hatch = B_PLU.add_hatch(color=LINECOLOR["pluvial"])
    hatch.paths.add_polyline_path(
        [
            (-h_flecha - radio, 0),
            (-h_flecha - radio, -b_flecha),
            (0 - radio, 0),
            (-h_flecha - radio, b_flecha),
        ],
        is_closed=1,
    )
    # Add invisible attribute definition to the block
    B_PLU.add_attdef(tag="pz_name", dxfattribs={"insert": (0, 0), "height": 0, "invisible": True})

    B_COMB = doc.blocks.new(name="B_COMB")
    B_COMB.add_circle(center=(0, 0), radius=radio, dxfattribs=dict2)
    hatch = B_COMB.add_hatch(color=LINECOLOR["combinado"])
    hatch.paths.add_polyline_path(
        [
            (-h_flecha - radio, 0),
            (-h_flecha - radio, -b_flecha),
            (0 - radio, 0),
            (-h_flecha - radio, b_flecha),
        ],
        is_closed=1,
    )
    B_COMB.add_attdef(tag="pz_name", dxfattribs={"insert": (0, 0), "height": 0, "invisible": True})

    B_POZO = doc.blocks.new(name="B_POZO")
    B_POZO.add_circle(center=(0, 0), radius=radio, dxfattribs=dict2)
    B_POZO.add_lwpolyline([(separacion_radio_normal * radio, -radio), (separacion_radio_normal * radio, radio)], dxfattribs=dict2)
    B_POZO.add_attdef(tag="pz_name", dxfattribs={"insert": (0, 0), "height": 0, "invisible": True})

    B_EXISTENTE = doc.blocks.new(name="B_EXISTENTE")
    B_EXISTENTE.add_circle(center=(0, 0), radius=radio, dxfattribs=dict_existente)
    hatch = B_EXISTENTE.add_hatch(color=LINECOLOR["existente"])
    hatch.paths.add_polyline_path(
        [
            (-h_flecha - radio, 0),
            (-h_flecha - radio, -b_flecha),
            (0 - radio, 0),
            (-h_flecha - radio, b_flecha),
        ],
        is_closed=1,
    )
    B_EXISTENTE.add_attdef(tag="pz_name", dxfattribs={"insert": (0, 0), "height": 0, "invisible": True})

    B_POZO_EXISTENTE = doc.blocks.new(name="B_POZO_EXISTENTE")
    B_POZO_EXISTENTE.add_circle(center=(0, 0), radius=radio, dxfattribs=dict_existente)
    B_POZO_EXISTENTE.add_attdef(tag="pz_name", dxfattribs={"insert": (0, 0), "height": 0, "invisible": True})

    add_canal_pozo(doc, radio, separacion_radio_canal, h_flecha, start=True)
    add_canal_pozo(doc, radio, separacion_radio_canal, h_flecha, b_flecha, start=False)

    # bloque de interferencias
    interferencia_dist = h_flecha * 1
    interferencia_dist_rigth = interferencia_dist * 3
    INTERFERENCIA_EXISTENTE = doc.blocks.new(name="B_INTERFERENCIA")
    INTERFERENCIA_EXISTENTE.add_lwpolyline([(0, 0), (interferencia_dist_rigth, 0)], dxfattribs=dict_interferencia)
    hatch = INTERFERENCIA_EXISTENTE.add_hatch(color=LINECOLOR["interferencia"])
    edge_path = hatch.paths.add_edge_path()
    edge_path.add_ellipse((0, 0), major_axis=(0, 0.45), ratio=1)
    edge_path.add_ellipse((interferencia_dist_rigth, 0), major_axis=(0, 0.45), ratio=1)

    INTERFERENCIA_EXISTENTE.add_attdef(
        "INTERFERENCIA",
        (interferencia_dist_rigth * 1.2, 2 * letra + 2 * d3),
        dxfattribs={"height": letra, "color": 6, "style": "Letra_Arial"},
    )
    INTERFERENCIA_EXISTENTE.add_attdef(
        "DIMENSION",
        (interferencia_dist_rigth * 1.2, letra + d3),
        dxfattribs={"height": letra, "color": 6, "style": "Letra_Arial"},
    )
    INTERFERENCIA_EXISTENTE.add_attdef(
        "ELEVACION",
        (interferencia_dist_rigth * 1.2, 0),
        dxfattribs={"height": letra, "color": 6, "style": "Letra_Arial"},
    )
    INTERFERENCIA_EXISTENTE.add_attdef(
        "COORDENADAS",
        (interferencia_dist_rigth * 1.2, -letra - d3),
        dxfattribs={"height": letra, "color": 6, "style": "Letra_Arial"},
    )
    INTERFERENCIA_EXISTENTE.add_attdef(
        "REFERENCIA",
        (interferencia_dist_rigth * 1.2, -2 * letra - 2 * d3),
        dxfattribs={"height": letra, "color": 6, "style": "Letra_Arial"},
    )

    # bloques de pozos
    B_0 = doc.blocks.new(name="B_0")
    B_0.add_lwpolyline([(0, 0), (d1, d1 - d3), (d2, d1 - d3)], dxfattribs=dict2)
    B_0.add_attdef(
        "NAME",
        (d1, d1),
        dxfattribs={"height": letra, "color": 3, "style": "Letra_Arial"},
    )
    B_0.add_attdef(
        "POZO",
        (d1, d1 + letra + 2 * d3),
        dxfattribs={"height": letra1, "color": 4, "style": "Letra_Arial"},
    )
    B_0.add_attdef(
        "NORTE",
        (d1, d1 + letra + 2 * d3 + letra1 + 2 * d3),
        dxfattribs={"height": letra, "color": 150, "style": "Letra_Arial"},
    )
    B_0.add_attdef(
        "ESTE",
        (d1, d1 + letra + 2 * d3 + letra1 + 2 * d3 + letra + 2 * d3),
        dxfattribs={"height": letra, "color": 150, "style": "Letra_Arial"},
    )
    B_0.add_attdef(
        "OBSERVACION",
        (d1, d1 + letra + 2 * d3 + letra1 + 2 * d3 + letra + 2 * d3 + letra + 2 * d3),
        dxfattribs={"height": letra, "color": 30, "style": "Letra_Arial"},
    )
    B_0.add_attdef(tag="pz_name", dxfattribs={"insert": (0, 0), "height": 0, "invisible": True})

    B_90 = doc.blocks.new(name="B_90")
    B_90.add_lwpolyline([(0, 0), (-d1, d1 - d3), (-d2, d1 - d3)], dxfattribs=dict2)
    B_90.add_attdef(
        "NAME",
        (-d2, d1),
        dxfattribs={"height": letra, "color": 3, "style": "Letra_Arial"},
    )
    B_90.add_attdef(
        "POZO",
        (-d2, d1 + letra + 2 * d3),
        dxfattribs={"height": letra1, "color": 4, "style": "Letra_Arial"},
    )
    B_90.add_attdef(
        "NORTE",
        (-d2, d1 + letra + 2 * d3 + letra1 + 2 * d3),
        dxfattribs={"height": letra, "color": 150, "style": "Letra_Arial"},
    )
    B_90.add_attdef(
        "ESTE",
        (-d2, d1 + letra + 2 * d3 + letra1 + 2 * d3 + letra + 2 * d3),
        dxfattribs={"height": letra, "color": 150, "style": "Letra_Arial"},
    )
    B_90.add_attdef(
        "OBSERVACION",
        (-d2, d1 + letra + 2 * d3 + letra1 + 2 * d3 + letra + 2 * d3 + letra + 2 * d3),
        dxfattribs={"height": letra, "color": 30, "style": "Letra_Arial"},
    )
    B_90.add_attdef(tag="pz_name", dxfattribs={"insert": (0, 0), "height": 0, "invisible": True})

    B_180 = doc.blocks.new(name="B_180")
    B_180.add_lwpolyline([(0, 0), (-d1, -d1 + d3), (-d2, -d1 + d3)], dxfattribs=dict2)
    # B_180.add_attdef("OBSERVACION", (-d2, -d1 - 2 * d3 + letra + letra1), dxfattribs={"height": letra, "color": 30, "style": "Letra_Arial"}, )
    B_180.add_attdef(
        "OBSERVACION",
        (-d2, -d1 - 2 * d3 + letra1),
        dxfattribs={"height": letra, "color": 30, "style": "Letra_Arial"},
    )
    B_180.add_attdef(
        "NAME",
        (-d2, -d1 - letra),
        dxfattribs={"height": letra, "color": 3, "style": "Letra_Arial"},
    )
    B_180.add_attdef(
        "POZO",
        (-d2, -d1 - 2 * d3 - letra - letra1),
        dxfattribs={"height": letra1, "color": 4, "style": "Letra_Arial"},
    )
    B_180.add_attdef(
        "NORTE",
        (-d2, -d1 - 5 * d3 - 3 * letra - letra1),
        dxfattribs={"height": letra, "color": 150, "style": "Letra_Arial"},
    )
    B_180.add_attdef(
        "ESTE",
        (-d2, -d1 - 4 * d3 - 2 * letra - letra1),
        dxfattribs={"height": letra, "color": 150, "style": "Letra_Arial"},
    )
    B_180.add_attdef(tag="pz_name", dxfattribs={"insert": (0, 0), "height": 0, "invisible": True})

    B_270 = doc.blocks.new(name="B_270")
    B_270.add_lwpolyline([(0, 0), (d1, -d1 + d3), (d2, -d1 + d3)], dxfattribs=dict2)
    B_270.add_attdef(
        "OBSERVACION",
        (d1, -d1 + letra),
        dxfattribs={"height": letra, "color": 30, "style": "Letra_Arial"},
    )
    B_270.add_attdef(
        "NAME",
        (d1, -d1 - letra),
        dxfattribs={"height": letra, "color": 3, "style": "Letra_Arial"},
    )
    B_270.add_attdef(
        "POZO",
        (d1, -d1 - letra - 2 * d3 - letra1),
        dxfattribs={"height": letra1, "color": 4, "style": "Letra_Arial"},
    )
    B_270.add_attdef(
        "NORTE",
        (d1, -d1 - letra - 2 * d3 - letra1 - 2 * d3 - letra),
        dxfattribs={"height": letra, "color": 150, "style": "Letra_Arial"},
    )
    B_270.add_attdef(
        "ESTE",
        (d1, -d1 - letra - 2 * d3 - letra1 - 2 * d3 - letra - d3 - letra),
        dxfattribs={"height": letra, "color": 150, "style": "Letra_Arial"},
    )
    B_270.add_attdef(tag="pz_name", dxfattribs={"insert": (0, 0), "height": 0, "invisible": True})

    B = doc.blocks.new(name="B")

    radio, h_flecha, b_flecha, letra = (
        radio * scale,
        h_flecha * scale,
        b_flecha * scale,
        letra * scale,
    )

    # interferencias
    mleaderstyle = doc.mleader_styles.duplicate_entry("Standard", "EZDXF")
    mleaderstyle.set_mtext_style("Letra_Arial")
    mleaderstyle.set_dxf_attrib("arrow_head_size", letra)
    mleaderstyle.dxf.char_height = letra
    mleaderstyle.dxf.landing_gap_size = 0.5

    for i in ramal.values():
        # propiedades de lineas y texto
        if m_ramales[i]["Tipo"][1]:
            a0 = LAYER[m_ramales[i]["Tipo"][1].lower()]
            a1 = LINECOLOR[m_ramales[i]["Tipo"][1].lower()]
            a2 = LINETYPES[m_ramales[i]["Tipo"][1].lower()]
            a3 = LINEWEIGHT[m_ramales[i]["Tipo"][1].lower()]
            bloque = BLOQUE_POZO[m_ramales[i]["Tipo"][1].lower()]
        else:
            a0 = LAYER["sanitario"]
            a1 = LINECOLOR["sanitario"]
            a2 = LINETYPES["sanitario"]
            a3 = LINEWEIGHT["sanitario"]
            bloque = BLOQUE_POZO["sanitario"]
        dict1 = {
            "layer": a0,
            "color": a1,
            "linetype": a2,
            "lineweight": a3,
            "ltscale": 2.5,
        }

        # remover pozos de canales superficiales abiertos
        # -------------------------------------------------------------------------------------------------------------
        filtro_rectangular = m_ramales[i]["Seccion"] == "rectangular"
        filtro_canal_abierto = np.zeros(len(m_ramales[i]["Seccion"]), dtype=bool)
        if len(filtro_rectangular.nonzero()[0]) > 0:
            # smaller depth from each trench
            h_min = np.min([m_ramales[i]["HI"][filtro_rectangular], m_ramales[i]["HI"][filtro_rectangular]], axis=0)
            # altura seccion
            h_seccion = seccion_str2float(m_ramales[i]["D_ext"])[filtro_rectangular]

            # indices de secciones rectangulares
            index_rectangular = filtro_rectangular.nonzero()[0]
            # canal abierto
            is_abierto = np.isclose(h_seccion, h_min, atol=0.4)
            filtro_canal_abierto[index_rectangular] = is_abierto

        filtro_canal_abierto = filtro_canal_abierto[1:]

        # preparar datos
        coordX, coordY = m_ramales[i]["X"], m_ramales[i]["Y"]
        ang_v, cuadrante = ang_coords(coordX, coordY)
        ang_v = np.insert(ang_v, -1, ang_v[-1])
        L_v = np.round(m_ramales[i]["L"][1:], 3)
        ZFI = np.round(m_ramales[i]["ZFI"][1:], 3)
        ZFF = np.round(m_ramales[i]["ZFF"][1:], 3)
        cuadrantes = cuadrante_mat(cuadrante)

        if isinstance(cuadrantes[0], int):
            cuadrante1 = [cuadrantes[0], cuadrantes[1]]
            cuadrante_X = cuadrante1[0]
            cuadrante_Y = cuadrante1[1]
            cuadrante = [cuadrante]
        else:
            cuadrante1 = list(zip(*cuadrantes))
            cuadrante_X = cuadrante1[0]
            cuadrante_Y = cuadrante1[1]

        radio_array = np.where(filtro_canal_abierto, radio / 2.5, radio)
        radio_arr_start = radio_array.copy()
        if "nuevo" in m_ramales[i]["Estado"]:
            radio_arr_start[0] = (radio / 2.5) * separacion_radio_canal if filtro_canal_abierto[0] else radio * separacion_radio_normal

        coordX1 = coordX[0:-1] + np.abs((radio_arr_start * np.cos(np.radians(ang_v[0:-1])))) * cuadrante_X
        coordX2 = coordX[0:-1] + np.abs(((L_v - radio_array - h_flecha) * np.cos(np.radians(ang_v[0:-1])))) * cuadrante_X

        coordY1 = coordY[0:-1] + np.abs((radio_arr_start * np.sin(np.radians(ang_v[0:-1])))) * cuadrante_Y
        coordY2 = coordY[0:-1] + np.abs(((L_v - radio_array - h_flecha) * np.sin(np.radians(ang_v[0:-1])))) * cuadrante_Y

        coordX3 = coordX1 + np.abs((((L_v - radio_array * 2 - h_flecha) / 2.0) * np.cos(np.radians(ang_v[0:-1])))) * cuadrante_X
        coordY3 = coordY1 + np.abs((((L_v - radio_array * 2 - h_flecha) / 2.0) * np.sin(np.radians(ang_v[0:-1])))) * cuadrante_Y

        # PREPARACION DE EJES
        tuberia1 = list(zip(coordX1, coordY1))
        tuberia2 = list(zip(coordX2, coordY2))
        tuberia = list(zip(tuberia1, tuberia2))

        # plot line given state new or existing
        if "nuevo" in m_ramales[i]["Estado"]:
            for j in range(len(tuberia)):
                chosen_dict = dict_canal_abierto if filtro_canal_abierto[j] else dict1
                line_x_data = msp.add_line(tuberia[j][0], tuberia[j][1], dxfattribs=chosen_dict)
                line_x_data.set_xdata(APPID, [(1000, f"{i},{m_ramales[i]['Tramo'][j + 1]}")])
        else:
            for j, tubo in enumerate(tuberia):
                line_x_data = msp.add_line(tubo[0], tubo[1], dxfattribs=dict_existente)
                line_x_data.set_xdata(APPID, [(1000, f"{i},{m_ramales[i]['Tramo'][j + 1]}")])

        # agregar texto de cota de entrada y salida de los pozos
        for j_x_data in range(len(ZFI)):
            # Determinar la alineación del texto basado en el cuadrante
            text_align_x_data = TextEntityAlignment.TOP_LEFT if (cuadrante[j_x_data] == 0) or (cuadrante[j_x_data] == 270) else TextEntityAlignment.TOP_RIGHT

            # Determinar la rotación del texto
            rotation_x_data = ang_v[j_x_data] if (cuadrante[j_x_data] == 0) or (cuadrante[j_x_data] == 270) else ang_v[j_x_data] - 180

            # Crear el texto con sus atributos
            text_x_data = msp.add_text(
                np.round(ZFI[j_x_data], 3),
                dxfattribs={
                    "style": "Letra_Arial",
                    "layer": "01_COTA_ENTRADA",
                    "color": 41,
                    "rotation": rotation_x_data,
                    "height": letra,
                },
            )

            # Establecer la ubicación y alineación del texto
            text_x_data.set_placement((coordX1[j_x_data], coordY1[j_x_data]), align=text_align_x_data)
            text_x_data.set_xdata(APPID, [(1000, f"{i},{m_ramales[i]['Tramo'][j_x_data + 1]}")])

        for j_x_data in range(len(ZFF)):
            # Determinar la alineación del texto basado en el cuadrante
            text_align_x_data = TextEntityAlignment.BOTTOM_RIGHT if (cuadrante[j_x_data] == 0) or (cuadrante[j_x_data] == 270) else TextEntityAlignment.BOTTOM_LEFT

            # Determinar la rotación del texto
            rotation_x_data = ang_v[j_x_data] if (cuadrante[j_x_data] == 0) or (cuadrante[j_x_data] == 270) else ang_v[j_x_data] - 180

            # Crear el texto con sus atributos
            text_x_data = msp.add_text(
                np.round(ZFF[j_x_data], 3),
                dxfattribs={
                    "style": "Letra_Arial",
                    "layer": "01_COTA_ENTRADA",
                    "color": 41,
                    "rotation": rotation_x_data,
                    "height": letra,
                },
            )

            # Establecer la ubicación y alineación del texto
            text_x_data.set_placement((coordX2[j_x_data], coordY2[j_x_data]), align=text_align_x_data)
            text_x_data.set_xdata(APPID, [(1000, f"{i},{m_ramales[i]['Tramo'][j_x_data + 1]}")])

        x_flechas, y_flechas, ang_flechas = coordX[1:], coordY[1:], ang_v[0:-1]
        # plot hatch for pozo given state existing
        if "nuevo" in m_ramales[i]["Estado"]:
            for j in range(len(x_flechas)):
                if filtro_canal_abierto[j]:
                    try:
                        if m_ramales[i]["Conexion"][j + 1]:
                            cond_list = m_ramales[i]["Conexion"][j + 1].split(",")
                            cond_connect_to_canal = False
                            for cond in cond_list:
                                ramal_from_to, pz_from_to = cond.split(".")
                                from_to_seccion = m_ramales[ramal_from_to]["Seccion"][int(pz_from_to)]
                                from_to_hmin = np.min([m_ramales[ramal_from_to]["HF"][int(pz_from_to)], m_ramales[ramal_from_to]["HI"][int(pz_from_to)]])
                                from_to_hseccion = seccion_str2float(m_ramales[ramal_from_to]["D_ext"])[int(pz_from_to)]

                                if from_to_seccion in ["rectangular"] and np.isclose(from_to_hseccion, from_to_hmin, atol=0.4):
                                    cond_connect_to_canal = True
                                    break  # If we find one that meets the condition, we can stop checking
                        else:
                            cond_connect_to_canal = True

                    except Exception as e:
                        print(f"An error occurred: {e}")
                        cond_connect_to_canal = False
                else:
                    cond_connect_to_canal = False

                if filtro_canal_abierto[j] and cond_connect_to_canal:
                    bloque_select = "B_PLU_CANAL"
                else:
                    bloque_select = bloque

                block_name = bloque_select
                insert_point = (x_flechas[j], y_flechas[j])
                dxf_attribs = {"xscale": scale, "yscale": scale, "rotation": ang_v[j]}
                attribute_values = {}
                add_block_with_attributes(m_ramales, msp, block_name, insert_point, dxf_attribs, attribute_values, i, j + 1, APPID, "Pozo")

            if m_ramales[i]["Conexion"][0] and m_ramales[i]["Estado"][0] in ["existente"]:
                block_name = "B_POZO_EXISTENTE"
                insert_point = (coordX[0], coordY[0])
                dxf_attribs = {
                    "xscale": scale,
                    "yscale": scale,
                    "rotation": ang_v[0],
                }
                attribute_values = {}
                add_block_with_attributes(m_ramales, msp, block_name, insert_point, dxf_attribs, attribute_values, i, 0, APPID, "Pozo")

                hatch = msp.add_hatch(color=102)
                edge_path = hatch.paths.add_edge_path()
                edge_path.add_ellipse(
                    (m_ramales[i]["X"][0], m_ramales[i]["Y"][0]),
                    major_axis=(0, radio - 0.25 * radio),
                    ratio=1,
                )
                hatch.set_xdata(APPID, [(1000, f"{i},{m_ramales[i]['Pozo'][0]}")])

            else:
                if m_ramales[i]["Conexion"][0]:
                    cond_init_list = [_ for _ in m_ramales[i]["Conexion"][0].split(",") if not _.endswith(".0")]
                    if len(cond_init_list) > 0:
                        cond_init_pz = False
                    else:
                        cond_init_pz = True
                else:
                    cond_init_pz = True

                # if cond_init_pz:
                # si es canal abierto poner simbologia de inicio de canal abierto
                if filtro_canal_abierto[0]:
                    block_name = "B_POZO_CANAL"
                    insert_point = (coordX[0], coordY[0])
                    dxf_attribs = {
                        "xscale": scale,
                        "yscale": scale,
                        "rotation": ang_v[0],
                    }
                    attribute_values = {}
                    add_block_with_attributes(m_ramales, msp, block_name, insert_point, dxf_attribs, attribute_values, i, 0, APPID, "Pozo")

                else:
                    block_name = "B_POZO"
                    insert_point = (coordX[0], coordY[0])
                    dxf_attribs = {
                        "xscale": scale,
                        "yscale": scale,
                        "rotation": ang_v[0],
                    }
                    attribute_values = {}
                    add_block_with_attributes(m_ramales, msp, block_name, insert_point, dxf_attribs, attribute_values, i, 0, APPID, "Pozo")

        else:
            block_name = "B_POZO_EXISTENTE"
            insert_point = (coordX[0], coordY[0])
            dxf_attribs = {
                "xscale": scale,
                "yscale": scale,
                "rotation": ang_v[0],
            }
            attribute_values = {}
            add_block_with_attributes(m_ramales, msp, block_name, insert_point, dxf_attribs, attribute_values, i, 0, APPID, "Pozo")

            hatch = msp.add_hatch(color=102)
            edge_path = hatch.paths.add_edge_path()
            edge_path.add_ellipse(
                (m_ramales[i]["X"][0], m_ramales[i]["Y"][0]),
                major_axis=(0, radio - 0.25 * radio),
                ratio=1,
            )
            hatch.set_xdata(APPID, [(1000, f"{i},{m_ramales[i]['Pozo'][0]}")])

            for j in range(len(x_flechas)):
                block_name = BLOQUE_POZO["existente"]
                insert_point = (x_flechas[j], y_flechas[j])
                dxf_attribs = {"xscale": scale, "yscale": scale, "rotation": ang_v[j]}
                attribute_values = {}
                add_block_with_attributes(m_ramales, msp, block_name, insert_point, dxf_attribs, attribute_values, i, j, APPID, "Pozo")

                hatch = msp.add_hatch(color=102)
                edge_path = hatch.paths.add_edge_path()
                edge_path.add_ellipse(
                    (m_ramales[i]["X"][j], m_ramales[i]["Y"][j]),
                    major_axis=(0, radio - 0.25 * radio),
                    ratio=1,
                )
                hatch.set_xdata(APPID, [(1000, f"{i},{m_ramales[i]['Pozo'][j]}")])

        D_ext = D_ext_string(i, m_ramales)
        # plot hydraulic text given state new or existing
        if "nuevo" in m_ramales[i]["Estado"]:
            chosen_color = 5 if filtro_canal_abierto[j] else a1
            for j in range(len(coordX3)):
                units = " mm" if m_ramales[i]["Seccion"][j + 1] in ["circular"] else " m"
                nomenclatura = "D: " if m_ramales[i]["Seccion"][j + 1] in ["circular"] else "S: "
                d_convert = (
                    D_ext[j + 1] if m_ramales[i]["Seccion"][j + 1] in ["circular"] else "x".join((np.array(D_ext[j + 1].split("x")).astype(float).round(2) / 1000).astype(str))
                )
                current_string = (
                    "     \\P"
                    + "L: "
                    + str(m_ramales[i]["L"][j + 1])
                    + " m \\P"
                    + nomenclatura
                    + d_convert
                    + units
                    + str(m_ramales[i]["Material"][j + 1])
                    + "\\P"
                    + str("rug: " + str(m_ramales[i]["Rugosidad"][j + 1]) + "\\P" if m_ramales[i]["Seccion"][j + 1] == "rectangular" else "")
                    + "J: "
                    + str(np.round(np.asarray(m_ramales[i]["S"][j + 1]) * 100, 1))
                    + "% \\P"
                    + "q: "
                    + str(np.round(m_ramales[i]["q_accu"][j + 1], 2))
                    + " L/s \\P"
                    + "v: "
                    + str(m_ramales[i]["v"][j + 1])
                    + " m/s \\P"
                    + "h/D: "
                    + str(np.round(np.asarray(m_ramales[i]["h/D"][j + 1]) * 100, 1))
                    + "% \\P"
                    + " "
                )
                mtext_x_data = msp.add_mtext(
                    current_string,
                    dxfattribs={
                        "line_spacing_factor": 0.85,
                        "style": "Letra_Arial",
                        "layer": "04_DATOS_GRILLA",
                        "color": chosen_color,
                        "char_height": letra,
                        "attachment_point": 2,
                        "width": (
                            m_ramales[i]["L"][j + 1] - radio * 2 - h_flecha if m_ramales[i]["L"][j + 1] - radio * 2 - h_flecha > 14 else m_ramales[i]["L"][j + 1] + radio * 2
                        ),
                        "rotation": (ang_v[j] if (cuadrante[j] == 0) or (cuadrante[j] == 270) else ang_v[j] - 180),
                        "insert": (coordX3[j], coordY3[j]),
                    },
                )
                mtext_x_data.set_xdata(APPID, [(1000, f"{i},{m_ramales[i]['Tramo'][j + 1]}")])
        else:
            for j in range(len(coordX3)):
                units = " mm" if m_ramales[i]["Seccion"][j + 1] in ["circular"] else " m"
                nomenclatura = "D: " if m_ramales[i]["Seccion"][j + 1] in ["circular"] else "S: "
                d_convert = (
                    D_ext[j + 1] if m_ramales[i]["Seccion"][j + 1] in ["circular"] else "x".join((np.array(D_ext[j + 1].split("x")).astype(float).round(2) / 1000).astype(str))
                )
                current_string = (
                    "     \\P"
                    + "L: "
                    + str(m_ramales[i]["L"][j + 1])
                    + " m \\P"
                    + nomenclatura
                    + d_convert
                    + units
                    + str(m_ramales[i]["Material"][j + 1])
                    + "\\P"
                    + str("rug: " + str(m_ramales[i]["Rugosidad"][j + 1]) + "\\P" if m_ramales[i]["Seccion"][j + 1] == "rectangular" else "")
                    + "J: "
                    + str(np.round(float(m_ramales[i]["S"][j + 1]) * 100, 1))
                    + "% \\P"
                    + "q: "
                    + str(np.round(m_ramales[i]["q_accu"][j + 1], 2))
                    + " L/s \\P"
                    + "v: "
                    + str(m_ramales[i]["v"][j + 1])
                    + " m/s \\P"
                    + "h/D: "
                    + str(np.round(float(m_ramales[i]["h/D"][j + 1]) * 100, 1))
                    + "% \\P"
                    + " "
                )
                mtext_x_data = msp.add_mtext(
                    current_string,
                    dxfattribs={
                        "line_spacing_factor": 0.85,
                        "style": "Letra_Arial",
                        "layer": "04_DATOS_GRILLA",
                        "color": 102,
                        "char_height": letra,
                        "attachment_point": 2,
                        "width": (
                            m_ramales[i]["L"][j + 1] - radio * 2 - h_flecha if m_ramales[i]["L"][j + 1] - radio * 2 - h_flecha > 14 else m_ramales[i]["L"][j + 1] + radio * 2
                        ),
                        "rotation": (ang_v[j] if (cuadrante[j] == 0) or (cuadrante[j] == 270) else ang_v[j] - 180),
                        "insert": (coordX3[j], coordY3[j]),
                    },
                )
                mtext_x_data.set_xdata(APPID, [(1000, f"{i},{m_ramales[i]['Tramo'][j + 1]}")])

        ZTI = np.insert(
            m_ramales[i]["ZTI"][1:],
            len(m_ramales[i]["ZTI"][1:]),
            m_ramales[i]["ZTF"][-1],
        )

        if not m_ramales[i]["Pozo"][0] in not_draw_pz:
            dxf_attribs = {"xscale": scale, "yscale": scale, "rotation": ang_v[0] if (cuadrante[0] == 0 or cuadrante[0] == 270) else ang_v[0] - 180}
            attribute_values = {
                "OBSERVACION": str(m_ramales[i]["Obs"][0]),
                "NAME": "Z " + str(round(ZTI[0], 3)),
                "POZO": str(m_ramales[i]["Pozo"][0]),
                "NORTE": "N " + str(round(m_ramales[i]["Y"][0], 2)),
                "ESTE": "E " + str(round(m_ramales[i]["X"][0], 2)),
            }
            block_name = "B_90" if (cuadrante[0] == 0 or cuadrante[0] == 270) else "B_0"
            insert_point = (coordX[0], coordY[0])
            add_block_with_attributes(m_ramales, msp, block_name, insert_point, dxf_attribs, attribute_values, i, 0, APPID, "Pozo")

        if not m_ramales[i]["Conexion"][-1]:
            if not m_ramales[i]["Pozo"][-1] in not_draw_pz:
                block_name = "B_0" if (cuadrante[-1] == 0) or (cuadrante[-1] == 270) else "B_90"
                insert_point = (x_flechas[j], y_flechas[j])
                dxf_attribs = {"xscale": scale, "yscale": scale, "rotation": 0}
                attribute_values = {
                    "OBSERVACION": str(m_ramales[i]["Obs"][-1]),
                    "NAME": "Z " + str(ZTI[-1]),
                    "POZO": str(m_ramales[i]["Pozo"][-1]),
                    "NORTE": "N " + str(np.round(m_ramales[i]["Y"][-1], 2)),
                    "ESTE": "E " + str(np.round(m_ramales[i]["X"][-1], 2)),
                }
                add_block_with_attributes(m_ramales, msp, block_name, insert_point, dxf_attribs, attribute_values, i, -1, APPID, "Pozo")

                hatch = msp.add_hatch(color=11)
                edge_path = hatch.paths.add_edge_path()
                edge_path.add_ellipse(
                    (m_ramales[i]["X"][-1], m_ramales[i]["Y"][-1]),
                    major_axis=(0, radio - 0.25 * radio),
                    ratio=1,
                )
                hatch.set_xdata(APPID, [(1000, f"{i},{m_ramales[i]['Pozo'][-1]}")])

        if "existente" in m_ramales[i]["Estado"] and m_ramales[i]["Conexion"][-1]:
            endPz = m_ramales[i]["Conexion"][-1].split(",")
            max_heigth = np.min([m_ramales[_.split(".")[0]]["ZFF"][int(_.split(".")[1]) if int(_.split(".")[1]) != 0 else 1] for _ in endPz])
            # check if it uses same manhole or not
            if m_ramales[i]["ZFF"][-1] == max_heigth:
                hatch = msp.add_hatch(color=102)
                edge_path = hatch.paths.add_edge_path()
                edge_path.add_ellipse(
                    (m_ramales[i]["X"][-1], m_ramales[i]["Y"][-1]),
                    major_axis=(0, radio - 0.25 * radio),
                    ratio=1,
                )
                hatch.set_xdata(APPID, [(1000, f"{i},{m_ramales[i]['Pozo'][-1]}")])

        if len(m_ramales[i]["Pozo"]) > 2:
            dif_ang = np.insert(ang_v[1:] - ang_v[0:-1], 0, 0)
            cuadrante1 = [str(cuadrante[i]) + "-" + str(cuadrante[i + 1]) for i in range(len(cuadrante) - 1)]
            cuadrante1 = np.insert(cuadrante1, 0, cuadrante1[0])
            cuadrante1 = np.insert(cuadrante1, -1, cuadrante1[-1])
            rotation1 = np.vectorize(rotation)
            bloques = rotation1(dif_ang, cuadrante1, m_ramales[i]["Conexion"])

            for k in range(1, len(bloques[0]) - 1):
                if bloques[1][k] == 0:
                    ang_rot = 0
                if bloques[1][k] == 1:
                    ang_rot = ang_v[k + bloques[1][k]] - 180
                if bloques[1][k] == -1:
                    ang_rot = ang_v[k + bloques[1][k]]
                if bloques[1][k] == 2:
                    ang_rot = ang_v[k - 1] + 180
                if bloques[1][k] == 3:
                    ang_rot = ang_v[k + 1]

                if m_ramales[i]["Pozo"][k] in not_draw_pz:
                    continue
                else:
                    block_name = str(bloques[0][k])
                    insert_point = (coordX[k], coordY[k])
                    dxf_attribs = {"xscale": scale, "yscale": scale, "rotation": ang_rot}
                    attribute_values = {
                        "OBSERVACION": str(m_ramales[i]["Obs"][k]),
                        "NAME": "Z " + str(round(ZTI[k], 3)),
                        "POZO": str(m_ramales[i]["Pozo"][k]),
                        "NORTE": "N " + str(round(m_ramales[i]["Y"][k], 2)),
                        "ESTE": "E " + str(round(m_ramales[i]["X"][k], 2)),
                    }
                    add_block_with_attributes(m_ramales, msp, block_name, insert_point, dxf_attribs, attribute_values, i, k, APPID, "Pozo")

        # interferencias
        if "Interferencia" in list(m_ramales[i].keys()):
            index_interference = (m_ramales[i]["Interferencia"] != None).nonzero()[0]
            for interference_pos in index_interference:
                lista_show_in_plane = m_ramales[i]["Interferencia"][interference_pos]["show_in_plane"]
                lista_seccion = m_ramales[i]["Interferencia"][interference_pos]["seccion"]
                lista_dimension_circular = m_ramales[i]["Interferencia"][interference_pos]["D"]
                lista_dimension_rectangular = np.array(
                    [
                        m_ramales[i]["Interferencia"][interference_pos]["b"],
                        m_ramales[i]["Interferencia"][interference_pos]["h"],
                    ]
                ).T
                lista_elevation = m_ramales[i]["Interferencia"][interference_pos]["bottom_elevation"]
                lista_coordenadas = m_ramales[i]["Interferencia"][interference_pos]["coords"]
                lista_referencia = m_ramales[i]["Interferencia"][interference_pos]["obs"]

                for (
                    seccion,
                    dimension_circular,
                    dimension_rectangular,
                    elevation,
                    coordenada,
                    referencia,
                    show_in_plane_value,
                ) in zip(
                    lista_seccion,
                    lista_dimension_circular,
                    lista_dimension_rectangular,
                    lista_elevation,
                    lista_coordenadas,
                    lista_referencia,
                    lista_show_in_plane,
                ):
                    if not show_in_plane_value:
                        continue

                    dimension_symbol = "D:" if "circular" in seccion else "seccion:"
                    dimension = round(dimension_circular, 3) if "circular" in seccion else str(round(dimension_rectangular[0], 3)) + "x" + str(round(dimension_rectangular[1], 3))
                    pos = interference_pos if interference_pos == 0 else interference_pos - 1

                    obs_interference_text = f"{dimension_symbol} {dimension}m\\Pelev: {round(elevation, 3)}\\Pcoords: {round(coordenada[0], 1)},{round(coordenada[1], 1)}\\P{referencia.replace(',', '\\P').replace('\\P ', '\\P')}"

                    # Add leader
                    target_point = Vec2((coordenada[0], coordenada[1]))

                    ml_builder = msp.add_multileader_mtext("EZDXF", dxfattribs=dict_interferencia)

                    ml_builder.set_leader_properties(color=6, lineweight=2.5)
                    ml_builder.set_arrow_properties(size=letra * 0.3, name=ARROWS.dot)
                    ml_builder.set_content(
                        obs_interference_text,
                        style="Letra_arial",
                        alignment=MTextLineAlignment.MIDDLE,
                    )
                    ml_builder.set_connection_properties(landing_gap=0.5, dogleg_length=0.0)

                    # Adjust line spacing settings AFTER setting content
                    mtext = ml_builder.context.mtext  # Get the MText object
                    mtext.line_spacing_factor = 0.70  # Adjust this value as needed
                    mtext.line_spacing_style = 1  # 1 = Exactly, 2 = At Least

                    text_width, _ = estimate_text_size(obs_interference_text, letra)
                    _, text_height = get_exact_text_dimensions(obs_interference_text, "Letra_Arial", letra)

                    original_rot = ang_v[pos]
                    leader_length = 10

                    # Determine quadrant and adjust rotations
                    if 0 <= original_rot < 90:
                        leader_rot = original_rot + 90 - 180
                        offset = leader_length

                    elif 90 <= original_rot < 180:
                        leader_rot = original_rot - 90
                        offset = leader_length

                    elif 180 <= original_rot < 270:
                        leader_rot = original_rot - 90 - 180
                        offset = leader_length

                    else:  # 270 <= original_rot < 360
                        leader_rot = original_rot + 90
                        offset = leader_length

                    # Ensure angles are within 0-360 range
                    leader_rot = leader_rot % 360

                    # Convert to radians for ezdxf
                    leader_rot_rad = math.radians(leader_rot)

                    # Set leader line
                    ml_builder.quick_leader(
                        obs_interference_text,
                        target=target_point,
                        segment1=Vec2.from_angle(leader_rot_rad, offset),
                        connection_type=mleader.HorizontalConnection.middle_of_text,
                    )
                    new_target = Vec2(move_point(coordenada[0], coordenada[1], offset * scale, leader_rot))

                    # Move the text point up by half the text height
                    text_center = Vec2(
                        move_point(
                            new_target.x,
                            new_target.y,
                            -text_height / 2,
                            leader_rot - 90,
                        )
                    )
                    ml_builder.build(insert=text_center, rotation=leader_rot)
                    # Obtener el MultiLeader del builder
                    mleader_x_data = ml_builder.multileader  # Este es el objeto MultiLeader actual
                    mleader_x_data.set_xdata(APPID, [(1000, f"{i},{m_ramales[i]['Tramo'][interference_pos]}")])

    # # Define the target block names
    # target_block_names = {"B_0", "B_90", "B_180", "B_270"}
    # # Apply the rotation logic
    # doc = rotate_specific_blocks_to_avoid_intersections(doc, msp, target_block_names,  buffer_distance=0.05, rotate_angle=10)
 

    # "GUARDAR DXF"
    extents = appsettings.update_extents(doc)
    zoom.center(doc.modelspace(), extents.center, extents.size)
    doc.saveas("PROYECTO_" + project_name + os.path.sep + "01_DXF" + os.path.sep + "01_OUT" + os.path.sep + "00_PLANTA_" + str(project_name) + ".dxf")

    # guardar escala
    text_content = str(scale)
    # Specify the path and name of the file
    file_path = "PROYECTO_" + project_name + os.path.sep + "01_DXF" + os.path.sep + "01_OUT" + os.path.sep + "00_PLANTA_" + str(project_name) + "_scale.txt"
    # Open the file in write mode and write the string to it
    with open(file_path, "w") as file:
        file.write(text_content)


def get_extents(dxf_file_path):
    # Load the DXF file
    doc = ezdxf.readfile(dxf_file_path)
    msp = doc.modelspace()

    # Initialize min and max values with None
    min_x = min_y = float("inf")
    max_x = max_y = float("-inf")
    coords = []

    # Iterate through all entities in the model space
    for entity in msp:
        coords.append(get_entity_points(entity))
        # Check if entity has graphical representation, which means it has points
        if entity.dxftype() in (
            "LINE",
            "LWPOLYLINE",
            "CIRCLE",
            "ARC",
            "TEXT",
            "SOLID",
            "POINT",
        ):
            points = []
            if entity.dxftype() == "LINE":
                points.extend([entity.dxf.start, entity.dxf.end])
            elif entity.dxftype() == "LWPOLYLINE":
                points.extend(entity.get_points(format="xy"))
            elif entity.dxftype() in ("CIRCLE", "ARC"):
                # For circles and arcs, consider the extremes
                cx, cy = entity.dxf.center.x, entity.dxf.center.y
                r = entity.dxf.radius
                points.extend([(cx - r, cy - r), (cx + r, cy + r)])
            elif entity.dxftype() == "TEXT":
                # For text, consider the insertion point
                points.append((entity.dxf.insert.x, entity.dxf.insert.y))
            elif entity.dxftype() == "SOLID":
                # SOLID can have 3 or 4 points
                points.extend(entity.points())
            elif entity.dxftype() == "POINT":
                points.append(entity.dxf.location)

            for point in points:
                min_x = min(min_x, point[0])
                min_y = min(min_y, point[1])
                max_x = max(max_x, point[0])
                max_y = max(max_y, point[1])

    coords = np.concatenate([_ for _ in coords if len(_) > 0])
    return (min_x, min_y, max_x, max_y), coords.T


def get_entity_points(entity):
    points = []
    if entity.dxftype() == "LINE":
        points.append(entity.dxf.start.xyz[0:2])
        points.append(entity.dxf.end.xyz[0:2])

    # Add more elif blocks for other entity types as needed
    return points


def rotate_polygon(polygon: List[Tuple[float, float]], angle: float, center: Tuple[float, float]) -> List[Tuple[float, float]]:
    """Rotate a polygon around a center point by a given angle in degrees."""
    angle_rad = math.radians(angle)
    cos_angle = math.cos(angle_rad)
    sin_angle = math.sin(angle_rad)
    cx, cy = center
    rotated_polygon = []
    for x, y in polygon:
        x -= cx
        y -= cy
        x_new = x * cos_angle - y * sin_angle
        y_new = x * sin_angle + y * cos_angle
        rotated_polygon.append((x_new + cx, y_new + cy))
    return rotated_polygon


def extract_all_dxf_lines(dxf_path):
    """Extract all lines (start and end points) from a DXF file."""
    doc = ezdxf.readfile(dxf_path)
    modelspace = doc.modelspace()

    # Initialize a list to collect all lines in the DXF
    lines = []

    # Extract only "LINE" entities from the DXF
    for entity in modelspace.query("LINE"):
        start = (entity.dxf.start.x, entity.dxf.start.y)
        end = (entity.dxf.end.x, entity.dxf.end.y)

        lines.append((start, end))

    return np.concatenate(lines)


def get_viewport_polygons(extents, overlap_percentage, scale_viewport, coords):
    # A1 sheet size in meters
    a1_width_m = 0.636 * 1000
    a1_height_m = 0.569 * 1000

    # Calculate model extents based on the custom scale factor
    model_width = a1_width_m * scale_viewport
    model_height = a1_height_m * scale_viewport
    model_extents = (model_width, model_height)
    x_min, y_min, x_max, y_max = extents

    total_width = x_max - x_min
    total_heigth = y_max - y_min

    polygon_number_width = int(round(total_width / model_width, 0) + 1)
    polygon_number_heigth = int(round(total_heigth / model_height, 0) + 1)

    overlap = int(overlap_percentage * model_width)

    heigth_cover = model_height * polygon_number_heigth - (polygon_number_heigth - 1) * overlap
    check_heigth = (y_max + overlap - heigth_cover) > y_min

    width_cover = model_width * polygon_number_width - (polygon_number_width - 1) * overlap
    check_width = (x_min - overlap + width_cover) < x_max

    if check_width:
        polygon_number_width = polygon_number_width + 1

    if check_heigth:
        polygon_number_heigth = polygon_number_heigth + 1

    y_max_update = y_max
    polygons = []

    for pos_width in range(polygon_number_width):
        for pos_heigth in range(polygon_number_heigth):
            x0 = x_min - overlap
            x1 = x0 + model_width
            y0 = y_max_update + overlap
            y1 = y0 - model_height

            polygon = [(x0, y0), (x0, y1), (x1, y1), (x1, y0), (x0, y0)]
            filtro_in = nb_is_inside_parallel(coords.copy(), np.array(polygon).copy())

            if len(np.nonzero(filtro_in)[0]) > 0:
                polygons.append(polygon)

            # update y position
            y_max_update = y1

        # update x position
        x_min = x1
        y_max_update = y_max

    return model_extents, polygons


def add_rectangle_to_dxf(layout, bottom_left, top_right, color=4):
    dict2 = {"layer": "05_TARJETA", "linetype": "CONTINUOUS", "color": color}
    # Coordinates for the rectangle
    x1, y1 = bottom_left
    x2, y2 = top_right

    # Define the 4 corners of the rectangle
    # The order is bottom-left, bottom-right, top-right, top-left
    points = [(x1, y1), (x2, y1), (x2, y2), (x1, y2)]

    # Add the rectangle as a closed LWPOLYLINE
    layout.add_lwpolyline(points, close=True, dxfattribs=dict2)


def add_grid_to_dxf_layout(
    layout,
    rect_width,
    rect_height,
    reference_bounds,
    init_coords,
    intervals=(6, 6),
    label=True,
):
    interval_x = 6
    interval_y = 6
    interval_x, interval_y = intervals

    # Extract rectangle and GeoDataFrame bounds
    # rect_x, rect_y = 20, 15
    rect_x, rect_y, rect_x_end, rect_y_end = init_coords

    # Start and end points for grid lines within the rectangle
    start_x, end_x = rect_x, rect_x + rect_width
    start_y, end_y = rect_y, rect_y + rect_height

    # Calculate the interval between the lines
    interval_length_x = rect_width / interval_x
    interval_length_y = rect_height / interval_y

    # Calculate the positions of the lines
    line_width_positions = [(i + 1) * interval_length_x for i in range(interval_x - 1)]
    line_heigth_positions = [(i + 1) * interval_length_y for i in range(interval_y - 1)]

    x_reference_range = reference_bounds[0] + line_width_positions
    y_reference_range = reference_bounds[1] + line_heigth_positions

    # Draw grid lines
    for pos, x in enumerate(line_width_positions):
        layout.add_line(
            (x, rect_y),
            (x, rect_y + rect_height),
            dxfattribs={
                "color": 9,
                "linetype": "DASHED",
                "color": 9,
                "lineweight": 1.5,
                "ltscale": 5,
            },
        )
        if label:
            layout.add_text(
                str(round(x_reference_range[pos], 2)),
                dxfattribs={"height": 2, "rotation": 0, "style": "ArialStyle"},
            ).set_placement((x, rect_y - 3.5), align=TextEntityAlignment.CENTER)

            layout.add_text(
                str(round(x_reference_range[pos], 2)),
                dxfattribs={"height": 2, "rotation": 0, "style": "ArialStyle"},
            ).set_placement((x, rect_y_end + 1.5), align=TextEntityAlignment.CENTER)  # 580.5

    for pos, y in enumerate(line_heigth_positions):
        layout.add_line(
            (rect_x, y),
            (rect_width + rect_x, y),
            dxfattribs={
                "color": 9,
                "linetype": "DASHED",
                "color": 9,
                "lineweight": 1.5,
                "ltscale": 5,
            },
        )
        if label:
            layout.add_text(
                str(round(x_reference_range[pos], 2)),
                dxfattribs={"height": 2, "rotation": 90, "style": "ArialStyle"},
            ).set_placement((rect_x - 1.5, y), align=TextEntityAlignment.CENTER)

            layout.add_text(
                str(round(x_reference_range[pos], 2)),
                dxfattribs={"height": 2, "rotation": 90, "style": "ArialStyle"},
            ).set_placement((rect_width + 2 + 1.5 + 20, y), align=TextEntityAlignment.CENTER)


def create_north_arrow_block(doc, block_name="NorthArrow", size=4, text_size=5):
    """
    Create a reusable block representing a north arrow.

    :param doc: The DXF document.
    :param block_name: The name of the block to be created.
    :param size: The size of the outer triangle in drawing units.
    :param text_size: The height of the 'N' label text.
    """
    # Create a new block definition or use an existing one
    if block_name not in doc.blocks:
        block = doc.blocks.new(name=block_name)
    else:
        block = doc.blocks[block_name]

    # Coordinates for the outer triangle
    outer_triangle = [(0, 0), (size, -size * 2), (-size, -size * 2), (0, 0)]

    # Coordinates for the inner triangle (negative space)
    inner_size = size * 0.4  # Adjust the size ratio as needed
    inner_triangle = [
        (0, -inner_size * 2),
        (inner_size, -size * 2),
        (-inner_size, -size * 2),
        (0, -inner_size * 2),
    ]

    # Add the outer triangle as a polyline
    block.add_lwpolyline(outer_triangle, close=True, dxfattribs={"color": 7})  # Black color

    # Add the inner triangle as a polyline
    block.add_lwpolyline(inner_triangle, close=True, dxfattribs={"color": 255})  # White color

    # Add the 'N' text above the triangle
    text_position = (0, text_size)
    block.add_text(
        text="N",
        dxfattribs={
            "insert": text_position,
            "style": "ArialStyle",
            "height": text_size,
            "halign": 1,  # Center horizontal alignment
            "valign": 1,  # Middle vertical alignment
        },
    ).set_placement(text_position, align=TextEntityAlignment.MIDDLE_CENTER)

    return block_name


def create_notes_block(
    doc,
    block_name="NotesBlock",
    width=80,
    height=185,
    text="NOTAS:",
    text_height=2,
    text_style="ArialStyle",
):
    """
    :param doc: The DXF document.
    :param block_name: The name of the block to be created.
    :param width: The width of the block.
    :param height: The height of the block.
    :param text: The label text at the top-left corner.
    :param text_height: The height of the label text.
    :param text_style: The style name for the text.
    """
    # Ensure the text style exists or create it
    if text_style not in doc.styles:
        doc.styles.new(text_style, dxfattribs={"font": "Arial.ttf"})

    # Create a new block or retrieve the existing one
    if block_name not in doc.blocks:
        block = doc.blocks.new(name=block_name)
    else:
        block = doc.blocks[block_name]

    # Add the rectangular border
    border = [(0, 0), (width, 0), (width, height), (0, height), (0, 0)]
    block.add_lwpolyline(border, close=True)

    # Add the "NOTAS:" label at the top-left corner
    block.add_text(
        text="NOTAS:",
        dxfattribs={
            "insert": (2, height - text_height * 2),  # Position near the top-left
            "height": text_height,
            "style": text_style,
            "halign": 1,  # Center alignment
            "valign": 0,  # Bottom vertical alignment
        },
    ).set_placement((2, height - text_height * 2), align=TextEntityAlignment.BOTTOM_LEFT)

    # block.add_mtext('TRAMOS CONTENIDOS EN LA LAMINA:\\P' + str(text),
    #                   dxfattribs={'style': text_style,
    #                               'char_height': 1.8, 'attachment_point': 1,
    #                               'width':75,
    #                               'insert': (2, height - text_height * 4),
    #                               'rotation':0})

    return block_name


def create_notes_mtext(
    doc,
    msp,
    insert_points,
    text,
    h_original,
    text_height=2,
    width=75,
    text_style="ArialStyle",
):
    """
    :param doc: The DXF document.
    :param block_name: The name of the block to be created.
    :param width: The width of the block.
    :param height: The height of the block.
    :param text: The label text at the top-left corner.
    :param text_height: The height of the label text.
    :param text_style: The style name for the text.
    """
    # Ensure the text style exists or create it
    if text_style not in doc.styles:
        doc.styles.new(text_style, dxfattribs={"font": "Arial.ttf"})

    x_insert, y_insert = insert_points

    msp.add_mtext(
        "TRAMOS CONTENIDOS EN LA LAMINA:\\P" + format_intervals(text),
        dxfattribs={
            "style": text_style,
            "char_height": 1.8,
            "attachment_point": 1,
            "width": width,
            "insert": (x_insert + 2, y_insert + h_original - text_height * 4),
            "rotation": 0,
        },
    )


def create_and_scale_scalebar(
    doc,
    block_name="ScaleBar",
    layout_scale="1:500",
    max_real_world_distance=80,
    height=2,
    face_color=7,
    text_style="ArialStyle",
):
    """
    Create a reusable scale bar block in a DXF document with a specified layout scale and real-world length.

    :param doc: The DXF document.
    :param block_name: The name of the block to be created.
    :param layout_scale: The scale in the layout (e.g., "1:500").
    :param max_real_world_distance: The real-world distance the scale bar should represent.
    :param drawing_length: The width of the scale bar in drawing units.
    :param height: The height of the scale bar rectangles.
    :param edge_color: The color index for the border of the scale bar rectangles.
    :param face_color: The color index for filling the scale bar rectangles.
    :param text_style: The style name for the text labels.
    """
    # Ensure the text style is available
    if text_style not in doc.styles:
        doc.styles.new(text_style, dxfattribs={"font": "Arial.ttf"})

    # Parse the scale ratio
    try:
        scale_factor = int(layout_scale.split(":")[1])
    except (ValueError, IndexError):
        print(f"Invalid scale format: {layout_scale}")
        return None

    # Calculate the final scale bar length in drawing units based on the scale factor
    if scale_factor <= 1000:
        scale_length = int(round(max_real_world_distance * 1000 / scale_factor, 0))
    else:
        scale_length = int(round(1000 * scale_factor / max_real_world_distance, 0))

    layout_length = 80

    lower_left_coord = (0, 0)

    # Create the block or retrieve the existing one
    block = doc.blocks.new(name=block_name)

    total_rect = [
        (lower_left_coord[0], lower_left_coord[1]),
        (lower_left_coord[0] + layout_length, lower_left_coord[1]),
        (lower_left_coord[0] + layout_length, lower_left_coord[1] + height),
        (lower_left_coord[0], lower_left_coord[1] + height),
        (lower_left_coord[0], lower_left_coord[1]),
    ]
    block.add_lwpolyline(total_rect, close=True, dxfattribs={"color": face_color})

    # Add left (black) rectangle
    left_rect = [
        (lower_left_coord[0], lower_left_coord[1]),
        (lower_left_coord[0] + layout_length / 3, lower_left_coord[1]),
        (lower_left_coord[0] + layout_length / 3, lower_left_coord[1] + height),
        (lower_left_coord[0], lower_left_coord[1] + height),
        (lower_left_coord[0], lower_left_coord[1]),
    ]
    block.add_lwpolyline(left_rect, close=True, dxfattribs={"color": face_color})

    left_hatch = block.add_hatch(dxfattribs={"color": face_color})
    left_hatch.paths.add_polyline_path(left_rect, is_closed=True)

    # Add right (white) rectangle
    right_rect = [
        (lower_left_coord[0] + layout_length * (2 / 3), lower_left_coord[1]),
        (lower_left_coord[0] + layout_length, lower_left_coord[1]),
        (lower_left_coord[0] + layout_length, lower_left_coord[1] + height),
        (lower_left_coord[0] + layout_length * (2 / 3), lower_left_coord[1] + height),
        (lower_left_coord[0] + layout_length * (2 / 3), lower_left_coord[1]),
    ]
    block.add_lwpolyline(right_rect, close=True, dxfattribs={"color": 7})  # White outline
    right_hatch = block.add_hatch(dxfattribs={"color": 7})
    right_hatch.paths.add_polyline_path(right_rect, is_closed=True)

    # Add left, middle, and right labels
    left_label = "0 m"
    middle_value = round(scale_length // 2 / 10) * 10
    middle_label = f"{middle_value} m"
    right_label = f"{round(scale_length / 10) * 10} m"

    block.add_text(
        text=left_label,
        dxfattribs={
            "insert": (lower_left_coord[0], lower_left_coord[1] - (height * 0.5) - 2),
            "height": 2,
            "style": text_style,
            "halign": 1,  # Center alignment
            "valign": 0,  # Bottom vertical alignment
            "rotation": 0,
        },
    ).set_placement(
        (lower_left_coord[0], lower_left_coord[1] - (height * 0.5) - 2),
        align=TextEntityAlignment.CENTER,
    )

    block.add_text(
        text=middle_label,
        dxfattribs={
            "insert": (
                lower_left_coord[0] + layout_length / 2,
                lower_left_coord[1] - (height * 0.5) - 2,
            ),
            "height": 2,
            "style": text_style,
            "halign": 1,  # Center alignment
            "valign": 0,  # Bottom vertical alignment
            "rotation": 0,
        },
    ).set_placement(
        (
            lower_left_coord[0] + layout_length / 2,
            lower_left_coord[1] - (height * 0.5) - 2,
        ),
        align=TextEntityAlignment.CENTER,
    )

    block.add_text(
        text=right_label,
        dxfattribs={
            "insert": (
                lower_left_coord[0] + layout_length,
                lower_left_coord[1] - (height * 0.5) - 2,
            ),
            "height": 2,
            "style": text_style,
            "halign": 1,  # Center alignment
            "valign": 0,  # Bottom vertical alignment
            "rotation": 0,
        },
    ).set_placement(
        (lower_left_coord[0] + layout_length, lower_left_coord[1] - (height * 0.5) - 2),
        align=TextEntityAlignment.CENTER,
    )

    # Add the "Escala" label
    escala_label = f"Escala 1:{round(int(scale_factor) / 10) * 10}"
    block.add_text(
        text=escala_label,
        dxfattribs={
            "insert": (
                lower_left_coord[0] + layout_length / 2,
                lower_left_coord[1] - (height * 2) - 6,
            ),
            "height": 3.5,
            "style": text_style,
            "halign": 1,  # Center alignment
            "valign": 0,  # Bottom vertical alignment
            "rotation": 0,
        },
    ).set_placement(
        (
            lower_left_coord[0] + layout_length / 2,
            lower_left_coord[1] - (height * 2) - 6,
        ),
        align=TextEntityAlignment.CENTER,
    )

    return block_name


def make_tarjeta_block(doc, layout_content):
    

    line_dict_cyan = {"layer": "05_TARJETA", "color": 4}
    line_dict_red = {"layer": "05_TARJETA", "color": 4}
    line_dict_magenta = {"layer": "05_TARJETA", "color": 6}

    # Create a new block definition named 'RectangleDesign'
    block = doc.blocks.new(name="TARJETA_PYPIPER")

    # ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    # A1 paper size in inches (landscape orientation)
    width_a1 = 841
    height_a1 = 594
    # ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    rect_width = width_a1 - 10
    rect_height = height_a1 - 10
    add_rectangle_to_dxf(layout=block, top_right=(rect_width, rect_height), bottom_left=(15, 10), color=6)
    # ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    block.add_lwpolyline([(0, 30), (0, 0), (30, 0)], dxfattribs=line_dict_magenta)
    block.add_lwpolyline([(0, 594 - 30), (0, 594), (30, 594)], dxfattribs=line_dict_magenta)
    block.add_lwpolyline([(841 - 30, 0), (841, 0), (841, 30)], dxfattribs=line_dict_magenta)
    block.add_lwpolyline([(841 - 30, 594), (841, 594), (841, 594 - 30)], dxfattribs=line_dict_magenta)
    # ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    rect_width = width_a1 - 15
    rect_height = height_a1 - 10 - 5
    add_rectangle_to_dxf(layout=block, top_right=(rect_width, rect_height), bottom_left=(20, 15))
    # ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    rect_width = 65
    rect_height = height_a1 - 10 - 5
    add_rectangle_to_dxf(
        layout=block,
        top_right=(width_a1 - 15, rect_height),
        bottom_left=(width_a1 - 15 - rect_width, 15),
    )
    # ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    rect_width = 65
    rect_height = 195 + 15
    add_rectangle_to_dxf(
        layout=block,
        top_right=(width_a1 - 15, rect_height),
        bottom_left=(width_a1 - 15 - rect_width, 15),
    )
    # ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    rect_width = 65
    rect_height = 210 + 15
    add_rectangle_to_dxf(
        layout=block,
        top_right=(width_a1 - 15, 195 + rect_height),
        bottom_left=(width_a1 - 15 - rect_width, 15 + 195),
    )
    # ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    rect_width = 65
    rect_height = 76 + 15
    add_rectangle_to_dxf(
        layout=block,
        top_right=(width_a1 - 15, 195 + 210 + rect_height),
        bottom_left=(width_a1 - 15 - rect_width, 15 + 195 + 210),
    )
    # ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    rect_width = 22
    rect_height = 210 + 15
    add_rectangle_to_dxf(
        layout=block,
        top_right=(width_a1 - 58, 195 + rect_height),
        bottom_left=(width_a1 - 58 - rect_width, 15 + 195),
    )
    # ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    rect_width = 25
    rect_height = 210 + 15
    add_rectangle_to_dxf(
        layout=block,
        top_right=(width_a1 - 33, 195 + rect_height),
        bottom_left=(width_a1 - 33 - rect_width, 15 + 195),
    )
    # ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    rect_width = 65
    rect_height = 45 + 15
    add_rectangle_to_dxf(
        layout=block,
        top_right=(width_a1 - 15, 195 + 210 + 76 + rect_height),
        bottom_left=(width_a1 - 15 - rect_width, 15 + 195 + 210 + 76),
    )
    # ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    pos = 0
    for width_ in [5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]:
        rect_height = 76
        block.add_lwpolyline(
            [
                (width_a1 - 80 + pos, 195 + 210 + 15),
                (width_a1 - 80 + pos, 195 + 210 + 15 + rect_height),
            ],
            dxfattribs=line_dict_red,
        )
        pos = pos + width_
    # ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    pos = 0
    for width_ in [5, 24, 18]:
        rect_height = 45
        pos = pos + width_
        block.add_lwpolyline(
            [
                (width_a1 - 80 + pos, 15 + 195 + 210 + 76),
                (width_a1 - 80 + pos, 15 + 195 + 210 + 76 + rect_height),
            ],
            dxfattribs=line_dict_cyan,
        )
    # ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    pos = 0
    for width_ in [13, 13, 13, 13]:
        rect_height = 38
        pos = pos + width_
        block.add_lwpolyline(
            [
                (width_a1 - 80 + pos, 15 + 195 + 210 + 76 + 45),
                (width_a1 - 80 + pos, 15 + 195 + 210 + 76 + 45 + rect_height),
            ],
            dxfattribs=line_dict_cyan,
        )
    # ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    block.add_lwpolyline(
        [(width_a1 - 80 + 43, 25), (width_a1 - 80 + 43, 25 + 47)],
        dxfattribs=line_dict_red,
    )
    block.add_lwpolyline(
        [(width_a1 - 80 + 43, 86), (width_a1 - 80 + 43, 86 + 50)],
        dxfattribs=line_dict_red,
    )
    block.add_lwpolyline(
        [(width_a1 - 80 + 43, 158), (width_a1 - 80 + 43, 158 + 45)],
        dxfattribs=line_dict_red,
    )
    block.add_lwpolyline([(width_a1 - 20, 15), (width_a1 - 20, 210)], dxfattribs=line_dict_cyan)
    block.add_lwpolyline([(width_a1 - 77.5, 37), (width_a1 - 77.5, 21 + 153)], dxfattribs=line_dict_cyan)
    block.add_lwpolyline(
        [(width_a1 - 77.5 + 18.5, 37), (width_a1 - 77.5 + 18.5, 21 + 153)],
        dxfattribs=line_dict_cyan,
    )

    block.add_lwpolyline([(783.2, 505), (783.2, 505 + 31.5)], dxfattribs=line_dict_red)
    block.add_lwpolyline([(783.2 + 17.5, 505), (783.2 + 17.5, 505 + 31.5)], dxfattribs=line_dict_red)
    block.add_lwpolyline([(783.2 + 17.5, 505), (783.2 + 17.5, 505 + 31.5)], dxfattribs=line_dict_red)
    block.add_lwpolyline(
        [(783.2 + 17.5 * 2, 505), (783.2 + 17.5 * 2, 505 + 31.5)],
        dxfattribs=line_dict_red,
    )

    # ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    center_point = (772.75, 174)  # Example center point (x, y)
    radius = 9.25  # Example radius
    start_angle = 0  # Example start angle in degrees
    end_angle = 180  # Example end angle in degrees
    block.add_arc(
        center=center_point,
        radius=radius,
        start_angle=start_angle,
        end_angle=end_angle,
        dxfattribs=line_dict_cyan,
    )

    center_point = (772.75, 37)  # Example center point (x, y)
    radius = 9.25  # Example radius
    start_angle = 180  # Example start angle in degrees
    end_angle = 0  # Example end angle in degrees
    block.add_arc(
        center=center_point,
        radius=radius,
        start_angle=start_angle,
        end_angle=end_angle,
        dxfattribs=line_dict_cyan,
    )
    # ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
    if "ArialStyle" not in doc.styles:
        doc.styles.new("ArialStyle", dxfattribs={"font": "Arial.ttf"})

    # Define a new text style using 'romans.shx'
    if "RomanStyle" not in doc.styles:
        doc.styles.new("RomanStyle", dxfattribs={"font": "romans.shx"})

    text_content = layout_content['nombre_responsable_entidad_1']
    insert_point = (808.3, 48.5)
    block.add_text(
        text=text_content,
        dxfattribs={
            "insert": insert_point,
            "height": 2,  # Example text height
            "style": "RomanStyle",
            "halign": 1,  # 1 for center alignment
            "valign": 1,  # 1 for middle vertical alignment
            "rotation": 90,  # Rotate the text by 90 degrees
        },
    ).set_placement(insert_point, align=TextEntityAlignment.CENTER)

    text_content =  layout_content['titulo_responsable_entidad_1']
    insert_point = (808.3 + 3.5, 48.5)
    block.add_text(
        text=text_content,
        dxfattribs={
            "insert": insert_point,
            "height": 2,  # Example text height
            "style": "RomanStyle",
            "halign": 1,  # 1 for center alignment
            "valign": 1,  # 1 for middle vertical alignment
            "rotation": 90,  # Rotate the text by 90 degrees
        },
    ).set_placement(insert_point, align=TextEntityAlignment.CENTER)

    text_content = layout_content['rol_responsable_entidad_1']
    insert_point = (808.3 + 3.5 * 2, 48.5)
    block.add_text(
        text=text_content,
        dxfattribs={
            "insert": insert_point,
            "height": 2,  # Example text height
            "style": "RomanStyle",
            "halign": 1,  # 1 for center alignment
            "valign": 1,  # 1 for middle vertical alignment
            "rotation": 90,  # Rotate the text by 90 degrees
        },
    ).set_placement(insert_point, align=TextEntityAlignment.CENTER)

    text_content = layout_content['nombre_responsable_entidad_2']
    insert_point = (808.3, 111)
    block.add_text(
        text=text_content,
        dxfattribs={
            "insert": insert_point,
            "height": 2,  # Example text height
            "style": "RomanStyle",
            "halign": 1,  # 1 for center alignment
            "valign": 1,  # 1 for middle vertical alignment
            "rotation": 90,  # Rotate the text by 90 degrees
        },
    ).set_placement(insert_point, align=TextEntityAlignment.CENTER)

    text_content = layout_content['titulo_responsable_entidad_2']
    insert_point = (808.3 + 3.5, 111)
    block.add_text(
        text=text_content,
        dxfattribs={
            "insert": insert_point,
            "height": 2,  # Example text height
            "style": "RomanStyle",
            "halign": 1,  # 1 for center alignment
            "valign": 1,  # 1 for middle vertical alignment
            "rotation": 90,  # Rotate the text by 90 degrees
        },
    ).set_placement(insert_point, align=TextEntityAlignment.CENTER)

    text_content = layout_content['rol_responsable_entidad_2']
    insert_point = (808.3 + 3.5 * 2, 111)
    block.add_text(
        text=text_content,
        dxfattribs={
            "insert": insert_point,
            "height": 2,  # Example text height
            "style": "RomanStyle",
            "halign": 1,  # 1 for center alignment
            "valign": 1,  # 1 for middle vertical alignment
            "rotation": 90,  # Rotate the text by 90 degrees
        },
    ).set_placement(insert_point, align=TextEntityAlignment.CENTER)

    text_content = layout_content['nombre_responsable_entidad_3']
    insert_point = (808.3, 180.5)
    block.add_text(
        text=text_content,
        dxfattribs={
            "insert": insert_point,
            "height": 2,  # Example text height
            "style": "RomanStyle",
            "halign": 1,  # 1 for center alignment
            "valign": 1,  # 1 for middle vertical alignment
            "rotation": 90,  # Rotate the text by 90 degrees
        },
    ).set_placement(insert_point, align=TextEntityAlignment.CENTER)

    text_content = layout_content['titulo_responsable_entidad_3']
    insert_point = (808.3 + 3.5, 180.5)
    block.add_text(
        text=text_content,
        dxfattribs={
            "insert": insert_point,
            "height": 2,  # Example text height
            "style": "RomanStyle",
            "halign": 1,  # 1 for center alignment
            "valign": 1,  # 1 for middle vertical alignment
            "rotation": 90,  # Rotate the text by 90 degrees
        },
    ).set_placement(insert_point, align=TextEntityAlignment.CENTER)

    text_content =  layout_content['rol_responsable_entidad_3']
    insert_point = (808.3 + 3.5 * 2, 180.5)
    block.add_text(
        text=text_content,
        dxfattribs={
            "insert": insert_point,
            "height": 2,  # Example text height
            "style": "RomanStyle",
            "halign": 1,  # 1 for center alignment
            "valign": 1,  # 1 for middle vertical alignment
            "rotation": 90,  # Rotate the text by 90 degrees
        },
    ).set_placement(insert_point, align=TextEntityAlignment.CENTER)

    text_content = layout_content['titulo_entidad_1']
    insert_point = (width_a1 - 72 + 4, 153.5 - 22 + 8-10)
    block.add_mtext(
        text_content,
        dxfattribs={
            "style": "ArialStyle",
            "layer": "05_TARJETA",
            "color": 7,
            "char_height": 2.2,
            "attachment_point": 5,
            "width": 95,
            "rotation": 90,
            "insert": insert_point,
        },
    )

 
    

    text_content = "ESTE PLANO ES PROPIEDAD DE EPMAPS. QUEDA EXPRESAMENTE PROHIBIDA SU DIFUSION, COPIA O USO SIN AUTORIZACION ESCRITA DE LA EMPRESA"
    insert_point = (width_a1 - 17, 22)
    block.add_text(
        text=text_content,
        dxfattribs={
            "insert": insert_point,
            "height": 1.2,  # Example text height
            "style": "RomanStyle",
            "halign": 1,  # 1 for center alignment
            "valign": 1,  # 1 for middle vertical alignment
            "rotation": 90,  # Rotate the text by 90 degrees
        },
    ).set_placement(insert_point, align=TextEntityAlignment.LEFT)

    text_content = "P R O Y E C T O : "
    insert_point = (765.5, 212)
    block.add_text(
        text=text_content,
        dxfattribs={
            "insert": insert_point,
            "height": 2.4,  # Example text height
            "style": "ArialStyle",
            "halign": 1,  # 1 for center alignment
            "valign": 1,  # 1 for middle vertical alignment
            "rotation": 90,  # Rotate the text by 90 degrees
        },
    ).set_placement(insert_point, align=TextEntityAlignment.LEFT)

    text_content = "C O N T E N I D O : "
    insert_point = (765.5 + 22.5, 212)
    block.add_text(
        text=text_content,
        dxfattribs={
            "insert": insert_point,
            "height": 2.4,  # Example text height
            "style": "ArialStyle",
            "halign": 1,  # 1 for center alignment
            "valign": 1,  # 1 for middle vertical alignment
            "rotation": 90,  # Rotate the text by 90 degrees
        },
    ).set_placement(insert_point, align=TextEntityAlignment.LEFT)

    text_content = "N O T A S   G E N E R A L E S : "
    insert_point = (width_a1 - 30, 212)
    block.add_text(
        text=text_content,
        dxfattribs={
            "insert": insert_point,
            "layer": "05_TARJETA",
            "color": 3,
            "height": 2.1,  # Example text height
            "style": "ArialStyle",
            "halign": 1,  # 1 for center alignment
            "valign": 1,  # 1 for middle vertical alignment
            "rotation": 90,  # Rotate the text by 90 degrees
        },
    ).set_placement(insert_point, align=TextEntityAlignment.LEFT)

    text_content = "O B S E R V A C I O N E S"
    insert_point = (765, 440)
    block.add_text(
        text=text_content,
        dxfattribs={
            "insert": insert_point,
            "layer": "05_TARJETA",
            "color": 3,
            "height": 2,  # Example text height
            "style": "ArialStyle",
            "halign": 1,  # 1 for center alignment
            "valign": 1,  # 1 for middle vertical alignment
            "rotation": 90,  # Rotate the text by 90 degrees
        },
    ).set_placement(insert_point, align=TextEntityAlignment.LEFT)

    text_content = "R E G I S T R O  /  D I S E Ñ O"
    insert_point = (765, 504.5 - 5)
    block.add_text(
        text=text_content,
        dxfattribs={
            "insert": insert_point,
            "layer": "05_TARJETA",
            "color": 3,
            "height": 2.0,  # Example text height
            "style": "ArialStyle",
            "halign": 1,  # 1 for center alignment
            "valign": 1,  # 1 for middle vertical alignment
            "rotation": 90,  # Rotate the text by 90 degrees
        },
    ).set_placement(insert_point, align=TextEntityAlignment.LEFT)

    #----------------------------------------------------------------------------------------
    text_content = layout_content['nombre_tecnico_responsabilidad_1']
    insert_point = (768.5 + 14 + 3, 497.5 + 7.5)
    block.add_text(
        text=text_content,
        dxfattribs={
            "insert": insert_point,
            "layer": "05_TARJETA",
            "color": 7,
            "height": 1.8,  # Example text height
            "width": 0.8,
            "style": "ArialStyle",
            "halign": 1,  # 1 for center alignment
            "valign": 1,  # 1 for middle vertical alignment
            "rotation": 90,  # Rotate the text by 90 degrees
        },
    ).set_placement(insert_point, align=TextEntityAlignment.LEFT)
    
    text_content = layout_content['nombre_tecnico_firma_1']
    insert_point = (768.5, 497.5)
    block.add_text(
        text=text_content,
        dxfattribs={
            "insert": insert_point,
            "layer": "05_TARJETA",
            "color": 3,
            "height": 1.8,  # Example text height
            "width": 0.8,
            "style": "ArialStyle",
            "halign": 1,  # 1 for center alignment
            "valign": 1,  # 1 for middle vertical alignment
            "rotation": 90,  # Rotate the text by 90 degrees
        },
    ).set_placement(insert_point, align=TextEntityAlignment.LEFT)
    
    #----------------------------------------------------------------------------------------
    text_content = layout_content['nombre_tecnico_firma_2']
    insert_point = (768.5 + 31.5 - 7.2, 497.5)
    block.add_text(
        text=text_content,
        dxfattribs={
            "insert": insert_point,
            "layer": "05_TARJETA",
            "color": 3,
            "height": 1.8,  # Example text height
            "width": 0.8,
            "style": "ArialStyle",
            "halign": 1,  # 1 for center alignment
            "valign": 1,  # 1 for middle vertical alignment
            "rotation": 90,  # Rotate the text by 90 degrees
        },
    ).set_placement(insert_point, align=TextEntityAlignment.LEFT)
    
    text_content = layout_content['nombre_tecnico_responsabilidad_2']
    insert_point = (768.5 + 31.5 - 7.2 - 5.8 + 13 + 3, 497.5 + 7.5)
    block.add_text(
        text=text_content,
        dxfattribs={
            "insert": insert_point,
            "layer": "05_TARJETA",
            "color": 7,
            "height": 1.8,  # Example text height
            "width": 0.8,
            "style": "ArialStyle",
            "halign": 1,  # 1 for center alignment
            "valign": 1,  # 1 for middle vertical alignment
            "rotation": 90,  # Rotate the text by 90 degrees
        },
    ).set_placement(insert_point, align=TextEntityAlignment.LEFT)
    
    
    
    #----------------------------------------------------------------------------------------
    text_content =layout_content['nombre_tecnico_firma_3']
    insert_point = (768.5 + 31.5 - 7.2  +  18, 497.5)
    block.add_text(
        text=text_content,
        dxfattribs={
            "insert": insert_point,
            "layer": "05_TARJETA",
            "color": 3,
            "height": 1.8,  # Example text height
            "width": 0.8,
            "style": "ArialStyle",
            "halign": 1,  # 1 for center alignment
            "valign": 1,  # 1 for middle vertical alignment
            "rotation": 90,  # Rotate the text by 90 degrees
        },
    ).set_placement(insert_point, align=TextEntityAlignment.LEFT)
    
    text_content = layout_content['nombre_tecnico_responsabilidad_3']
    insert_point = (768.5 + 31.5 - 7.2  +  18 + 5.8 + 0.9 + 3, 497.5 + 7.5)
    block.add_text(
        text=text_content,
        dxfattribs={
            "insert": insert_point,
            "layer": "05_TARJETA",
            "color": 7,
            "height": 1.8,  # Example text height
            "width": 0.8,
            "style": "ArialStyle",
            "halign": 1,  # 1 for center alignment
            "valign": 1,  # 1 for middle vertical alignment
            "rotation": 90,  # Rotate the text by 90 degrees
        },
    ).set_placement(insert_point, align=TextEntityAlignment.LEFT)
    #----------------------------------------------------------------------------------------




    # text_content = "N U M E R O:"
    # insert_point = (763.5 +13 * 4, 546.5 - 4)
    # block.add_text(
    #     text=text_content,
    #     dxfattribs={
    #         'insert': insert_point,
    #         'layer': '05_TARJETA',
    #         'color': 3,
    #         'height': 1.8,  # Example text height
    #         'width': 0.8,
    #         'style': 'ArialStyle',
    #         'halign': 1,  # 1 for center alignment
    #         'valign': 1,  # 1 for middle vertical alignment
    #         'rotation': 90  # Rotate the text by 90 degrees
    #     }).set_placement(insert_point, align=TextEntityAlignment.LEFT)

    # Common text attributes
    text_attributes = {
        "layer": "05_TARJETA",
        "color": 3,
        "height": 1.8,
        "width": 0.8,
        "style": "ArialStyle",
        "halign": 1,
        "valign": 1,
        "rotation": 90,
    }

    # Initial insertion point coordinates
    start_x = 763.5
    start_y = 546.5 - 4
    x_offset = 13

    # Text contents
    texts = [
        "F E C H A :",
        "D I S E Ñ O :",
        "A R C H I V O   C A D:",
        "E S C A L A:",
        "N U M E R O:",
    ]

    # Assuming 'block' is a BlockLayout object from the 'ezdxf' library
    for i, text_content in enumerate(texts):
        insert_point = (start_x + x_offset * i, start_y)
        text_entity = block.add_text(
            text=text_content,
            dxfattribs={
                **text_attributes,  # Expand the common attributes into the dict
                "insert": insert_point,
            },
        )
        text_entity.set_placement(insert_point, align=TextEntityAlignment.LEFT)

    text_content = layout_content['titulo_general'].upper()
    insert_point = (773, 250)
    block.add_mtext(
        text_content,
        dxfattribs={
            "style": "ArialStyle",
            "layer": "05_TARJETA",
            "color": 3,
            "char_height": 2.7,
            "attachment_point": 4,
            "width": 170,
            "rotation": 90,
            "insert": insert_point,
        },
    )
    
    
    

    text_content = "1) TODAS LAS DIMENSIONES Y COORDENADAS ESTAN EN METROS Y PREVALECEN A LA ESCALA\n2) SE DEBERA VERFICAR EN CAMPO LAS DIMENSIONES AQUI EXPUESTAS\n3) SISTEMA DE REFERENCIA ESPACIAL: SIRES-DMQ\n4) TODA MODIFICACION SE HARA CONSTAR EN REGISTRO/DISEÑO CON FIRMA DE RESPONSABILIDAD"
    insert_point = (width_a1 - 30 + 3.5, 212)
    block.add_mtext(
        text_content,
        dxfattribs={
            "style": "ArialStyle",
            "layer": "05_TARJETA",
            "color": 3,
            "char_height": 1.5,
            "attachment_point": 1,
            "width": 120,
            "rotation": 90,
            "insert": insert_point,
        },
    )


def make_ubicacion_block(doc, polygons: List[np.ndarray], max_height: float):
    """
    Create a reusable block with the name 'LAYOUT_UBICACION', containing labeled polygons.
    """
    # Create the block
    block = doc.blocks.new(name="LAYOUT_UBICACION")
    line_dict = {
        "layer": "06_UBICACION",
        "color": 161,
        "lineweight": 5,
    }

    if "ArialStyle" not in doc.styles:
        doc.styles.new("ArialStyle", dxfattribs={"font": "Arial.ttf"})

    # Calculate the overall bounding box for all polygons
    polygon_coords = np.concatenate(polygons).T
    min_x, max_x = np.min(polygon_coords[0]), np.max(polygon_coords[0])
    min_y, max_y = np.min(polygon_coords[1]), np.max(polygon_coords[1])
    real_width = max_x - min_x
    real_height = max_y - min_y

    # Calculate the initial scale based on width
    scale = int(105 * 0.8) / real_width  # Base scale for width

    # Adjust the scale to respect the max_height constraint
    if real_height * scale > max_height:
        scale = max_height / real_height  # Adjust scale for max height

    # Define the initial base point (desired insertion point)
    x_init = 656
    y_init = 579
    x_end = x_init + 105
    text_height = 2.5 / scale

    # Adjust polygons relative to the new insertion point
    center = np.mean([min_x, max_x]), np.mean([min_y, max_y])
    adjusted_polygons = [np.array([(x - center[0], y - center[1]) for x, y in polygon]) for polygon in polygons]

    min_label_y = []
    mean_label_x = []

    # Loop through each polygon and add to the block
    for index, polygon in enumerate(adjusted_polygons):
        block.add_lwpolyline(polygon, close=True, dxfattribs=line_dict)
        label_x = sum(x for x, y in polygon) / len(polygon)
        label_y = sum(y for x, y in polygon) / len(polygon)
        insert_point = (label_x + (text_height / 1.4) / 2, label_y - text_height)

        block.add_text(
            text=str(index + 1),
            dxfattribs={
                "insert": insert_point,
                "height": text_height,
                "style": "ArialStyle",
                "halign": 1,
                "valign": 1,
                "rotation": 0,
                "color": 161,
            },
        ).set_placement(insert_point, align=TextEntityAlignment.CENTER)

        min_label_y.append(np.min(polygon.T[1]))
        mean_label_x.append(np.mean(polygon.T[0]))

    # Add "UBICACION" title
    scale_height = scale * real_height
    scale_insert_point = ((x_end + x_init) / 2, y_init - 10 - scale_height / 2)
    title_x = np.mean(mean_label_x)
    title_y = np.min(min_label_y) - 10 / scale
    title_text_height = 3.5 / scale
    block.add_text(
        text="UBICACION",
        dxfattribs={
            "insert": (title_x, title_y),
            "height": title_text_height,
            "style": "ArialStyle",
            "halign": 1,
            "valign": 0,
            "rotation": 0,
            "color": 161,
        },
    ).set_placement((title_x, title_y), align=TextEntityAlignment.CENTER)

    # Return the original output
    min_y, min_x = np.min([np.min(_.T[1]) for _ in adjusted_polygons]), np.min([np.min(_.T[0]) for _ in adjusted_polygons])
    max_x, max_y = np.max([np.max(_.T[1]) for _ in adjusted_polygons]), np.max([np.max(_.T[0]) for _ in adjusted_polygons])

    return (scale_insert_point, scale, adjusted_polygons, (title_x, title_y), (min_x, min_y), (max_y, max_x))


def transform_polygon_dxf(
    polygon: List[Tuple[float, float]],
    insertion_point: Tuple[float, float],
    scale: float,
) -> List[Tuple[float, float]]:
    """
    Transform polygon coordinates based on a given insertion point and scale factor.

    :param polygon: Original polygon coordinates.
    :param insertion_point: Point where the polygon will be placed.
    :param scale: Scale factor to apply.
    :return: Transformed polygon coordinates.
    """
    return [(insertion_point[0] + x * scale, insertion_point[1] + y * scale) for x, y in polygon]


def add_hatch_to_new_polygon(
    layout,
    polygon: List[Tuple[float, float]],
    insertion_point: Tuple[float, float],
    scale: float,
):
    """
    Add an ANSI31 hatch pattern in blue to a new polygon in a layout.

    :param layout: The layout to which the hatch will be added.
    :param polygon: The polygon coordinates for the hatch.
    :param insertion_point: The insertion point for the polygon.
    :param scale: Scale factor for the polygon.
    """
    # Transform the polygon to match the layout's insertion point and scale
    transformed_polygon = transform_polygon_dxf(polygon, insertion_point, scale)

    # Add the hatch pattern in blue with an ANSI31 pattern
    hatch = layout.add_hatch(color=5, dxfattribs={"pattern_name": "ANSI31"})  # Blue color = 5
    hatch.paths.add_polyline_path(transformed_polygon, is_closed=True)
    # Adjust the pattern scale to make the lines visible
    hatch.set_pattern_fill(angle=0, scale=0.5, name="ANSI31", color=5)


def make_symbology_block(doc):
    appsettings.show_lineweight(doc=doc, state=True)
    doc.units = ezdxf.units.M

    dict_existente = {
        "layer": "01_POZO_EXISTENTE",
        "linetype": "DASHDOT",
        "color": 102,
        "lineweight": 30,
        "ltscale": 2.5,
    }
    dict2 = {
        "layer": "01_POZO",
        "linetype": "CONTINUOUS",
        "color": 11,
        "lineweight": 30,
        "ltscale": 5,
    }
    dict_interferencia = {
        "layer": "02_INTERFERENCIA",
        "linetype": "DOT2",
        "color": 6,
        "lineweight": 50,
        "ltscale": 2.5,
    }

    # "CREAR BLOQUES PARA INSERTAR"
    radio, h_flecha, b_flecha = 1.4, 2.5, 0.65
    d1 = 4.5
    d2 = 12.5
    d3 = 0.2
    letra = 1.8
    letra1 = 2.51

    if not "B_SAN" in doc.blocks:
        B_SAN = doc.blocks.new(name="B_SAN")
        B_SAN.add_circle(center=(0, 0), radius=radio, dxfattribs=dict2)
        hatch = B_SAN.add_hatch(color=LINECOLOR["sanitario"])
        hatch.paths.add_polyline_path(
            [
                (-h_flecha - radio, 0),
                (-h_flecha - radio, -b_flecha),
                (0 - radio, 0),
                (-h_flecha - radio, b_flecha),
            ],
            is_closed=1,
        )

    if not "B_PLU" in doc.blocks:
        B_PLU = doc.blocks.new(name="B_PLU")
        B_PLU.add_circle(center=(0, 0), radius=radio, dxfattribs=dict2)
        hatch = B_PLU.add_hatch(color=LINECOLOR["pluvial"])
        hatch.paths.add_polyline_path(
            [
                (-h_flecha - radio, 0),
                (-h_flecha - radio, -b_flecha),
                (0 - radio, 0),
                (-h_flecha - radio, b_flecha),
            ],
            is_closed=1,
        )

    if not "B_COMB" in doc.blocks:
        B_COMB = doc.blocks.new(name="B_COMB")
        B_COMB.add_circle(center=(0, 0), radius=radio, dxfattribs=dict2)
        hatch = B_COMB.add_hatch(color=LINECOLOR["combinado"])
        hatch.paths.add_polyline_path(
            [
                (-h_flecha - radio, 0),
                (-h_flecha - radio, -b_flecha),
                (0 - radio, 0),
                (-h_flecha - radio, b_flecha),
            ],
            is_closed=1,
        )

    if not "B_POZO" in doc.blocks:
        B_POZO = doc.blocks.new(name="B_POZO")
        B_POZO.add_circle(center=(0, 0), radius=radio, dxfattribs=dict2)
        B_POZO.add_lwpolyline([(-1.30 * radio, -radio), (-1.30 * radio, radio)], dxfattribs=dict2)

    if not "B_0" in doc.blocks:
        B_0 = doc.blocks.new(name="B_0")
        B_0.add_lwpolyline([(0, 0), (d1, d1 - d3), (d2, d1 - d3)], dxfattribs=dict2)
        B_0.add_attdef(
            "NAME",
            (d1, d1),
            dxfattribs={"height": letra, "color": 3, "style": "Letra_Arial"},
        )
        B_0.add_attdef(
            "POZO",
            (d1, d1 + letra + 2 * d3),
            dxfattribs={"height": letra1, "color": 4, "style": "Letra_Arial"},
        )
        B_0.add_attdef(
            "NORTE",
            (d1, d1 + letra + 2 * d3 + letra1 + 2 * d3),
            dxfattribs={"height": letra, "color": 150, "style": "Letra_Arial"},
        )
        B_0.add_attdef(
            "ESTE",
            (d1, d1 + letra + 2 * d3 + letra1 + 2 * d3 + letra + 2 * d3),
            dxfattribs={"height": letra, "color": 150, "style": "Letra_Arial"},
        )
        B_0.add_attdef(
            "OBSERVACION",
            (
                d1,
                d1 + letra + 2 * d3 + letra1 + 2 * d3 + letra + 2 * d3 + letra + 2 * d3,
            ),
            dxfattribs={"height": letra, "color": 30, "style": "Letra_Arial"},
        )

    if not "B_INTERFERENCIA" in doc.blocks:
        # bloque de interferencias
        interferencia_dist = h_flecha * 1
        interferencia_dist_rigth = interferencia_dist * 3
        INTERFERENCIA_EXISTENTE = doc.blocks.new(name="B_INTERFERENCIA")
        INTERFERENCIA_EXISTENTE.add_lwpolyline([(0, 0), (interferencia_dist_rigth, 0)], dxfattribs=dict_interferencia)
        hatch = INTERFERENCIA_EXISTENTE.add_hatch(color=LINECOLOR["interferencia"])
        edge_path = hatch.paths.add_edge_path()
        edge_path.add_ellipse((0, 0), major_axis=(0, 0.45), ratio=1)
        edge_path.add_ellipse((interferencia_dist_rigth, 0), major_axis=(0, 0.45), ratio=1)

        INTERFERENCIA_EXISTENTE.add_attdef(
            "INTERFERENCIA",
            (interferencia_dist_rigth * 1.2, 2 * letra + 2 * d3),
            dxfattribs={"height": letra, "color": 6, "style": "Letra_Arial"},
        )
        INTERFERENCIA_EXISTENTE.add_attdef(
            "DIMENSION",
            (interferencia_dist_rigth * 1.2, letra + d3),
            dxfattribs={"height": letra, "color": 6, "style": "Letra_Arial"},
        )
        INTERFERENCIA_EXISTENTE.add_attdef(
            "ELEVACION",
            (interferencia_dist_rigth * 1.2, 0),
            dxfattribs={"height": letra, "color": 6, "style": "Letra_Arial"},
        )
        INTERFERENCIA_EXISTENTE.add_attdef(
            "COORDENADAS",
            (interferencia_dist_rigth * 1.2, -letra - d3),
            dxfattribs={"height": letra, "color": 6, "style": "Letra_Arial"},
        )
        INTERFERENCIA_EXISTENTE.add_attdef(
            "REFERENCIA",
            (interferencia_dist_rigth * 1.2, -2 * letra - 2 * d3),
            dxfattribs={"height": letra, "color": 6, "style": "Letra_Arial"},
        )

    B_POZO_EXISTENTE = doc.blocks.new(name="B_POZO_EXISTENTE_SYMBOLOGIA")
    B_POZO_EXISTENTE.add_circle(center=(0, 0), radius=radio, dxfattribs=dict_existente)
    hatch = B_POZO_EXISTENTE.add_hatch(color=102)
    hatch.paths.add_polyline_path(
        [
            (-h_flecha - radio, 0),
            (-h_flecha - radio, -b_flecha),
            (0 - radio, 0),
            (-h_flecha - radio, b_flecha),
        ],
        is_closed=1,
    )
    edge_path = hatch.paths.add_edge_path()
    edge_path.add_ellipse((0, 0), major_axis=(0, radio - 0.25 * radio), ratio=1)

    # Create a new block definition
    block_name = "SIMBOLOGIA"
    block = doc.blocks.new(name=block_name)

    # sanitario
    # ----------------------------------------------------------------------------------------------------------------------
    a0 = LAYER["sanitario"]
    a1 = LINECOLOR["sanitario"]
    a2 = LINETYPES["sanitario"]
    a3 = LINEWEIGHT["sanitario"]

    dict1 = {"layer": a0, "color": a1, "linetype": a2, "lineweight": a3, "ltscale": 2.5}
    block.add_lwpolyline([(20, 0), (0, 0)], close=False, dxfattribs=dict1)
    block.add_blockref("B_SAN", insert=(23, 0), dxfattribs={"xscale": 1, "yscale": 1, "rotation": 0})
    block.add_text(
        text="SANITARIO",
        dxfattribs={
            "insert": (32, -2),  # Adjust relative to the block's center
            "height": 2,
            "style": "ArialStyle",
            "halign": 1,  # Center alignment
            "valign": 0,  # Bottom vertical alignment
            "rotation": 0,
        },
    ).set_placement((32, 0), align=TextEntityAlignment.MIDDLE_LEFT)

    # pluvial
    # ----------------------------------------------------------------------------------------------------------------------
    a0 = LAYER["pluvial"]
    a1 = LINECOLOR["pluvial"]
    a2 = LINETYPES["pluvial"]
    a3 = LINEWEIGHT["pluvial"]

    dict1 = {"layer": a0, "color": a1, "linetype": a2, "lineweight": a3, "ltscale": 2.5}
    block.add_lwpolyline([(20, -6), (0, -6)], close=False, dxfattribs=dict1)
    block.add_blockref("B_PLU", insert=(23, -6), dxfattribs={"xscale": 1, "yscale": 1, "rotation": 0})
    block.add_text(
        text="PLUVIAL",
        dxfattribs={
            "insert": (32, -2 - 6),  # Adjust relative to the block's center
            "height": 2,
            "style": "ArialStyle",
            "halign": 1,  # Center alignment
            "valign": 0,  # Bottom vertical alignment
            "rotation": 0,
        },
    ).set_placement((32, 0 - 6), align=TextEntityAlignment.MIDDLE_LEFT)

    # combinado
    # ----------------------------------------------------------------------------------------------------------------------
    a0 = LAYER["combinado"]
    a1 = LINECOLOR["combinado"]
    a2 = LINETYPES["combinado"]
    a3 = LINEWEIGHT["combinado"]

    dict1 = {"layer": a0, "color": a1, "linetype": a2, "lineweight": a3, "ltscale": 2.5}
    block.add_lwpolyline([(20, -12), (0, -12)], close=False, dxfattribs=dict1)
    block.add_blockref("B_COMB", insert=(23, -12), dxfattribs={"xscale": 1, "yscale": 1, "rotation": 0})
    block.add_text(
        text="COMBINADO",
        dxfattribs={
            "insert": (32, -2 - 12),  # Adjust relative to the block's center
            "height": 2,
            "style": "ArialStyle",
            "halign": 1,  # Center alignment
            "valign": 0,  # Bottom vertical alignment
            "rotation": 0,
        },
    ).set_placement((32, 0 - 12), align=TextEntityAlignment.MIDDLE_LEFT)

    # existente
    # ----------------------------------------------------------------------------------------------------------------------
    block.add_lwpolyline([(20, -18), (0, -18)], close=False, dxfattribs=dict_existente)
    block.add_auto_blockref(
        "B_POZO_EXISTENTE_SYMBOLOGIA",
        (23, -18),
        {},
        dxfattribs={"xscale": 1, "yscale": 1, "rotation": 0},
    )
    block.add_text(
        text="EXISTENTE",
        dxfattribs={
            "insert": (32, -2 - 18),  # Adjust relative to the block's center
            "height": 2,
            "style": "ArialStyle",
            "halign": 1,  # Center alignment
            "valign": 0,  # Bottom vertical alignment
            "rotation": 0,
        },
    ).set_placement((32, 0 - 18), align=TextEntityAlignment.MIDDLE_LEFT)

    # elevacion  entrada y salida
    # ----------------------------------------------------------------------------------------------------------------------
    a0 = LAYER["sanitario"]
    a1 = LINECOLOR["sanitario"]
    a2 = LINETYPES["sanitario"]
    a3 = LINEWEIGHT["sanitario"]

    dict1 = {"layer": a0, "color": a1, "linetype": a2, "lineweight": a3, "ltscale": 2.5}
    block.add_lwpolyline([(20, -28), (0, -28)], close=False, dxfattribs=dict1)
    block.add_auto_blockref("B_SAN", (23, -28), {}, dxfattribs={"xscale": 1, "yscale": 1, "rotation": 0})
    block.add_blockref("B_pozo", insert=(0, -28), dxfattribs={"xscale": 1, "yscale": 1, "rotation": 0})
    block.add_mtext(
        "ELEVACION DE FONDO\\PENTRADA Y SALIDA ",
        dxfattribs={
            "style": "ArialStyle",
            "char_height": 2,
            "attachment_point": 1,
            "width": 50,
            "rotation": 0,
            "insert": (32, -28 + 2.5),
        },
    )

    block.add_text(
        "2385.265",
        dxfattribs={
            "style": "Letra_Arial",
            "layer": "01_COTA_ENTRADA",
            "color": 41,
            "rotation": 0,
            "height": letra,
        },
    ).set_placement((0, -24), align=TextEntityAlignment.TOP_LEFT)
    block.add_text(
        "2384.143",
        dxfattribs={
            "style": "Letra_Arial",
            "layer": "01_COTA_ENTRADA",
            "color": 41,
            "rotation": 0,
            "height": letra,
        },
    ).set_placement((19, -32.5), align=TextEntityAlignment.BOTTOM_RIGHT)

    # elevacion  tapa
    # ----------------------------------------------------------------------------------------------------------------------
    a0 = LAYER["sanitario"]
    a1 = LINECOLOR["sanitario"]
    a2 = LINETYPES["sanitario"]
    a3 = LINEWEIGHT["sanitario"]

    dict1 = {"layer": a0, "color": a1, "linetype": a2, "lineweight": a3, "ltscale": 2.5}
    block.add_lwpolyline([(3, -50), (0, -50)], close=False, dxfattribs=dict1)
    block.add_auto_blockref(
        "B_0",
        (3, -50),
        values={
            "OBSERVACION": "OBSERVACIONES",
            "NAME": "Z 2880.397",
            "POZO": "0.10",
            "NORTE": "N 9969984.45",
            "ESTE": "E 773235.44",
        },
        dxfattribs={"xscale": 1, "yscale": 1, "rotation": 0},
    )

    block.add_auto_blockref("B_SAN", (3, -50), {}, dxfattribs={"xscale": 1, "yscale": 1, "rotation": 0})
    block.add_mtext(
        "OBSERVACIONES\\PCOORDENADAS\\PNOMBRE\\PELEVACION TAPA ",
        dxfattribs={
            "style": "ArialStyle",
            "char_height": 2,
            "attachment_point": 1,
            "width": 50,
            "rotation": 0,
            "insert": (32, -48 + 10),
        },
    )

    # INTERFERENCIAS
    interference_dict = {
        "INTERFERENCIA": "INTERFERENCIA",
        "DIMENSION": "D: 0.54 m",
        "ELEVACION": "elev: 2569.314",
        "COORDENADAS": "coord:732616,9746461",
        "REFERENCIA": "Referencia Interferencia",
    }

    block.add_auto_blockref(
        "B_INTERFERENCIA",
        insert=(0, -58),
        values=interference_dict,
        dxfattribs={"xscale": 1, "yscale": 1, "rotation": 0},
    )

    block.add_text(
        text="INTERFERENCIAS",
        dxfattribs={
            "insert": (32, -2 - 58),  # Adjust relative to the block's center
            "height": 2,
            "style": "ArialStyle",
            "halign": 1,  # Center alignment
            "valign": 0,  # Bottom vertical alignment
            "rotation": 0,
        },
    ).set_placement((32, 0 - 58), align=TextEntityAlignment.MIDDLE_LEFT)

    dict1 = {
        "layer": a0,
        "color": 250,
        "linetype": "DASHED",
        "lineweight": 0.5,
        "ltscale": 2.5,
    }
    block.add_lwpolyline([(20, -68), (0, -68)], close=False, dxfattribs=dict1)
    block.add_mtext(
        "INTERFERENCIA\\PALCANTARILLADO EXISTENTE",
        dxfattribs={
            "style": "ArialStyle",
            "char_height": 2,
            "attachment_point": 4,
            "width": 50,
            "rotation": 0,
            "insert": (32, -68),
        },
    )

    dict1 = {"layer": a0, "color": 249, "lineweight": 0.5, "ltscale": 2.5}
    block.add_lwpolyline([(20, -68 - 8), (0, -68 - 8)], close=False, dxfattribs=dict1)
    block.add_mtext(
        "INTERFERENCIA\\PAGUA POTABLE EXISTENTE",
        dxfattribs={
            "style": "ArialStyle",
            "char_height": 2,
            "attachment_point": 4,
            "width": 50,
            "rotation": 0,
            "insert": (32, -68 - 8),
        },
    )

    block.add_text(
        text="SIMBOLOGIA",
        dxfattribs={
            "insert": (25, -2 - 72),  # Adjust relative to the block's center
            "height": 3.5,
            "style": "ArialStyle",
            "halign": 1,  # Center alignment
            "valign": 0,  # Bottom vertical alignment
            "rotation": 0,
        },
    ).set_placement((25, 0 - 72 - 6 - 8 - 8), align=TextEntityAlignment.CENTER)

    return 94


def add_benchmark_table_block(
    doc,
    block_name="BenchmarkTable",
    row_height=6,
    column_widths=(10, 15, 15, 15, 40),
    headers=None,
    points=None,
):
    """
    Add a benchmark table as a block in the DXF document with the insertion point at the top-left corner.

    :param doc: The DXF document.
    :param block_name: The name of the block that will be created.
    :param row_height: The height of each row in the table.
    :param column_widths: A tuple defining the widths of each column.
    :param headers: A list of strings for the column headers.
    :param points: A list of points, each being a tuple (name, north, east, elevation, location).
    """
    # Create a new block or retrieve an existing one
    if block_name not in doc.blocks:
        block = doc.blocks.new(name=block_name)
    else:
        block = doc.blocks[block_name]

    # Define the default headers if not provided
    if headers is None:
        headers = ["PUNTO", "NORTE", "ESTE", "COTA", "UBICACION"]

    # Define the default rows if no points are provided
    if points is None:
        points = [
            ("BM-1", "", "", "", ""),
            ("BM-2", "", "", "", ""),
            ("BM-3", "", "", "", ""),
            ("BM-4", "", "", "", ""),
        ]

    num_rows = len(points) + 1  # Add one row for the headers
    total_width = sum(column_widths)
    total_height = row_height * num_rows

    # Draw the outer border
    block.add_lwpolyline(
        [
            (0, -total_height),
            (total_width, -total_height),
            (total_width, 0),
            (0, 0),
            (0, -total_height),
        ],
        close=True,
    )

    # Draw the horizontal lines (rows)
    for i in range(num_rows + 1):
        block.add_line((0, -i * row_height), (total_width, -i * row_height))

    # Draw the vertical lines (columns)
    current_x = 0
    for width in column_widths:
        current_x += width
        block.add_line((current_x, 0), (current_x, -total_height))

    # Add the headers to the first row
    current_x = 0
    for header, width in zip(headers, column_widths):
        insert_point = (current_x + width / 2, -row_height / 2)
        block.add_text(
            text=header,
            dxfattribs={
                "insert": insert_point,
                "height": 1.8,
                "halign": 1,  # Center alignment
                "valign": 1,  # Middle vertical alignment
                "style": "ArialStyle",
            },
        ).set_placement(insert_point, align=TextEntityAlignment.MIDDLE_CENTER)
        current_x += width

    # Add the data to the subsequent rows
    for row_index, point_data in enumerate(points, start=1):
        current_x = 0
        for data, width in zip(point_data, column_widths):
            insert_point = (current_x + width / 2, -(row_index + 0.5) * row_height)
            block.add_text(
                text=data,
                dxfattribs={
                    "insert": insert_point,
                    "height": 1.5,
                    "halign": 1,  # Center alignment
                    "valign": 1,  # Middle vertical alignment
                    "style": "ArialStyle",
                },
            ).set_placement(insert_point, align=TextEntityAlignment.MIDDLE_CENTER)
            current_x += width

    # Add the "REFERENCIAS" text below the table
    arial_style_name = "ArialStyle"
    if arial_style_name not in doc.styles:
        doc.styles.new(arial_style_name, dxfattribs={"font": "Arial.ttf"})

    block.add_text(
        text="REFERENCIAS",
        dxfattribs={
            "insert": (
                total_width / 2,
                -total_height - 10,
            ),  # Adjust -10 to position the text below the table
            "height": 3,
            "style": arial_style_name,
            "halign": 1,  # Center alignment
            "valign": 1,  # Middle vertical alignment
        },
    ).set_placement((total_width / 2, -total_height - 10), align=TextEntityAlignment.MIDDLE_CENTER)

    return total_height


def add_date_and_name(layout, layout_scale, contenido):
    now = datetime.now()

    # Convert to a string in day-month-year format
    formatted_date = now.strftime("%m-%Y")

    layout.add_text(
        text=formatted_date,
        dxfattribs={
            "insert": (767, 546),  # Adjust relative to the block's center
            "height": 2,
            "style": "ArialStyle",
            "halign": 1,  # Center alignment
            "valign": 0,  # Bottom vertical alignment
            "rotation": 90,
        },
    ).set_placement((766, 546), align=TextEntityAlignment.MIDDLE_LEFT)

    layout.add_text(
        text=layout_scale,
        dxfattribs={
            "insert": (7766 + 40, 546),  # Adjust relative to the block's center
            "height": 2,
            "style": "ArialStyle",
            "halign": 1,  # Center alignment
            "valign": 0,  # Bottom vertical alignment
            "rotation": 90,
        },
    ).set_placement((766 + 40, 546), align=TextEntityAlignment.MIDDLE_LEFT)

    layout.add_mtext(
        contenido,
        dxfattribs={
            "style": "Letra_Arial",
            "layer": "05_TARJETA",
            "color": 3,
            "char_height": 3,
            "attachment_point": 1,
            "width": 170,
            "insert": (792, 242),
            "rotation": 90,
        },
    )


def add_codigo_numero(layout, layout_number, codigo):
    layout.add_text(
        text=codigo + str(layout_number),
        dxfattribs={
            "insert": (7766 + 40 + 15, 546),  # Adjust relative to the block's center
            "height": 2,
            "style": "ArialStyle",
            "halign": 1,  # Center alignment
            "valign": 0,  # Bottom vertical alignment
            "rotation": 90,
        },
    ).set_placement((766 + 40 + 15, 546), align=TextEntityAlignment.MIDDLE_LEFT)


def is_evenly_distributed(polygon_coords, point_coords):
    """
    Check if the points are evenly distributed or occupy a rational extent of the polygon.
    Returns True if the distribution is satisfactory, otherwise False.
    """
    # Create the polygon object
    polygon_geom = Polygon(polygon_coords)

    # Calculate the bounding box of the polygon
    minx, miny, maxx, maxy = polygon_geom.bounds

    # Divide the polygon bounding box into a 2x2 grid (quadrants)
    midx = (minx + maxx) / 2
    midy = (miny + maxy) / 2

    # Define the four quadrants using Polygon objects
    quadrants = {
        "Q1": np.array([(midx, midy), (midx, maxy), (maxx, maxy), (maxx, midy), (midx, midy)]),
        "Q2": np.array([(minx, midy), (minx, maxy), (midx, maxy), (midx, midy), (minx, midy)]),
        "Q3": np.array([(minx, miny), (minx, midy), (midx, midy), (midx, miny), (minx, miny)]),
        "Q4": np.array([(midx, miny), (midx, midy), (maxx, midy), (maxx, miny), (midx, miny)]),
    }

    # Count the number of points in each quadrant
    quadrant_counts = {key: 0 for key in quadrants}

    for item in quadrants.items():
        quadrant, polygon = item
        # inside_filter = nb_is_inside_parallel(point_coords.copy(), polygon.copy())
        inside_filter = np.array([Polygon(polygon).contains(Point(_)) for _ in point_coords])
        quadrant_counts[quadrant] = inside_filter.nonzero()[0].size

    # Determine if the points are evenly distributed by checking if one quadrant has too many points
    max_threshold = len(point_coords) // 3  # Example threshold: no more than half in one quadrant
    for count in quadrant_counts.values():
        if count > max_threshold:
            return False  # Points are concentrated in a small area

    return True  # Points are evenly distributed or occupy a rational extent


def remove_overlapping_polygons(polygons, overlap_threshold=0.5):
    # Convert coordinate lists to Shapely Polygons
    shapely_polygons = [Polygon(poly) for poly in polygons]
    current_area = shapely_polygons[0].area
    remove_polygons = []

    for number, polygon_number in enumerate(shapely_polygons):
        if number not in remove_polygons:
            for second_number, second_polygon_number in enumerate(shapely_polygons):
                if second_number != number:
                    intersection_polygon = polygon_number.intersection(second_polygon_number)
                    intersection_polygon_area = intersection_polygon.area

                    if (intersection_polygon_area / current_area) >= overlap_threshold:
                        remove_polygons.append(second_number)

    # Return the original coordinate lists, not the Shapely objects
    return [poly for i, poly in enumerate(polygons) if i not in remove_polygons]


def key_func(k):
    # This function extracts numeric parts for sorting alphanumeric codes
    # Modified to handle underscore as part of the string section
    return [int(text) if text.isdigit() else text for text in re.split("([0-9]+)", k.replace("_", ""))]


def format_intervals(elements):
    # Convert list into sorted order based on the numeric parts
    elements = sorted(elements, key=key_func)

    # Group the sorted elements
    grouped = []
    for k, g in groupby(enumerate(elements), lambda ix: ix[0] - key_func(ix[1])[1]):
        group = list(map(lambda x: x[1], g))
        if len(group) == 1:
            grouped.append(f"({group[0]})")
        else:
            grouped.append(f"({group[0]}-{group[-1]})")

    return ", ".join(grouped)


def recenter_polygon(polygon_coords, point_coords):
    """
    Re-center the polygon around the new center if points are not evenly distributed.
    Returns the new polygon coordinates as a list of tuples.
    """
    # Create the original polygon object
    original_polygon = Polygon(polygon_coords)

    # Create a MultiPoint object from the point coordinates
    points = MultiPoint(point_coords)

    # Calculate the centroid of the points
    new_center = points.centroid

    # Calculate the centroid of the original polygon
    original_center = original_polygon.centroid

    # Calculate the translation offset
    x_offset = new_center.x - original_center.x
    y_offset = new_center.y - original_center.y

    # Recenter the polygon using the calculated offset
    recentered_polygon = [(x + x_offset, y + y_offset) for x, y in polygon_coords]

    return np.array(recentered_polygon)


def scale_to_string(scale_float):
    """
    Convert a scale float to a 1:X style scale string.

    Args:
    scale_float (float): The scale as a float, where 1 corresponds to 1:1000.

    Returns:
    str: A string representing the scale in 1:X format.
    """
    if scale_float <= 0:
        raise ValueError("Scale must be a positive number.")

    # Calculate the scale denominator based on the input
    scale_denominator = round(1000 / (1 / scale_float) / 10) * 10

    # Return the formatted scale string
    return f"1:{int(scale_denominator)}"


def create_multi_polygon_block(msp, polygons):
    # Convert all polygons to numpy arrays and close them if necessary
    polygons = [np.array(poly) for poly in polygons]
    polygons = [np.vstack((poly, poly[0])) if not np.array_equal(poly[0], poly[-1]) else poly for poly in polygons]

    # Calculate the overall bounding box
    all_points = np.vstack(polygons)
    min_point = all_points.min(axis=0)
    max_point = all_points.max(axis=0)

    # Create a new block
    block_name = f"MultiPolygonBlock_{len(polygons)}"
    block = msp.doc.blocks.new(name=block_name)

    # Common attributes for entities
    common_attribs = {
        "layer": "08_POLIGONOS_UBICACION",
        "color": 161,
        "lineweight": 35,  # 35 corresponds to 0.35mm, which is 3.5 in AutoCAD terms
        "linetype": "DASHED",
    }

    for i, polygon in enumerate(polygons, start=1):
        # Add the polygon to the block, with coordinates relative to min_point
        block.add_lwpolyline((polygon - min_point).tolist(), dxfattribs=common_attribs)

        # Calculate text position and size
        # center = polygon.mean(axis=0)
        polygon_height = polygon[:, 1].max() - polygon[:, 1].min()
        polygon_width = polygon[:, 0].max() - polygon[:, 0].min()

        # Use the smaller dimension and apply a safety factor
        min_dimension = min(polygon_width, polygon_height)
        text_height = min_dimension * 0.15  # 40% of the smaller dimension as a starting point

        # Create a temporary text object to measure its width
        temp_text = msp.add_text(
            str(i),
            dxfattribs={"style": "Letra_Arial", "height": text_height, "color": 161},
        )
        text_width = temp_text.dxf.width
        msp.delete_entity(temp_text)

        # text height
        text_height = 0.1 * polygon_height

        # Add a label at the centroid of each polygon
        label_x = sum(x for x, y in polygon) / len(polygon)
        label_y = sum(y for x, y in polygon) / len(polygon)

        insert_point = np.array((label_x + 2 * text_width, label_y - text_height)) - min_point

        block.add_text(
            text=str(i),
            dxfattribs={
                "insert": insert_point,
                "height": text_height,
                "style": "ArialStyle",
                "halign": 1,  # Center alignment
                "valign": 1,  # Middle vertical alignment
                "rotation": 0,  # Rotate the text if necessary
                "color": 161,
                "layer": "08_POLIGONOS_UBICACION",
            },
        ).set_placement(insert_point, align=TextEntityAlignment.CENTER)

    # Insert the block into modelspace at the min_point
    block_ref = msp.add_blockref(block_name, insert=min_point.tolist(), dxfattribs=common_attribs)

    return block_ref, min_point.tolist()


def initialize_dxf(input_path):
    try:
        # # Read the existing DXF file
        # original_doc = ezdxf.readfile(input_path)
        #
        # # Create a new document with R2000 version, as in your original code
        # new_doc = ezdxf.new("R2004", setup=True)
        #
        # # Use Importer to copy content from original to new document
        # importer = Importer(original_doc, new_doc)
        #
        # # Import all entities from modelspace
        # # importer.import_modelspace( importer.target.modelspace())
        # importer.import_modelspace()
        #
        # # Import all block definitions
        # # Get all block names from the original document
        # block_names = [block.name for block in original_doc.blocks]
        # importer.import_blocks(block_names)
        #
        # # Import all table entries (layers, linetypes, textstyles, etc.)
        # importer.import_tables()
        #
        # # importer.import_entity(multileaders[0],  importer.target.modelspace())
        # # importer.import_entities(multileaders, importer.target.modelspace())
        #
        # # Finalize the import process
        # importer.finalize()
        #
        # # # Start copying modelspace entities
        # # modelspace = new_doc.modelspace()
        # # # Explicitly import multileaders and other specific entities if needed
        # # multileaders = original_doc.modelspace().query('MULTILEADER')
        # # for entity in multileaders:
        # #      # Copy entity along with its associated objects if needed
        # #     new_mleader = entity.copy()
        # #     modelspace.add_entity(new_mleader)
        #
        #
        # # Set the new filename in the metadata (without actually saving)
        # new_doc.filename = os.path.basename(input_path)
        #
        # print(f"DXF document initialized from {input_path}")
        return ezdxf.readfile(input_path)

    except ezdxf.DXFError as e:
        print(f"An error occurred while reading/writing the DXF file: {str(e)}")
        return None
    except Exception as e:
        print(f"An unexpected error occurred: {str(e)}")
        return None


class XrefManager:
    def __init__(self, xref_folder):
        """
        Initialize XrefManager

        Args:
            xref_folder (str): Path to folder containing xref files
            (can be relative or absolute, including parent directories)
        """
        # Handle paths like '../referencias' or absolute paths
        self.xref_folder = os.path.abspath(xref_folder)

    def get_xref_files(self):
        """
        Get sorted list of DWG and DXF files from xref folder as dictionaries containing
        path and name information, sorted by numbers in filenames using regex.

        Returns:
            list[dict]: List of dictionaries with keys 'path' and 'name' for each xref file
        """

        def extract_number(filename):
            numbers = re.findall(r"\d+", filename)
            if numbers:
                return int(numbers[0])
            return float("inf")

        xref_files = []
        for f in os.listdir(self.xref_folder):
            if f.lower().endswith((".dwg", ".dxf")):
                xref_files.append(
                    {
                        "path": os.path.join(self.xref_folder, f),
                        "name": os.path.splitext(f)[0],  # filename without extension
                    }
                )

        # Sort the list of dictionaries based on numbers in filenames
        return sorted(xref_files, key=lambda x: extract_number(x["name"]))

    def create_xref_dict(self):
        """Create dictionary of xref names and their order"""
        xref_dict = {}
        for i, filename in enumerate(self.get_xref_files()):
            xref_name = "_".join(os.path.splitext(filename)[0].split("_")[1:])
            xref_dict[xref_name] = i
        return xref_dict

    def get_relative_paths(self, base_path):
        """Get dictionary of xref names and their relative paths"""
        relative_paths = {}
        # Get absolute path of the DXF file's directory
        base_dir = os.path.dirname(os.path.abspath(base_path))

        for filename in self.get_xref_files():
            # Get absolute path of xref file
            full_path = os.path.join(self.xref_folder, filename)
            # Calculate relative path from DXF to xref
            relative_path = os.path.relpath(full_path, base_dir)
            xref_name = "_".join(os.path.splitext(filename)[0].split("_")[1:])
            relative_paths[xref_name] = relative_path

        return relative_paths

    def detach_xref(self, doc, xref_name):
        # Get modelspace
        msp = doc.modelspace()

        # Delete ALL block references to the xref in modelspace first
        for entity in msp.query('INSERT[name=="%s"]' % xref_name):
            msp.delete_entity(entity)

        # Also check paperspace layouts for any references
        for layout in doc.layouts:
            for entity in layout.query('INSERT[name=="%s"]' % xref_name):
                layout.delete_entity(entity)

        # Now we can safely delete the block definition
        blocks = doc.blocks
        if xref_name in blocks:
            blocks.delete_block(xref_name)

    def attach_xref(self, doc, xref_path: str, xref_name: str, z_index: int = -1000) -> None:
        """
        Attach a DWG file as an XREF with specific z-ordering.

        Args:
            xref_path: Path to the DWG file
            xref_name: Name to reference the XREF
            z_index: Z-order index for multiple XREFs (defaults to -1)
        """
        if xref_name not in doc.layers:
            layer = doc.layers.add(name=xref_name)
        else:
            layer = doc.layers.get(xref_name)

        self.detach_xref(doc, xref_name)
        ref = xref.attach(doc, block_name=xref_name, insert=(0, 0), filename=xref_path)
        ref.dxf.layer = xref_name
        ref.dxf.elevation = z_index - 1000


def setup_layout_properties(layout) -> None:
    """
    Configura todas las propiedades de ploteo del layout incluyendo transparencia
    """
    # layout.dxf.page_setup_name =  'PyPiper'
    # layout.page_setup_name = 'PyPiper'
    layout.set_plot_style("PyPiper.ctb", True)
    layout.show_plot_styles(True)
    layout.use_plot_styles(True)
    layout.print_lineweights(True)

    # PLOT_VIEWPORT_BORDERS = 1
    # SHOW_PLOT_STYLES = 2
    # PLOT_CENTERED = 4
    # PLOT_HIDDEN = 8
    # USE_STANDARD_SCALE = 16
    # PLOT_PLOTSTYLES = 32
    # SCALE_LINEWEIGHTS = 64
    # PRINT_LINEWEIGHTS = 128
    # DRAW_VIEWPORTS_FIRST = 512
    # MODEL_TYPE = 1024
    # UPDATE_PAPER = 2048
    # ZOOM_TO_PAPER_ON_UPDATE = 4096
    # INITIALIZING = 8192
    # PREV_PLOT_INIT = 16384

    # Set plot flags - using bit flags
    plot_flags = 0
    plot_flags |= 0x02  # Show plot styles
    plot_flags |= 0x800  # Plot transparency
    plot_flags |= 0x40  # Save changes to layout

    # layout.dxf.plot_layout_flags = plot_flags

    # layout.dxf.plot_layout_flags = (
    #     2 +     # Show/Display plot styles
    #     0x800   # Plot transparency
    # )
    return layout

def insert_png_logo(
    doc,
    layout,
    png_path: str,
    max_height_units: float,
    insert: tuple,
    rotation: float = 0.0,
    layer: str = None
) -> None:
    """
    Insert a PNG logo into a DXF layout with a specified maximum height, maintaining aspect ratio.

    Args:
        doc: ezdxf.document.Drawing, the DXF document.
        layout: ezdxf.layouts.BaseLayout, the target layout (e.g., modelspace or paperspace).
        png_path: str, path to the PNG file.
        max_height_units: float, maximum height of the image in layout units.
        insert: tuple, (x, y) insertion point for the image.
        rotation: float, rotation angle in degrees (counterclockwise, default 0).
        layer: str, optional layer name for the image (default None, uses current layer).
    """
    # Get pixel dimensions using PIL
    try:
        with Image.open(png_path) as img:
            pixel_width, pixel_height = img.size
    except FileNotFoundError:
        raise FileNotFoundError(f"PNG file not found at {png_path}")
    except Exception as e:
        raise ValueError(f"Error reading PNG: {e}")

    # Calculate aspect ratio
    aspect_ratio = pixel_width / pixel_height

    # Calculate width to maintain aspect ratio
    width_units = max_height_units * aspect_ratio

    # Add IMAGEDEF entity
    image_def = doc.add_image_def(
        filename=png_path,
        size_in_pixel=(pixel_width, pixel_height)
    )

    # Prepare dxfattribs for layer if specified
    dxfattribs = {}
    if layer:
        dxfattribs["layer"] = layer

    # Add IMAGE entity
    layout.add_image(
        insert=insert,
        size_in_units=(width_units, max_height_units),
        image_def=image_def,
        rotation=rotation,
        dxfattribs=dxfattribs
    )

def add_viewports_to_dxf(dxf_path: str, polygons: List[List[Tuple[float, float]]], scale_viewport: float, referencias, layout_notes, Fase=None, xref_folder_path=None, layout_content=None):
    
    # Open the existing DXF document
    doc = initialize_dxf(dxf_path)
    msp = doc.modelspace()

    # add xref
    if xref_folder_path:
        # Initialize with folder path
        xref_manager = XrefManager(xref_folder_path)
        # Get ordered xref data
        xref_data = xref_manager.get_xref_files()

        for xref in xref_data:
            xref_manager.attach_xref(doc, xref_path=xref["path"], xref_name=xref["name"])

    make_tarjeta_block(doc, layout_content)
    
    (
        insert_point_ubicacion,
        scale_ubicacion,
        polygons_ubicacion,
        low_point,
        SW_extent_ubicacion,
        NE_extent_ubicacion,
    ) = make_ubicacion_block(doc, polygons, 90)

    symbology_insert_point = transform_polygon_dxf([low_point], insert_point_ubicacion, scale_ubicacion)
    symbology_insert_point = (680, symbology_insert_point[0][1] - 20)
    symbology_heigth = make_symbology_block(doc)

    referencias_insert_point = (
        656 + (105 - 95) / 2,
        symbology_insert_point[1] - symbology_heigth - 20,
    )
    referencias_heigth = add_benchmark_table_block(doc, block_name="REFERENCIAS", headers=None, points=referencias)

    h_original = 202.5
    note_insert_points = (
        656 + (105 - 80) / 2,
        referencias_insert_point[1] - referencias_heigth - h_original - 20,
    )
    create_notes_block(
        doc,
        block_name="NotesBlock",
        width=80,
        height=h_original,
        text="NOTAS:",
        text_height=3,
    )

    create_north_arrow_block(doc, "NORTH_START")

    scale_convert = scale_to_string(scale_viewport)
    create_and_scale_scalebar(doc, block_name="SCALEBAR", layout_scale=scale_convert)

    # create block polygons
    create_multi_polygon_block(msp, polygons)

    # definir codigo
    if "pluvial" in layout_content['contenido'].lower():
        codigo = "plu-pl-"
    elif "sanitario" in layout_content['contenido'].lower():
        codigo = "san-pl-"
    elif "combinado" in layout_content['contenido'].lower():
        codigo = "comb-pl-"
    else:
        codigo = "alc-pl-"

    for index, polygon in enumerate(polygons):
        if Fase:
            layout_name = f"c{Fase}-{codigo}{index + 1}"  # borrar, esto es solo para solanda , hay que agreagra un argumento con prefix para poner el componente
        else:
            layout_name = f"{codigo}{index + 1}"

        if layout_name not in doc.layouts:
            layout = doc.layouts.new(name=layout_name)
        else:
            layout = doc.layouts.get(layout_name)

        # get layout
        psp = layout
        a1_width = 0.841 * 1000
        a1_height = 0.594 * 1000

        a1_width_viewport = 0.636 * 1000
        a1_height_viewport = 0.564 * 1000

        # reset page properties:
        psp.page_setup(size=(a1_width, a1_height), margins=(0, 0, 0, 0))

        # Activar el uso de plot styles
        layout = setup_layout_properties(layout)

        centroid_x = np.mean([polygon[0][0], polygon[2][0]])
        centroid_y = np.mean([polygon[0][1], polygon[2][1]])

        # add a new viewport to the paperspace:
        vp = psp.add_viewport(  # center of viewport in paperspace:
            center=(
                a1_width * 0.5 - (a1_width - a1_width_viewport) * 0.5 + 20,
                a1_height * 0.5,
            ),  # size of the viewport in paperspace:
            size=(a1_width_viewport, a1_height_viewport),  # center in modelspace:
            view_center_point=(centroid_x, centroid_y),  # the view height to show in modelspace units:
            view_height=a1_height_viewport * scale_viewport,
            dxfattribs={
                "layer": "05_TARJETA",
                "color": 4,
            },  # The view width is proportional to the viewport size!
        )
        vp.set_flag_state(ezdxf.const.VSF_LOCK_ZOOM, True)
        # vp.frozen_layers = ['04_ubicacion']

        WS = transform_polygon_dxf([SW_extent_ubicacion], insert_point_ubicacion, scale_ubicacion)
        EN = transform_polygon_dxf([NE_extent_ubicacion], insert_point_ubicacion, scale_ubicacion)
        vp_ubicacion_width = EN[0][0] - WS[0][0]
        vp_ubicacion_heigth = EN[0][1] - WS[0][1]
        center_vp_ubicacion = np.array(WS)[0] + [
            vp_ubicacion_width / 2,
            vp_ubicacion_heigth / 2,
        ]

        extent_polygons_x = np.array([(np.array(_).T[0].min(), np.array(_).T[0].max()) for _ in polygons])
        extent_polygons_y = np.array([(np.array(_).T[1].min(), np.array(_).T[1].max()) for _ in polygons])
        extent_xmin, extent_xmax = np.min(extent_polygons_x), np.max(extent_polygons_x)
        extent_ymin, extent_ymax = np.min(extent_polygons_y), np.max(extent_polygons_y)
        centroid_vp_ubicacion = np.mean((extent_xmin, extent_xmax)), np.mean((extent_ymin, extent_ymax))

        vp_ubicacion = psp.add_viewport(  # center of viewport in paperspace:
            center=(center_vp_ubicacion),  # size of the viewport in paperspace:
            size=(max(vp_ubicacion_width, 90), vp_ubicacion_heigth),  # center in modelspace:
            view_center_point=centroid_vp_ubicacion,  # the view height to show in modelspace units:
            view_height=(extent_ymax - extent_ymin),
            dxfattribs={
                "layer": "05_TARJETA",
                "color": 4,
            },  # The view width is proportional to the viewport size!
        )

        all_layers = [_.dxf.name for _ in doc.layers]
        layer_to_keep_visible = [
            "00_SANITARIO",
            "01_PLUVIAL",
            "02_COMBINADO",
            "01_POZO_EXISTENTE",
        ] + [_["name"] for _ in xref_data]

        vp_ubicacion.frozen_layers = list(set(all_layers).difference(set(layer_to_keep_visible)))

        psp.add_blockref("TARJETA_PYPIPER", (0, 0))

        layout.add_blockref(
            "LAYOUT_UBICACION",
            insert_point_ubicacion,
            dxfattribs={"xscale": scale_ubicacion, "yscale": scale_ubicacion},
        )

        add_hatch_to_new_polygon(
            layout,
            polygons_ubicacion[index],
            insertion_point=insert_point_ubicacion,
            scale=scale_ubicacion,
        )

        layout.add_blockref("SIMBOLOGIA", symbology_insert_point, dxfattribs={"xscale": 1, "yscale": 1})

        # create_notes_block(doc, block_name=f'NotesBlock{layout_name}', width=80, height=140, text=layout_notes[index + 1], text_height=3)

        layout.add_blockref("NotesBlock", note_insert_points, dxfattribs={"xscale": 1, "yscale": 1})
        create_notes_mtext(
            doc,
            layout,
            insert_points=note_insert_points,
            text=layout_notes[index + 1],
            h_original=h_original,
        )

        layout.add_blockref(
            "REFERENCIAS",
            referencias_insert_point,
            dxfattribs={"xscale": 1, "yscale": 1},
        )

        layout.add_blockref("NORTH_START", (656 + 52.5, 70 - 17.5), dxfattribs={"xscale": 1, "yscale": 1})
        layout.add_blockref("SCALEBAR", (656 + 12.5, 50 - 17.5), dxfattribs={"xscale": 1, "yscale": 1})
        
        insert_png_logo(
            doc,
            layout,
            png_path= layout_content['logo'],
            max_height_units= 16,
            insert= (a1_width - 59 - 1.25, 37),
            rotation= 90,
            layer='LOGO')

        add_date_and_name(layout, layout_scale=scale_convert, contenido=layout_content['contenido'])

        if Fase:
            add_codigo_numero(layout, index + 1, f"c{Fase}-{codigo}")
        else:
            add_codigo_numero(layout, index + 1, codigo)

        # get polygon bounds
        points_array = np.array(polygon)

        # Extract the bounds
        min_x = np.min(points_array[:, 0])
        max_x = np.max(points_array[:, 0])
        min_y = np.min(points_array[:, 1])
        max_y = np.max(points_array[:, 1])

        # The reference_bounds will be:
        reference_bounds = [min_x, min_y, max_x, max_y]
        # rect_x, rect_y = 20, 15
        main_viewport_coords = 20, 15, 656, 579
        add_grid_to_dxf_layout(
            layout,
            a1_width_viewport,
            a1_height_viewport,
            reference_bounds,
            label=True,
            init_coords=main_viewport_coords,
            intervals=(6, 6),
        )

    # erase anoying Layout1 default.
    # Get the layouts collection
    layouts = doc.layouts

    # Name of the layout to delete
    layout_name = "Layout1"

    # Check if the layout exists before attempting to delete it
    if layout_name in layouts:
        layouts.delete(layout_name)

    # Save the modified DXF document
    name = os.path.basename(dxf_path).split(".")[0] + "_LAYOUTS"
    path = os.path.join(os.path.dirname(dxf_path), name + ".dxf")
    doc.saveas(path)


def invert_dictionary(original_dict):
    inverted_dict = {}
    for key, values in original_dict.items():
        for value in values:
            if value not in inverted_dict:
                inverted_dict[value] = []
            inverted_dict[value].append(key)
    return inverted_dict


def find_location_in_polygons(project_name, dxf_path, vector_path, polygon_list, Fase=None):
    import json

    # read vector file
    df_tuberias = gpd.read_file(vector_path, enigne="pyogrio")
    if Fase:
        df_tuberias = df_tuberias[df_tuberias["Fase"] == Fase]

    # get points from tuberias
    coordenadas_tuberias = df_tuberias.geometry.centroid.get_coordinates().to_numpy().T
    polygon_dict = {}
    for pos, polygon in enumerate(polygon_list, start=1):
        filtro_inside = nb_is_inside_parallel(coordenadas_tuberias.copy(), np.array(polygon).copy())
        polygon_dict[pos] = df_tuberias["Ramal"][filtro_inside].unique()

    name = os.path.basename(dxf_path).split(".")[0] + "_LAYOUTS"
    path = os.path.join(os.path.dirname(dxf_path), name + "_layout.txt")
    with open(path, "w") as file:
        json.dump(invert_dictionary(polygon_dict), file)

    name = os.path.basename(dxf_path).split(".")[0] + "_LAYOUTS"
    path = os.path.join(os.path.dirname(dxf_path), name + "_layout_index.txt")

    # definir codigo
    if "pluvial" in layout_content['contenido'].lower():
        codigo = "plu-pl-"
    elif "sanitario" in layout_content['contenido'].lower():
        codigo = "san-pl-"
    elif "combinado" in layout_content['contenido'].lower():
        codigo = "comb-pl-"
    else:
        codigo = "alc-pl-"

    polygon_dict_copy = polygon_dict.copy()
    if not codigo == "alc-pl-":
        for new_ramal in polygon_dict_copy.keys():
            new_list = [_ for _ in polygon_dict_copy[new_ramal] if not "E" in _]
            polygon_dict_copy[new_ramal] = new_list

    # format_intervals
    index = codigo + pd.Series(list(polygon_dict_copy.keys())).astype(str)
    df = pd.DataFrame(
        [format_intervals(_) for _ in polygon_dict_copy.values()],
        index=index,
        columns=["Ramales"],
    )
    df["Referencia"] = df.index
    df = df[["Referencia", "Ramales"]]
    df.to_csv(path)

    table2cad(
        df,
        project_name,
        name=project_name + "_plane_index_table",
        align_left=True,
        row_heigth=3,
    )

    return polygon_dict


def get_viewport_polygons_from_dxf(dxf_file_path):
    # Read the DXF file
    doc = ezdxf.readfile(dxf_file_path)
    msp = doc.modelspace()
    # Extract polygons from the DXF file
    polygons = []

    # Search for LWPOLYLINE entities
    for entity in msp.query("LWPOLYLINE"):
        polygon = [(point[0], point[1]) for point in entity.get_points()]
        polygons.append(polygon)

    # Search for POLYLINE entities
    for entity in msp.query("POLYLINE"):
        polygon = [(vertex.dxf.location[0], vertex.dxf.location[1]) for vertex in entity.vertices]
        polygons.append(polygon)
    # Calculate model extents from the polygons
    all_points = np.array([point for polygon in polygons for point in polygon])
    x_min, y_min = np.min(all_points, axis=0)
    x_max, y_max = np.max(all_points, axis=0)
    model_extents = (x_max - x_min, y_max - y_min)
    return model_extents, polygons


def create_plane_layouts(
    project_name, dxf_path, vector_path, referencias,layout_content, overlap_percentage=0.05, scale_viewport=None, dxf_polygon_path=None, Fase=None, xref_folder_path=None
):
    
    
    if not scale_viewport:
        directory_path, file_name = os.path.split(dxf_path)
        scale_path = directory_path + os.path.sep + file_name.split(".")[0] + "_scale.txt"
        with open(scale_path, "r") as file:
            file_content = file.read().strip()  # Read the entire content and strip any extra whitespace
            scale_viewport = float(file_content)  # Convert the string directly to a float

    # get polygons
    if dxf_polygon_path:
        model_viewport_extent, polygons = get_viewport_polygons_from_dxf(dxf_polygon_path)
    else:
        # get dxf extent
        extents, coords = get_extents(dxf_path)
        model_viewport_extent, polygons = get_viewport_polygons(extents, overlap_percentage, scale_viewport, coords)

        lines = extract_all_dxf_lines(dxf_path)
        points = np.array(lines.T).copy()
        points_pairwise = points.T

        polygon_dict = {}
        for pos, polygon in enumerate(polygons):
            polygon = np.array(polygon).copy()

            inside_filter = nb_is_inside_parallel(points, polygon.copy())

            polygon_dict[pos] = (points_pairwise[inside_filter], polygon)

            cond = is_evenly_distributed(polygon, points_pairwise[inside_filter])
            if not cond:
                polygons[pos] = recenter_polygon(polygon, points_pairwise[inside_filter])

        # remove intersecting polygons
        polygons = remove_overlapping_polygons(polygons)

    # get dictionary of profiles insides polygons
    layout_notes = find_location_in_polygons(project_name, dxf_path, vector_path, polygons, Fase)
    # add all viewports
    add_viewports_to_dxf(dxf_path, polygons, scale_viewport, referencias, layout_notes, Fase, xref_folder_path, layout_content)

    sys.exit()


def m_ramales2cad(m_ramales, shp_name):
    # "CREAR MODELO EN DXF"
    doc = ezdxf.new("R2007", setup=True)
    msp = doc.modelspace()
    doc.styles.new("Letra_Arial", dxfattribs={"font": "ARIALN.TTF"})

    dict2 = {
        "layer": "01_POZO",
        "linetype": "CONTINUOUS",
        "color": 11,
        "lineweight": 30,
        "ltscale": 5,
    }
    fontsize = 2
    font = ImageFont.truetype("ARIALN.TTF", fontsize)

    x_accu = [0]
    for _ramal in m_ramales.keys():
        df = pd.DataFrame(m_ramales[_ramal])
        df = df.round(3)
        df = df.replace(np.nan, "")
        df = df.replace("None", "")
        df = df.fillna("")
        df = df.drop(columns=["S_min", "Pozo_hmin", "D_min", "Derivacion"])
        cols_remove = list(df.columns)
        cols_remove.remove("Obs")
        new_cols = cols_remove + ["Obs"]
        df = df.reindex(new_cols, axis=1)
        cols = df.columns
        rows = df.index

        row_heigth = 2
        str_width = 1.35

        max_pos = [np.argmax(list(map(len, df[_].astype(str)))) for _ in df.columns]
        _content_str = [font.font.getsize(str(df[_[1]][_[0]]))[0][0] for _ in zip(max_pos, df.columns)]
        _content_cols = [font.font.getsize(str(_))[0][0] for _ in df.columns]
        _content_len = np.max([_content_cols, _content_str], axis=0)

        _len = np.array([0] + list(_content_len))
        _len = np.cumsum(_len * str_width) + (2 * str_width)
        _len = _len + max(x_accu)

        # draw line
        x0 = _len[0]
        x1 = max(_len)
        x2 = x1
        x3 = _len[0]

        y0 = 0
        y1 = 0
        y2 = (-row_heigth * len(rows)) + row_heigth
        y3 = (-row_heigth * len(rows)) + row_heigth

        points = np.array(list(zip([x0, x1, x2, x3, x0], [y0, y1, y2, y3, y0])))
        msp.add_polyline2d(points, dxfattribs=dict2)

        # vertical lines
        vertical_lines = _len
        horizontal_up = [0] * len(vertical_lines)
        horizontal_down = [y2] * len(vertical_lines)

        for pos in range(len(vertical_lines)):
            points = np.array(
                list(
                    zip(
                        [vertical_lines[pos], vertical_lines[pos]],
                        [horizontal_up[pos], horizontal_down[pos]],
                    )
                )
            )
            msp.add_polyline2d(points, dxfattribs=dict2)

        # vertical lines
        horizontal_lines = -np.array(range(0, len(rows))) * row_heigth
        vertical_left = [x0] * len(horizontal_lines)
        vertical_rigth = [x2] * len(horizontal_lines)
        for pos in range(len(horizontal_lines)):
            points = np.array(
                list(
                    zip(
                        [vertical_left[pos], vertical_rigth[pos]],
                        [horizontal_lines[pos], horizontal_lines[pos]],
                    )
                )
            )
            msp.add_polyline2d(points, dxfattribs=dict2)

        move_pos = list(np.diff(vertical_lines) / 2.0) + [0]
        for pos_col, col in enumerate(cols):
            arr = df[col]
            for pos_row, row in enumerate(rows):
                if pos_row == 0:
                    txt = col
                    y = horizontal_lines[pos_row] + (row_heigth / 2.0)
                else:
                    txt = arr.iloc[pos_row]
                    y = horizontal_lines[pos_row] + (row_heigth - 1.6) / 2.0

                if isinstance(txt, float):
                    x = vertical_lines[pos_col]
                    msp.add_text(
                        txt,
                        dxfattribs={
                            "style": "Letra_Arial",
                            "layer": "00_TABLAS",
                            "color": 41,
                            "rotation": 0,
                            "height": 1.6,
                        },
                    ).set_pos((x, y), align="LEFT")
                else:
                    x = vertical_lines[pos_col] + move_pos[pos_col]
                    msp.add_text(
                        txt,
                        dxfattribs={
                            "style": "Letra_Arial",
                            "layer": "00_TABLAS",
                            "color": 41,
                            "rotation": 0,
                            "height": 1.6,
                        },
                    ).set_pos((x, y), align="CENTER")
        x_accu.append(max(_len) + 10)

    doc.saveas("PROYECTO_" + shp_name + os.path.sep + "01_DXF" + os.path.sep + "01_OUT_PL_PF" + os.path.sep + "02_TABLA_" + str(shp_name) + ".dxf")


def table2cad(
    df,
    project_name,
    remove_cols=None,
    filter_out=None,
    name=None,
    align_left=False,
    row_heigth=None,
):
    # "CREAR MODELO EN DXF"
    doc = ezdxf.new("R2010", setup=True)
    msp = doc.modelspace()
    doc.styles.new("Letra_Arial", dxfattribs={"font": "ARIALN.TTF"})

    dict2 = {
        "layer": "01_POZO",
        "linetype": "CONTINUOUS",
        "color": 9,
        "lineweight": 10,
        "ltscale": 5,
    }
    fontsize = 2
    font = ImageFont.truetype("ARIALN.TTF", fontsize)
    for col in df.columns:
        _type = df[col].dropna().to_numpy()

        if len(_type) > 0:
            if isinstance(df[col].dropna().to_numpy()[-1], float):
                try:
                    df[col] = df[col].astype(float).round(3).astype(str)
                except:
                    df[col] = df[col].astype(str)
    # modificar strings
    df = df.replace(np.nan, "")
    df = df.replace("None", "")
    df = df.fillna("")
    if remove_cols:
        df = df.drop(columns=remove_cols)
    try:
        cols_remove = list(df.columns)
        cols_remove.remove("Obs")
        new_cols = cols_remove + ["Obs"]
        df = df.reindex(new_cols, axis=1)
    except:
        pass

    # filter
    # filter_out={'Estado':'nuevo'}
    if filter_out:
        for key, value in zip(filter_out.keys(), filter_out.values()):
            try:
                remove_index = np.char.equal(df[key].to_numpy().astype(str), value).nonzero()[0]
                df = df.drop(remove_index, errors="ignore")
            except:
                pass

    # get shape
    cols = df.columns
    rows = df.index

    if not row_heigth:
        row_heigth = 2

    _content_len = []
    for col in df.columns:
        length = list(map(len, df[col].astype(str).to_list()))
        max_length = np.argmax(length)
        try:
            _content_len.append(get_exact_text_dimensions(df[col][max_length + 1], style_name="Letra_arial", char_height=1.6)[0] + 2)
        except:
            _content_len.append(get_exact_text_dimensions(df[col][max_length], style_name="Letra_arial", char_height=1.6)[0] + 2)

    _len = np.array([0] + list(_content_len))
    _len = np.cumsum(_len)

    # draw line
    x0 = _len[0]
    x1 = max(_len)
    x2 = x1
    x3 = _len[0]

    y0 = 0
    y1 = 0
    y2 = (-row_heigth * len(rows)) + row_heigth
    y3 = (-row_heigth * len(rows)) + row_heigth

    points = np.array(list(zip([x0, x1, x2, x3, x0], [y0, y1, y2, y3, y0])))
    msp.add_polyline2d(points, dxfattribs=dict2)

    # vertical lines
    vertical_lines = _len
    horizontal_up = [0] * len(vertical_lines)
    horizontal_down = [y2] * len(vertical_lines)

    for pos in range(len(vertical_lines)):
        points = np.array(
            list(
                zip(
                    [vertical_lines[pos], vertical_lines[pos]],
                    [horizontal_up[pos], horizontal_down[pos]],
                )
            )
        )
        msp.add_polyline2d(points, dxfattribs=dict2)

    # vertical lines
    horizontal_lines = -np.array(range(0, len(rows))) * row_heigth
    vertical_left = [x0] * len(horizontal_lines)
    vertical_rigth = [x2] * len(horizontal_lines)
    for pos in range(len(horizontal_lines)):
        points = np.array(
            list(
                zip(
                    [vertical_left[pos], vertical_rigth[pos]],
                    [horizontal_lines[pos], horizontal_lines[pos]],
                )
            )
        )
        msp.add_polyline2d(points, dxfattribs=dict2)

    move_pos = list(np.diff(vertical_lines) / 2.0) + [0]
    for pos_col, col in enumerate(cols):
        arr = pd.concat([pd.Series([col]), df[col]], ignore_index=True)
        for pos_row, row in enumerate(rows):
            # if pos_row == 0:
            #     txt = col
            #     y = horizontal_lines[pos_row] + (row_heigth / 2.0)

            txt = arr.iloc[pos_row]
            y = horizontal_lines[pos_row] + (row_heigth - 1.6) / 2.0

            if isinstance(txt, float):
                x = vertical_lines[pos_col]
                msp.add_text(
                    round(txt, 3),
                    dxfattribs={
                        "style": "Letra_Arial",
                        "layer": "00_TABLAS",
                        "color": 41,
                        "rotation": 0,
                        "height": 1.6,
                    },
                ).set_pos((x, y), align="LEFT")
            else:
                x = vertical_lines[pos_col] + move_pos[pos_col]
                if align_left:
                    aling = TextEntityAlignment.LEFT
                    x = x - move_pos[pos_col]
                else:
                    aling = TextEntityAlignment.CENTER
                msp.add_text(
                    text=txt,
                    dxfattribs={
                        "style": "Letra_Arial",
                        "layer": "00_TABLAS",
                        "color": 41,
                        "rotation": 0,
                        "height": 1.6,
                    },
                ).set_placement((x, y), align=aling)

    if not name:
        name = project_name

    doc.saveas("PROYECTO_" + project_name + os.path.sep + "01_DXF" + os.path.sep + "01_OUT" + os.path.sep + "02_TABLA_" + str(name) + ".dxf")


"######################################################################################################################"
"OPTIMIZACION PERFIL VERTICAL "
"######################################################################################################################"


def rdp(points, epsilon):
    # get the start and end points
    start = np.tile(np.expand_dims(points[0], axis=0), (points.shape[0], 1))
    end = np.tile(np.expand_dims(points[-1], axis=0), (points.shape[0], 1))

    # find distance from other_points to line formed by start and end
    dist_point_to_line = np.abs(np.cross(end - start, points - start, axis=-1)) / np.linalg.norm(end - start, axis=-1)
    # get the index of the points with the largest distance
    max_idx = np.argmax(dist_point_to_line)
    max_value = dist_point_to_line[max_idx]

    result = []
    if max_value > epsilon:
        partial_results_left = rdp(points[: max_idx + 1], epsilon)
        result += [list(i) for i in partial_results_left if list(i) not in result]
        partial_results_right = rdp(points[max_idx:], epsilon)
        result += [list(i) for i in partial_results_right if list(i) not in result]
    else:
        result += [points[0], points[-1]]

    return result


def is_between(a, b, c):
    """
    get index position of  point c insert trench between points a and b
    """
    return np.argmin(
        (distance.cdist(c, a) + distance.cdist(c, b)) - np.sqrt((a.T[0] - b.T[0]) ** 2 + (a.T[1] - b.T[1]) ** 2),
        axis=1,
    )


def consecutive(data, stepsize=1):
    return np.split(data, np.where(np.diff(data) != stepsize)[0] + 1)



def get_clean_geometry(df):
    default_values_dict = {
        # Cadenas ("U256")
        "Estado": "nuevo",
        "Material": "PVC",
        "metodo_constructivo": "zanja abierta",
        "Obs": "",
        "Pozo": None,  # Añadido
        "Ramal": None,  # Añadido
        "Rugosidad": "liso",
        "Seccion": "circular",
        "Tipo": "sanitario",
        "tipo_nudo": "pozo",
        "Tramo": None,  # Añadido
        "Fase": "1",
        # Float
        "D_ext": "0.0",
        "D_int": "0.0",
        "D_min": None,
        "HF": np.nan,
        "HI": np.nan,
        "L": np.nan,
        "LT": np.nan,
        "Pozo_hmin": None,
        "Rug": np.nan,
        "S": np.nan,
        "SALTO": np.nan,
        "S_min": None,
        "S_user": None,
        "X": np.nan,  # Añadido
        "Y": np.nan,  # Añadido
        "Z": np.nan,
        "ZFF": np.nan,
        "ZFI": np.nan,
        "ZTF": np.nan,
        "ZTI": np.nan,
        # Bool
        "Derivacion": False,
        # Object
        "Conexion": None,
        'cobertura_min':np.nan
    }

    type_values_dict = {
        # Cadenas ("U256")
        "Estado": "U256",
        "Material": "U256",
        "metodo_constructivo": "U256",
        "Obs": "U256",
        "Pozo": "U256",
        "Ramal": "U256",
        "Rugosidad": "U256",
        "Seccion": "U256",
        "Tipo": "U256",
        "tipo_nudo": "U256",
        "Tramo": "U256",
        "Fase": "U256",
        # Float
        "D_ext": "U256",
        "D_int": "U256",
        "D_min": float,
        "HF": float,
        "HI": float,
        "L": float,
        "LT": float,
        "Pozo_hmin": float,
        "Rug": float,
        "S": float,
        "SALTO": float,
        "S_min": float,
        "S_user": float,
        "X": float,
        "Y": float,
        "Z": float,
        "ZFF": float,
        "ZFI": float,
        "ZTF": float,
        "ZTI": float,
        # Bool
        "Derivacion": bool,
        # Object
        "Conexion": object,
        'cobertura_min':float
    }

    columns_read = list(type_values_dict.keys())


    # ----------------------------------------------------------------
    # Read file and make sure geometry lines are valid
    # ----------------------------------------------------------------
    columns_read = columns_read

    # Filter columns if they exist in the GeoDataFrame
    existing_columns = set(df.columns)
    selected_columns = list(existing_columns.intersection(columns_read + ["geometry"]))
    df = df[selected_columns]
    

    # Check for columns_read items are present in the df, if not the use the default value an type
    for column in columns_read:
        if column not in df.columns:
            df[column] = default_values_dict[column]

    # check for valid geometry
    mask_valid = df.geometry.is_valid
    df = df[mask_valid]

    # avoid empty geometries
    not_empty_geometry = np.invert(df["geometry"].is_empty)
    df = df[not_empty_geometry]

    # check for geomtry type
    mask_geometry = df.geom_type.isin(["MultiLineString", "LineString"])
    df = df[mask_geometry]
    df = df.explode()

    # check for derivacion make all bool
    df["Derivacion"] = df["Derivacion"].apply(to_bool).to_numpy()

    # Sort dataframe to avoid conection errors, by Ramal
    # Get the sorted index using the custom sorting function defined by a lambda
    sorted_index = index_natsorted(df["Ramal"], key=lambda x: (x is None, x))
    # Sort DataFrame by this index
    df = df.reindex(index=order_by_index(df.index, sorted_index)).round(3)
    # Reindex
    df.reset_index(drop=True, inplace=True)
    df["Conexion"] = np.array([np.nan] * len(df["Conexion"]))

    # get ramal labels
    _r = df["Ramal"].dropna().unique().astype(str)

    ############################################################################################################
    # Operaciones para modificar los ramales para tramos existentes y nuevos
    ############################################################################################################

    # Renumerar los ramales aumentando la numeracion para  los nuevos
    index_count = np.where(df["Ramal"].to_numpy() == None)[0]
    if len(index_count) > 0:
        # set Estado None to Nuevo
        df.loc[index_count, "Estado"] = "nuevo"
        if len(_r) > 0:
            # start_count = np.max(_r.astype(int))
            start_count = (
                pd.to_numeric(
                    df["Ramal"].dropna().str.replace(r"[A-Za-z]", "", regex=True),
                    errors="coerce",
                )
                .dropna()
                .astype(int)
                .max()
            )
        else:
            start_count = -1
        diff_array = np.array((range(start_count + 1, start_count + len(index_count) + 1, 1))).astype(str)
        _r = np.append(_r, diff_array).astype(str)
        df.loc[index_count, "Ramal"] = diff_array

    # agregar 'E' en ramales, conexion, pozo y tramos existentes
    index_existente = np.where(df["Estado"] == "existente")[0]
    if len(index_existente):
        # modificar Ramal
        # ramal_existente = pd.Series(['E'] * len(index_existente), index=index_existente).str.cat(df['Ramal'][index_existente], sep='').to_numpy()
        ramal_existente = pd.Series(["E"] * len(index_existente), index=index_existente).str.cat(
            df["Ramal"].str.replace(r"[A-Za-z]", "", regex=True)[index_existente],
            sep="",
        )
        df.loc[index_existente, "Ramal"] = ramal_existente

        # modificar Pozo
        pozo_existente = (
            pd.Series(["E"] * len(index_existente), index=index_existente)
            .str.cat(
                df["Pozo"].str.replace(r"[A-Za-z]", "", regex=True)[index_existente],
                sep="",
            )
            .to_numpy()
        )
        df.loc[index_existente, "Pozo"] = pozo_existente

        # modificar Tramo
        start_pz, end_pz = pp_char_split(
            df["Tramo"].str.replace("[^0-9._-]", "", regex=True)[index_existente].to_numpy(),
            _split="-",
        )
        start_array = pd.Series(["E"] * len(index_existente), index=index_existente).str.cat(start_pz, sep="")
        end_array = pd.Series(["E"] * len(index_existente), index=index_existente).str.cat(end_pz, sep="")
        tramo_existente = start_array.str.cat(end_array, sep="-").to_numpy()
        df.loc[index_existente, "Tramo"] = tramo_existente

        # actualizar nombre de ramales
        _r = df["Ramal"].dropna().unique().astype(str)
        # actualizar nombre de ramales
        _r = df["Ramal"].dropna().unique().astype(str)


    cols = list(df.columns)
    values = len(cols) * [0.0]
    estado_array = df["Estado"].to_numpy().astype(str)
    df.index = df["Ramal"]
    
    return df



def opt_vertical_profile(
    m_ramales,
    ramal,
    elev_source,
    step,
    shape_file,
    epsilon=0.7,
    min_distance=15,
    max_distance=110,
    skip_ramal=[],
):
    # read vector file
    _file = gpd.read_file(shape_file, engine="pyogrio")
    # _file = get_clean_geometry(_file)
    _file['Ramal'] =  None
    _file['Estado'] =  'nuevo'
    # skip ramales que son existentes
    list_skip_existente = [m_ramales[_]["Ramal"][0] for _ in ramal.values() if "existente" in m_ramales[_]["Estado"]]
    skip_ramal = skip_ramal + list_skip_existente
    skip_ramal = np.array(skip_ramal).astype(str)

    # un diciconario para mapear el ramal modificado de m_ramales cuando existen ramales nuevos y existentes
    key_translate = [m_ramales[_]["Ramal"][0] for _ in ramal.values() if "existente" not in m_ramales[_]["Estado"]]
    value_translate = np.where(_file["Ramal"].to_numpy() == None)[0]
    translate_ramal = dict(zip(key_translate, value_translate))

    min_distance = min_distance + 1
    # get profile x,y,z values
    terreno = elev_source.get_profile_m_ramales(m_ramales, step, skip_existing=True)

    _total = len(list(terreno.keys()))
    # get simplify points in  profile
    for i in terreno.keys():
        if i not in skip_ramal:
            # print(i, ' of ', _total - 1)
            # x and y coordintaes
            x_terreno, y_terreno = terreno[i][0], terreno[i][1]
            abscisas_terreno, elevacion_terreno = terreno[i][2], terreno[i][3]

            # simplified profile points
            points = np.array([abscisas_terreno, elevacion_terreno]).T
            simple_abscisas_terreno, simple_elevacion_terreno = np.array(rdp(points, epsilon)).T

            # simplified points index
            index_simple = [_ for _ in range(len(abscisas_terreno)) if abscisas_terreno[_] in simple_abscisas_terreno]

            # get points for simplified points
            simple_x_terreno = x_terreno[index_simple]
            simple_y_terreno = y_terreno[index_simple]

            # check for distance lesser than min_distance
            points_ramal = np.array([m_ramales[i]["X"], m_ramales[i]["Y"]]).T
            points_simple = np.array([simple_x_terreno, simple_y_terreno]).T
            _dist = distance.cdist(points_simple, points_ramal)
            _dist_min = np.min(_dist, axis=1)
            # index of points to keep
            index_kept = np.where(_dist_min > min_distance)
            simple_x_terreno, simple_y_terreno = (
                simple_x_terreno[index_kept],
                simple_y_terreno[index_kept],
            )

            # original coordinates
            x, y = m_ramales[i]["X"], m_ramales[i]["Y"]
            # get index simple points to insert in original goemtry
            simple_points = np.array([simple_x_terreno, simple_y_terreno]).T
            line_points = np.array([x, y]).T
            index_insert = is_between(line_points[:-1], line_points[1:], simple_points)

            # insert simple points in existing goemtry
            x_insert = np.insert(x, index_insert + 1, simple_x_terreno)
            y_insert = np.insert(y, index_insert + 1, simple_y_terreno)

            # update goemtry inserted index points
            new_index = [_ for _ in range(len(x_insert)) if x_insert[_] in simple_x_terreno]

            # get elevation for new geometry
            z_insert = elev_source.get_elevation_from_tree_coords(np.array([x_insert, y_insert]).T)

            diff_z = z_insert[:-1] - z_insert[1:]
            diff_L = np.sqrt((x_insert[:-1] - x_insert[1:]) ** 2 + (y_insert[:-1] - y_insert[1:]) ** 2)

            s = diff_z / diff_L
            check_points = new_index
            remove_index = []

            # minimum slope
            s_min = 0.4 / 100
            # maximun differece in slope between points
            max_s_diff = 3 / 100
            for j in check_points:
                # (j-1) and (j) are the points to check
                # + +
                if s[j - 1] >= s_min and s[j] >= s_min:
                    # check if s has roughly the same direction, max difference 2%
                    if np.abs(s[j - 1] - s[j]) < max_s_diff:
                        remove_index.append(j)
                # - +
                if s[j - 1] <= s_min and s[j] > s_min:
                    # #check if heigth increment has a vlaue lesser than min_distance / 2.0
                    if np.abs(s[j - 1] * diff_L[j - 1]) > epsilon:
                        remove_index.append(j)
                        continue
                    # check if s has roughly the same direction, max difference 2%
                    if np.abs(s[j - 1] - s[j]) < max_s_diff:
                        remove_index.append(j)
                # + -
                if s[j - 1] > s_min and s[j] <= s_min:
                    # check if s has roughly the same direction, max difference 2%
                    if np.abs(s[j - 1] - s[j]) < max_s_diff:
                        remove_index.append(j)
                # - -
                if s[j - 1] <= s_min and s[j] <= s_min:
                    remove_index.append(j)

            # unique indexes
            remove_index = np.unique(remove_index)
            # remove index
            if len(remove_index) > 0:
                x_insert = np.delete(x_insert, remove_index)
                y_insert = np.delete(y_insert, remove_index)

            # check for distance greater than max_distance
            tolerance = 0.1  # 10% tolerance, adjust as needed
            fuzzy_threshold = max_distance * (1 + tolerance)  # e.g., 132 with 10% tolerance

            # Start with initial distance calculation
            _dist = dist2d_vector(x_insert, y_insert)
            index_max = np.where(_dist > fuzzy_threshold)[0]  # Only split if above fuzzy threshold

            while len(index_max) > 0:
                yvalues_insert = []
                xvalues_insert = []

                # Calculate midpoints for segments that exceed the fuzzy threshold
                for _ in index_max:
                    xvalues_insert.append((x_insert[_] + x_insert[_ + 1]) / 2.0)
                    yvalues_insert.append((y_insert[_] + y_insert[_ + 1]) / 2.0)

                # Insert the new points
                x_insert = np.insert(x_insert, index_max + 1, xvalues_insert)
                y_insert = np.insert(y_insert, index_max + 1, yvalues_insert)

                # Recalculate distances and update segments exceeding fuzzy threshold
                _dist = dist2d_vector(x_insert, y_insert)
                index_max = np.where(_dist > fuzzy_threshold)[0]

            # create new geoemtry and replace original
            if len(key_translate) == 0:
                _file.geometry[int[i]] = LineString(zip(x_insert, y_insert))
            else:
                _file.geometry[translate_ramal[str(i)]] = LineString(zip(x_insert, y_insert))

    # save shapefile
    name = shape_file.split(os.path.sep)[-1].split(".")[0] + "_VERTICAL_OPT"
    path_search = re.search("00_GIS", shape_file)
    index_string = path_search.regs[0][1]
    path_out = shape_file[:index_string] + os.path.sep + r"02_OUT" + os.path.sep + r"00_VERTICAL_OPT"

    # cheack for path
    if not os.path.exists(path_out):
        os.makedirs(path_out)
    # writte to shapefile
    # _file.to_file(path_out + os.path.sep + name + '.shp', driver='ESRI Shapefile')
    _file.to_file(path_out + os.path.sep + name + ".gpkg", driver="GPKG")

    # read new file
    # check if m_ramales has exinting or new ramales
    estado_array = _file["Estado"].to_numpy()
    cond_estado = np.char.equal(estado_array.astype(str), "existente").nonzero()[0]
    if len(cond_estado) == 0:
        # m_ramales, ramal = get_geometry_GIS_V1([path_out + os.path.sep + name + ".gpkg"], dmax=dmax)
        m_ramales, ramal = get_geometry_pypiper_GIS([path_out + os.path.sep + name + ".gpkg"], dmax=1)
    else:
        m_ramales, ramal = get_geometry_pypiper_GIS([path_out + os.path.sep + name + ".gpkg"], dmax=1)

    return m_ramales, ramal


"######################################################################################################################"
"SOLUCIONAR INTERFERENCIAS"
"######################################################################################################################"


def make_list_2D_array(ll, dtype):
    """

    Funciton to get 2D array from a list of lists

    """
    # Convert a nested Python list to a nested numba.typed.List
    # This version uses exceptions to auto-detect the nesting-depth.
    try:
        # Try and convert x to a Numpy array. If this succeeds
        # then we have reached the end of the nesting-depth.
        arr = np.asarray(ll, dtype=dtype)
    except:
        lens = np.array([len(item) for item in ll])
        mask = lens[:, None] > np.arange(lens.max())
        arr = np.zeros(mask.shape, dtype=dtype)
        arr[mask] = np.concatenate(ll)

    return arr


def convert2(x, dtype):
    # Convert a nested Python list to a nested numba.typed.List
    # This version uses exceptions to auto-detect the nesting-depth.
    try:
        # Try and convert x to a Numpy array. If this succeeds
        # then we have reached the end of the nesting-depth.
        y = np.asarray(x, dtype=dtype)
    #
    except:
        # If the conversion to a Numpy array fails, then it can
        # be because not all elements of x can be converted to
        # the given dtype. There is currently no way to distinguish
        # if this is because x is a nested list, or just a list
        # of simple elements with incompatible types.

        # Recursively call this function on all elements of x.
        y = [convert2(x_, dtype=dtype) for x_ in x]

        # Convert Python list to Numba list.
        y = numba.typed.List(y)

    return y


def is_line_same(df, m_ramales, obs_interference, pos_interference, ramal_interference):
    cond_list = []
    cond_show_profile = []
    cond_show_plane = []
    cond_interference = []

    for _ in obs_interference:
        # split
        tipo, tramo = _.split(",")
        # replace tramo in the stirng
        tramo = tramo.replace("tramo:", "").replace(" ", "")
        filtro = df["Tramo"] == tramo
        # get coordinates
        coords = df[filtro].geometry.get_coordinates()
        x, y = coords["x"].to_numpy(), coords["y"].to_numpy()
        coords_interference = np.array([x, y]).T

        # get coords from pypiper
        x1, y1 = (
            m_ramales[ramal_interference]["X"][pos_interference - 1],
            m_ramales[ramal_interference]["Y"][pos_interference - 1],
        )
        x2, y2 = (
            m_ramales[ramal_interference]["X"][pos_interference],
            m_ramales[ramal_interference]["Y"][pos_interference],
        )
        coords_pypiper_line = np.array([[x1, y1], [x2, y2]])
        dist = distance.cdist(coords_interference, coords_pypiper_line)

        # condition for same line (sum 0 in diagonal)
        cond1 = np.sum(np.diag(dist)) < 0.01
        if cond1:
            cond_list.append(False)
            cond_show_profile.append(False)
            cond_show_plane.append(False)
            continue

        cond2 = np.any(dist < 0.01)
        if cond2:
            # conexion de tuberia pypiper hacia tuberia que recibe, puede ser nueva o existente
            cond_new = m_ramales[ramal_interference]["Estado"][pos_interference]
            # conexion = m_ramales[ramal_interference]['Conexion'][pos_interference - 1]

            if pos_interference == 1 and cond_new in ["nuevo"]:
                cond_list.append(True)
                cond_show_profile.append(True)
                cond_show_plane.append(False)
                cond_interference.append(False)

            elif pos_interference == len(m_ramales[ramal_interference]["Conexion"]) - 1 and cond_new in ["nuevo"]:
                cond_list.append(True)
                cond_show_profile.append(True)
                cond_show_plane.append(False)
                cond_interference.append(False)

            else:
                cond_list.append(False)
                cond_show_profile.append(False)
                cond_show_plane.append(False)
                cond_interference.append(False)

            continue

        # is actually a inteference
        cond_list.append(True)
        cond_show_profile.append(True)
        cond_show_plane.append(True)
        cond_interference.append(True)

    return (
        np.array(cond_list),
        np.array(cond_show_profile),
        np.array(cond_show_plane),
        np.array(cond_interference),
    )


@profile
def check_interferences(m_ramales, ramal, interference_sources):
    # crear array de lineas de m_ramales
    m_ramales_lines = []
    m_ramales_tramos = []
    for _ramal in m_ramales.keys():
        # create interference key in dictionary
        m_ramales[_ramal]["Interferencia"] = np.empty(shape=len(m_ramales[_ramal]["Obs"]), dtype=dict)

        # crear puntos de linea
        points = np.array([m_ramales[_ramal]["X"], m_ramales[_ramal]["Y"]]).T.reshape(-1, 1, 2)
        # modificar los puntos a linea
        line = np.concatenate([points[:-1], points[1:]], axis=1)
        m_ramales_lines.append(line)
        m_ramales_tramos.append(m_ramales[_ramal]["Tramo"][1:])

    # concatenar las listas
    m_ramales_lines = np.concatenate(m_ramales_lines)
    m_ramales_tramos = np.concatenate(m_ramales_tramos)

    # list of interferences TRUE
    list_of_interferences = []

    for interference_item in interference_sources:
        interference_source, interference_type = (
            interference_item["interference_source"],
            interference_item["interference_type"],
        )

        if interference_type in ["pypiper"]:
            # open shapefile for interference
            # df = gpd.read_file(interference_source, engine='pyogrio')
            # df = pyogrio.read_dataframe(interference_source, use_arrow=True)
            df = gpd.read_file(interference_source, engine="pyogrio")
            df.drop_duplicates("geometry")
            df = df.drop_duplicates("geometry")
            df.reset_index(inplace=True)
            # interferences lines coordinates
            interference_lines = np.array([_.coords.xy for _ in df.geometry]).astype(float)
            # interference lines names
            interference_tramos = df["Tramo"].to_numpy()
            # interferences state
            interference_state = df["Estado"].to_numpy()
            # interference type
            interference_water_type = df["Tipo"].to_numpy()
            # interference  lines fondo de pozo inicial
            interference_ZFI = df["ZFI"].to_numpy()
            interference_ZFF = df["ZFF"].to_numpy()
            # interference complete length
            interference_line_length = df["L"].to_numpy()
            # interference  lines diameter
            b_arr, h_arr = pp_char_split(df["D_ext"], _split="x")
            interference_diameter = b_arr.astype(float)
            # section type
            interference_seccion_type = df["Seccion"].to_numpy()
            # interference  lines slopes
            interference_x_start = np.array([_.T[0] for _ in interference_lines])

            # get array of line intersection
            line_intersections = nb_get_line_intersect(m_ramales_lines.copy(), interference_lines.copy())

            for pos, intersection in enumerate(line_intersections):
                indice = np.invert(np.isnan(intersection)).nonzero()

                if len(indice[0]) > 0:
                    interference_index = np.unique(indice[0])
                    # get distance from intersection point to ZFI x coordinate of interference line
                    coord_start_interference = interference_x_start[interference_index]
                    coord_interference = line_intersections[pos][interference_index]
                    # interference length from axis to axis (L + 2 * ancho_pozo)
                    interference_length = np.diag(distance.cdist(coord_interference, coord_start_interference, "euclidean"))
                    # get interference elevation min and max
                    ancho_pozo_interference = np.where(
                        interference_diameter[interference_index] < par_dxf(ancho_pozo_limite=1),
                        par_dxf(ancho_pozo_menor_limite=1),
                        np.around(
                            interference_diameter[interference_index] + par_dxf(ancho_pozo_mayor_limite=1),
                            decimals=1,
                        )
                        / 2.0,
                    )
                    interference_real_slope = (interference_ZFI[interference_index] - interference_ZFF[interference_index]) / (
                        interference_line_length[interference_index] - 2 * ancho_pozo_interference
                    )
                    interference_bottom_elevation = interference_ZFI[interference_index] - ((interference_length - ancho_pozo_interference) * interference_real_slope)
                    interference_top_elevation = interference_bottom_elevation + interference_diameter[interference_index]

                    # get ramal y pozo
                    _ramal, _pozo = m_ramales_tramos[pos].split("-")[0].split(".")
                    _pozo = int(_pozo)

                    # ancho de pozo (mitad del ancho de pozo)
                    ancho_pozo = get_ancho_pozo(_ramal, m_ramales)
                    # la posicion de _pozo es la anterior porque no es el tramo, es el pozo inicial
                    coord_start_m_ramales = np.array([m_ramales[_ramal]["X"][_pozo], m_ramales[_ramal]["Y"][_pozo]])

                    # index for the m_ramales line
                    index_m_ramales = np.char.equal(m_ramales[_ramal]["Tramo"], m_ramales_tramos[pos]).nonzero()[0]
                    # real slope considering ancho de pozo
                    real_slope = (m_ramales[_ramal]["ZFI"][index_m_ramales] - m_ramales[_ramal]["ZFF"][index_m_ramales]) / (
                        m_ramales[_ramal]["L"][index_m_ramales] - ancho_pozo[_pozo] * 2
                    )
                    # interference length on line from center and form manhole line
                    interference_length_from_center = distance.cdist([coord_start_m_ramales], coord_interference)[0]
                    interference_length = interference_length_from_center - ancho_pozo[_pozo]
                    line_bottom_elevation = m_ramales[_ramal]["ZFI"][index_m_ramales] - (interference_length * real_slope)
                    line_top_elevation = m_ramales[_ramal]["ZFI"][index_m_ramales] - (interference_length * real_slope) + D_ext_float(_ramal, m_ramales)[index_m_ramales]

                    obs_interference = [
                        __ + " " + ___ + ", tramo:" + str(tramo)
                        for tramo, __, ___ in zip(
                            interference_tramos[np.unique(indice[0])],
                            interference_water_type[[interference_index]][0],
                            interference_state[[interference_index][0]],
                        )
                    ]
                    ramal_interference, pos_interference = m_ramales_tramos[pos].split("-")[1].split(".")
                    pos_interference = int(pos_interference)

                    # check for several line, interference position
                    # line above, interference below
                    cond1 = (line_bottom_elevation >= interference_top_elevation) * 1
                    # line below, interference above
                    cond2 = (line_top_elevation <= interference_bottom_elevation) * 1

                    # check for same line intersection
                    cond_list, cond_show_profile, cond_show_plane, cond_interference = is_line_same(
                        df,
                        m_ramales,
                        obs_interference,
                        pos_interference,
                        ramal_interference,
                    )

                    cond4 = ((cond1 + cond2) > 0).all()

                    # line refers to the m_ramales pipe line
                    if cond4:
                        if not isinstance(
                            m_ramales[ramal_interference]["Interferencia"][pos_interference],
                            dict,
                        ):
                            interference_false_dict = {
                                "seccion": interference_seccion_type[interference_index][cond_list],
                                "b": b_arr[interference_index][cond_list].astype(float),
                                "h": h_arr[interference_index][cond_list].astype(float),
                                "D": interference_diameter[interference_index][cond_list],
                                "top_elevation": interference_top_elevation[cond_list],
                                "bottom_elevation": interference_bottom_elevation[cond_list],
                                "coords": coord_interference[cond_list],
                                "length_on_line": interference_length[cond_list],
                                "interference": False,
                                "obs": list(np.array(obs_interference)[cond_list]),
                                "length_on_line_from_center": interference_length_from_center[cond_list],
                                "future_remove_of_pipe": np.array([False] * len(interference_top_elevation[cond_list])),
                                "show_in_profile": cond_show_profile,
                                "show_in_plane": cond_show_plane,
                            }

                            if len(interference_false_dict["D"]) > 0:
                                m_ramales[ramal_interference]["Interferencia"][pos_interference] = interference_false_dict.copy()

                        else:
                            current_dict = m_ramales[ramal_interference]["Interferencia"][pos_interference]

                            current_dict["seccion"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["seccion"],
                                interference_seccion_type[interference_index][cond_list],
                            )
                            current_dict["b"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["b"],
                                b_arr[interference_index][cond_list].astype(float),
                            )
                            current_dict["h"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["h"],
                                h_arr[interference_index][cond_list].astype(float),
                            )
                            current_dict["D"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["D"],
                                interference_diameter[interference_index][cond_list],
                            )
                            current_dict["top_elevation"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["top_elevation"],
                                interference_top_elevation[cond_list],
                            )
                            current_dict["bottom_elevation"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["bottom_elevation"],
                                interference_bottom_elevation[cond_list],
                            )
                            current_dict["coords"] = np.concatenate(
                                [
                                    m_ramales[ramal_interference]["Interferencia"][pos_interference]["coords"],
                                    coord_interference[cond_list],
                                ]
                            )
                            current_dict["length_on_line"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["length_on_line"],
                                interference_length[cond_list],
                            )
                            current_dict["obs"] = m_ramales[ramal_interference]["Interferencia"][pos_interference]["obs"] + list(np.array(obs_interference)[cond_list])
                            current_dict["length_on_line_from_center"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["length_on_line_from_center"],
                                interference_length_from_center[cond_list],
                            )
                            current_dict["future_remove_of_pipe"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["future_remove_of_pipe"],
                                np.where(
                                    interference_water_type[[interference_index]][0] == "remover",
                                    True,
                                    False,
                                )[cond_list],
                            )
                            current_dict["show_in_profile"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["show_in_profile"],
                                cond_show_profile,
                            )
                            current_dict["show_in_plane"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["show_in_plane"],
                                cond_show_plane,
                            )

                    else:
                        if not isinstance(
                            m_ramales[ramal_interference]["Interferencia"][pos_interference],
                            dict,
                        ):
                            interference_true_dict = {
                                "seccion": interference_seccion_type[interference_index][cond_list],
                                "b": b_arr[interference_index][cond_list].astype(float),
                                "h": h_arr[interference_index][cond_list].astype(float),
                                "D": interference_diameter[interference_index][cond_list],
                                "top_elevation": interference_top_elevation[cond_list],
                                "bottom_elevation": interference_bottom_elevation[cond_list],
                                "coords": coord_interference[cond_list],
                                "length_on_line": interference_length[cond_list],
                                "interference": (True if np.any(cond_interference == True) else False),
                                "obs": list(np.array(obs_interference)[cond_list]),
                                "interference_position": "interference",
                                "length_on_line_from_center": interference_length_from_center[cond_list],
                                "future_remove_of_pipe": np.where(
                                    interference_water_type[[interference_index]][0] == "remover",
                                    True,
                                    False,
                                )[cond_list],  # this line need to be check becasue the user may not always put remover in  Tipo column of the file to remove this pipes.
                                "show_in_profile": cond_show_profile,
                                "show_in_plane": cond_show_plane,
                            }

                            if len(interference_true_dict["D"]) > 0:
                                m_ramales[ramal_interference]["Interferencia"][pos_interference] = interference_true_dict.copy()

                        else:
                            current_dict = m_ramales[ramal_interference]["Interferencia"][pos_interference]

                            current_dict["seccion"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["seccion"],
                                interference_seccion_type[interference_index][cond_list],
                            )
                            current_dict["b"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["b"],
                                b_arr[interference_index][cond_list].astype(float),
                            )
                            current_dict["h"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["h"],
                                h_arr[interference_index][cond_list].astype(float),
                            )
                            current_dict["D"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["D"],
                                interference_diameter[interference_index][cond_list],
                            )
                            current_dict["top_elevation"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["top_elevation"],
                                interference_top_elevation[cond_list],
                            )
                            current_dict["bottom_elevation"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["bottom_elevation"],
                                interference_bottom_elevation[cond_list],
                            )
                            current_dict["coords"] = np.concatenate(
                                [
                                    m_ramales[ramal_interference]["Interferencia"][pos_interference]["coords"],
                                    coord_interference[cond_list],
                                ]
                            )
                            current_dict["length_on_line"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["length_on_line"],
                                interference_length[cond_list],
                            )
                            current_dict["interference"] = (True if np.any(cond_interference == True) else False,)
                            current_dict["obs"] = m_ramales[ramal_interference]["Interferencia"][pos_interference]["obs"] + list(np.array(obs_interference)[cond_list])
                            current_dict["length_on_line_from_center"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["length_on_line_from_center"],
                                interference_length_from_center[cond_list],
                            )
                            current_dict["future_remove_of_pipe"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["future_remove_of_pipe"],
                                np.where(
                                    interference_water_type[[interference_index]][0] == "remover",
                                    True,
                                    False,
                                )[cond_list],
                            )
                            current_dict["show_in_profile"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["show_in_profile"],
                                cond_show_profile,
                            )
                            current_dict["show_in_plane"] = np.append(
                                m_ramales[ramal_interference]["Interferencia"][pos_interference]["show_in_plane"],
                                cond_show_plane,
                            )

                    if np.all(cond_list == False):
                        continue

                    if m_ramales[ramal_interference]["Estado"][pos_interference] in ["nuevo"]:
                        pipe_remove_check = m_ramales[ramal_interference]["Interferencia"][pos_interference]["future_remove_of_pipe"]

                        if (pipe_remove_check + 0 == 0).all():
                            if np.any(cond_interference == True) and m_ramales[ramal_interference]["Interferencia"][pos_interference]["interference"]:
                                list_of_interferences.append([ramal_interference, pos_interference])

    return m_ramales, ramal, list_of_interferences


def non_rigth_triangle_solver(
    ancho_pozo,
    distance_to_move,
    i,
    interference_lenght_position,
    m_ramales,
    m_ramales_pos,
    real_slope,
):
    b = m_ramales[i]["L"][m_ramales_pos] - interference_lenght_position - ancho_pozo[m_ramales_pos] * 2
    a = b * real_slope
    c = (a**2 + b**2) ** 0.5
    ang_A = 90 - np.rad2deg(np.arctan(real_slope))
    b1 = c.copy()
    c1 = distance_to_move.copy()
    a1 = (b1**2 + c1**2 - 2 * b * c * np.cos(np.deg2rad(ang_A))) ** 0.5
    ang_C = np.rad2deg(np.arcsin((np.sin(np.deg2rad(ang_A)) * c1) / a1))
    ang_B = 180 - ang_C - ang_A
    b2 = m_ramales[i]["L"][m_ramales_pos] - ancho_pozo[m_ramales_pos] * 2
    a2 = np.tan(np.arctan(real_slope)) * b2
    c2 = (a2**2 + b2**2) ** 0.5
    b3 = c2.copy()
    c3 = (np.sin(np.deg2rad(ang_C)) / np.sin(np.deg2rad(ang_B))) * b3
    distance_to_move_triangle = c3.copy()
    return distance_to_move_triangle


def fix_interferences(m_ramales, ramal):
    # round slope value
    round_slope_value = 0.001
    # minimun depth cover
    minimum_depth_cover_general = 0.5
    # max slope change
    max_slope_change = 0.03
    # min length for change of slope
    min_lenght_slope = 10
    # security length to avoid interference
    avoid_length = 0.15

    # revisar la llegada de ramales nuevo a existentes
    for i in ramal.keys():
        # indice para modificar los tramos nuevos unicamente
        index = np.char.equal(m_ramales[i]["Estado"], "nuevo").nonzero()[0]
        if index.size > 0:
            # minum cover
            # minimum_depth_cover = m_ramales[i]['cobertura_min'][0] if m_ramales[i]['cobertura_min'][0] > 0 else minimum_depth_cover_general
            minimum_depth_cover = minimum_depth_cover_general

            # check for interferences in ramal
            index_interference = (m_ramales[i]["Interferencia"] != None).nonzero()[0]
            interference_items = m_ramales[i]["Interferencia"][index_interference]
            # ancho de pozo (L/2)
            ancho_pozo = get_ancho_pozo(i, m_ramales)
            borrar = 0
            for interference_item, m_ramales_pos in zip(interference_items, index_interference):
                # check if there is an intersection of the interference
                if interference_item["interference"]:
                    interference_bottom_elevations = interference_item["bottom_elevation"]
                    interference_top_elevations = interference_item["top_elevation"]
                    interference_lenght_position_list = np.where(
                        interference_item["length_on_line"] < 0,
                        0,
                        interference_item["length_on_line"],
                    )
                    interference_lenght_position_from_center_list = np.where(
                        interference_item["length_on_line_from_center"] < 0,
                        0,
                        interference_item["length_on_line_from_center"],
                    )
                    future_remove_of_pipe = interference_item["future_remove_of_pipe"]

                    for (
                        interference_bottom_elevation,
                        interference_top_elevation,
                        interference_lenght_position_from_center,
                        interference_lenght_position,
                        pipe_remove,
                    ) in zip(
                        interference_bottom_elevations,
                        interference_top_elevations,
                        interference_lenght_position_from_center_list,
                        interference_lenght_position_list,
                        future_remove_of_pipe,
                    ):
                        # check for zero values
                        interference_lenght_position_from_center = (
                            interference_lenght_position_from_center if interference_lenght_position_from_center != 0 else interference_lenght_position_from_center + 0.01
                        )

                        # update elevations after changes
                        # real slope
                        real_slope = (m_ramales[i]["ZFI"][m_ramales_pos] - m_ramales[i]["ZFF"][m_ramales_pos]) / (m_ramales[i]["L"][m_ramales_pos] - ancho_pozo[m_ramales_pos] * 2)
                        # get line top and bottom elevation
                        line_bottom_elevation = m_ramales[i]["ZFI"][m_ramales_pos] - (interference_lenght_position * real_slope)
                        line_top_elevation = m_ramales[i]["ZFI"][m_ramales_pos] - (interference_lenght_position * real_slope) + D_ext_float(i, m_ramales)[m_ramales_pos]

                        # check for line with more than one interference, if the previius interference fix resolve all of them.
                        # line above, interference below
                        cond1 = (line_bottom_elevation >= interference_top_elevation) * 1
                        # line below, interference above
                        cond2 = (line_top_elevation <= interference_bottom_elevation) * 1
                        cond3 = ((cond1 + cond2) > 0).all()
                        if cond3:
                            continue

                        if pipe_remove:
                            continue

                        # check if elevation needs to move up or down
                        move_below, move_above = (
                            np.round(
                                np.abs(interference_bottom_elevation - line_top_elevation) + avoid_length,
                                2,
                            ),
                            np.round(
                                np.abs(interference_top_elevation - line_bottom_elevation) + avoid_length,
                                2,
                            ),
                        )

                        smin_temp = np.array(Smin(m_ramales[i]["Material"], m_ramales))
                        smin_usuario = m_ramales[i]["S_min"]
                        filtro_smin = ~np.isnan(smin_usuario)
                        filtro_smin = filtro_smin.nonzero()[0]
                        if len(filtro_smin) > 0:
                            smin = smin_temp.copy()
                            smin[filtro_smin] = smin_usuario[filtro_smin]
                        else:
                            smin = smin_temp.copy()

                        # get new ZFI
                        min_ZFI = m_ramales[i]["ZFF"][m_ramales_pos] + smin[m_ramales_pos] * m_ramales[i]["L"][m_ramales_pos]
                        # get maximun SALTO distance
                        available_jump = np.round(m_ramales[i]["ZFI"][m_ramales_pos] - min_ZFI, 2)
                        # get actual length to move considering the traingle law
                        if interference_lenght_position > 0:
                            distance_to_move_jump = np.round(
                                non_rigth_triangle_solver(
                                    ancho_pozo,
                                    move_below,
                                    i,
                                    interference_lenght_position,
                                    m_ramales,
                                    m_ramales_pos,
                                    real_slope,
                                ),
                                2,
                            )  # if distance_to_move_jump * 10 > move_below:  #     distance_to_move_jump = move_below + 0.1
                        else:
                            distance_to_move_jump = move_below.copy()

                        # get conditions
                        # conditions checking if a small change in slope would move the pipe enough
                        cond_slope_jump = interference_lenght_position_from_center * max_slope_change < move_below
                        # conditiont for locate the poistion of the interference
                        cond_lenght_interference = interference_lenght_position_from_center <= m_ramales[i]["L"][m_ramales_pos] / 3.0
                        # check for a small length of the trench
                        cond_lenght_slope = m_ramales[i]["L"][m_ramales_pos] < min_lenght_slope

                        # save ZFF and ZFI elevations to be restored after slope change
                        ZFF_old = m_ramales[i]["ZFF"].copy()

                        # 1. disminuir pendiente de tramo para mover sobre la interferencia
                        m_ramales, cond = get_smaller_slope(
                            ZFF_old,
                            i,
                            m_ramales,
                            m_ramales_pos,
                            minimum_depth_cover,
                            move_above,
                            interference_lenght_position_from_center,
                            round_slope_value,
                            smin,
                        )
                        if cond:
                            continue

                        # available jump > need jump
                        if available_jump >= distance_to_move_jump:
                            # 2. hacer salto en el pozo anterior
                            m_ramales, cond = get_manhole_jump_available_jump(
                                i,
                                m_ramales,
                                m_ramales_pos,
                                distance_to_move_jump,
                                cond_slope_jump,
                                cond_lenght_interference,
                                cond_lenght_slope,
                            )
                            if cond:
                                continue
                        else:
                            # 2. hacer salto en el pozo anterior
                            m_ramales, cond = get_manhole_jump_not_available_jump(
                                ZFF_old,
                                cond_lenght_interference,
                                cond_lenght_slope,
                                cond_slope_jump,
                                i,
                                interference_lenght_position,
                                line_top_elevation,
                                m_ramales,
                                m_ramales_pos,
                                move_below,
                                round_slope_value,
                                smin,
                            )
                            if cond:
                                continue

                        # 3. aumentar la pendiente de tramo para mover bajo la interfernecia
                        m_ramales, cond = get_bigger_slope(
                            ZFF_old,
                            i,
                            interference_lenght_position_from_center,
                            m_ramales,
                            m_ramales_pos,
                            round_slope_value,
                            smin,
                            ancho_pozo,
                            interference_bottom_elevation,
                            avoid_length,
                            move_below,
                        )
                        if cond:
                            continue

                        if not cond:
                            print("No hay caso de:", i, m_ramales_pos)
                borrar = borrar + 1

    # "DIMENSIONAR SECCIONES"
    m_ramales, ramal = get_sizing_int(m_ramales, ramal, xy_inter)
    m_ramales, ramal = get_sizing_ext(m_ramales, ramal)
    m_ramales, ramal = get_SLL(m_ramales, ramal)
    m_ramales, ramal = get_SPLL(m_ramales, ramal)
    m_ramales, ramal = get_sizing_SPLL(m_ramales, ramal, xy_inter)

    return m_ramales, ramal


def get_manhole_jump_not_available_jump(
    ZFF_old,
    cond_lenght_interference,
    cond_lenght_slope,
    cond_slope_jump,
    i,
    interference_lenght_position,
    line_top_elevation,
    m_ramales,
    m_ramales_pos,
    move_below,
    round_slope_value,
    smin,
):
    if (cond_slope_jump or cond_lenght_interference) or cond_lenght_slope:
        # check for distance to move with minimun slope
        elevation_minimun_slope = line_top_elevation - move_below + interference_lenght_position * smin[m_ramales_pos]
        current_pipe_size = D_ext_float(i, m_ramales)[m_ramales_pos]
        heigth_minimun_slope = np.round(
            m_ramales[i]["ZFI"][m_ramales_pos] + current_pipe_size - elevation_minimun_slope,
            2,
        )
        # generar el salto de forma completa con distancia distance_to_move_jump
        m_ramales[i]["SALTO"][m_ramales_pos] = m_ramales[i]["SALTO"][m_ramales_pos] + heigth_minimun_slope
        # new ZFI
        new_ZFI = m_ramales[i]["ZFI"][m_ramales_pos] - heigth_minimun_slope
        m_ramales[i]["ZFI"][m_ramales_pos] = new_ZFI
        # new slope
        m_ramales[i]["S"][m_ramales_pos] = np.round(smin[m_ramales_pos], 3)
        # update elevations and manhole heigth
        m_ramales = update_elevations(i, m_ramales, m_ramales_pos)
        # decrease slope in next trenches to return to same elevation in posterior manholes
        m_ramales = balance_slope_next_trench(ZFF_old, i, m_ramales, m_ramales_pos, round_slope_value, smin)
        # decrease jumps in next trenches to return to same elevation in posterior manholes
        m_ramales = balance_jump_next_trench(i, m_ramales, m_ramales_pos)
        # ZFF_old = m_ramales[i]['ZFF'] # actuallizar

        return m_ramales, True
    else:
        return m_ramales, False


def get_bigger_slope(
    ZFF_old,
    i,
    interference_lenght_position_from_center,
    m_ramales,
    m_ramales_pos,
    round_slope_value,
    smin,
    ancho_pozo,
    interference_bottom_elevation,
    avoid_length,
    move_below,
):
    # current pipe size
    current_pipe_size = D_ext_float(i, m_ramales)[m_ramales_pos]

    if interference_lenght_position_from_center > m_ramales[i]["L"][m_ramales_pos] - ancho_pozo[m_ramales_pos]:
        project_heigth = (m_ramales[i]["ZFF"][m_ramales_pos] + current_pipe_size - interference_bottom_elevation) + avoid_length
        project_length = m_ramales[i]["L"][m_ramales_pos] - ancho_pozo[m_ramales_pos]
    else:
        project_heigth = move_below
        project_length = interference_lenght_position_from_center

    # get additional slope
    slope_change_need_it = np.round(project_heigth / project_length, 3)
    # new slope
    new_slope = m_ramales[i]["S"][m_ramales_pos] + slope_change_need_it if (m_ramales[i]["S"][m_ramales_pos] + slope_change_need_it) >= smin[m_ramales_pos] else smin[m_ramales_pos]
    m_ramales[i]["S"][m_ramales_pos] = new_slope
    # update elevations and manhole heigth
    m_ramales = update_elevations(i, m_ramales, m_ramales_pos)
    # decrease slope in next trenches to reutnr to same elevation in posterior manholes
    m_ramales = balance_slope_next_trench(ZFF_old, i, m_ramales, m_ramales_pos, round_slope_value, smin)
    # decrease jumps in next trenches to return to same elevation in posterior manholes
    m_ramales = balance_jump_next_trench(i, m_ramales, m_ramales_pos)
    # ZFF_old = m_ramales[i]['ZFF'] # actuallizar

    # restar profundidad ganada por cambio de pendiete en caso de que haya un salto en el pozo continuo
    if m_ramales_pos + 1 < len(m_ramales[i]["S"]):
        if m_ramales[i]["SALTO"][m_ramales_pos + 1] > 0:
            heigth = slope_change_need_it * m_ramales[i]["L"][m_ramales_pos]
            if heigth <= m_ramales[i]["SALTO"][m_ramales_pos + 1]:
                # modificar SALTO
                m_ramales[i]["SALTO"][m_ramales_pos + 1] = m_ramales[i]["SALTO"][m_ramales_pos + 1] - heigth
                # modificar ZFI
                m_ramales[i]["ZFI"][m_ramales_pos + 1] = m_ramales[i]["ZFI"][m_ramales_pos + 1] + heigth
                new_slope = np.round(
                    (m_ramales[i]["ZFI"][m_ramales_pos + 1] - m_ramales[i]["ZFF"][m_ramales_pos + 1]) / m_ramales[i]["L"][m_ramales_pos + 1],
                    3,
                )
            else:
                # modificar salto
                m_ramales[i]["SALTO"][m_ramales_pos + 1] = 0
                # modificar ZFI
                m_ramales[i]["ZFI"][m_ramales_pos + 1] = m_ramales[i]["ZFF"][m_ramales_pos]
                new_slope = np.round(
                    (m_ramales[i]["ZFI"][m_ramales_pos + 1] - m_ramales[i]["ZFF"][m_ramales_pos + 1]) / m_ramales[i]["L"][m_ramales_pos + 1],
                    3,
                )

            # check if there is a Conexion after m_ramales_pos
            cond = len(np.where(m_ramales[i]["Conexion"][m_ramales_pos + 1 : -1])[0])
            if cond == 0:
                # initial depth
                initial_depth = par_basicos(h_min=1) if m_ramales[i]["cobertura_min"][0] <= 0.0 or np.isnan(m_ramales[i]["cobertura_min"][0]) else m_ramales[i]["cobertura_min"][0]
                new_slope = np.round(
                    (m_ramales[i]["ZFI"][m_ramales_pos + 1] - (m_ramales[i]["ZTF"][m_ramales_pos + 1] - initial_depth)) / m_ramales[i]["L"][m_ramales_pos + 1],
                    3,
                )
                # check min slope
                new_slope = new_slope if new_slope >= smin[m_ramales_pos + 1] else smin[m_ramales_pos + 1]

            # modificar slope
            m_ramales[i]["S"][m_ramales_pos + 1] = new_slope
            # update elevations and manhole heigth
            m_ramales = update_elevations(i, m_ramales, m_ramales_pos + 1)
    return m_ramales, True


def get_smaller_slope(
    ZFF_old,
    i,
    m_ramales,
    m_ramales_pos,
    minimum_depth_cover,
    move_above,
    interference_lenght_position_from_center,
    round_slope_value,
    smin,
):
    """

    :param ZFF_old:
    :param i:
    :param m_ramales:
    :param m_ramales_pos:
    :param minimum_depth_cover:
    :param move_above:
    :param round_slope_value:
    :param smin:
    :return: funcion que retorna la tuberia con una menor pendiente para evitar la interferencia
    """
    # get need it slope
    slope_change_need_it = np.round(move_above / interference_lenght_position_from_center, 3)
    # check if the chnaged slope keep minimum manhole depth
    heigth_change = m_ramales[i]["L"][m_ramales_pos] * slope_change_need_it
    current_manhole_heigth = m_ramales[i]["HF"][m_ramales_pos]
    current_pipe_size = D_ext_float(i, m_ramales)[m_ramales_pos]
    new_slope = m_ramales[i]["S"][m_ramales_pos] - slope_change_need_it
    # preguntar si cumple la condiciones de disminucion de pendiente
    cond_heigth_change = (current_manhole_heigth - heigth_change - float(current_pipe_size)) > minimum_depth_cover
    if cond_heigth_change and new_slope >= smin[m_ramales_pos]:
        # new slope
        m_ramales[i]["S"][m_ramales_pos] = new_slope
        # update elevations and manhole heigth
        m_ramales = update_elevations(i, m_ramales, m_ramales_pos)
        # decrease slope in next trenches to reutnr to same elevation in posterior manholes
        m_ramales = balance_slope_next_trench(ZFF_old, i, m_ramales, m_ramales_pos, round_slope_value, smin)
        # decrease jumps in next trenches to return to same elevation in posterior manholes
        m_ramales = balance_jump_next_trench(i, m_ramales, m_ramales_pos)
        # ZFF_old = m_ramales[i]['ZFF'] # actuallizar

        return m_ramales, True
    else:
        return m_ramales, False


def get_manhole_jump_available_jump(
    i,
    m_ramales,
    m_ramales_pos,
    distance_to_move_jump,
    cond_slope_jump,
    cond_lenght_interference,
    cond_lenght_slope,
):
    # do jump in manhole and update slope
    if (cond_slope_jump or cond_lenght_interference) or cond_lenght_slope:
        # new SALTO
        new_jump = m_ramales[i]["SALTO"][m_ramales_pos] + distance_to_move_jump
        m_ramales[i]["SALTO"][m_ramales_pos] = new_jump
        # new ZFI
        new_ZFI = m_ramales[i]["ZFI"][m_ramales_pos] - distance_to_move_jump
        m_ramales[i]["ZFI"][m_ramales_pos] = new_ZFI
        # new slope
        new_slope = (m_ramales[i]["ZFI"][m_ramales_pos] - m_ramales[i]["ZFF"][m_ramales_pos]) / m_ramales[i]["L"][m_ramales_pos]
        m_ramales[i]["S"][m_ramales_pos] = np.round(new_slope, 3)
        return m_ramales, True
    else:
        return m_ramales, False


def update_elevations(i, m_ramales, m_ramales_pos):
    # assing new elevations ZFI, ZFF
    dif_h_s = m_ramales[i]["ZFF"][m_ramales_pos] - (m_ramales[i]["ZFI"][m_ramales_pos] - (m_ramales[i]["S"][m_ramales_pos] * m_ramales[i]["L"][m_ramales_pos]))
    m_ramales[i]["ZFF"][m_ramales_pos:] = m_ramales[i]["ZFF"][m_ramales_pos:] - dif_h_s
    m_ramales[i]["ZFI"][m_ramales_pos + 1 :] = m_ramales[i]["ZFI"][m_ramales_pos + 1 :] - dif_h_s
    m_ramales[i]["HI"] = m_ramales[i]["ZTI"] - m_ramales[i]["ZFI"]
    m_ramales[i]["HF"] = m_ramales[i]["ZTF"] - m_ramales[i]["ZFF"]
    # assing new manhole heigth  HF, HI
    m_ramales[i]["HI"] = m_ramales[i]["ZTI"] - m_ramales[i]["ZFI"]
    m_ramales[i]["HF"] = m_ramales[i]["ZTF"] - m_ramales[i]["ZFF"]

    return m_ramales


def balance_slope_next_trench(ZFF_old, i, m_ramales, m_ramales_pos, round_slope_value, smin):
    """

    :param ZFF_old:
    :param i:
    :param m_ramales:
    :param m_ramales_pos:
    :param round_slope_value:
    :param smin: array de pendientes minimas segun el material
    :return:
    """

    # modificar tramos siguiente reduciendo la pendiente para llegar a las mismas profundidad de excavaciones
    # check next trench for changing slope
    cond_check = True
    new_pos = m_ramales_pos
    while cond_check:
        # get index of next trench
        new_pos = new_pos + 1
        if new_pos < len(m_ramales[i]["S"]):
            # check if slope can compensate difference of elevation need to change (dif_h_s value)
            slope_change_need_it = np.round(
                (ZFF_old[new_pos] - m_ramales[i]["ZFF"][new_pos]) / m_ramales[i]["L"][new_pos],
                3,
            )
            new_slope = m_ramales[i]["S"][new_pos] - slope_change_need_it if (m_ramales[i]["S"][new_pos] - slope_change_need_it) >= smin[new_pos] else smin[new_pos]
            # assing new slope
            m_ramales[i]["S"][new_pos] = new_slope

            # assing new elevations ZFI, ZFF
            new_dif_h_s = m_ramales[i]["ZFF"][new_pos] - (m_ramales[i]["ZFI"][new_pos] - (m_ramales[i]["S"][new_pos] * m_ramales[i]["L"][new_pos]))
            m_ramales[i]["ZFF"][new_pos:] = m_ramales[i]["ZFF"][new_pos:] - new_dif_h_s
            m_ramales[i]["ZFI"][new_pos + 1 :] = m_ramales[i]["ZFI"][new_pos + 1 :] - new_dif_h_s
            m_ramales[i]["HI"] = m_ramales[i]["ZTI"] - m_ramales[i]["ZFI"]
            m_ramales[i]["HF"] = m_ramales[i]["ZTF"] - m_ramales[i]["ZFF"]

            # assing new manhole heigth  HF, HI
            m_ramales[i]["HI"] = m_ramales[i]["ZTI"] - m_ramales[i]["ZFI"]
            m_ramales[i]["HF"] = m_ramales[i]["ZTF"] - m_ramales[i]["ZFF"]

            # check for similar elevations in ZFF
            cond_1 = np.where(ZFF_old[new_pos:] - m_ramales[i]["ZFF"][new_pos:] < 0)[0]
            cond_2 = np.invert(
                np.isclose(
                    m_ramales[i]["ZFF"][new_pos:],
                    ZFF_old[new_pos:],
                    atol=m_ramales[i]["L"][new_pos] * round_slope_value,
                )
            ).nonzero()[0]
            if cond_1.size == 0 and cond_2.size == 0:
                cond_check = False
        else:
            cond_check = False
    return m_ramales


def balance_jump_next_trench(i, m_ramales, m_ramales_pos):
    """
    Balances the network by adjusting jumps (SALTO) considering connections
    """

    cond_check = True
    new_pos = m_ramales_pos
    max_pos = len(m_ramales[i]["S"]) - 1
    min_elev_arr = get_min_elev_trench(i, m_ramales)

    while cond_check and new_pos < max_pos:  # Added explicit length check
        # Initialize connection tracking

        has_connections = False

        # Get connections for current position
        current_connections = m_ramales[i]["Conexion"][new_pos]

        # Check connections and split if they exist
        if current_connections:
            # connections_list = current_connections.split(',')
            # # Process all valid connections
            # for connection in connections_list:
            #     if connection:
            #         ramal_desde, pz_desde = connection.split(".")
            #         connection_elevation = m_ramales[ramal_desde]["ZFF"][int(pz_desde)]
            #         min_connection_elevation = min(min_connection_elevation, connection_elevation)
            #         has_connections = True
            #
            #
            # pozo_hmin = np.nan_to_num(m_ramales[i]['Pozo_hmin'][new_pos])
            # min_pz_hmin_elevation = m_ramales[i]['ZTF'][new_pos] - pozo_hmin
            # min_elevation = min(min_connection_elevation, min_pz_hmin_elevation)
            if min_elev_arr[new_pos + 1] != 1000000:
                min_elevation = min_elev_arr[new_pos + 1]
                has_connections = True

        if has_connections:
            # Diferencia considerando tanto conexiones como el tramo anterior
            elevation_difference = min(min_elevation - m_ramales[i]["ZFI"][new_pos + 1], m_ramales[i]["ZFF"][new_pos] - m_ramales[i]["ZFI"][new_pos + 1])
            if elevation_difference > 0:
                # Hay espacio para reducir el salto
                current_jump = m_ramales[i]["SALTO"][new_pos + 1]
                new_jump = max(0, current_jump - elevation_difference)
                m_ramales[i]["SALTO"][new_pos + 1] = new_jump

                # Actualizar elevaciones
                m_ramales[i]["ZFI"][new_pos + 1 :] = m_ramales[i]["ZFI"][new_pos + 1 :] + elevation_difference
                m_ramales[i]["ZFF"][new_pos + 1 :] = m_ramales[i]["ZFF"][new_pos + 1 :] + elevation_difference
                m_ramales[i]["HI"] = m_ramales[i]["ZTI"] - m_ramales[i]["ZFI"]
                m_ramales[i]["HF"] = m_ramales[i]["ZTF"] - m_ramales[i]["ZFF"]

            # Siempre avanzamos después de procesar una posición
            new_pos += 1
        else:
            # Diferencia considerando tanto conexiones como el tramo anterior
            elevation_difference = min(min_elev_arr[new_pos + 1] - m_ramales[i]["ZFI"][new_pos + 1], m_ramales[i]["ZFF"][new_pos] - m_ramales[i]["ZFI"][new_pos + 1])
            if elevation_difference > 0:
                # Hay espacio para reducir el salto
                current_jump = m_ramales[i]["SALTO"][new_pos + 1]
                new_jump = max(0, current_jump - elevation_difference)
                m_ramales[i]["SALTO"][new_pos + 1] = new_jump

                # Actualizar elevaciones
                m_ramales[i]["ZFI"][new_pos + 1 :] = m_ramales[i]["ZFI"][new_pos + 1 :] + elevation_difference
                m_ramales[i]["ZFF"][new_pos + 1 :] = m_ramales[i]["ZFF"][new_pos + 1 :] + elevation_difference
                m_ramales[i]["HI"] = m_ramales[i]["ZTI"] - m_ramales[i]["ZFI"]
                m_ramales[i]["HF"] = m_ramales[i]["ZTF"] - m_ramales[i]["ZFF"]

            # Si no hay conexiones, avanzamos
            new_pos += 1

        # Verificar si la red está balanceada
        remaining_positions = np.isclose(m_ramales[i]["ZFI"][new_pos:], min_elev_arr[new_pos:], atol=0.01)

        if remaining_positions.all():
            cond_check = False

    return m_ramales


def get_min_elev_trench(i, m_ramales):
    min_elev_list = []
    for conexion in m_ramales[i]["Conexion"]:
        min_connection_elevation = float("inf")
        if conexion:
            connections_list = conexion.split(",")
            for connection in connections_list:
                if connection:
                    ramal_desde, pz_desde = connection.split(".")
                    connection_elevation = m_ramales[ramal_desde]["ZFF"][int(pz_desde)]
                    min_connection_elevation = min(min_connection_elevation, connection_elevation)
                else:
                    min_connection_elevation = 1000000
            min_elev_list.append(min_connection_elevation)

        else:
            min_connection_elevation = 1000000
            min_elev_list.append(min_connection_elevation)
    min_elev_arr = np.roll(min_elev_list, 1)[1:]
    pozo_hmin = np.roll(np.nan_to_num(m_ramales[i]["Pozo_hmin"]), 1)
    pozo_hmin_elev = m_ramales[i]["ZTI"][1:] - pozo_hmin[1:]
    min_elev = np.min([min_elev_arr, pozo_hmin_elev], axis=0)
    min_elev = np.insert(min_elev, 0, 1000000)
    return min_elev


def manage_interferences(m_ramales, ramal, interference_sources):
    n_max = 5
    cont = 0
    cond = True

    # identify interferences
    m_ramales, ramal, list_of_interferences = check_interferences(m_ramales, ramal, interference_sources)

    while cond:
        # locate and fix interferences
        while len(list_of_interferences) > 0:
            cont = cont + 1
            print("try fix interference: ", cont)

            # fix interferences
            m_ramales, ramal = fix_interferences(m_ramales, ramal)
            # # identify interferences
            m_ramales, ramal, list_of_interferences = check_interferences(m_ramales, ramal, interference_sources)

            if cont > n_max:
                print("No puede resolver las interferencias: ", list_of_interferences)
                print([m_ramales[_[0]]["Interferencia"][int(_[1])]["obs"] for _ in list_of_interferences])
                print([m_ramales[_[0]]["Interferencia"][int(_[1])]["obs"] for _ in list_of_interferences])
                shp_out(m_ramales, ramal, project_name)
                cad_profile_out(m_ramales, ramal, project_name, elev_source=elev_source, step=5)
                sys.exit("ERROR")

        cont = 0
        m_ramales, ramal = check_pz(m_ramales, ramal, xy_inter)
        # m_ramales = check_pz_overfitting(m_ramales, xy_inter)
        m_ramales, ramal = get_opt_V(m_ramales, ramal, xy_inter)

        # identify interferences
        m_ramales, ramal, list_of_interferences = check_interferences(m_ramales, ramal, interference_sources)

        if len(list_of_interferences) == 0:
            cond = False

    return m_ramales, ramal


def check_depth_jump_consistency(m_ramales):
    for i in m_ramales.keys():
        m_ramales[i]["HI"] = m_ramales[i]["ZTI"] - m_ramales[i]["ZFI"]
        m_ramales[i]["HF"] = m_ramales[i]["ZTF"] - m_ramales[i]["ZFF"]
    return m_ramales


"######################################################################################################################"
"MAKE FIGURES FOR PRESENTATION"
"######################################################################################################################"


def hex_to_rgb(value):
    """
    Converts hex to rgb colours
    value: string of 6 characters representing a hex colour.
    Returns: list length 3 of RGB values"""
    value = value.strip("#")  # removes hash symbol if present
    lv = len(value)
    return tuple(int(value[i : i + lv // 3], 16) for i in range(0, lv, lv // 3))


def rgb_to_dec(value):
    """
    Converts rgb to decimal colours (i.e. divides each value by 256)
    value: list (length 3) of RGB values
    Returns: list (length 3) of decimal values"""
    return [v / 256 for v in value]


def get_continuous_cmap(hex_list, float_list=None):
    import matplotlib as mpl

    """ creates and returns a color map that can be used in heat map figures.
        If float_list is not provided, colour map graduates linearly between each color in hex_list.
        If float_list is provided, each color in hex_list is mapped to the respective location in float_list.

        Parameters
        ----------
        hex_list: list of hex code strings
        float_list: list of floats between 0 and 1, same length as hex_list. Must start with 0 and end with 1.

        Returns
        ----------
        colour map"""
    rgb_list = [rgb_to_dec(hex_to_rgb(i)) for i in hex_list]
    if float_list:
        pass
    else:
        float_list = list(np.linspace(0, 1, len(rgb_list)))

    cdict = dict()
    for num, col in enumerate(["red", "green", "blue"]):
        col_list = [[float_list[i], rgb_list[i][num], rgb_list[i][num]] for i in range(len(float_list))]
        cdict[col] = col_list
    cmp = mpl.colors.LinearSegmentedColormap("my_cmp", segmentdata=cdict, N=256)
    return cmp


def categorical_variables_bar_old(
    df,
    variable,
    title,
    labels,
    out_dir,
    existente=True,
    name=False,
    make_it_graduated=False,
):
    import matplotlib.pyplot as plt
    import matplotlib as mpl

    mpl.rcParams.update({"font.size": 16})

    # Binning the data if make_it_graduated is True
    if make_it_graduated:
        # Define the maximum value for binning based on the data
        max_value = round(seccion_str2float(df[variable]).max(), 1)
        min_value = round(seccion_str2float(df[variable]).min(), 1)
        min_value = np.max([0, min_value])
        # Define the range and adjust the max_value and min_value to be multiples of 0.1
        if max_value == min_value:
            val = 0.05
        else:
            val = (max_value - min_value) / 25
        range_size = round(round(val / val) * 0.1, 2)
        min_value = np.floor(min_value / range_size) * range_size - 0.1
        max_value = np.ceil(max_value / range_size) * range_size + 0.1

        # Create bins with the specified bin size
        bins = np.arange(min_value, max_value + range_size, range_size)
        bin_size = len(bins)
        # Bin the data
        df["binned"] = pd.cut(seccion_str2float(df[variable]), bins, include_lowest=True)
        # Update the variable to use the binned data
        variable = "binned"
    else:
        bin_size = len(np.unique(df[variable]))

    cantidad_nuevo = [df.loc[(df[variable] == _) & (df["Estado"] == "nuevo")]["L"].sum().round(0) for _ in np.unique(df[variable])]
    df_nuevo = pd.Series(cantidad_nuevo, index=np.unique(df[variable]))
    df_nuevo = df_nuevo.replace(0, np.nan)
    df_nuevo = df_nuevo.dropna(how="all", axis=0)
    df_nuevo.index = [str(_) + "  Nuevo" for _ in list(df_nuevo.index)]

    if existente:
        cantidad_existente = [df.loc[(df[variable] == _) & (df["Estado"] == "existente")]["L"].sum().round(0) for _ in np.unique(df[variable])]
        df_existente = pd.Series(cantidad_existente, index=np.unique(df[variable]))
        df_existente = df_existente.replace(0, np.nan)
        df_existente = df_existente.dropna(how="all", axis=0)
        df_existente.index = [str(_) + " Existente" for _ in list(df_existente.index)]

        cantidad_nuevo = [df.loc[(df[variable] == _) & (df["Estado"] == "nuevo")]["L"].sum().round(0) for _ in np.unique(df[variable])]
        df_nuevo = pd.Series(cantidad_nuevo, index=np.unique(df[variable]))
        df_nuevo = df_nuevo.replace(0, np.nan)
        df_nuevo = df_nuevo.dropna(how="all", axis=0)
        df_nuevo.index = [str(_) + "  Nuevo" for _ in list(df_nuevo.index)]
    else:
        cantidad_nuevo = [df.loc[(df[variable] == _) & (df["Estado"] == "nuevo")]["L"].sum().round(0) for _ in np.unique(df[variable])]
        df_nuevo = pd.Series(cantidad_nuevo, index=np.unique(df[variable]))
        df_nuevo = df_nuevo.replace(0, np.nan)
        df_nuevo = df_nuevo.dropna(how="all", axis=0)

    if existente:
        df_ = pd.Series(
            list(df_existente.to_numpy()) + list(df_nuevo.to_numpy()),
            index=list(df_existente.index) + list(df_nuevo.index),
        )
    else:
        df_ = pd.Series(df_nuevo.to_numpy(), index=df_nuevo.index)

    # Figure Size
    base_fig, heigth_fig = max(int(18 * (bin_size / 20)), 8), max(int(bin_size * 0.8), 5)
    fig = plt.figure(figsize=(base_fig, heigth_fig))

    # Horizontal Bar Plot
    ax = df_.plot.barh(align="center")

    # Remove axes splines
    # for s in ['top', 'bottom', 'left', 'right']:
    #     ax.spines[s].set_visible(False)

    # Remove x, y Ticks
    ax.xaxis.set_ticks_position("none")
    # ax.yaxis.set_ticks_position('none')

    # Add padding between axes and labels
    ax.xaxis.set_tick_params(pad=5)
    ax.yaxis.set_tick_params(pad=10)
    ax.set_yticklabels(df_.index)

    # Add x, y gridlines
    ax.grid(True, color="grey", linestyle="-.", linewidth=0.5, alpha=1)

    # Show top values
    ax.invert_yaxis()

    # Add annotation to bars
    for i in ax.patches:
        plt.text(
            i.get_width() + 0.2,
            i.get_y() + i._height / 2,
            str(int((i.get_width()))) + "" + labels,
            fontweight="bold",
            fontsize="16",
        )

    # Add Plot Title
    ax.set_title(title + "(" + labels + ")", loc="center", fontsize="18")
    plt.tight_layout()

    # Show Plot
    if out_dir:
        plt.savefig(out_dir + os.path.sep + name + "_bar_chart.png")
    else:
        plt.show()


def categorical_variables_bar(
    df,
    variable,
    title,
    labels,
    out_dir,
    existente=True,
    name=False,
    make_it_graduated=False,
):
    import matplotlib.pyplot as plt
    import matplotlib as mpl

    mpl.rcParams.update({"font.size": 25})

    # Binning the data if make_it_graduated is True
    if make_it_graduated:
        # Define the maximum value for binning based on the data
        max_value = round(seccion_str2float(df[variable]).max(), 1)
        min_value = round(seccion_str2float(df[variable]).min(), 1)
        min_value = np.max([0, min_value])
        # Define the range and adjust the max_value and min_value to be multiples of 0.1
        if max_value == min_value:
            val = 0.05
        else:
            val = (max_value - min_value) / 25
        range_size = round(round(val / val) * 0.1, 2)
        min_value = np.floor(min_value / range_size) * range_size - 0.1
        max_value = np.ceil(max_value / range_size) * range_size + 0.1

        # Create bins with the specified bin size
        bins = np.arange(min_value, max_value + range_size, range_size)
        bin_size = len(bins)
        # Bin the data
        df["binned"] = pd.cut(seccion_str2float(df[variable]), bins, include_lowest=True)
        # Update the variable to use the binned data
        variable = "binned"
    else:
        bin_size = len(np.unique(df[variable]))

    cantidad_nuevo = [df.loc[(df[variable] == _) & (df["Estado"] == "nuevo")]["L"].sum().round(0) for _ in np.unique(df[variable])]
    df_nuevo = pd.Series(cantidad_nuevo, index=np.unique(df[variable]))
    df_nuevo = df_nuevo.replace(0, np.nan)
    df_nuevo = df_nuevo.dropna(how="all", axis=0)
    df_nuevo.index = [str(_) + "  Nuevo" for _ in list(df_nuevo.index)]

    if existente:
        cantidad_existente = [df.loc[(df[variable] == _) & (df["Estado"] == "existente")]["L"].sum().round(0) for _ in np.unique(df[variable])]
        df_existente = pd.Series(cantidad_existente, index=np.unique(df[variable]))
        df_existente = df_existente.replace(0, np.nan)
        df_existente = df_existente.dropna(how="all", axis=0)
        df_existente.index = [str(_) + " Existente" for _ in list(df_existente.index)]

        cantidad_nuevo = [df.loc[(df[variable] == _) & (df["Estado"] == "nuevo")]["L"].sum().round(0) for _ in np.unique(df[variable])]
        df_nuevo = pd.Series(cantidad_nuevo, index=np.unique(df[variable]))
        df_nuevo = df_nuevo.replace(0, np.nan)
        df_nuevo = df_nuevo.dropna(how="all", axis=0)
        df_nuevo.index = [str(_) + "  Nuevo" for _ in list(df_nuevo.index)]
    else:
        cantidad_nuevo = [df.loc[(df[variable] == _) & (df["Estado"] == "nuevo")]["L"].sum().round(0) for _ in np.unique(df[variable])]
        df_nuevo = pd.Series(cantidad_nuevo, index=np.unique(df[variable]))
        df_nuevo = df_nuevo.replace(0, np.nan)
        df_nuevo = df_nuevo.dropna(how="all", axis=0)

    if existente:
        df_ = pd.Series(
            list(df_existente.to_numpy()) + list(df_nuevo.to_numpy()),
            index=list(df_existente.index) + list(df_nuevo.index),
        )
    else:
        df_ = pd.Series(df_nuevo.to_numpy(), index=df_nuevo.index)

    # Figure Size
    base_fig, heigth_fig = 18, 8
    fig = plt.figure(figsize=(base_fig, heigth_fig))

    # Horizontal Bar Plot
    ax = df_.plot.barh(align="center", width=0.5)

    # Get y-axis limits dynamically
    if len(df_) == 1:
        y_min, y_max = -2, 2
        plt.ylim(y_min, y_max)

    # Remove axes splines
    # for s in ['top', 'bottom', 'left', 'right']:
    for s in ["top", "bottom", "right"]:
        ax.spines[s].set_visible(False)

    # Remove x, y Ticks
    ax.xaxis.set_ticks_position("none")
    # ax.yaxis.set_ticks_position('none')

    # Add padding between axes and labels
    ax.xaxis.set_tick_params(pad=5)
    ax.yaxis.set_tick_params(pad=10)
    ax.set_yticklabels(df_.index)
    ax.set_xticklabels([])

    # Add x, y gridlines
    ax.grid(True, color="grey", linestyle="-.", linewidth=1, alpha=1)

    # Show top values
    ax.invert_yaxis()

    # Add annotation to bars
    for i in ax.patches:
        plt.text(
            i.get_width() + 0.2,
            i.get_y() + i._height / 2,
            str(int((i.get_width()))) + "" + labels,
            fontweight="bold",
            fontsize="25",
        )

    # Add Plot Title
    ax.set_title(title + "(" + labels + ")", loc="center", fontsize="25")
    plt.tight_layout()

    # Show Plot
    if out_dir:
        plt.savefig(out_dir + os.path.sep + name + "_bar_chart.png")
    else:
        plt.show()


def hist(x, title, labels, out_dir=None, ax=None, fig=None, name=None):
    import matplotlib.pyplot as plt
    import seaborn as sns
    import matplotlib as mpl
    import warnings

    warnings.filterwarnings("ignore")

    mpl.rcParams.update({"font.size": 25})
    from statsmodels.distributions.empirical_distribution import ECDF

    if not fig:
        fig = plt.figure(figsize=(21, 11))

    if not ax:
        ax = plt.axes()
    plt.ylabel("Frecuencia")
    plt.xlabel(labels)

    x = x[~np.isnan(x)]
    x = x[np.isfinite(x)]

    hist_kwargs = {"density": True, "rwidth": 0.95}
    kde_kwargs = {}
    sns.distplot(x, hist_kws=hist_kwargs, kde_kws=kde_kwargs, label="Histograma", ax=ax)

    ax_bis = ax.twinx()
    ecdf = ECDF(x)
    ax_bis.plot(
        ecdf.x,
        ecdf.y,
        color="red",
        linewidth=3,
        linestyle="-",
        label="Frecuencia Acumulada",
    )
    plt.xlabel(labels)
    plt.ylabel("Frecuencia Acumulada")
    plt.title(title)

    # #Estadisticos
    v_pdf = 0.80
    h_pdf = 0.05
    sep = 0.05

    datos_ordenado = np.flip(np.sort(x))
    datos_ordenado = datos_ordenado[datos_ordenado > 0]
    mean = np.nanmean(datos_ordenado)
    number_events = np.arange(len(datos_ordenado)) + 1
    prob_acumulada = number_events / np.max(number_events)

    plt.text(
        h_pdf,
        v_pdf,
        "Estadisticas",
        horizontalalignment="left",
        verticalalignment="center",
        transform=ax.transAxes,
        color="black",
        fontweight="bold",
    )
    plt.text(
        h_pdf,
        v_pdf - sep,
        "$E[X]$ " + labels + ": " + str(np.round(mean, 4)),
        horizontalalignment="left",
        verticalalignment="center",
        transform=ax.transAxes,
        color="black",
    )
    plt.text(
        h_pdf,
        v_pdf - sep * 2,
        r"$\sigma [X]$: " + str(np.round(np.nanstd(x), 4)),
        horizontalalignment="left",
        verticalalignment="center",
        transform=ax.transAxes,
        color="black",
    )
    plt.text(
        h_pdf,
        v_pdf - sep * 3,
        r"$CV [X]$: " + str(np.round(np.nanstd(x) / mean, 4)),
        horizontalalignment="left",
        verticalalignment="center",
        transform=ax.transAxes,
        color="black",
    )
    plt.text(
        h_pdf,
        v_pdf - sep * 4,
        "$Var[X]$: " + str(np.round(np.nanvar(x), 4)),
        horizontalalignment="left",
        verticalalignment="center",
        transform=ax.transAxes,
        color="black",
    )
    plt.text(
        h_pdf,
        v_pdf - sep * 5,
        "$Min[X]$: " + str(np.round(np.nanmin(x), 4)),
        horizontalalignment="left",
        verticalalignment="center",
        transform=ax.transAxes,
        color="black",
    )
    plt.text(
        h_pdf,
        v_pdf - sep * 6,
        "$Max[X]$: " + str(np.round(np.nanmax(x), 4)),
        horizontalalignment="left",
        verticalalignment="center",
        transform=ax.transAxes,
        color="black",
    )

    plt.text(
        h_pdf,
        v_pdf - sep * 7.5,
        r"$P_{25}$ " + labels + ": " + str(np.round(np.nanpercentile(x, 25), 4)),
        horizontalalignment="left",
        verticalalignment="center",
        transform=ax.transAxes,
        color="black",
    )
    plt.text(
        h_pdf,
        v_pdf - sep * 8.5,
        r"$P_{50}$ " + labels + ": " + str(np.round(np.nanmedian(x), 4)),
        horizontalalignment="left",
        verticalalignment="center",
        transform=ax.transAxes,
        color="black",
    )
    plt.text(
        h_pdf,
        v_pdf - sep * 9.5,
        r"$P_{75}$ " + labels + ": " + str(np.round(np.nanpercentile(x, 75), 4)),
        horizontalalignment="left",
        verticalalignment="center",
        transform=ax.transAxes,
        color="black",
    )
    plt.text(
        h_pdf,
        v_pdf - sep * 10.5,
        r"$P_{90}$ " + labels + ": " + str(np.round(np.nanpercentile(x, 90), 4)),
        horizontalalignment="left",
        verticalalignment="center",
        transform=ax.transAxes,
        color="black",
    )

    ax_bis.legend(loc="upper left")
    ax.legend(loc="upper right")
    plt.tight_layout()

    if out_dir:
        if name:
            plt.savefig(out_dir + os.path.sep + name + "_hist" + ".png")
        else:
            plt.savefig(out_dir + os.path.sep + title + "_hist" + ".png")
    else:
        plt.show()

    return [np.round(mean, 4)] + list(
        np.round(
            np.nanpercentile(
                x,
                [
                    50,
                    75,
                    90,
                ],
            ),
            4,
        )
    )


def calculate_dpi_for_area(width_meters, height_meters):
    # Given base values for the larger map
    base_width_meters = 2143.6340720053995
    base_height_meters = 2284.2890773471445
    base_dpi = 165

    # Given base values for the smaller map
    small_width_meters = 798.6195400506258
    small_height_meters = 681.4634731188416
    known_good_dpi_for_small_map = 50

    # Calculate the area of both maps
    base_area = base_width_meters * base_height_meters
    small_area = small_width_meters * small_height_meters

    # Calculate the ratio of the areas
    area_ratio = small_area / base_area

    # Adjust the DPI based on the square root of the area ratio
    adjusted_dpi = base_dpi * np.sqrt(area_ratio)

    # Now calculate the correction factor based on the known good DPI for the small map
    correction_factor = known_good_dpi_for_small_map / adjusted_dpi
    area = width_meters * height_meters
    # Apply the correction factor to the adjusted DPI based on the new area
    dpi = base_dpi * np.sqrt(area / base_area) * correction_factor
    return dpi


def plot_areas_old(gpd_df, title, out_dir, name=False, image_path=None):
    import matplotlib.pyplot as plt
    import matplotlib

    from matplotlib_scalebar.scalebar import ScaleBar
    from matplotlib.lines import Line2D
    from matplotlib.ticker import FuncFormatter
    import contextily as cx

    # cmap_name = 'jet'
    hex_list = ["#0078ff", "##05ff01", "#f8f800", "#ff8300", "#f701ff", "#ff0105"]
    cmap = get_continuous_cmap(hex_list)

    # gpd_df = gpd_df.explode()
    gpd_df["area"] = np.round(gpd_df.geometry.area / 10000, 1)
    filtro_area = gpd_df["area"] > 0.1
    gpd_df = gpd_df[filtro_area]
    gpd_df["id"] = range(gpd_df["area"].size)

    variable = "id"

    _vmax, _vmin = np.max(gpd_df[variable]), np.min(gpd_df[variable])
    if isinstance(_vmax, str) or isinstance(_vmin, str):
        new_code = list(range(len(np.unique(gpd_df[variable]))))
        dict_code = dict(zip(np.unique(gpd_df[variable]), new_code))
        _vmax, _vmin = max(new_code), min(new_code)
        color_list = np.array(itemgetter(*gpd_df[variable].to_numpy().astype(str))(dict_code))
    else:
        color_list = gpd_df[variable].to_numpy()

    # normalizar los valores de color
    norm = matplotlib.colors.Normalize(vmin=_vmin, vmax=_vmax)

    dict_color = {}
    for _i in np.unique(color_list):
        _c = matplotlib.colors.to_hex(cmap(norm(_i)))
        _color = np.where(np.char.equal(color_list.astype(str), str(_i)), _c, color_list)
        dict_color[str(_i)] = _c
    gpd_df["color"] = itemgetter(*color_list.astype(str))(dict_color)
    dict_color = dict(zip(np.unique(gpd_df[variable]), dict_color.values()))

    fig, ax = plt.subplots(nrows=1, ncols=1)
    # plot areas
    gpd_df.plot(
        ax=ax,
        linewidth=4,
        edgecolor=gpd_df["color"],
        facecolor="none",
        categorical=True,
        legend=True,
    )

    # plot image
    if image_path:
        # Open the GeoTIFF file
        src = rasterio.open(image_path)

        # Read the three bands (red, green, blue)
        r = src.read(1)
        g = src.read(2)
        b = src.read(3)

        # Stack the bands into an RGB image (rasterio reads in (band, row, col) order)
        rgb = np.dstack((r, g, b))

        # # Get the bounds of the raster
        bounds = src.bounds

        # Calculate the extent of the raster
        extent = [bounds.left, bounds.right, bounds.bottom, bounds.top]

        # Plot the RGB data with the extent
        cax = ax.imshow(rgb, extent=extent, alpha=0.7)

    else:
        crs = gpd_df.crs  # this should be the same as the one in the file
        w, s, e, n = gpd_df.to_crs("epsg:4326").total_bounds
        zoom = cx.tile._calculate_zoom(w, s, e, n)
        cx.add_basemap(
            ax,
            crs=crs,
            source="http://www.google.cn/maps/vt?lyrs=s@189&gl=cn&x={x}&y={y}&z={z}",
            alpha=0.5,
            zoom=zoom + 1,
        )

        # Create a dummy transparent image to get cax reference
        dummy_img = np.zeros((2, 2, 4))  # RGBA image with alpha=0
        dummy_img[:, :, 3] = 0  # Set alpha channel to 0 (fully transparent)
        cax = ax.imshow(dummy_img, extent=[w, e, s, n], alpha=0)

    # Get the total boundary of all geometries
    bounds = gpd_df.total_bounds

    x_min, y_min, x_max, y_max = bounds

    # resize figure
    width_figure, heigth_figure = x_max - x_min, y_max - y_min
    dpi = calculate_dpi_for_area(width_figure, heigth_figure)

    # Calculate the width and height of the figure in inches
    width_in_inches = width_figure / dpi
    height_in_inches = heigth_figure / dpi

    # set figure size
    fig.set_size_inches(width_in_inches, height_in_inches)

    # Calculate font size for x-axis and y-axis labels
    aspect_ratio_1 = width_in_inches / height_in_inches
    aspect_ratio_2 = height_in_inches / width_in_inches
    aspect_ratio = max(aspect_ratio_2, aspect_ratio_1)

    base_font_size = 14
    font_size = base_font_size * aspect_ratio
    matplotlib.rcParams.update({"font.size": font_size})

    # Calculate centroids
    centroids = gpd_df.geometry.centroid

    # Step 2: Calculate areas in hectares and create labels
    area_hectares = gpd_df.area / 10000  # Convert from square meters to hectares
    labels_ = [f"{count_} - {name_}\n{round(area, 1)} Ha" for area, name_, count_ in zip(area_hectares, gpd_df["outfall"], gpd_df[variable])]

    # Step 3: Annotate each centroid with the area
    cont = 0
    for label_, centroid in zip(labels_, centroids):
        ax.annotate(
            cont,
            xy=(centroid.x, centroid.y),
            xytext=(3, 3),  # Offset the text slightly
            textcoords="offset points",
            bbox=dict(boxstyle="round,pad=0.3", fc="white", ec="black", lw=2),
            ha="center",
            va="bottom",
            fontsize=font_size,
        )
        cont = cont + 1

    # Set the y-axis to scientific notation
    ax.ticklabel_format(style="sci", scilimits=(6, 6), axis="y")

    # Set the font size of the scientific notation labels to 18 points
    label = ax.yaxis.get_offset_text()
    label.set_size(font_size)

    # Set the tick labels using a lambda function
    ax.xaxis.set_major_formatter(FuncFormatter(lambda x, pos: str(int(x))))

    # Set the font size of the xtick labels
    for tick in ax.xaxis.get_major_ticks():
        tick.label1.set_fontsize(font_size)

    # Set the font size of the ytick labels
    for tick in ax.yaxis.get_major_ticks():
        tick.label1.set_fontsize(font_size)

    # Create scale bar
    scalebar = ScaleBar(dx=1, label="escala", location="upper left", frameon="False", box_alpha=0.1)
    ax.add_artist(scalebar)

    # north arrow
    x, y, arrow_length = 0.98, 0.98, 0.05
    ax.annotate(
        "N",
        xy=(x, y),
        xytext=(x, y - arrow_length),
        arrowprops=dict(facecolor="black", width=4, headwidth=12),
        ha="center",
        va="center",
        xycoords=ax.transAxes,
        fontsize=font_size,
    )

    # # good aspect ratio to a figures in a A4 paper sheet
    # A4_factor = 1.5 / 1
    # unidad = labels if labels == '' else ' [' + labels + ']'

    try:
        custom_legend = [Line2D([0], [0], color=color, lw=3.5) for key, color in zip(dict_color.keys(), dict_color.values())]
    except:
        custom_legend = [Line2D([0], [0], color=color, lw=3.5) for key, color in zip(dict_color.keys(), dict_color.values())]
    custom_names = [str(_) for _ in labels_]

    # get dimensions of viewport and figure
    # Get the position of the axes object in inches
    bbox = fig.get_tightbbox(fig.canvas.get_renderer())
    # Calculate the width of the space between the left and right spines
    axis_width_in_inches, axis_height_in_inches = bbox.width, bbox.height
    # Get the width and height of the figure in inches
    figure_width_in_inches, figure_height_in_inches = fig.get_size_inches()

    # attempt horizontal legend position
    # first atempt to legend draw
    legend = ax.legend(
        custom_legend,
        custom_names,
        title="Leyenda " + title,
        bbox_to_anchor=(0.5, 1.02),
        loc="lower center",
        ncol=1,
        fontsize=font_size,
    )
    # Draw the legend
    fig.canvas.draw()
    # Get the DPI of the figure
    dpi = fig.dpi
    # get legend width and heigth
    legend_width_in_inches, legend_height_in_inches = (
        legend.get_window_extent().width / dpi,
        legend.get_window_extent().height / dpi,
    )

    col_number_horizontal = 1
    cond = True
    # check if the heigth of figures is bigger than legend heigth, if not add 1 column
    while cond:
        if col_number_horizontal <= len(custom_names) and legend_width_in_inches < axis_width_in_inches:
            col_number_horizontal = col_number_horizontal + 1
            # change columns number
            legend = ax.legend(
                custom_legend,
                custom_names,
                title="Leyenda " + title,
                loc="lower center",
                bbox_to_anchor=(0.5, 1.02),
                ncol=col_number_horizontal,
                fontsize=font_size,
            )
            # Draw the legend
            fig.canvas.draw()
            # get legend width and heigth
            legend_width_in_inches, legend_height_in_inches = (
                legend.get_window_extent().width / dpi,
                legend.get_window_extent().height / dpi,
            )
        else:
            if legend_width_in_inches > axis_width_in_inches:
                col_number_horizontal = col_number_horizontal - 1
                while col_number_horizontal * round((len(custom_names) / col_number_horizontal), 0) > len(custom_names) + 1:
                    col_number_horizontal = col_number_horizontal - 1
            # change columns number
            legend = ax.legend(
                custom_legend,
                custom_names,
                title="Leyenda " + title,
                loc="lower center",
                bbox_to_anchor=(0.5, 1.02),
                ncol=col_number_horizontal,
                fontsize=font_size,
            )
            # Draw the legend
            fig.canvas.draw()
            # get legend width and heigth
            legend_width_in_inches, legend_height_in_inches = (
                legend.get_window_extent().width / dpi,
                legend.get_window_extent().height / dpi,
            )
            cond = False

    # factor of shape
    width, heigth = (
        axis_width_in_inches,
        axis_height_in_inches + legend_height_in_inches,
    )
    # # check the orientation of the figure
    # factor_horizontal = width / heigth
    # factor_position = np.argmin([abs(factor_horizontal - A4_factor), abs(factor_vertical - A4_factor)])

    # if factor_position == 0:
    #     ncol = col_number_horizontal
    #     bbox_to_anchor = (0.5, 1.02)
    #     loc = "lower center"
    # else:
    #     ncol = col_number_vertical
    #     bbox_to_anchor = (1.02, 1)
    #     loc = "upper left"
    # add legend
    # legend = ax.legend(custom_legend, custom_names, title='Leyenda ' + title, loc=loc, bbox_to_anchor=bbox_to_anchor, ncol=ncol, frameon=False)
    legend = ax.legend(
        custom_legend,
        custom_names,
        title="Leyenda " + title,
        loc="lower center",
        bbox_to_anchor=(0.5, 1.02),
        ncol=col_number_horizontal,
        frameon=False,
        fontsize=font_size,
    )

    # Get the extent of the GeoDataFrame
    minx, miny, maxx, maxy = gpd_df.total_bounds
    additional_x = (maxx - minx) * 0.05
    additional_y = (maxy - miny) * 0.05
    # Set the extent of the axes
    ax.set_xlim(minx - additional_x, maxx + additional_x)
    ax.set_ylim(miny - additional_y, maxy + additional_y)

    # grid
    ax.grid(color="gray", linestyle="--", linewidth=2.0)

    # set equal aspect ratio
    ax.set_aspect("equal", adjustable="box")

    # Adjust the layout to minimize white space
    fig.tight_layout()

    # plt.show()
    if out_dir:
        plt.savefig(out_dir + os.path.sep + name + "_area", bbox_inches="tight")
        return dpi, width_in_inches, height_in_inches
    else:
        plt.show()


def plot_areas(gpd_df, title, out_dir, name=False, image_path=None):
    import matplotlib.pyplot as plt
    import matplotlib

    from matplotlib_scalebar.scalebar import ScaleBar
    from matplotlib.lines import Line2D
    from matplotlib.ticker import FuncFormatter
    import contextily as cx

    # cmap_name = 'jet'
    hex_list = ["#0078ff", "##05ff01", "#f8f800", "#ff8300", "#f701ff", "#ff0105"]
    cmap = get_continuous_cmap(hex_list)

    # gpd_df = gpd_df.explode()
    gpd_df["area"] = np.round(gpd_df.geometry.area / 10000, 1)
    filtro_area = gpd_df["area"] > 0.1
    gpd_df = gpd_df[filtro_area]
    gpd_df["id"] = range(gpd_df["area"].size)

    variable = "id"

    _vmax, _vmin = np.max(gpd_df[variable]), np.min(gpd_df[variable])
    if isinstance(_vmax, str) or isinstance(_vmin, str):
        new_code = list(range(len(np.unique(gpd_df[variable]))))
        dict_code = dict(zip(np.unique(gpd_df[variable]), new_code))
        _vmax, _vmin = max(new_code), min(new_code)
        color_list = np.array(itemgetter(*gpd_df[variable].to_numpy().astype(str))(dict_code))
    else:
        color_list = gpd_df[variable].to_numpy()

    # normalizar los valores de color
    norm = matplotlib.colors.Normalize(vmin=_vmin, vmax=_vmax)

    dict_color = {}
    for _i in np.unique(color_list):
        _c = matplotlib.colors.to_hex(cmap(norm(_i)))
        _color = np.where(np.char.equal(color_list.astype(str), str(_i)), _c, color_list)
        dict_color[str(_i)] = _c
    gpd_df["color"] = itemgetter(*color_list.astype(str))(dict_color)
    dict_color = dict(zip(np.unique(gpd_df[variable]), dict_color.values()))

    fig, ax = plt.subplots(nrows=1, ncols=1)
    # plot areas
    gpd_df.plot(
        ax=ax,
        linewidth=4,
        edgecolor=gpd_df["color"],
        facecolor="none",
        categorical=True,
        legend=True,
    )

    # plot image
    if image_path:
        # Open the GeoTIFF file
        src = rasterio.open(image_path)

        # Read the three bands (red, green, blue)
        r = src.read(1)
        g = src.read(2)
        b = src.read(3)

        # Stack the bands into an RGB image (rasterio reads in (band, row, col) order)
        rgb = np.dstack((r, g, b))

        # # Get the bounds of the raster
        bounds = src.bounds

        # Calculate the extent of the raster
        extent = [bounds.left, bounds.right, bounds.bottom, bounds.top]

        # Plot the RGB data with the extent
        cax = ax.imshow(rgb, extent=extent, alpha=0.7)

    else:
        crs = gpd_df.crs  # this should be the same as the one in the file
        w, s, e, n = gpd_df.to_crs("epsg:4326").total_bounds
        zoom = cx.tile._calculate_zoom(w, s, e, n)
        cx.add_basemap(
            ax,
            crs=crs,
            source="http://www.google.cn/maps/vt?lyrs=s@189&gl=cn&x={x}&y={y}&z={z}",
            alpha=0.5,
            zoom=zoom + 1,
        )

        # Create a dummy transparent image to get cax reference
        dummy_img = np.zeros((2, 2, 4))  # RGBA image with alpha=0
        dummy_img[:, :, 3] = 0  # Set alpha channel to 0 (fully transparent)
        cax = ax.imshow(dummy_img, extent=[w, e, s, n], alpha=0)

    # ------------------------------------------------------------------------
    # Compute bounding box & clamp aspect ratio by expanding x-limits
    minx, miny, maxx, maxy = gpd_df.total_bounds
    width_data = maxx - minx
    height_data = maxy - miny

    desired_max_aspect = 1.2  # e.g., no taller than 1:1.2
    current_aspect = height_data / width_data
    if current_aspect > desired_max_aspect:
        # Expand width so final aspect ratio is no taller than desired_max_aspect
        new_width = height_data / desired_max_aspect
        diff = new_width - width_data
        minx -= diff / 2
        maxx += diff / 2
        width_data = new_width

    # Recompute figure size based on possibly expanded x-range
    dpi = calculate_dpi_for_area(width_data, height_data)
    width_in_inches = width_data / dpi
    height_in_inches = height_data / dpi
    fig.set_size_inches(width_in_inches, height_in_inches)

    # Add a small margin around bounding box so shapes aren't on the edge
    margin_x = 0.05 * (maxx - minx)
    margin_y = 0.05 * (maxy - miny)
    ax.set_xlim(minx - margin_x, maxx + margin_x)
    ax.set_ylim(miny - margin_y, maxy + margin_y)

    # (Optional) Keep geometry from being distorted
    ax.set_aspect("equal", adjustable="box")

    # ------------------------------------------------------------------------
    # Calculate font size for x-axis and y-axis labels
    aspect_ratio_1 = width_in_inches / height_in_inches
    aspect_ratio_2 = height_in_inches / width_in_inches
    aspect_ratio = max(aspect_ratio_2, aspect_ratio_1)

    base_font_size = 14
    font_size = base_font_size * aspect_ratio
    matplotlib.rcParams.update({"font.size": font_size})

    # Calculate centroids
    centroids = gpd_df.geometry.centroid

    # Step 2: Calculate areas in hectares and create labels
    area_hectares = gpd_df.area / 10000  # Convert from square meters to hectares
    labels_ = [f"{count_} - {name_}\n{round(area, 1)} Ha" for area, name_, count_ in zip(area_hectares, gpd_df["outfall"], gpd_df[variable])]

    # Step 3: Annotate each centroid with the area
    cont = 0
    for label_, centroid in zip(labels_, centroids):
        ax.annotate(
            cont,
            xy=(centroid.x, centroid.y),
            xytext=(3, 3),  # Offset the text slightly
            textcoords="offset points",
            bbox=dict(boxstyle="round,pad=0.3", fc="white", ec="black", lw=2),
            ha="center",
            va="bottom",
            fontsize=font_size,
        )
        cont = cont + 1

    # Set the y-axis to scientific notation
    ax.ticklabel_format(style="sci", scilimits=(6, 6), axis="y")

    # Set the font size of the scientific notation labels to 18 points
    label = ax.yaxis.get_offset_text()
    label.set_size(font_size)

    # Set the tick labels using a lambda function
    ax.xaxis.set_major_formatter(FuncFormatter(lambda x, pos: str(int(x))))

    # Set the font size of the xtick labels
    for tick in ax.xaxis.get_major_ticks():
        tick.label1.set_fontsize(font_size)

    # Set the font size of the ytick labels
    for tick in ax.yaxis.get_major_ticks():
        tick.label1.set_fontsize(font_size)

    # Create scale bar
    scalebar = ScaleBar(dx=1, label="escala", location="upper left", frameon="False", box_alpha=0.1)
    ax.add_artist(scalebar)

    # north arrow
    x, y, arrow_length = 0.98, 0.98, 0.05
    ax.annotate(
        "N",
        xy=(x, y),
        xytext=(x, y - arrow_length),
        arrowprops=dict(facecolor="black", width=4, headwidth=12),
        ha="center",
        va="center",
        xycoords=ax.transAxes,
        fontsize=font_size,
    )

    try:
        custom_legend = [Line2D([0], [0], color=color, lw=3.5) for key, color in zip(dict_color.keys(), dict_color.values())]
    except:
        custom_legend = [Line2D([0], [0], color=color, lw=3.5) for key, color in zip(dict_color.keys(), dict_color.values())]
    custom_names = [str(_) for _ in labels_]

    # get dimensions of viewport and figure
    bbox = fig.get_tightbbox(fig.canvas.get_renderer())
    # Calculate the width of the space between the left and right spines
    axis_width_in_inches, axis_height_in_inches = bbox.width, bbox.height

    # attempt horizontal legend position
    # first atempt to legend draw
    legend = ax.legend(
        custom_legend,
        custom_names,
        title="Leyenda " + title,
        bbox_to_anchor=(0.5, 1.02),
        loc="lower center",
        ncol=1,
        fontsize=font_size,
    )
    # Draw the legend
    fig.canvas.draw()
    # Get the DPI of the figure
    dpi = fig.dpi
    # get legend width and heigth
    legend_width_in_inches, legend_height_in_inches = (
        legend.get_window_extent().width / dpi,
        legend.get_window_extent().height / dpi,
    )

    col_number_horizontal = 1
    cond = True
    # check if the heigth of figures is bigger than legend heigth, if not add 1 column
    while cond:
        if col_number_horizontal <= len(custom_names) and legend_width_in_inches < axis_width_in_inches:
            col_number_horizontal = col_number_horizontal + 1
            # change columns number
            legend = ax.legend(
                custom_legend,
                custom_names,
                title="Leyenda " + title,
                loc="lower center",
                bbox_to_anchor=(0.5, 1.02),
                ncol=col_number_horizontal,
                fontsize=font_size,
            )
            # Draw the legend
            fig.canvas.draw()
            # get legend width and heigth
            legend_width_in_inches, legend_height_in_inches = (
                legend.get_window_extent().width / dpi,
                legend.get_window_extent().height / dpi,
            )
        else:
            if legend_width_in_inches > axis_width_in_inches:
                col_number_horizontal = col_number_horizontal - 1
                while col_number_horizontal * round((len(custom_names) / col_number_horizontal), 0) > len(custom_names) + 1:
                    col_number_horizontal = col_number_horizontal - 1
            # change columns number
            legend = ax.legend(
                custom_legend,
                custom_names,
                title="Leyenda " + title,
                loc="lower center",
                bbox_to_anchor=(0.5, 1.02),
                ncol=col_number_horizontal,
                fontsize=font_size,
            )
            # Draw the legend
            fig.canvas.draw()
            # get legend width and heigth
            legend_width_in_inches, legend_height_in_inches = (
                legend.get_window_extent().width / dpi,
                legend.get_window_extent().height / dpi,
            )
            cond = False

    legend = ax.legend(
        custom_legend,
        custom_names,
        title="Leyenda " + title,
        loc="lower center",
        bbox_to_anchor=(0.5, 1.02),
        ncol=col_number_horizontal,
        frameon=False,
        fontsize=font_size,
    )

    # grid
    ax.grid(color="gray", linestyle="--", linewidth=2.0)

    # Adjust the layout to minimize white space
    fig.tight_layout()

    # plt.show()
    if out_dir:
        plt.savefig(out_dir + os.path.sep + name + "_planimetria", bbox_inches="tight")
        return dpi, width_in_inches, height_in_inches
    else:
        plt.show()


def plot_areas_variables_old(gpd_df, title, out_dir, variable="area", name=False, image_path=None, graduated=True, dissolve=False, label_area=False):
    import matplotlib.pyplot as plt
    import matplotlib
    import matplotlib.colors as mcolors
    from matplotlib_scalebar.scalebar import ScaleBar
    from matplotlib.lines import Line2D
    from matplotlib.ticker import FuncFormatter
    from mpl_toolkits.axes_grid1 import make_axes_locatable
    import contextily as cx
    import numpy as np
    import seaborn as sns
    import os

    # Define color scheme
    hex_list = ["#0078ff", "#05ff01", "#f8f800", "#ff8300", "#f701ff", "#ff0105"]
    cmap = mcolors.LinearSegmentedColormap.from_list("custom", hex_list)

    # Calculate area and add ID (no filtering)
    gpd_df["area"] = np.round(gpd_df.geometry.area, 1)
    gpd_df["id"] = range(len(gpd_df))

    if dissolve:
        geo_crs = gpd_df.crs
        min_area_threshold = 1
        gpd_df = gpd_df.dissolve(by=variable).reset_index()
        # Filter out geometries smaller than the threshold
        gpd_df = gpd_df[gpd_df["area"] > min_area_threshold].drop(columns=["area"]).reset_index(drop=True)
        # Clean up original geometries
        gpd_df["geometry"] = gpd_df.geometry.buffer(0)  # Fix topological issues

        # Buffer slightly to connect nearby areas (adjust tolerance)
        gpd_df["geometry"] = gpd_df.geometry.buffer(0.1)

        # Simplify to smooth boundaries
        gpd_df["geometry"] = gpd_df.geometry.simplify(tolerance=0.1, preserve_topology=True)

    # Validate variable exists in DataFrame
    if variable not in gpd_df.columns:
        raise ValueError(f"Variable '{variable}' not found in GeoDataFrame columns")

    # Get min and max values
    _vmax, _vmin = np.max(gpd_df[variable]), np.min(gpd_df[variable])

    fig, ax = plt.subplots(nrows=1, ncols=1)

    # Handle graduated vs categorical plotting
    if graduated:
        # Normalize for continuous gradient
        norm = mcolors.Normalize(vmin=_vmin, vmax=_vmax)
        # Plot with fill colors based on the variable
        gpd_df.plot(
            ax=ax,
            column=variable,
            cmap=cmap,
            linewidth=2,
            edgecolor="black",
            alpha=0.5,
            norm=norm,
            legend=False,  # We'll add a custom colorbar
        )
    else:
        # Categorical: unique colors for each value
        unique_values = np.unique(gpd_df[variable])
        float_colors = sns.color_palette("gist_rainbow", n_colors=len(unique_values))
        hex_list = [mcolors.to_hex(color) for color in float_colors]
        dict_color = dict(zip(unique_values, hex_list))
        # Apply colors directly to the plot
        gpd_df["color"] = gpd_df[variable].map(dict_color)
        gpd_df.plot(
            ax=ax,
            color=gpd_df["color"],
            linewidth=2,
            edgecolor="black",
            alpha=0.5,
            legend=False,  # We'll add a custom legend
        )

    # Add image or basemap
    if image_path:
        src = rasterio.open(image_path)
        r = src.read(1)
        g = src.read(2)
        b = src.read(3)
        rgb = np.dstack((r, g, b))
        bounds = src.bounds
        extent = [bounds.left, bounds.right, bounds.bottom, bounds.top]
        ax.imshow(rgb, extent=extent, alpha=0.7)
    else:
        crs = gpd_df.crs
        w, s, e, n = gpd_df.to_crs("epsg:4326").total_bounds
        zoom = cx.tile._calculate_zoom(w, s, e, n)
        cx.add_basemap(ax, crs=crs, source="http://www.google.cn/maps/vt?lyrs=s@189&gl=cn&x={x}&y={y}&z={z}", alpha=0.5, zoom=zoom + 1)

    # Get bounds and set figure size
    bounds = gpd_df.total_bounds
    x_min, y_min, x_max, y_max = bounds
    width_figure, height_figure = x_max - x_min, y_max - y_min
    dpi = calculate_dpi_for_area(width_figure, height_figure)
    width_in_inches = width_figure / dpi
    height_in_inches = height_figure / dpi
    fig.set_size_inches(width_in_inches, height_in_inches)

    # Calculate font size
    aspect_ratio = max(width_in_inches / height_in_inches, height_in_inches / width_in_inches)
    base_font_size = 14
    font_size = base_font_size * aspect_ratio
    matplotlib.rcParams.update({"font.size": font_size})

    # Format axes
    ax.ticklabel_format(style="sci", scilimits=(6, 6), axis="y")
    label = ax.yaxis.get_offset_text()
    label.set_size(font_size)
    ax.xaxis.set_major_formatter(FuncFormatter(lambda x, pos: str(int(x))))
    for tick in ax.xaxis.get_major_ticks():
        tick.label1.set_fontsize(font_size)
    for tick in ax.yaxis.get_major_ticks():
        tick.label1.set_fontsize(font_size)

    # Add scale bar
    scalebar = ScaleBar(dx=1, label="escala", location="upper left", frameon=False, box_alpha=0.1)
    ax.add_artist(scalebar)

    # Add north arrow
    x, y, arrow_length = 0.98, 0.98, 0.05
    ax.annotate(
        "N", xy=(x, y), xytext=(x, y - arrow_length), arrowprops=dict(facecolor="black", width=4, headwidth=12), ha="center", va="center", xycoords=ax.transAxes, fontsize=font_size
    )

    # Add colorbar or legend
    if graduated:
        # Adaptive colorbar placement
        figure_width_in_inches, figure_height_in_inches = fig.get_size_inches()
        A4_factor = 1.5 / 1
        sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=_vmin, vmax=_vmax))
        divider = make_axes_locatable(ax)
        if (figure_width_in_inches / figure_height_in_inches) > A4_factor:
            cax = divider.append_axes("top", size=0.175, pad=1.1)
            cbar = plt.colorbar(sm, cax=cax, orientation="horizontal")
            cbar.set_label(title, fontsize=font_size, labelpad=-1)
        else:
            cax = divider.append_axes("right", size=0.175, pad=0.1)
            cbar = plt.colorbar(sm, cax=cax, orientation="vertical")
            cbar.set_label(title, fontsize=font_size, labelpad=2)
        cbar.ax.tick_params(labelsize=font_size)
    else:
        # Categorical legend (no title)
        unique_values = np.unique(gpd_df[variable])
        if dissolve and len(unique_values) > 10:
            # If dissolve is True and there are more than 10 unique values, show only "Leyenda: [variable]"
            ax.legend(handles=[], title=f"Leyenda: {title}", bbox_to_anchor=(0.5, 1.02), loc="lower center", ncol=1, frameon=False, fontsize=font_size)
        else:
            # Normal categorical legend with individual values
            float_colors = sns.color_palette("gist_rainbow", n_colors=len(unique_values))
            hex_list = [mcolors.to_hex(color) for color in float_colors]
            dict_color = dict(zip(unique_values, hex_list))
            custom_legend = [Line2D([0], [0], color=color, lw=3.5) for color in dict_color.values()]
            custom_names = [str(key) for key in dict_color.keys()]
            bbox = fig.get_tightbbox(fig.canvas.get_renderer())
            axis_width_in_inches = bbox.width
            legend = ax.legend(custom_legend, custom_names, bbox_to_anchor=(0.5, 1.02), loc="lower center", ncol=1, frameon=False, fontsize=font_size)
            fig.canvas.draw()
            dpi = fig.dpi
            legend_width_in_inches = legend.get_window_extent().width / dpi
            col_number = 1
            while col_number <= len(custom_names) and legend_width_in_inches < axis_width_in_inches:
                col_number += 1
                legend = ax.legend(custom_legend, custom_names, bbox_to_anchor=(0.5, 1.02), loc="lower center", ncol=col_number, frameon=False, fontsize=font_size)
                fig.canvas.draw()
                legend_width_in_inches = legend.get_window_extent().width / dpi
            if legend_width_in_inches > axis_width_in_inches:
                col_number = max(col_number - 1, 1)
            legend = ax.legend(
                custom_legend, custom_names, bbox_to_anchor=(0.5, 1.02), title="Leyenda " + title, loc="lower center", ncol=col_number, frameon=False, fontsize=font_size
            )

    if label_area:
        for label_, centroid in zip(gpd_df[variable], gpd_df.geometry.centroid):
            ax.annotate(
                label_,
                xy=(centroid.x, centroid.y),
                xytext=(3, 3),  # Offset the text slightly
                textcoords="offset points",
                bbox=dict(boxstyle="round,pad=0.3", fc="white", ec="black", lw=2),
                ha="center",
                va="bottom",
                fontsize=font_size * 0.7,
            )

    # Set extent with padding
    minx, miny, maxx, maxy = gpd_df.total_bounds
    additional_x = (maxx - minx) * 0.05
    additional_y = (maxy - miny) * 0.05
    ax.set_xlim(minx - additional_x, maxx + additional_x)
    ax.set_ylim(miny - additional_y, maxy + additional_y)

    # Add grid and set aspect
    ax.grid(color="gray", linestyle="--", linewidth=2.0)
    ax.set_aspect("equal", adjustable="box")

    # Adjust layout
    fig.tight_layout()

    if out_dir:
        plt.savefig(out_dir + os.path.sep + name + "_area", bbox_inches="tight")
        return dpi, width_in_inches, height_in_inches
    else:
        plt.show()


def plot_areas_variables(gpd_df, title, out_dir, variable="area", name=False, image_path=None, graduated=True, dissolve=False, label_area=False):
    import matplotlib.pyplot as plt
    import matplotlib
    import matplotlib.colors as mcolors
    from matplotlib_scalebar.scalebar import ScaleBar
    from matplotlib.lines import Line2D
    from matplotlib.ticker import FuncFormatter
    from mpl_toolkits.axes_grid1 import make_axes_locatable
    import contextily as cx
    import numpy as np
    import seaborn as sns
    import os

    # Define color scheme
    hex_list = ["#0078ff", "#05ff01", "#f8f800", "#ff8300", "#f701ff", "#ff0105"]
    cmap = mcolors.LinearSegmentedColormap.from_list("custom", hex_list)

    # Calculate area and add ID (no filtering)
    gpd_df["area"] = np.round(gpd_df.geometry.area, 1)
    gpd_df["id"] = range(len(gpd_df))

    if dissolve:
        geo_crs = gpd_df.crs
        min_area_threshold = 1
        gpd_df = gpd_df.dissolve(by=variable).reset_index()
        # Filter out geometries smaller than the threshold
        gpd_df = gpd_df[gpd_df["area"] > min_area_threshold].drop(columns=["area"]).reset_index(drop=True)
        # Clean up original geometries
        gpd_df["geometry"] = gpd_df.geometry.buffer(0)  # Fix topological issues

        # Buffer slightly to connect nearby areas (adjust tolerance)
        gpd_df["geometry"] = gpd_df.geometry.buffer(0.1)

        # Simplify to smooth boundaries
        gpd_df["geometry"] = gpd_df.geometry.simplify(tolerance=0.1, preserve_topology=True)

    # Validate variable exists in DataFrame
    if variable not in gpd_df.columns:
        raise ValueError(f"Variable '{variable}' not found in GeoDataFrame columns")

    # Get min and max values
    _vmax, _vmin = np.max(gpd_df[variable]), np.min(gpd_df[variable])

    fig, ax = plt.subplots(nrows=1, ncols=1)

    # Handle graduated vs categorical plotting
    if graduated:
        # Normalize for continuous gradient
        norm = mcolors.Normalize(vmin=_vmin, vmax=_vmax)
        # Plot with fill colors based on the variable
        gpd_df.plot(
            ax=ax,
            column=variable,
            cmap=cmap,
            linewidth=2,
            edgecolor="black",
            alpha=0.5,
            norm=norm,
            legend=False,  # We'll add a custom colorbar
        )
    else:
        # Categorical: unique colors for each value
        unique_values = np.unique(gpd_df[variable])
        float_colors = sns.color_palette("gist_rainbow", n_colors=len(unique_values))
        hex_list = [mcolors.to_hex(color) for color in float_colors]
        dict_color = dict(zip(unique_values, hex_list))
        # Apply colors directly to the plot
        gpd_df["color"] = gpd_df[variable].map(dict_color)
        gpd_df.plot(
            ax=ax,
            color=gpd_df["color"],
            linewidth=2,
            edgecolor="black",
            alpha=0.5,
            legend=False,  # We'll add a custom legend
        )

    # Add image or basemap
    if image_path:
        src = rasterio.open(image_path)
        r = src.read(1)
        g = src.read(2)
        b = src.read(3)
        rgb = np.dstack((r, g, b))
        bounds = src.bounds
        extent = [bounds.left, bounds.right, bounds.bottom, bounds.top]
        ax.imshow(rgb, extent=extent, alpha=0.7)
    else:
        crs = gpd_df.crs
        w, s, e, n = gpd_df.to_crs("epsg:4326").total_bounds
        zoom = cx.tile._calculate_zoom(w, s, e, n)
        cx.add_basemap(ax, crs=crs, source="http://www.google.cn/maps/vt?lyrs=s@189&gl=cn&x={x}&y={y}&z={z}", alpha=0.5, zoom=zoom + 1)

    # ------------------------------------------------------------------------
    # Compute bounding box & clamp aspect ratio by expanding x-limits
    minx, miny, maxx, maxy = gpd_df.total_bounds
    width_data = maxx - minx
    height_data = maxy - miny

    desired_max_aspect = 1.2  # e.g., no taller than 1:1.2
    current_aspect = height_data / width_data
    if current_aspect > desired_max_aspect:
        # Expand width so final aspect ratio is no taller than desired_max_aspect
        new_width = height_data / desired_max_aspect
        diff = new_width - width_data
        minx -= diff / 2
        maxx += diff / 2
        width_data = new_width

    # Recompute figure size based on possibly expanded x-range
    dpi = calculate_dpi_for_area(width_data, height_data)
    width_in_inches = width_data / dpi
    height_in_inches = height_data / dpi
    fig.set_size_inches(width_in_inches, height_in_inches)

    # Add a small margin around bounding box so shapes aren't on the edge
    margin_x = 0.05 * (maxx - minx)
    margin_y = 0.05 * (maxy - miny)
    ax.set_xlim(minx - margin_x, maxx + margin_x)
    ax.set_ylim(miny - margin_y, maxy + margin_y)

    # (Optional) Keep geometry from being distorted
    ax.set_aspect("equal", adjustable="box")

    # ------------------------------------------------------------------------

    # Calculate font size
    aspect_ratio = max(width_in_inches / height_in_inches, height_in_inches / width_in_inches)
    base_font_size = 14
    font_size = base_font_size * aspect_ratio
    matplotlib.rcParams.update({"font.size": font_size})

    # Format axes
    ax.ticklabel_format(style="sci", scilimits=(6, 6), axis="y")
    label = ax.yaxis.get_offset_text()
    label.set_size(font_size)
    ax.xaxis.set_major_formatter(FuncFormatter(lambda x, pos: str(int(x))))
    for tick in ax.xaxis.get_major_ticks():
        tick.label1.set_fontsize(font_size)
    for tick in ax.yaxis.get_major_ticks():
        tick.label1.set_fontsize(font_size)

    # Add scale bar
    scalebar = ScaleBar(dx=1, label="escala", location="upper left", frameon=False, box_alpha=0.1)
    ax.add_artist(scalebar)

    # Add north arrow
    x, y, arrow_length = 0.98, 0.98, 0.05
    ax.annotate(
        "N", xy=(x, y), xytext=(x, y - arrow_length), arrowprops=dict(facecolor="black", width=4, headwidth=12), ha="center", va="center", xycoords=ax.transAxes, fontsize=font_size
    )

    # Add colorbar or legend
    if graduated:
        # Adaptive colorbar placement
        figure_width_in_inches, figure_height_in_inches = fig.get_size_inches()
        A4_factor = 1.5 / 1
        sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=_vmin, vmax=_vmax))
        divider = make_axes_locatable(ax)
        if (figure_width_in_inches / figure_height_in_inches) > A4_factor:
            cax = divider.append_axes("top", size=0.175, pad=1.1)
            cbar = plt.colorbar(sm, cax=cax, orientation="horizontal")
            cbar.set_label(title, fontsize=font_size, labelpad=-1)
        else:
            cax = divider.append_axes("right", size=0.175, pad=0.1)
            cbar = plt.colorbar(sm, cax=cax, orientation="vertical")
            cbar.set_label(title, fontsize=font_size, labelpad=2)
        cbar.ax.tick_params(labelsize=font_size)
    else:
        # Categorical legend (no title)
        unique_values = np.unique(gpd_df[variable])
        if dissolve and len(unique_values) > 10:
            # If dissolve is True and there are more than 10 unique values, show only "Leyenda: [variable]"
            ax.legend(handles=[], title=f"Leyenda: {title}", bbox_to_anchor=(0.5, 1.02), loc="lower center", ncol=1, frameon=False, fontsize=font_size)
        else:
            # Normal categorical legend with individual values
            float_colors = sns.color_palette("gist_rainbow", n_colors=len(unique_values))
            hex_list = [mcolors.to_hex(color) for color in float_colors]
            dict_color = dict(zip(unique_values, hex_list))
            custom_legend = [Line2D([0], [0], color=color, lw=3.5) for color in dict_color.values()]
            custom_names = [str(key) for key in dict_color.keys()]
            bbox = fig.get_tightbbox(fig.canvas.get_renderer())
            axis_width_in_inches = bbox.width
            legend = ax.legend(custom_legend, custom_names, bbox_to_anchor=(0.5, 1.02), loc="lower center", ncol=1, frameon=False, fontsize=font_size)
            fig.canvas.draw()
            dpi = fig.dpi
            legend_width_in_inches = legend.get_window_extent().width / dpi
            col_number = 1
            while col_number <= len(custom_names) and legend_width_in_inches < axis_width_in_inches:
                col_number += 1
                legend = ax.legend(custom_legend, custom_names, bbox_to_anchor=(0.5, 1.02), loc="lower center", ncol=col_number, frameon=False, fontsize=font_size)
                fig.canvas.draw()
                legend_width_in_inches = legend.get_window_extent().width / dpi
            if legend_width_in_inches > axis_width_in_inches:
                col_number = max(col_number - 1, 1)
            legend = ax.legend(
                custom_legend, custom_names, bbox_to_anchor=(0.5, 1.02), title="Leyenda " + title, loc="lower center", ncol=col_number, frameon=False, fontsize=font_size
            )

    if label_area:
        for label_, centroid, area_ in zip(gpd_df[variable], gpd_df.geometry.centroid, gpd_df.geometry.area):
            if area_ > (5000):
                
                ax.annotate(
                    label_,
                    xy=(centroid.x, centroid.y),
                    xytext=(3, 3),  # Offset the text slightly
                    textcoords="offset points",
                    bbox=dict(boxstyle="round,pad=0.3", fc="white", ec="black", lw=2),
                    ha="center",
                    va="bottom",
                    fontsize=font_size * 0.7,
                )

    # Add grid and set aspect
    ax.grid(color="gray", linestyle="--", linewidth=2.0)

    # Adjust layout
    fig.tight_layout()

    if out_dir:
        plt.savefig(out_dir + os.path.sep + name + "_planimetria", bbox_inches="tight")
        return dpi, width_in_inches, height_in_inches
    else:
        plt.show()


def adjust_text_sizes(ax, fig, title, max_font_size=14, min_font_size=9):
    # Calculate the density of ticks and plot size
    xticks = len(ax.get_xticks())
    yticks = len(ax.get_yticks())
    bbox = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())
    width, height = bbox.width, bbox.height

    # Normalize font size based on number of ticks and axis length
    tick_font_size = np.clip(
        max_font_size - 0.05 * (xticks / width + yticks / height),
        min_font_size,
        max_font_size,
    )
    ax.tick_params(axis="both", labelsize=tick_font_size)

    # Adjust existing legend size
    if ax.get_legend() is not None:
        legend = ax.get_legend()
        plt.setp(legend.get_texts(), fontsize=tick_font_size * 1.15)  # Update the font size of existing legend texts
        plt.setp(legend.get_title(), fontsize=tick_font_size * 1.25)  # Update the font size of the legend title

    return tick_font_size


def format_ticks(ax):
    # Format the tick labels to display as regular integers
    ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f"{int(x):,}"))  # Adds commas as thousands separators
    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda y, _: f"{int(y):,}"))

    # Rotate x-axis tick labels to 90 degrees
    ax.tick_params(axis="y", labelrotation=90)
    # Vertically center y-axis tick labels
    for label in ax.get_yticklabels():
        label.set_verticalalignment("center")


def plot_variables_old(
    gpd_df,
    variable,
    title,
    labels,
    out_dir,
    categorica=False,
    name=False,
    cut_extreme_values=False,
    breakpoints=False,
    image_path=None,
    make_existing_new_color=False,
    hide_existente=False,
):
    import matplotlib.pyplot as plt
    import matplotlib
    import matplotlib.colors as mcolors
    from matplotlib_scalebar.scalebar import ScaleBar
    from matplotlib.lines import Line2D
    from mpl_toolkits.axes_grid1 import make_axes_locatable
    from matplotlib.ticker import FuncFormatter
    import contextily as cx
    import seaborn as sns

    color_existente = "k"
    # import random
    # hex_list = ["#0078ff", "#ff0105", "#f8f800", "#ff8300", "#f701ff", "##05ff01", ]
    hex_list = [
        "#0078ff",  # Bright Blue
        "#ff0105",  # Bright Red
        "#f8f800",  # Bright Yellow
        "#f701ff",  # Bright Magenta
        # "#ffaa00" ,  # Amber
        "#05ff01",  # Bright Green
        "#ff8300",  # Bright Orange
        # "#00ffff",  # Cyan
        # "#ff00aa",  # Hot Pink
        # "#9900ff",  # Purple
    ]

    if hide_existente:
        filtro_gpd_df = gpd_df["Estado"] == "nuevo"
        gpd_df = gpd_df[filtro_gpd_df].copy()

    # random.shuffle(hex_list)

    cmap = get_continuous_cmap(hex_list)
    # cmap= 'jet'

    gpd_df = gpd_df.explode(index_parts=True)
    gpd_df.reset_index(drop=True, inplace=True)
    gpd_df["numerical_D_ext"] = seccion_str2float(gpd_df["D_ext"].to_numpy())
    if variable == "D_ext":
        variable = "numerical_D_ext"

    if make_existing_new_color:
        try:
            filtro_existente = gpd_df["metodo_constructivo"].isin(["existente"]).to_numpy().nonzero()[0]
            filtro_nuevo = gpd_df["Estado"].isin(["nuevo"]).to_numpy().nonzero()[0]
        except:
            filtro_existente = gpd_df["Estado"].isin(["existente"]).to_numpy().nonzero()[0]
            filtro_nuevo = gpd_df["Estado"].isin(["nuevo"]).to_numpy().nonzero()[0]

    if make_existing_new_color and breakpoints:
        new_max_value = np.round(np.nanmax(gpd_df[variable][filtro_nuevo].dropna()), 1)
        last_item = np.where(breakpoints <= new_max_value)[0][-1]
        breakpoints = breakpoints[:last_item] + [new_max_value]

    if categorica:
        if make_existing_new_color:
            _vmax, _vmin = np.max(gpd_df[variable][filtro_nuevo]), np.min(gpd_df[variable][filtro_nuevo])
        else:
            _vmax, _vmin = np.max(gpd_df[variable]), np.min(gpd_df[variable])

        # if isinstance(_vmax, str) or isinstance(_vmin, str):
        #     new_code = list(range(len(np.unique(gpd_df[variable]))))
        #     dict_code = dict(zip(np.unique(gpd_df[variable]), new_code))
        #     _vmax, _vmin = max(new_code), min(new_code)
        #     color_list = np.array(itemgetter(*gpd_df[variable].to_numpy().astype(str))(dict_code))
        # else:
        #     color_list = gpd_df[variable].to_numpy()

        # # normalizar los valores de color
        # norm = matplotlib.colors.Normalize(vmin=_vmin, vmax=_vmax)
        # dict_color = {}
        # for _i in np.unique(color_list):
        #     _c = matplotlib.colors.to_hex(cmap(norm(_i)))
        #     _color = np.where(np.char.equal(color_list.astype(str), str(_i)), _c, color_list)
        #     dict_color[str(_i)] = _c
        # gpd_df["color"] = itemgetter(*color_list.astype(str))(dict_color)
        # dict_color = dict(zip(np.unique(gpd_df[variable]), dict_color.values()))

        float_colors = sns.color_palette("gist_rainbow", n_colors=len(np.unique(gpd_df[variable])))
        hex_list = [mcolors.to_hex(color) for color in float_colors]
        # Set the seed
        random.seed(42)
        random.shuffle(hex_list)

        dict_color = dict(zip(np.unique(gpd_df[variable]), hex_list))
        gpd_df["color"] = gpd_df[variable].map(dict_color)

    else:
        if make_existing_new_color:
            _vmax, _vmin = np.max(gpd_df[variable][filtro_nuevo]), np.min(gpd_df[variable][filtro_nuevo])
        else:
            _vmax, _vmin = np.max(gpd_df[variable]), np.min(gpd_df[variable])

        # Normalize your values to the range [0, 1]
        norm = mcolors.Normalize(vmin=_vmin, vmax=_vmax)
        normalized_values = norm(gpd_df[variable])
        rgba_colors = cmap(normalized_values)
        # Apply your custom colormap to normalized values to get an array of colors
        gpd_df["color"] = [mcolors.to_hex(rgb[:3]) for rgb in rgba_colors]

        if make_existing_new_color:
            gpd_df["color"][filtro_existente] = color_existente

        if not breakpoints:
            if make_existing_new_color:
                vals_array_filtro = np.isfinite(gpd_df[variable][filtro_nuevo].to_numpy())
                vals_array = gpd_df[variable][filtro_nuevo].to_numpy()[vals_array_filtro]
            else:
                vals_array_filtro = np.isfinite(gpd_df[variable].to_numpy())
                vals_array = gpd_df[variable].to_numpy()[vals_array_filtro]

            if cut_extreme_values:
                vals_array = remove_extreme_values(vals_array)
            _vmax, _vmin = np.max(vals_array), np.min(vals_array)
            if variable == "h/D":
                _vmax = 0.8
        else:
            cmap_discrete = mcolors.ListedColormap(cmap(np.linspace(0, 1, len(breakpoints))))
            norm = mcolors.BoundaryNorm(breakpoints, cmap_discrete.N)

    # Plot the data
    x_list, y_list = [], []

    fig, ax = plt.subplots(nrows=1, ncols=1)

    # Find the min and max of the normalized D_ext values
    min_d_ext = gpd_df["numerical_D_ext"].min()
    max_d_ext = gpd_df["numerical_D_ext"].max()
    # Calculate dynamic min and max line widths based on the data
    dynamic_min_line_width = 1.5
    dynamic_max_line_width = 5

    # Apply dynamic normalization
    # gpd_df["dynamic_line_width"] = gpd_df["numerical_D_ext"].apply(lambda x: dynamic_min_line_width + (dynamic_max_line_width - dynamic_min_line_width) * (x - min_d_ext) / (max_d_ext - min_d_ext))

    # Apply dynamic normalization with edge case handling
    if min_d_ext == max_d_ext:
        gpd_df["dynamic_line_width"] = gpd_df["numerical_D_ext"].apply(lambda x: dynamic_min_line_width + (dynamic_max_line_width - dynamic_min_line_width) * 0.5)
    else:
        gpd_df["dynamic_line_width"] = gpd_df["numerical_D_ext"].apply(
            lambda x: dynamic_min_line_width + (dynamic_max_line_width - dynamic_min_line_width) * (x - min_d_ext) / (max_d_ext - min_d_ext)
        )

    # color_existente = '#ffffff'

    if categorica:
        # gpd_df.plot(ax=ax, linewidth=gpd_df['dynamic_line_width'], cmap=cmap_name, categorical=True, legend=True)
        if make_existing_new_color:
            gpd_df["color"].iloc[filtro_existente] = color_existente
            dict_color["existente"] = color_existente
            # gpd_df.iloc[filtro_nuevo, :].plot(ax=ax, linewidth=gpd_df['dynamic_line_width'], color=gpd_df['color'][filtro_nuevo], categorical=True, legend=True)
            gpd_df.plot(
                ax=ax,
                linewidth=gpd_df["dynamic_line_width"],
                color=gpd_df["color"],
                categorical=True,
                legend=True,
            )
        else:
            gpd_df.plot(
                ax=ax,
                linewidth=gpd_df["dynamic_line_width"],
                color=gpd_df["color"],
                categorical=True,
                legend=True,
            )

    else:
        if make_existing_new_color:
            # plot
            gpd_df_copy = gpd_df.iloc[filtro_existente]
            gpd_df_copy.plot(
                ax=ax,
                linewidth=gpd_df["dynamic_line_width"],
                color=color_existente,
                zorder=200,
            )
            _vmax, _vmin = (
                gpd_df[variable][filtro_nuevo].dropna().max(),
                gpd_df[variable][filtro_nuevo].dropna().min(),
            )

            if not breakpoints:
                # gpd_df.iloc[filtro_nuevo, :].plot(column=variable, ax=ax, linewidth=gpd_df['dynamic_line_width'], cmap=cmap, vmax=_vmax, vmin=_vmin)
                gpd_df.iloc[filtro_nuevo, :].plot(
                    ax=ax,
                    linewidth=gpd_df["dynamic_line_width"],
                    color=gpd_df["color"][filtro_nuevo],
                    vmax=_vmax,
                    vmin=_vmin,
                )
            else:
                gpd_df.iloc[filtro_nuevo, :].plot(
                    column=variable,
                    ax=ax,
                    linewidth=gpd_df["dynamic_line_width"],
                    cmap=cmap_discrete,
                    norm=norm,
                )

        else:
            if not breakpoints:
                if make_existing_new_color:
                    # gpd_df.plot(column=variable, ax=ax, linewidth=gpd_df['dynamic_line_width'], cmap=cmap, vmax=_vmax, vmin=_vmin)
                    gpd_df.iloc[filtro_nuevo, :].plot(
                        ax=ax,
                        linewidth=gpd_df["dynamic_line_width"],
                        color=gpd_df["color"][filtro_nuevo],
                        vmax=_vmax,
                        vmin=_vmin,
                    )
                else:
                    gpd_df.plot(
                        ax=ax,
                        linewidth=gpd_df["dynamic_line_width"],
                        color=gpd_df["color"],
                        vmax=_vmax,
                        vmin=_vmin,
                    )
            else:
                gpd_df.plot(
                    column=variable,
                    ax=ax,
                    linewidth=gpd_df["dynamic_line_width"],
                    cmap=cmap_discrete,
                    norm=norm,
                )

    if image_path:
        # Open the GeoTIFF file
        src = rasterio.open(image_path)

        # Read the three bands (red, green, blue)
        r = src.read(1)
        g = src.read(2)
        b = src.read(3)

        # Stack the bands into an RGB image (rasterio reads in (band, row, col) order)
        rgb = np.dstack((r, g, b))

        # # Get the bounds of the raster
        bounds = src.bounds

        # Calculate the extent of the raster
        extent = [bounds.left, bounds.right, bounds.bottom, bounds.top]

        # Plot the RGB data with the extent
        cax = ax.imshow(rgb, extent=extent, alpha=0.4)

    else:
        crs = gpd_df.crs  # this should be the same as the one in the file
        w, s, e, n = gpd_df.to_crs("epsg:4326").total_bounds
        zoom = cx.tile._calculate_zoom(w, s, e, n)
        cx.add_basemap(
            ax,
            crs=crs,
            source="http://www.google.cn/maps/vt?lyrs=s@189&gl=cn&x={x}&y={y}&z={z}",
            alpha=0.5,
            zoom=zoom + 1,
        )
        # create an empty imshow
        cax = ax.imshow([[0]], extent=[w, e, s, n])

    for geom, _width, _color in zip(gpd_df.geometry, gpd_df["dynamic_line_width"], gpd_df["color"]):
        x, y = geom.coords.xy
        x_list.append(x)
        y_list.append(y)
        # calculate position and direction vectors:
        x0 = x[0]
        x1 = x[1]
        y0 = y[0]
        y1 = y[1]
        xpos = (x0 + x1) / 2
        ypos = (y0 + y1) / 2
        xdir = x1 - x0
        ydir = y1 - y0
        # plot arrow on each line:
        ax.annotate(
            "",
            xytext=(xpos, ypos),
            xy=(xpos + 0.001 * xdir, ypos + 0.001 * ydir),
            arrowprops=dict(
                arrowstyle="->",
                color="k",
                lw=1,
                mutation_scale=_width * 3 if _width * 3 > 10 else 10,
            ),
            zorder=201,
        )  # ax.annotate("", xytext=(xpos, ypos), xy=(xpos + 0.001 * xdir, ypos + 0.001 * ydir), arrowprops=dict(arrowstyle="->", color=_color,  lw=1, mutation_scale=_width * 3. if _width * 3. > 10 else 10), zorder=201)

    # resize figure
    x_list = np.concatenate(x_list)
    y_list = np.concatenate(y_list)
    x_max, x_min = np.max(x_list), np.min(x_list)
    y_max, y_min = np.max(y_list), np.min(y_list)
    width_figure, heigth_figure = x_max - x_min, y_max - y_min

    dpi = calculate_dpi_for_area(width_figure, heigth_figure)

    # Calculate the width and height of the figure in inches
    width_in_inches = width_figure / dpi
    height_in_inches = heigth_figure / dpi

    # set figure size
    fig.set_size_inches(width_in_inches, height_in_inches)

    # Calculate font size for x-axis and y-axis labels
    aspect_ratio_1 = width_in_inches / height_in_inches
    aspect_ratio_2 = height_in_inches / width_in_inches
    aspect_ratio = max(aspect_ratio_2, aspect_ratio_1)

    base_font_size = 14
    font_size = base_font_size * aspect_ratio
    matplotlib.rcParams.update({"font.size": font_size})

    # Set the y-axis to scientific notation
    ax.ticklabel_format(style="sci", scilimits=(6, 6), axis="y")

    # Set the font size of the scientific notation labels to 18 points
    label = ax.yaxis.get_offset_text()
    label.set_size(font_size)

    # good aspect ratio to a figures in a A4 paper sheet
    A4_factor = 1.5 / 1
    unidad = labels if labels == "" else " [" + labels + "]"
    title = title + unidad + " (" + str(np.unique(gpd_df["Tipo"])[0]) + ")"

    if categorica:
        try:
            custom_legend = [Line2D([0], [0], color=color, lw=3.5) for key, color in zip(dict_color.keys(), dict_color.values())]
        except:
            custom_legend = [Line2D([0], [0], color=color, lw=3.5) for key, color in zip(dict_color.keys(), dict_color.values())]
        custom_names = [str(_) + labels for _ in dict_color]

        # get dimensions of viewport and figure
        # Get the position of the axes object in inches
        bbox = fig.get_tightbbox(fig.canvas.get_renderer())
        # Calculate the width of the space between the left and right spines
        axis_width_in_inches, axis_height_in_inches = bbox.width, bbox.height

        # attempt horizontal legend position
        # first atempt to legend draw
        legend = ax.legend(
            custom_legend,
            custom_names,
            title="Leyenda " + title,
            bbox_to_anchor=(0.5, 1.02),
            loc="lower center",
            ncol=1,
            fontsize=font_size,
        )
        # Draw the legend
        fig.canvas.draw()
        # Get the DPI of the figure
        dpi = fig.dpi
        # get legend width and heigth
        legend_width_in_inches, legend_height_in_inches = (
            legend.get_window_extent().width / dpi,
            legend.get_window_extent().height / dpi,
        )

        col_number_horizontal = 1
        cond = True
        # check if the heigth of figures is bigger than legend heigth, if not add 1 column
        while cond:
            if col_number_horizontal <= len(custom_names) and legend_width_in_inches < axis_width_in_inches:
                col_number_horizontal = col_number_horizontal + 1
                # change columns number
                legend = ax.legend(
                    custom_legend,
                    custom_names,
                    title="Leyenda " + title,
                    loc="lower center",
                    bbox_to_anchor=(0.5, 1.02),
                    ncol=col_number_horizontal,
                    fontsize=font_size,
                    labelspacing=0.1,
                )
                # Draw the legend
                fig.canvas.draw()
                # get legend width and heigth
                legend_width_in_inches, legend_height_in_inches = (
                    legend.get_window_extent().width / dpi,
                    legend.get_window_extent().height / dpi,
                )
            else:
                if legend_width_in_inches > axis_width_in_inches:
                    col_number_horizontal = max(col_number_horizontal - 1, 1)
                    while col_number_horizontal * round((len(custom_names) / col_number_horizontal), 0) > len(custom_names) + 1:
                        col_number_horizontal = col_number_horizontal - 1
                # change columns number
                legend = ax.legend(
                    custom_legend,
                    custom_names,
                    title="Leyenda " + title,
                    loc="lower center",
                    bbox_to_anchor=(0.5, 1.02),
                    ncol=col_number_horizontal,
                    fontsize=font_size,
                    labelspacing=0.1,
                )
                # Draw the legend
                fig.canvas.draw()
                # get legend width and heigth
                legend_width_in_inches, legend_height_in_inches = (
                    legend.get_window_extent().width / dpi,
                    legend.get_window_extent().height / dpi,
                )
                cond = False

        legend = ax.legend(
            custom_legend,
            custom_names,
            title="Leyenda " + title,
            loc="lower center",
            bbox_to_anchor=(0.5, 1.02),
            ncol=col_number_horizontal,
            frameon=False,
            fontsize=font_size,
            labelspacing=0.1,
        )
    else:
        # Get the width and height of the figure in inches
        figure_width_in_inches, figure_height_in_inches = fig.get_size_inches()

        if (figure_width_in_inches / figure_height_in_inches) > A4_factor:
            # add colorbar
            sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=_vmin, vmax=_vmax))
            divider = make_axes_locatable(ax)
            cax = divider.append_axes("top", size=0.175, pad=1.1)
            cbar = plt.colorbar(sm, cax=cax, orientation="horizontal")
            cbar.set_label(title, fontsize=font_size, labelpad=-1)
        else:
            if not breakpoints:
                # add colorbar
                sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=_vmin, vmax=_vmax))
                divider = make_axes_locatable(ax)
                cax = divider.append_axes("right", size=0.175, pad=0.1)
                cbar = plt.colorbar(sm, cax=cax, orientation="vertical")
                cbar.set_label(title, fontsize=font_size, labelpad=2)
            else:
                # Create a ScalarMappable
                sm = plt.cm.ScalarMappable(cmap=cmap_discrete, norm=norm)
                divider = make_axes_locatable(ax)
                cax = divider.append_axes("right", size=0.175, pad=0.1)
                cbar = plt.colorbar(sm, cax=cax, orientation="vertical")
                cbar.set_label(title, fontsize=font_size, labelpad=2)

    # # Get the extent of the GeoDataFrame
    # minx, miny, maxx, maxy = gpd_df.total_bounds
    # additional_x = (maxx - minx) * 0.05
    # additional_y = (maxy - miny) * 0.05
    # # Set the extent of the axes
    # ax.set_xlim(minx - additional_x, maxx + additional_x)
    # ax.set_ylim(miny - additional_y, maxy + additional_y)

    # ------------------------------------------------------------------------
    # Get the extent of the GeoDataFrame
    minx, miny, maxx, maxy = gpd_df.total_bounds

    # Calculate the width and height of the plot
    width = maxx - minx
    height = maxy - miny

    # Add some padding (e.g., 5% of the width/height)
    additional_x = width * 0.05
    additional_y = height * 0.05

    # Calculate the aspect ratio (height / width)
    aspect_ratio = height / width

    # Define a threshold for "too tall" (e.g., aspect ratio > 1.5 means it's too tall)
    tall_threshold = 1.5

    # Adjust the limits to make it more square if too tall
    if aspect_ratio > tall_threshold:
        # Calculate how much to extend the x-limits to match the height
        additional_x_needed = (height - width) / 2
        minx = minx - additional_x_needed - additional_x
        maxx = maxx + additional_x_needed + additional_x
    else:
        # Use the original bounds with padding if not too tall
        minx = minx - additional_x
        maxx = maxx + additional_x

    # Set the y-limits with padding
    miny = miny - additional_y
    maxy = maxy + additional_y

    # Set the extent of the axes
    ax.set_xlim(minx, maxx)
    ax.set_ylim(miny, maxy)

    # Optional: Force the aspect ratio to be equal for a perfect square appearance
    ax.set_aspect("equal")

    # ------------------------------------------------------------------------

    format_ticks(ax)
    tick_font_size = adjust_text_sizes(ax, fig, title)

    # Create scale bar
    scalebar = ScaleBar(
        dx=1,
        units="m",
        label="Escala",
        location="upper left",
        frameon=False,
        box_alpha=0.1,
        font_properties={"size": tick_font_size},
    )
    ax.add_artist(scalebar)

    # north arrow
    x, y, arrow_length = 0.98, 0.98, 0.05 * (tick_font_size / font_size)
    ax.annotate(
        "N",
        xy=(x, y),
        xytext=(x, y - arrow_length),
        arrowprops=dict(
            facecolor="black",
            width=4 * (tick_font_size / font_size),
            headwidth=12 * (tick_font_size / font_size),
        ),
        ha="center",
        va="center",
        xycoords=ax.transAxes,
        fontsize=tick_font_size,
    )

    # grid
    ax.grid(color="gray", linestyle="--", linewidth=2.0)

    # set equal aspect ratio
    ax.set_aspect("equal", adjustable="box")

    # Adjust the layout to minimize white space
    fig.tight_layout()

    # plt.show()
    if out_dir:
        plt.savefig(out_dir + os.path.sep + name + "_planimetria", bbox_inches="tight")
        plt.close("all")
        del fig, ax, cax
        return dpi, width_in_inches, height_in_inches
    else:
        plt.show()


def plot_variables(
    gpd_df,
    variable,
    title,
    labels,
    out_dir,
    categorica=False,
    name=False,
    cut_extreme_values=False,
    breakpoints=False,
    image_path=None,
    make_existing_new_color=False,
    hide_existente=False,
):
    import matplotlib.pyplot as plt
    import matplotlib
    import matplotlib.colors as mcolors
    from matplotlib_scalebar.scalebar import ScaleBar
    from matplotlib.lines import Line2D
    from mpl_toolkits.axes_grid1 import make_axes_locatable
    from matplotlib.ticker import FuncFormatter
    import contextily as cx
    import seaborn as sns

    color_existente = "k"
    # import random
    # hex_list = ["#0078ff", "#ff0105", "#f8f800", "#ff8300", "#f701ff", "##05ff01", ]
    hex_list = [
        "#0078ff",  # Bright Blue
        "#ff0105",  # Bright Red
        "#f8f800",  # Bright Yellow
        "#f701ff",  # Bright Magenta
        # "#ffaa00" ,  # Amber
        "#05ff01",  # Bright Green
        "#ff8300",  # Bright Orange
        # "#00ffff",  # Cyan
        # "#ff00aa",  # Hot Pink
        # "#9900ff",  # Purple
    ]

    if hide_existente:
        filtro_gpd_df = gpd_df["Estado"] == "nuevo"
        gpd_df = gpd_df[filtro_gpd_df].copy()

    # random.shuffle(hex_list)

    cmap = get_continuous_cmap(hex_list)
    # cmap= 'jet'

    gpd_df = gpd_df.explode(index_parts=True)
    gpd_df.reset_index(drop=True, inplace=True)
    gpd_df["numerical_D_ext"] = seccion_str2float(gpd_df["D_ext"].to_numpy())
    if variable == "D_ext":
        variable = "numerical_D_ext"

    if make_existing_new_color:
        try:
            filtro_existente = gpd_df["metodo_constructivo"].isin(["existente"]).to_numpy().nonzero()[0]
            filtro_nuevo = gpd_df["Estado"].isin(["nuevo"]).to_numpy().nonzero()[0]
        except:
            filtro_existente = gpd_df["Estado"].isin(["existente"]).to_numpy().nonzero()[0]
            filtro_nuevo = gpd_df["Estado"].isin(["nuevo"]).to_numpy().nonzero()[0]

    if make_existing_new_color and breakpoints:
        new_max_value = np.round(np.nanmax(gpd_df[variable][filtro_nuevo].dropna()), 1)
        last_item = np.where(breakpoints <= new_max_value)[0][-1]
        breakpoints = breakpoints[:last_item] + [new_max_value]
        breakpoints = sorted(breakpoints)

    if categorica:
        if make_existing_new_color:
            _vmax, _vmin = np.max(gpd_df[variable][filtro_nuevo]), np.min(gpd_df[variable][filtro_nuevo])
        else:
            _vmax, _vmin = np.max(gpd_df[variable]), np.min(gpd_df[variable])

        # if isinstance(_vmax, str) or isinstance(_vmin, str):
        #     new_code = list(range(len(np.unique(gpd_df[variable]))))
        #     dict_code = dict(zip(np.unique(gpd_df[variable]), new_code))
        #     _vmax, _vmin = max(new_code), min(new_code)
        #     color_list = np.array(itemgetter(*gpd_df[variable].to_numpy().astype(str))(dict_code))
        # else:
        #     color_list = gpd_df[variable].to_numpy()

        # # normalizar los valores de color
        # norm = matplotlib.colors.Normalize(vmin=_vmin, vmax=_vmax)
        # dict_color = {}
        # for _i in np.unique(color_list):
        #     _c = matplotlib.colors.to_hex(cmap(norm(_i)))
        #     _color = np.where(np.char.equal(color_list.astype(str), str(_i)), _c, color_list)
        #     dict_color[str(_i)] = _c
        # gpd_df["color"] = itemgetter(*color_list.astype(str))(dict_color)
        # dict_color = dict(zip(np.unique(gpd_df[variable]), dict_color.values()))

        float_colors = sns.color_palette("gist_rainbow", n_colors=len(np.unique(gpd_df[variable])))
        hex_list = [mcolors.to_hex(color) for color in float_colors]
        # Set the seed
        random.seed(42)
        random.shuffle(hex_list)

        dict_color = dict(zip(np.unique(gpd_df[variable]), hex_list))
        gpd_df["color"] = gpd_df[variable].map(dict_color)

    else:
        if make_existing_new_color:
            _vmax, _vmin = np.max(gpd_df[variable][filtro_nuevo]), np.min(gpd_df[variable][filtro_nuevo])
        else:
            _vmax, _vmin = np.max(gpd_df[variable]), np.min(gpd_df[variable])

        # Normalize your values to the range [0, 1]
        norm = mcolors.Normalize(vmin=_vmin, vmax=_vmax)
        normalized_values = norm(gpd_df[variable])
        rgba_colors = cmap(normalized_values)
        # Apply your custom colormap to normalized values to get an array of colors
        gpd_df["color"] = [mcolors.to_hex(rgb[:3]) for rgb in rgba_colors]

        if make_existing_new_color:
            gpd_df["color"][filtro_existente] = color_existente

        if not breakpoints:
            if make_existing_new_color:
                vals_array_filtro = np.isfinite(gpd_df[variable][filtro_nuevo].to_numpy())
                vals_array = gpd_df[variable][filtro_nuevo].to_numpy()[vals_array_filtro]
            else:
                vals_array_filtro = np.isfinite(gpd_df[variable].to_numpy())
                vals_array = gpd_df[variable].to_numpy()[vals_array_filtro]

            if cut_extreme_values:
                vals_array = remove_extreme_values(vals_array)
            _vmax, _vmin = np.max(vals_array), np.min(vals_array)
            if variable == "h/D":
                _vmax = 0.8
        else:
            breakpoints = sorted(breakpoints)
            cmap_discrete = mcolors.ListedColormap(cmap(np.linspace(0, 1, len(breakpoints))))
            norm = mcolors.BoundaryNorm(breakpoints, cmap_discrete.N)

    # Plot the data
    x_list, y_list = [], []

    fig, ax = plt.subplots(nrows=1, ncols=1)

    # Find the min and max of the normalized D_ext values
    min_d_ext = gpd_df["numerical_D_ext"].min()
    max_d_ext = gpd_df["numerical_D_ext"].max()
    # Calculate dynamic min and max line widths based on the data
    dynamic_min_line_width = 1.5
    dynamic_max_line_width = 5

    # Apply dynamic normalization
    # gpd_df["dynamic_line_width"] = gpd_df["numerical_D_ext"].apply(lambda x: dynamic_min_line_width + (dynamic_max_line_width - dynamic_min_line_width) * (x - min_d_ext) / (max_d_ext - min_d_ext))

    # Apply dynamic normalization with edge case handling
    if min_d_ext == max_d_ext:
        gpd_df["dynamic_line_width"] = gpd_df["numerical_D_ext"].apply(lambda x: dynamic_min_line_width + (dynamic_max_line_width - dynamic_min_line_width) * 0.5)
    else:
        gpd_df["dynamic_line_width"] = gpd_df["numerical_D_ext"].apply(
            lambda x: dynamic_min_line_width + (dynamic_max_line_width - dynamic_min_line_width) * (x - min_d_ext) / (max_d_ext - min_d_ext)
        )

    # color_existente = '#ffffff'

    if categorica:
        # gpd_df.plot(ax=ax, linewidth=gpd_df['dynamic_line_width'], cmap=cmap_name, categorical=True, legend=True)
        if make_existing_new_color:
            gpd_df["color"].iloc[filtro_existente] = color_existente
            dict_color["existente"] = color_existente
            # gpd_df.iloc[filtro_nuevo, :].plot(ax=ax, linewidth=gpd_df['dynamic_line_width'], color=gpd_df['color'][filtro_nuevo], categorical=True, legend=True)
            gpd_df.plot(
                ax=ax,
                linewidth=gpd_df["dynamic_line_width"],
                color=gpd_df["color"],
                categorical=True,
                legend=True,
            )
        else:
            gpd_df.plot(
                ax=ax,
                linewidth=gpd_df["dynamic_line_width"],
                color=gpd_df["color"],
                categorical=True,
                legend=True,
            )

    else:
        if make_existing_new_color:
            # plot
            gpd_df_copy = gpd_df.iloc[filtro_existente]
            gpd_df_copy.plot(
                ax=ax,
                linewidth=gpd_df["dynamic_line_width"],
                color=color_existente,
                zorder=200,
            )
            _vmax, _vmin = (
                gpd_df[variable][filtro_nuevo].dropna().max(),
                gpd_df[variable][filtro_nuevo].dropna().min(),
            )

            if not breakpoints:
                # gpd_df.iloc[filtro_nuevo, :].plot(column=variable, ax=ax, linewidth=gpd_df['dynamic_line_width'], cmap=cmap, vmax=_vmax, vmin=_vmin)
                gpd_df.iloc[filtro_nuevo, :].plot(
                    ax=ax,
                    linewidth=gpd_df["dynamic_line_width"],
                    color=gpd_df["color"][filtro_nuevo],
                    vmax=_vmax,
                    vmin=_vmin,
                )
            else:
                gpd_df.iloc[filtro_nuevo, :].plot(
                    column=variable,
                    ax=ax,
                    linewidth=gpd_df["dynamic_line_width"],
                    cmap=cmap_discrete,
                    norm=norm,
                )

        else:
            if not breakpoints:
                if make_existing_new_color:
                    # gpd_df.plot(column=variable, ax=ax, linewidth=gpd_df['dynamic_line_width'], cmap=cmap, vmax=_vmax, vmin=_vmin)
                    gpd_df.iloc[filtro_nuevo, :].plot(
                        ax=ax,
                        linewidth=gpd_df["dynamic_line_width"],
                        color=gpd_df["color"][filtro_nuevo],
                        vmax=_vmax,
                        vmin=_vmin,
                    )
                else:
                    gpd_df.plot(
                        ax=ax,
                        linewidth=gpd_df["dynamic_line_width"],
                        color=gpd_df["color"],
                        vmax=_vmax,
                        vmin=_vmin,
                    )
            else:
                gpd_df.plot(
                    column=variable,
                    ax=ax,
                    linewidth=gpd_df["dynamic_line_width"],
                    cmap=cmap_discrete,
                    norm=norm,
                )

    if image_path:
        # Open the GeoTIFF file
        src = rasterio.open(image_path)

        # Read the three bands (red, green, blue)
        r = src.read(1)
        g = src.read(2)
        b = src.read(3)

        # Stack the bands into an RGB image (rasterio reads in (band, row, col) order)
        rgb = np.dstack((r, g, b))

        # # Get the bounds of the raster
        bounds = src.bounds

        # Calculate the extent of the raster
        extent = [bounds.left, bounds.right, bounds.bottom, bounds.top]

        # Plot the RGB data with the extent
        cax = ax.imshow(rgb, extent=extent, alpha=0.4)

    else:
        crs = gpd_df.crs  # this should be the same as the one in the file
        w, s, e, n = gpd_df.to_crs("epsg:4326").total_bounds
        zoom = cx.tile._calculate_zoom(w, s, e, n)
        cx.add_basemap(
            ax,
            crs=crs,
            source="http://www.google.cn/maps/vt?lyrs=s@189&gl=cn&x={x}&y={y}&z={z}",
            alpha=0.5,
            zoom=zoom + 1,
        )
        # create an empty imshow
        cax = ax.imshow([[0]], extent=[w, e, s, n])


    #borrar turo
    gdf_topografia = gpd.read_file(r'C:\Users\chelo\OneDrive\SANTA_ISABEL\PROYECTO_norte_5\03_ELEVACION\01_XYZ\join.dxf')
    gdf_topografia = gdf_topografia.set_crs(32717, allow_override=True, inplace=True)
    gdf_topografia.plot(ax=ax, color='gray', linewidth=1)
    
    
    for geom, _width, _color in zip(gpd_df.geometry, gpd_df["dynamic_line_width"], gpd_df["color"]):
        x, y = geom.coords.xy
        x_list.append(x)
        y_list.append(y)
        # calculate position and direction vectors:
        x0 = x[0]
        x1 = x[1]
        y0 = y[0]
        y1 = y[1]
        xpos = (x0 + x1) / 2
        ypos = (y0 + y1) / 2
        xdir = x1 - x0
        ydir = y1 - y0
        # plot arrow on each line:
        ax.annotate(
            "",
            xytext=(xpos, ypos),
            xy=(xpos + 0.001 * xdir, ypos + 0.001 * ydir),
            arrowprops=dict(
                arrowstyle="->",
                color="k",
                lw=1,
                mutation_scale=_width * 3 if _width * 3 > 10 else 10,
            ),
            zorder=201,
        )  # ax.annotate("", xytext=(xpos, ypos), xy=(xpos + 0.001 * xdir, ypos + 0.001 * ydir), arrowprops=dict(arrowstyle="->", color=_color,  lw=1, mutation_scale=_width * 3. if _width * 3. > 10 else 10), zorder=201)

    # ----------------------------------------------------
    # (1) Gather bounding box from line coords
    x_list = np.concatenate(x_list)
    y_list = np.concatenate(y_list)
    x_min, x_max = np.min(x_list), np.max(x_list)
    y_min, y_max = np.min(y_list), np.max(y_list)

    width_data = x_max - x_min
    height_data = y_max - y_min

    # (2) Only expand x-limits if the plot is "too tall"
    desired_max_aspect = 1.2  # e.g., no taller than 1 : 1.2
    current_aspect = height_data / width_data

    if current_aspect > desired_max_aspect:
        # Expand width so that final aspect ratio == desired_max_aspect
        new_width = height_data / desired_max_aspect
        diff = new_width - width_data
        x_min -= diff / 2
        x_max += diff / 2
        width_data = new_width
        # (We do NOT touch y_min / y_max, so top/bottom data is never lost)

    # (3) Recompute figure size
    dpi = calculate_dpi_for_area(width_data, height_data)
    width_in_inches = width_data / dpi
    height_in_inches = height_data / dpi
    fig.set_size_inches(width_in_inches, height_in_inches)

    # (4) Apply new limits
    # ax.set_aspect("equal", adjustable="box")
    additional_x = (x_max - x_min) * 0.05
    additional_y = (y_max - y_min) * 0.05
    # Set the extent of the axes
    ax.set_xlim(x_min - additional_x, x_max + additional_x)
    ax.set_ylim(y_min - additional_y, y_max + additional_y)

    # Adjust the layout to minimize white space
    fig.tight_layout()
    # ----------------------------------------------------

    # Calculate font size for x-axis and y-axis labels
    aspect_ratio_1 = width_in_inches / height_in_inches
    aspect_ratio_2 = height_in_inches / width_in_inches
    aspect_ratio = max(aspect_ratio_2, aspect_ratio_1)

    base_font_size = 14
    font_size = base_font_size * aspect_ratio
    matplotlib.rcParams.update({"font.size": font_size})

    # Set the y-axis to scientific notation
    ax.ticklabel_format(style="sci", scilimits=(6, 6), axis="y")

    # Set the font size of the scientific notation labels to 18 points
    label = ax.yaxis.get_offset_text()
    label.set_size(font_size)

    # good aspect ratio to a figures in a A4 paper sheet
    A4_factor = 1.5 / 1
    unidad = labels if labels == "" else " [" + labels + "]"
    title = title + unidad + " (" + str(np.unique(gpd_df["Tipo"])[0]) + ")"

    if categorica:
        try:
            custom_legend = [Line2D([0], [0], color=color, lw=3.5) for key, color in zip(dict_color.keys(), dict_color.values())]
        except:
            custom_legend = [Line2D([0], [0], color=color, lw=3.5) for key, color in zip(dict_color.keys(), dict_color.values())]
        custom_names = [str(_) + labels for _ in dict_color]

        # get dimensions of viewport and figure
        # Get the position of the axes object in inches
        bbox = fig.get_tightbbox(fig.canvas.get_renderer())
        # Calculate the width of the space between the left and right spines
        axis_width_in_inches, axis_height_in_inches = bbox.width, bbox.height

        # attempt horizontal legend position
        # first atempt to legend draw
        legend = ax.legend(
            custom_legend,
            custom_names,
            title="Leyenda " + title,
            bbox_to_anchor=(0.5, 1.02),
            loc="lower center",
            ncol=1,
            fontsize=font_size,
        )
        # Draw the legend
        fig.canvas.draw()
        # Get the DPI of the figure
        dpi = fig.dpi
        # get legend width and heigth
        legend_width_in_inches, legend_height_in_inches = (
            legend.get_window_extent().width / dpi,
            legend.get_window_extent().height / dpi,
        )

        col_number_horizontal = 1
        cond = True
        # check if the heigth of figures is bigger than legend heigth, if not add 1 column
        while cond:
            if col_number_horizontal <= len(custom_names) and legend_width_in_inches < axis_width_in_inches:
                col_number_horizontal = col_number_horizontal + 1
                # change columns number
                legend = ax.legend(
                    custom_legend,
                    custom_names,
                    title="Leyenda " + title,
                    loc="lower center",
                    bbox_to_anchor=(0.5, 1.02),
                    ncol=col_number_horizontal,
                    fontsize=font_size,
                    labelspacing=0.1,
                )
                # Draw the legend
                fig.canvas.draw()
                # get legend width and heigth
                legend_width_in_inches, legend_height_in_inches = (
                    legend.get_window_extent().width / dpi,
                    legend.get_window_extent().height / dpi,
                )
            else:
                if legend_width_in_inches > axis_width_in_inches:
                    col_number_horizontal = max(col_number_horizontal - 1, 1)
                    while col_number_horizontal * round((len(custom_names) / col_number_horizontal), 0) > len(custom_names) + 1:
                        col_number_horizontal = col_number_horizontal - 1
                # change columns number
                legend = ax.legend(
                    custom_legend,
                    custom_names,
                    title="Leyenda " + title,
                    loc="lower center",
                    bbox_to_anchor=(0.5, 1.02),
                    ncol=col_number_horizontal,
                    fontsize=font_size,
                    labelspacing=0.1,
                )
                # Draw the legend
                fig.canvas.draw()
                # get legend width and heigth
                legend_width_in_inches, legend_height_in_inches = (
                    legend.get_window_extent().width / dpi,
                    legend.get_window_extent().height / dpi,
                )
                cond = False

        legend = ax.legend(
            custom_legend,
            custom_names,
            title="Leyenda " + title,
            loc="lower center",
            bbox_to_anchor=(0.5, 1.02),
            ncol=col_number_horizontal,
            frameon=False,
            fontsize=font_size,
            labelspacing=0.1,
        )
    else:
        # Get the width and height of the figure in inches
        figure_width_in_inches, figure_height_in_inches = fig.get_size_inches()

        if (figure_width_in_inches / figure_height_in_inches) > A4_factor:
            # add colorbar
            sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=_vmin, vmax=_vmax))
            divider = make_axes_locatable(ax)
            cax = divider.append_axes("top", size=0.175, pad=1.1)
            cbar = plt.colorbar(sm, cax=cax, orientation="horizontal")
            cbar.set_label(title, fontsize=font_size, labelpad=-1)
        else:
            if not breakpoints:
                # add colorbar
                sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=_vmin, vmax=_vmax))
                divider = make_axes_locatable(ax)
                cax = divider.append_axes("right", size=0.175, pad=0.1)
                cbar = plt.colorbar(sm, cax=cax, orientation="vertical")
                cbar.set_label(title, fontsize=font_size, labelpad=2)
            else:
                # Create a ScalarMappable
                sm = plt.cm.ScalarMappable(cmap=cmap_discrete, norm=norm)
                divider = make_axes_locatable(ax)
                cax = divider.append_axes("right", size=0.175, pad=0.1)
                cbar = plt.colorbar(sm, cax=cax, orientation="vertical")
                cbar.set_label(title, fontsize=font_size, labelpad=2)

    format_ticks(ax)
    tick_font_size = adjust_text_sizes(ax, fig, title)

    # Create scale bar
    scalebar = ScaleBar(
        dx=1,
        units="m",
        label="Escala",
        location="upper left",
        frameon=False,
        box_alpha=0.1,
        font_properties={"size": tick_font_size},
    )
    ax.add_artist(scalebar)

    # north arrow
    x, y, arrow_length = 0.98, 0.98, 0.05 * (tick_font_size / font_size)
    ax.annotate(
        "N",
        xy=(x, y),
        xytext=(x, y - arrow_length),
        arrowprops=dict(
            facecolor="black",
            width=4 * (tick_font_size / font_size),
            headwidth=12 * (tick_font_size / font_size),
        ),
        ha="center",
        va="center",
        xycoords=ax.transAxes,
        fontsize=tick_font_size,
    )

    # grid
    ax.grid(color="gray", linestyle="--", linewidth=2.0)

    # set equal aspect ratio
    # ax.set_aspect("equal", adjustable="datalim")
    # 2) Make the Axes itself a square in figure space
    # ax.set_box_aspect(1)  # requires Matplotlib 3.3+

    # # Adjust the layout to minimize white space
    # fig.tight_layout()

    # plt.show()
    if out_dir:
        plt.savefig(out_dir + os.path.sep + name + "_planimetria", bbox_inches="tight")
        plt.close("all")
        del fig, ax, cax
        return dpi, width_in_inches, height_in_inches
    else:
        plt.show()


def calculate_optimal_classes(data, max_classes=5):
    """
    Calculate the optimal number of classes for Jenks natural breaks.

    :param data: List or array of data points
    :param max_classes: Maximum number of classes to test for
    :return: Optimal number of classes
    """
    import jenkspy

    # Ensure data is a flat array
    data = np.ravel(data)

    # Calculate natural breaks for a range of number of classes
    wss = []
    for num_classes in range(2, max_classes + 1):
        breaks = jenkspy.jenks_breaks(data, n_classes=num_classes)
        within_var_sum = sum(
            sum((d - np.mean([x for x in data if breaks[i] <= x < breaks[i + 1]])) ** 2 for d in data if breaks[i] <= d < breaks[i + 1]) for i in range(len(breaks) - 1)
        )
        wss.append(within_var_sum)

    # Calculate the differences in within sum of squares
    wss_diff = np.diff(wss)

    # Find the "elbow" point, which is the class count with the largest second derivative
    second_derivatives = -np.diff(wss_diff)
    optimal_classes = np.argmax(second_derivatives) + 2  # +2 to adjust for the class range starting at 2

    return optimal_classes


def annotate_data(ax, text, x, y, text_x_offset=20, text_y_offset=10, fontsize=22):
    """
    Annotates the plot with text at a specified location with an optional offset.

    Parameters:
    - ax: Matplotlib Axes object where the annotation will be added.
    - text: The text of the annotation.
    - x, y: The x and y coordinates on the plot where the point of interest is located.
    - text_x_offset, text_y_offset: The offset from the point (x, y) to place the annotation text.
    """
    # Annotate the plot
    ax.annotate(
        text,
        xy=(x, y),  # Position of the point to annotate
        xytext=(
            text_x_offset,
            text_y_offset,
        ),  # Position of the text relative to the point
        textcoords="offset points",  # The position of the text is given as an offset from the point
        arrowprops=dict(arrowstyle="->", connectionstyle="arc3"),  # Properties of the arrow
        bbox=dict(
            boxstyle="round,pad=0.3",
            facecolor="lightyellow",
            edgecolor="black",
            alpha=0.5,
        ),  # Text box style
        fontsize=fontsize,  # Font size
        ha="center",
        zorder=101,
    )  # Horizontal alignment


def format_tick_labels(value, tick_number):
    return f"{int(value)}"


def plot_flodd_losses(
    gpd_df,
    colunma,
    image_path=None,
    mask=False,
    lines=None,
    name=None,
    out_dir=None,
    vol_min=50,
):
    import matplotlib.pyplot as plt
    import matplotlib
    from matplotlib_scalebar.scalebar import ScaleBar
    from mpl_toolkits.axes_grid1 import make_axes_locatable
    from matplotlib.colors import BoundaryNorm
    from matplotlib.ticker import FuncFormatter
    import contextily as cx
    import pandas as pd
    import jenkspy

    # fillna
    gpd_df.fillna(0, inplace=True)
    gpd_df[colunma] = gpd_df[colunma].astype(float)

    if mask:
        bound_gdf = gpd.read_file(mask, engine="pyogrio")
        bounds = bound_gdf.total_bounds
    else:
        bounds = gpd_df.total_bounds

    # create plot
    fig, ax = plt.subplots(nrows=1, ncols=1)

    try:
        line_df = gpd.read_file(lines, engine="pyogrio")
        line_df.plot(ax=ax, color="k", linewidth=1, alpha=0.75)
    except:
        pass

    filtro = gpd_df[colunma] > vol_min
    new_df = gpd_df[filtro]
    for _ in new_df.iterrows():
        annotate_data(
            ax,
            str(round(_[1]["vol"], 1)) + r" ($m^3$)",
            _[1]["geometry"].x,
            _[1]["geometry"].y,
            text_x_offset=20,
            text_y_offset=10,
            fontsize=18,
        )

    # plot white nodes
    gpd_df.plot(ax=ax, legend=False, color="white", markersize=3, zorder=99)

    # plot color nodes
    natural_breaks = int(calculate_optimal_classes(gpd_df[colunma].to_numpy()))
    n_classes = max(natural_breaks, 5)
    bins = jenkspy.jenks_breaks(gpd_df[colunma].to_numpy(), n_classes=n_classes)
    bins[0] = vol_min
    bins = np.array(bins)
    bins.sort()
    # This will create a boolean array where True corresponds to items >= vol_min
    condition = bins >= vol_min
    # Use this boolean array to filter the original array
    bins = bins[condition]

    gpd_df["category"] = pd.cut(gpd_df[colunma], bins=bins, labels=bins[:-1])
    gpd_df.plot(ax=ax, column="category", legend=False, cmap="jet", linewidth=3, zorder=1000)

    # plot image
    if image_path:
        # Open the GeoTIFF file
        src = rasterio.open(image_path)

        # Read the three bands (red, green, blue)
        r = src.read(1)
        g = src.read(2)
        b = src.read(3)

        # Stack the bands into an RGB image (rasterio reads in (band, row, col) order)
        rgb = np.dstack((r, g, b))

        # # Get the bounds of the raster
        image_bounds = src.bounds

        # Calculate the extent of the raster
        extent = [
            image_bounds.left,
            image_bounds.right,
            image_bounds.bottom,
            image_bounds.top,
        ]

        # Plot the RGB data with the extent
        cax = ax.imshow(rgb, extent=extent, alpha=0.7, zorder=0)
    else:
        crs = gpd_df.crs  # this should be the same as the one in the file
        w, s, e, n = bounds
        zoom = cx.tile._calculate_zoom(w, s, e, n)
        cx.add_basemap(
            ax,
            crs=crs,
            source="http://www.google.cn/maps/vt?lyrs=s@189&gl=cn&x={x}&y={y}&z={z}",
            alpha=0.5,
            zoom=zoom + 1,
        )

    # Get the total boundary of all geometries
    x_min, y_min, x_max, y_max = bounds
    width_figure, heigth_figure = x_max - x_min, y_max - y_min
    dpi = calculate_dpi_for_area(width_figure, heigth_figure)

    # Calculate the width and height of the figure in inches
    width_in_inches = width_figure / dpi
    height_in_inches = heigth_figure / dpi

    # set figure size
    fig.set_size_inches(width_in_inches, height_in_inches)

    # Calculate font size for x-axis and y-axis labels
    aspect_ratio_1 = width_in_inches / height_in_inches
    aspect_ratio_2 = height_in_inches / width_in_inches
    aspect_ratio = max(aspect_ratio_2, aspect_ratio_1)

    base_font_size = 14
    font_size = base_font_size * aspect_ratio
    matplotlib.rcParams.update({"font.size": font_size})

    # Set the y-axis to scientific notation
    ax.ticklabel_format(style="sci", scilimits=(6, 6), axis="y")

    # Set the font size of the scientific notation labels to 18 points
    label = ax.yaxis.get_offset_text()
    label.set_size(font_size)

    # Set the tick labels using a lambda function
    ax.xaxis.set_major_formatter(FuncFormatter(lambda x, pos: str(int(x))))

    # Set the font size of the xtick labels
    for tick in ax.xaxis.get_major_ticks():
        tick.label1.set_fontsize(font_size)

    # Set the font size of the ytick labels
    for tick in ax.yaxis.get_major_ticks():
        tick.label1.set_fontsize(font_size)

    # Create scale bar
    scalebar = ScaleBar(dx=1, label="escala", location="upper left", frameon="False", box_alpha=0.1)
    ax.add_artist(scalebar)

    # north arrow
    x, y, arrow_length = 0.98, 0.98, 0.05
    ax.annotate(
        "N",
        xy=(x, y),
        xytext=(x, y - arrow_length),
        arrowprops=dict(facecolor="black", width=4, headwidth=12),
        ha="center",
        va="center",
        xycoords=ax.transAxes,
        fontsize=font_size,
    )

    # Assume 'ax' is the matplotlib Axes object you're working with
    ax.yaxis.set_major_formatter(FuncFormatter(format_tick_labels))
    ax.xaxis.set_major_formatter(FuncFormatter(format_tick_labels))

    # Create a ScalarMappable
    cmap = plt.get_cmap("jet", len(bins) - 1)  # Get a colormap with discrete colors
    norm = BoundaryNorm(bins, cmap.N)  # Create a BoundaryNorm that maps values to bins

    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
    divider = make_axes_locatable(ax)
    cax = divider.append_axes("right", size=0.175, pad=0.1)
    cbar = plt.colorbar(sm, cax=cax, orientation="vertical")
    cbar.set_label("Perdida de volumen de agua por presurizacion", fontsize=font_size, labelpad=2)

    # Get the extent of the GeoDataFrame
    minx, miny, maxx, maxy = bounds
    additional_x = (maxx - minx) * 0.05
    additional_y = (maxy - miny) * 0.05
    # Set the extent of the axes
    ax.set_xlim(minx - additional_x, maxx + additional_x)
    ax.set_ylim(miny - additional_y, maxy + additional_y)

    # grid
    ax.grid(color="gray", linestyle="--", linewidth=2.0)

    # set equal aspect ratio
    ax.set_aspect("equal", adjustable="box")

    # Adjust the layout to minimize white space
    fig.tight_layout()

    if out_dir:
        plt.savefig(out_dir + os.path.sep + name + "_planimetria", bbox_inches="tight")
        return dpi, width_in_inches, height_in_inches
    else:
        plt.show()


def remove_extreme_values(data, z_threshold=2):
    """
    Remove extreme values (based on Z-score) and NaN/inf values from a NumPy array.

    Parameters:
    data (numpy.ndarray): The input array.
    z_threshold (float): The Z-score threshold to identify extreme values.

    Returns:
    numpy.ndarray: Array with extreme and NaN/inf values removed.
    """
    # Remove NaN and infinite values
    data = data[np.isfinite(data)]

    # Calculate the mean and standard deviation
    mean = np.mean(data)
    std = np.std(data)

    # Calculate the Z-scores
    z_scores = (data - mean) / std

    # Create a boolean mask where absolute Z-scores are below the threshold
    not_extreme_values_filter = np.abs(z_scores) < z_threshold

    # Apply the filter to remove extreme values
    filtered_data = data[not_extreme_values_filter]

    return filtered_data


def resumen_longitudes(df, out_dir):
    # # resumen = {"Diametro": [], "Material": [], "Seccion": [], "Estado": [], "L": [], "Fase": [], }
    # resumen = {"Diametro": [], "Material": [], "Seccion": [], "Estado": [], "L": []}
    #
    # df.index = df["Estado"]
    # for estado in np.unique(df["Estado"]):
    #     df_estado = df.loc[estado]
    #
    #     diametros = list(sorted(list(np.unique(df_estado["D_ext"]))))
    #     df_estado.index = df_estado["D_ext"]
    #     for diametro in diametros:
    #         df_diametro = df_estado.loc[diametro]
    #
    #         materiales = np.unique(df_diametro["Material"])
    #         if isinstance(df_diametro, pd.DataFrame):
    #             df_diametro.index = df_diametro["Material"]
    #         else:
    #             if isinstance(df_diametro["Material"], str):
    #                 index_diametro = [df_diametro["Material"]]
    #             df_diametro = pd.DataFrame([df_diametro.to_numpy()], columns=df_diametro.index, index=index_diametro, )
    #
    #         for material in materiales:
    #             df_material = df_diametro.loc[material]
    #
    #             secciones = np.unique(df_material["Seccion"])
    #             if isinstance(df_material, pd.DataFrame):
    #                 df_material.index = df_material["Seccion"]
    #             else:
    #                 if isinstance(df_material["Seccion"], str):
    #                     index_material = [df_material["Seccion"]]
    #                 df_material = pd.DataFrame([df_material.to_numpy()], columns=df_material.index, index=index_material, )
    #
    #             for seccion in secciones:
    #                 df_seccion = df_material.loc[seccion]
    #
    #                 fases = np.unique(df_material["Fase"])
    #
    #                 if isinstance(df_seccion, pd.DataFrame):
    #                     df_seccion.index = df_seccion["Fase"]
    #                 else:
    #                     # if isinstance(df_seccion['Fase'], (str, int, float, pd.Series)):
    #                     index_seccion = [df_seccion["Fase"]]
    #                     df_seccion = pd.DataFrame([df_seccion.to_numpy()], columns=df_seccion.index, index=index_seccion, )
    #
    #                 for fase in fases:
    #                     df_fases = df_seccion.loc[fase]
    #
    #                     resumen["L"].append(round(df_fases["L"].sum(), 0))
    #                     resumen["Material"].append(material)
    #                     resumen["Seccion"].append(seccion)
    #                     resumen["Estado"].append(estado)
    #                     resumen["Diametro"].append(diametro)
    #                     resumen["Fase"].append(fase)
    #
    # resumen = pd.DataFrame(resumen)
    # resumen = resumen.replace(0, np.nan)
    # resumen = resumen.dropna(how="all", axis=0)
    # resumen["porcentaje"] = (resumen["L"] / resumen["L"].sum() * 100).round(1).astype(str)
    #
    # resumen.to_excel(out_dir + os.path.sep + "01_resumen_longitudes.xlsx", index=False)
    #
    filtro_nuevo = df["Estado"] == "nuevo"
    df = df.loc[filtro_nuevo]

    # Group by Diametro, Material and Estado, then sum
    resumen = df.groupby(["D_ext", "Material", "Seccion", "Estado", "Fase"])["L"].sum().reset_index()
    # Calculate percentage
    total_length = resumen["L"].sum()
    resumen["Porcentaje"] = (resumen["L"] / total_length * 100).round(1)
    # Sort by Diametro and Material
    resumen = resumen.sort_values(["D_ext", "Material"])
    resumen.to_excel(out_dir + os.path.sep + "01_resumen_longitudes.xlsx", index=False)


def categorize_suelo(row):
    if row["N60"] < 3 and row["metodo_constructivo"] not in ["perforacion horizontal dirigida"]:
        return "Reemplazo total"
    elif 3 <= row["N60"] < 5 and row["metodo_constructivo"] not in ["perforacion horizontal dirigida"]:
        return "Reemplazo parcial"
    elif 5 <= row["N60"] < 8 and row["metodo_constructivo"] not in ["perforacion horizontal dirigida"]:
        return "Mejoramiento superficial"
    elif 8 <= row["N60"] < 10 and row["metodo_constructivo"] not in ["perforacion horizontal dirigida"]:
        return "Mejoramiento ligero"
    else:
        if row["metodo_constructivo"] not in ["perforacion horizontal dirigida"]:
            return "Sin mejoramiento"
        else:
            return "No aplica"


def categorize_entibado(row):
    if row["metodo_constructivo"] in ["perforacion horizontal dirigida"] or row["HF"] < 0.5:
        return "Sin entibado"

    if row["Estado"] in ["existente"]:
        return "No aplica"

    # Suelo firme (N60 > 4)
    if row["N60"] > 6:
        if row["HF"] < 0.5:
            return "Sin entibado"
        elif row["HF"] < 0.9:
            return "Entibado discontinuo madera"
        elif row["HF"] <= 2.0:
            return "Entibado continuo madera"
        else:  # HF > 2.0
            return "Entibado continuo metalico"

    # Suelo blando (N60 <= 4)
    else:
        if row["HF"] <= 2.0:
            return "Entibado continuo madera"
        else:  # HF > 2.0
            return "Entibado continuo metalico"


def add_metodologia_constructiva(gpd_df):
    gpd_df["metodo_constructivo"] = ""

    # data.str.contains(substring)
    metodos = [
        "mejorar suelo",
        "Perforacion Horizontal Dirigida",
        "Canal Mano",
        "Tunel",
        "Reparacion",
        "Colector",
        "Zanja Mano",
    ]
    metodos = [_.lower() for _ in metodos]
    gpd_df["Obs"] = gpd_df["Obs"].str.lower()

    # filtro por metodos
    for metodo in metodos:
        filtro = gpd_df["Obs"].str.contains(metodo)
        gpd_df["metodo_constructivo"][filtro] = metodo

    filtro_estado = np.logical_and(gpd_df["Estado"].isin(["nuevo"]), gpd_df["metodo_constructivo"] == "")
    gpd_df["metodo_constructivo"][filtro_estado] = "zanja abierta"

    filtro_existente = np.logical_and(gpd_df["Estado"].isin(["existente"]), gpd_df["metodo_constructivo"] == "")
    gpd_df["metodo_constructivo"][filtro_existente] = "existente"

    return gpd_df


def get_add_metodologia_constructiva(m_ramales):
    for _ramal in m_ramales.keys():
        m_ramales[_ramal]["metodo_constructivo"] = np.full_like(a=m_ramales[_ramal]["Ramal"], fill_value="", dtype="U256")

        # data.str.contains(substring)
        metodos = [
            "mejorar suelo",
            "Perforacion Horizontal Dirigida",
            "Tunel",
            "Reparacion",
            "Colector",
            "Zanja Mano",
        ]
        metodos = [_.lower() for _ in metodos]

        s = pd.Series(m_ramales[_ramal]["Obs"]).str.lower()
        # filtro por metodos
        for metodo in metodos:
            filtro = s.str.contains(metodo)
            m_ramales[_ramal]["metodo_constructivo"][filtro] = metodo

        s_estado = pd.Series(m_ramales[_ramal]["Estado"])

        filtro_estado = np.logical_and(s_estado.isin(["nuevo"]), m_ramales[_ramal]["metodo_constructivo"] == "")
        m_ramales[_ramal]["metodo_constructivo"][filtro_estado] = "zanja abierta"

        filtro_existente = np.logical_and(s_estado.isin(["existente"]), m_ramales[_ramal]["metodo_constructivo"] == "")
        m_ramales[_ramal]["metodo_constructivo"][filtro_existente] = "existente"

    return m_ramales


def get_files_and_new_filename(directory, name):
    """
    Scans the specified directory for files matching the 'xx_ANYNAME.png' pattern and
    generates a new filename in a sequential numeric format.

    Args:
    directory (str): The path to the directory to scan.

    Returns:
    tuple: A list of matched filenames and the next filename to use.
    """
    pattern = re.compile(r"^(\d+)_(.+)\.png$")  # Regex to match 'xx_ANYNAME.png' where xx are digits and ANYNAME can be any name
    max_num = 0
    files_matched = []

    # Iterate through all files in the given directory
    for filename in os.listdir(directory):
        match = pattern.match(filename)
        if match:
            files_matched.append(filename)
            # Extract the numeric part and find the maximum
            number = int(match.group(1))
            if number > max_num:
                max_num = number

    # Generate the new filename with incremented number, padded with zeros
    new_filename = f"{max_num + 1:02}_{name}"  # Change 'NEWNAME' to whatever name logic you need

    return new_filename


class TiempoRendimientoEjecuccion:
    def __init__(self):
        self.rendimientos = {
            "PVC": {
                0.110: [120, "1 maestro + 3 ayudantes", 6],
                0.160: [100, "1 maestro + 3 ayudantes", 6],
                0.200: [90, "1 maestro + 3 ayudantes", 6],
                0.250: [80, "1 maestro + 4 ayudantes", 6],
                0.315: [70, "1 maestro + 4 ayudantes", 6],
                0.440: [60, "1 maestro + 4 ayudantes", 6],
                0.540: [50, "1 maestro + 5 ayudantes", 6],
                0.650: [40, "2 maestros + 6 ayudantes + 1 operador", 6],
                0.760: [35, "2 maestros + 6 ayudantes + 1 operador", 6],
                0.875: [30, "2 maestros + 6 ayudantes + 1 operador", 6],
                0.975: [25, "2 maestros + 7 ayudantes + 1 operador", 6],
            },
            "PEAD": {
                0.200: [48, "1 maestro + 4 ayudantes", 6],
                0.315: [48, "1 maestro + 4 ayudantes", 6],
                0.400: [48, "1 maestro + 4 ayudantes", 6],
                0.500: [36, "1 maestro + 5 ayudantes", 6],
                0.630: [36, "2 maestros + 6 ayudantes + 1 operador", 6],
                0.710: [36, "2 maestros + 6 ayudantes + 1 operador", 6],
                0.800: [24, "2 maestros + 7 ayudantes + 1 operador", 6],
                0.900: [24, "2 maestros + 7 ayudantes + 1 operador", 6],
                1.000: [12, "2 maestros + 8 ayudantes + 1 operador", 6],
                1.200: [12, "2 maestros + 8 ayudantes + 1 operador", 6],
            },
            "PRFV": {
                0.300: [70, "1 maestro + 4 ayudantes", 6],
                0.400: [60, "1 maestro + 4 ayudantes", 6],
                0.500: [50, "1 maestro + 5 ayudantes", 6],
                0.600: [40, "2 maestros + 6 ayudantes + 1 operador", 6],
                0.700: [35, "2 maestros + 6 ayudantes + 1 operador", 6],
                0.800: [30, "2 maestros + 7 ayudantes + 1 operador", 6],
                0.900: [25, "2 maestros + 7 ayudantes + 1 operador", 6],
                1.000: [20, "2 maestros + 8 ayudantes + 1 operador", 6],
                1.200: [15, "2 maestros + 8 ayudantes + 1 operador", 6],
                1.500: [12, "2 maestros + 8 ayudantes + 1 operador", 6],
                2.000: [10, "2 maestros + 8 ayudantes + 1 operador", 6],
            },
            "HS": {
                0.160: [50, "1 maestro + 3 ayudantes + 1 operador", 1],
                0.200: [45, "1 maestro + 3 ayudantes + 1 operador", 1],
                0.300: [40, "1 maestro + 4 ayudantes + 1 operador", 1],
                0.400: [35, "1 maestro + 4 ayudantes + 1 operador", 1],
                0.500: [30, "1 maestro + 5 ayudantes + 1 operador", 1],
                0.600: [25, "2 maestros + 6 ayudantes + 1 operador", 1],
            },
        }

    def get_rendimiento_hormigon_in_situ(self, diametro, seccion_dim):
        base_seccion, altura_seccion = seccion_dim.split("x")
        base_seccion, altura_seccion = float(base_seccion), float(altura_seccion)

        """Calcula equipo y rendimiento para secciones de hormigón in situ"""
        if diametro <= 0.5:
            espesor = 0.15
            rendimiento = 12  # m3/dia
            return {
                "rendimiento": rendimiento / ((base_seccion * espesor * 2) + (altura_seccion + espesor * 2) * espesor),
                "equipo": "1 maestro + 4 ayudantes + 2 carpinteros + 1 operador mixer",
                "actividades": {
                    "encofrado": "2 carpinteros - 1 día cada 8m",
                    "armado": "2 fierreros - 1 día cada 8m",
                    "fundido": "1 maestro + 4 ayudantes - 8m por día",
                    "fraguado": "7 días obligatorios",
                },
            }
        elif diametro <= 1.0:
            espesor = 0.25
            rendimiento = 10  # m3/dia
            return {
                "rendimiento": rendimiento / ((base_seccion * espesor * 2) + (altura_seccion + espesor * 2) * espesor),
                "equipo": "2 maestros + 6 ayudantes + 3 fierreros + 3 carpinteros + 1 operador mixer + 1 operador grúa",
                "actividades": {
                    "encofrado": "3 carpinteros - 1 día cada 6m",
                    "armado": "3 fierreros - 1 día cada 6m",
                    "fundido": "2 maestros + 6 ayudantes - 6m por día",
                    "fraguado": "7 días obligatorios",
                },
            }
        else:
            espesor = 0.35
            rendimiento = 8  # m3/dia
            return {
                "rendimiento": rendimiento / ((base_seccion * espesor * 2) + (altura_seccion + espesor * 2) * espesor),
                "equipo": "2 maestros + 8 ayudantes + 4 fierreros + 4 carpinteros + 1 operador mixer + 1 operador grúa",
                "actividades": {
                    "encofrado": "4 carpinteros - 1 día cada 4m",
                    "armado": "4 fierreros - 1 día cada 4m",
                    "fundido": "2 maestros + 8 ayudantes - 4m por día",
                    "fraguado": "7 días obligatorios",
                },
            }

    def tiempo_ejeuccion(self, df_tramos):
        """
        Calcula los días de construcción para diferentes tipos de tubería

        Args:
            df_tramos: DataFrame con columnas ['longitud', 'material', 'diametro'] (en metros)
        Returns:
            DataFrame con resultados del cálculo
        """
        dias = []
        equipo = []
        detalles = []
        for _, row in df_tramos.iterrows():
            material = row["material"]
            diametro = row["diametro"]
            longitud = row["longitud"]
            seccion = row["seccion"]
            seccion_dim = row["seccion_dim"]

            if material == "HA" and seccion in ["rectangular"]:
                info = self.get_rendimiento_hormigon_in_situ(diametro, seccion_dim)
                dias_totales = longitud / info["rendimiento"]

                dias.append(round(dias_totales, 2))
                equipo.append(info["equipo"])
                detalles.append(info["actividades"])

            elif material in self.rendimientos:
                diametros = list(self.rendimientos[material].keys())
                closest_dia = min(diametros, key=lambda x: abs(x - diametro))
                rendimiento_diario = self.rendimientos[material][closest_dia][0]
                equipo_necesario = self.rendimientos[material][closest_dia][1]
                longitud_tubo = self.rendimientos[material][closest_dia][2]

                n_uniones = (longitud / longitud_tubo) - 1
                tiempo_por_union = 0.125
                tiempo_total = (longitud / rendimiento_diario) + (n_uniones * tiempo_por_union)

                dias.append(round(tiempo_total, 2))
                equipo.append(equipo_necesario)
                detalles.append(f"Tubos de {longitud_tubo}m - {int(n_uniones)} uniones")

            else:
                dias.append(None)
                equipo.append(None)
                detalles.append(None)

        return pd.DataFrame(
            {
                "Longitud": np.concatenate(df_tramos["longitud"].to_numpy()),
                "Material": np.concatenate(df_tramos["material"].to_numpy()),
                "Diámetro": np.concatenate(df_tramos["diametro"].to_numpy()),
                "Días": dias,
                "Equipo_Necesario": equipo,
                "Detalles": detalles,
            }
        )


class FrentesTrabajoAlcantarillado:
    def __init__(self, df):
        self.df = df
        self.resumen = None
        self.cronograma = None
        self.max_frentes_simultaneos = 3

    def procesar_frente(self, front_df):
        resultados = []
        rendimineto = TiempoRendimientoEjecuccion()
        for diametro in front_df["D_ext"].unique():
            df_diametro = front_df[front_df["D_ext"] == diametro]

            material_arr = df_diametro["Material"].to_numpy()
            diametro_arr = seccion_str2float(df_diametro["D_ext"]).astype(float)
            seccion_dim_arr = df_diametro["D_ext"].to_numpy()
            longitud_arr = df_diametro["L"].to_numpy()
            seccion_arr = df_diametro["Seccion"].to_numpy()
            s = pd.DataFrame([material_arr, diametro_arr, seccion_arr, seccion_dim_arr, longitud_arr]).T
            s.columns = [["material", "diametro", "seccion", "seccion_dim", "longitud"]]
            resultados_rendimiento = rendimineto.tiempo_ejeuccion(s)

            resultados.append(
                {
                    "Fase": front_df["Fase"].iloc[0],
                    "Frente de Trabajo": front_df["RamalOutFall"].iloc[0],
                    "Dependencia": front_df["DependenciaOutFall"].iloc[0],
                    "Diámetro": diametro,
                    "Longitud Total (m)": round(df_diametro["L"].sum(), 2),
                    "Tiempo Estimado (días)": resultados_rendimiento["Días"].sum(),
                }
            )
        return resultados

    def generar_resumen(self):
        resultados = []
        for _, phase_df in self.df.groupby("Fase"):
            for _, front_df in phase_df.groupby("RamalOutFall"):
                resultados.extend(self.procesar_frente(front_df))

        self.resumen = pd.DataFrame(resultados)
        self.resumen = self.resumen[["Fase", "Frente de Trabajo", "Dependencia", "Diámetro", "Longitud Total (m)", "Tiempo Estimado (días)"]]
        return self.resumen

    def generar_cronograma(self, output_dir):
        if self.resumen is None:
            self.generar_resumen()

        # Set start date
        gantt_data = []
        end_date_max = []
        current_date_fase = datetime(2026, 1, 9)
        # current_date_fase = datetime(2025, 6, 1)

        for fase, grupo in self.resumen.groupby("Fase"):
            grupo = grupo.reset_index(drop=True)  # Reset index at fase level
            current_date_fase = current_date_fase if len(end_date_max) == 0 else max(end_date_max)
            already_done_frente = set()
            pending_dependent_fronts = {}  # Store fronts waiting to start in parallel
            active_fronts = set()  # Keep track of currently active fronts
            cond = True
            end_frente_date = {}

            while cond:
                grupos = {name: group.reset_index(drop=True) for name, group in grupo.groupby("Frente de Trabajo")}

                # First process independent fronts (self-dependent)
                for frente, grupo_frente in grupos.items():
                    # Skip if this front is already processed
                    if frente in already_done_frente:
                        continue

                    # Process diameter ordering
                    split_diameter = grupo_frente["Diámetro"].str.split("x", expand=True)
                    if isinstance(split_diameter, pd.DataFrame):
                        if split_diameter.shape[1] == 1:
                            grupo_frente["order"] = np.where(split_diameter[0].notna(), split_diameter[0], grupo_frente["Diámetro"])
                        else:
                            grupo_frente["order"] = np.where(split_diameter[1].notna(), split_diameter[1], grupo_frente["Diámetro"])

                    else:
                        grupo_frente["order"] = split_diameter

                    order_index = natsort.index_natsorted(grupo_frente["order"], reverse=True)
                    grupo_frente = grupo_frente.loc[order_index].reset_index(drop=True)

                    # If front depends on itself, process it first
                    if frente == grupo_frente.loc[0, "Dependencia"]:
                        current_date = current_date_fase

                        for idx, row in grupo_frente.iterrows():
                            task_name = f"Frente:{row['Frente de Trabajo']}-Ø:{row['Diámetro']}-L:{round(row['Longitud Total (m)'], 1)}m"
                            duration = row["Tiempo Estimado (días)"]

                            end_date = current_date + timedelta(days=max(duration, 1))
                            gantt_data.append(
                                {
                                    "Task": task_name,
                                    "Start": current_date.strftime("%Y-%m-%d"),
                                    "Finish": end_date.strftime("%Y-%m-%d"),
                                    "Resource": f"Frente:{row['Frente de Trabajo']}-Ø:{row['Diámetro']}",
                                    "Fase": fase,
                                }
                            )

                            current_date = end_date
                            end_frente_date[frente] = end_date
                            end_date_max.append(end_date)

                        already_done_frente.add(frente)
                        # Add dependent fronts to pending
                        for dep_frente, dep_grupo in grupos.items():
                            if dep_grupo.loc[0, "Dependencia"] == frente and dep_frente not in already_done_frente:
                                if frente not in pending_dependent_fronts:
                                    pending_dependent_fronts[frente] = []
                                pending_dependent_fronts[frente].append(dep_frente)

                # Process pending dependent fronts (up to 3 in parallel)
                for dependency, waiting_fronts in list(pending_dependent_fronts.items()):
                    if dependency in end_frente_date and len(active_fronts) < 3:
                        start_date = end_frente_date[dependency]

                        while waiting_fronts and len(active_fronts) < 3:
                            next_front = waiting_fronts.pop(0)
                            if next_front not in already_done_frente:
                                active_fronts.add(next_front)
                                grupo_frente = grupos[next_front]
                                current_date = start_date

                                for idx, row in grupo_frente.iterrows():
                                    task_name = f"Frente:{row['Frente de Trabajo']}-Ø:{row['Diámetro']}-L:{round(row['Longitud Total (m)'], 1)}m"
                                    duration = row["Tiempo Estimado (días)"]

                                    end_date = current_date + timedelta(days=max(duration, 1))
                                    gantt_data.append(
                                        {
                                            "Task": task_name,
                                            "Start": current_date.strftime("%Y-%m-%d"),
                                            "Finish": end_date.strftime("%Y-%m-%d"),
                                            "Resource": f"Frente:{row['Frente de Trabajo']}-Ø:{row['Diámetro']}",
                                            "Fase": fase,
                                        }
                                    )

                                    current_date = end_date
                                    end_frente_date[next_front] = end_date
                                    end_date_max.append(end_date)

                                already_done_frente.add(next_front)

                        if not waiting_fronts:
                            del pending_dependent_fronts[dependency]

                # Update active_fronts based on completion dates
                current_date = max(end_date_max) if end_date_max else current_date_fase
                active_fronts = {front for front in active_fronts if end_frente_date.get(front) and end_frente_date[front] > current_date}

                # Check if all fronts are processed
                if already_done_frente == set(grupos.keys()):
                    cond = False

        # Create the timeline
        df = pd.DataFrame(gantt_data)
        df["Start"] = pd.to_datetime(df["Start"])
        df["Finish"] = pd.to_datetime(df["Finish"])
        # Calculate duration
        df["Duration"] = (df["Finish"] - df["Start"]).dt.days

        self.cronograma = df.copy()

        fig = px.timeline(
            df,
            x_start="Start",
            x_end="Finish",
            y="Task",
            color="Fase",
            color_discrete_sequence=px.colors.qualitative.Plotly,  # More vibrant color palette
            hover_data={
                "Start": "|%Y-%m-%d",  # Format start date
                "Finish": "|%Y-%m-%d",  # Format end date
                "Duration": ":.0f dias",  # Show duration in days
                # 'Resource': True,  # Include resource information
                "Fase": True,  # Include phase information
            },
            title="Cronograma de Ejecuccion",
            labels={"Task": "Frentes de Trabajo", "Fase": "Componente"},
        )

        fig.update_yaxes(autorange="reversed")

        # # # Guardar cronograma visual

        output_path = os.path.join(output_dir, "cronograma.html")
        fig.write_html(output_path)

        # fig = self.visualizar_cronograma(gantt_data)  # output_path = os.path.join(output_dir, "cronograma_nuevo.html")  # fig.write_html(output_path)

    def guardar_resultados(self, output_dir="resultados"):
        """
        Guarda todos los resultados en una ubicación específica

        Args:
            output_dir (str): Directorio donde se guardarán los resultados
        """
        # Crear directorio si no existe
        os.makedirs(output_dir, exist_ok=True)

        # Generar resumen y cronograma si no existen
        if self.resumen is None:
            self.generar_resumen()
        if self.cronograma is None:
            self.generar_cronograma(output_dir)

        # Guardar resumen y cronograma en un solo Excel
        with pd.ExcelWriter(os.path.join(output_dir, "resultados_frentes_trabajo.xlsx")) as writer:
            self.resumen.to_excel(writer, sheet_name="Resumen", index=False)
            self.cronograma.to_excel(writer, sheet_name="Cronograma", index=False)

    def visualizar_cronograma(self, gantt_data):
        df = pd.DataFrame(gantt_data)

        # Convert dates to datetime
        df["Start"] = pd.to_datetime(df["Start"])
        df["Finish"] = pd.to_datetime(df["Finish"])

        # Calculate duration for each task
        df["Duration"] = (df["Finish"] - df["Start"]).dt.days

        # Calculate critical path
        df["Is_Critical"] = df.groupby("Task")["Duration"].transform(lambda x: x >= x.quantile(0.75))

        # Create color map for different task types
        task_colors = {task: "rgb(46, 137, 205)" if i % 2 == 0 else "rgb(114, 44, 121)" for i, task in enumerate(df["Task"].unique())}

        # Create the figure
        fig = go.Figure()

        # Sort tasks by start date
        df = df.sort_values("Start")

        # Create positions for each unique task
        tasks = df["Task"].unique()
        task_positions = {task: i for i, task in enumerate(tasks)}

        # Add tasks as horizontal bars
        for task in df["Task"].unique():
            task_data = df[df["Task"] == task]

            # Add main task bars
            fig.add_trace(
                go.Bar(
                    y=[task_positions[task]] * len(task_data),  # Position on y-axis
                    x=task_data["Duration"],  # Duration in days
                    base=task_data["Start"],  # Start date
                    name=task,
                    orientation="h",  # Make bars horizontal
                    marker_color=task_colors[task],
                    marker_line_color="rgba(0, 0, 0, 0.5)",
                    marker_line_width=1,
                    customdata=np.stack(
                        (task_data["Task"], task_data["Resource"], task_data["Duration"], task_data["Start"].dt.strftime("%Y-%m-%d"), task_data["Finish"].dt.strftime("%Y-%m-%d")),
                        axis=-1,
                    ),
                    hovertemplate="<br>".join(
                        [
                            "<b>%{customdata[0]}</b>",
                            "Recurso: %{customdata[1]}",
                            "Duración: %{customdata[2]} días",
                            "Inicio: %{customdata[3]}",
                            "Fin: %{customdata[4]}",
                            "<extra></extra>",
                        ]
                    ),
                )
            )

            # Add markers for critical path tasks
            critical_tasks = task_data[task_data["Is_Critical"]]
            if not critical_tasks.empty:
                fig.add_trace(
                    go.Scatter(
                        x=critical_tasks["Start"],
                        y=[task_positions[task]] * len(critical_tasks),
                        mode="markers",
                        name="Ruta Crítica",
                        marker=dict(symbol="star", size=8, color="red", line=dict(width=1, color="red")),
                        showlegend=True,
                    )
                )

        # Calculate date range for x-axis
        date_range = pd.date_range(start=df["Start"].min(), end=df["Finish"].max(), freq="MS")

        # Update layout
        fig.update_layout(
            title={"text": "Cronograma de Ejecución", "y": 0.95, "x": 0.5, "xanchor": "center", "yanchor": "top", "font": dict(size=24)},
            barmode="relative",
            height=50 * len(tasks) + 200,  # Dynamic height based on number of tasks
            showlegend=True,
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
            xaxis=dict(
                title="Periodo de Ejecución",
                gridcolor="rgba(0, 0, 0, 0.1)",
                griddash="dash",
                ticktext=[d.strftime("%b %Y") for d in date_range],
                tickvals=date_range,
                tickangle=45,
                type="date",
            ),
            yaxis=dict(
                title="Actividades",
                gridcolor="rgba(0, 0, 0, 0.1)",
                griddash="dash",
                ticktext=list(tasks),
                tickvals=list(task_positions.values()),
                autorange="reversed",  # Reverse y-axis to show tasks from top to bottom
            ),
            plot_bgcolor="white",
            paper_bgcolor="white",
            margin=dict(l=200, r=50, t=100, b=100),  # Increased left margin for task names
        )

        # Add shapes for month divisions and current date
        shapes = []

        # Add vertical lines for months
        for date in date_range:
            shapes.append(
                dict(
                    type="line", x0=date, x1=date, y0=min(task_positions.values()) - 0.5, y1=max(task_positions.values()) + 0.5, line=dict(color="rgba(0, 0, 0, 0.2)", dash="dash")
                )
            )

        # Add vertical line for current date
        current_date = pd.Timestamp.now()
        if df["Start"].min() <= current_date <= df["Finish"].max():
            shapes.append(
                dict(
                    type="line",
                    x0=current_date,
                    x1=current_date,
                    y0=min(task_positions.values()) - 0.5,
                    y1=max(task_positions.values()) + 0.5,
                    line=dict(color="red", width=2),
                    name="Fecha Actual",
                )
            )

            # Add annotation for current date
            fig.add_annotation(x=current_date, y=max(task_positions.values()) + 0.5, text="Fecha Actual", showarrow=False, yshift=10)

        fig.update_layout(shapes=shapes)

        return fig


def freedman_diaconis_rule(data):
    """
    Calculate the optimal bin width using the Freedman-Diaconis rule.

    :param data: Input array of float values
    :return: Optimal number of bins
    """
    iqr = np.subtract(*np.percentile(data, [75, 25]))
    bin_width = 2 * iqr * len(data) ** (-1 / 3)
    data_range = np.ptp(data)  # Range of the data

    if bin_width == 0:
        # If IQR is 0, fall back to Sturge's rule
        return int(np.ceil(np.log2(len(data))) + 1)

    n_bins = int(np.ceil(data_range / bin_width))
    return max(n_bins, 1)  # Ensure at least one bin


def adaptive_binning(data, threshold=0.01):
    """
    Create adaptive bins for the given data.

    :param data: Input array of float values (mm)
    :param threshold: Minimum fraction of total data points required in a bin
    :return: Array of bin edges
    """
    # Calculate optimal number of bins
    n_bins = freedman_diaconis_rule(data)

    # Sort the data
    sorted_data = np.sort(data)

    # Initialize with equal-width bins
    bins = np.linspace(sorted_data.min(), sorted_data.max(), n_bins + 1)

    while True:
        # Count the number of points in each bin
        counts, _ = np.histogram(sorted_data, bins)

        # Calculate the fraction of points in each bin
        fractions = counts / len(sorted_data)

        # Find bins with too few points
        low_count_bins = np.where(fractions < threshold)[0]

        if len(low_count_bins) == 0:
            break

        # Merge low-count bins with their neighbors
        for bin_index in reversed(low_count_bins):
            if bin_index == len(bins) - 2:
                bins = np.delete(bins, -2)
            elif bin_index == 0:
                bins = np.delete(bins, 1)
            else:
                left_neighbor = fractions[bin_index - 1]
                right_neighbor = fractions[bin_index + 1]
                if left_neighbor < right_neighbor:
                    bins = np.delete(bins, bin_index)
                else:
                    bins = np.delete(bins, bin_index + 1)

    return bins


def make_figures(project_name, d_min=0, d_max=5, mask=None, image_path=None):
    path_in = "PROYECTO_" + project_name + os.path.sep + "00_GIS" + os.path.sep + "02_OUT" + os.path.sep + "01_RAMALES" + os.path.sep + project_name + ".gpkg"
    base_dir = os.getcwd()
    path_out_figuras = base_dir + os.path.sep + "PROYECTO_" + project_name + os.path.sep + "04_RESULTADOS" + os.path.sep + "00_FIGURAS"
    path_out_tablas = "PROYECTO_" + project_name + os.path.sep + "04_RESULTADOS" + os.path.sep + "01_TABLAS"
    if not os.path.exists(path_out_figuras):
        os.mkdir(path_out_figuras)

    if not os.path.exists(path_out_tablas):
        os.mkdir(path_out_tablas)

    # leer el resultado de el vector out
    gpd_df = gpd.read_file(path_in, engine="pyogrio")

    # clip data to area
    if mask:
        df_mask = gpd.read_file(mask, engine="pyogrio")
        gpd_df = gpd.clip(gpd_df, df_mask)

    filtro_diametro = np.logical_and(
        gpd_df["D_ext"].str.split("x", expand=True)[0].to_numpy().astype(float) >= d_min,
        gpd_df["D_ext"].str.split("x", expand=True)[0].to_numpy().astype(float) <= d_max,
    )
    gpd_df = gpd_df[filtro_diametro]
    indice = np.where(gpd_df["v"].dropna().to_numpy() > 0)[0]

    # hacer resumen de longitudes
    resumen_longitudes(gpd_df, out_dir=path_out_tablas)

    # draw cirlces and rectangles
    draw_circle(path_out_figuras)
    draw_rectnagle(path_out_figuras)

    size_ = gpd_df["Estado"].isin(["nuevo"]).to_numpy().nonzero()[0].size
    if size_ > 0:
        make_existing_new_color = True
    else:
        make_existing_new_color = False

    dict_path_figuras = {
        "rectangular_pipe.png": "rectangular_pipe.png",
        "circular_pipe.png": "circular_pipe.png",
        
        "area_aporte_planimetria.png": None,
        "area_curve_number_planimetria.png": None,
        "area_ramal_planimetria.png": None,
        "area_slope_planimetria.png": None,
        "area_imperv_planimetria.png": None,
        "area_densidad_planimetria.png": None,
        
        "estado_planimetria.png": None,
        
        "diametro_planimetria.png": None,
        "diametro_bar_chart.png": None,
        
        "velocidad_planimetria.png": None,
        "velocidad_hist.png": None,
        
        "calado_planimetria.png": None,
        "calado_hist.png": None,
        
        "profundidad_media_planimetria.png": None,
        "profundidad_media_hist.png": None,
        
        "caudal_planimetria.png": None,
        
        "pendiente_planimetria.png": None,
        "pendiente_hist.png": None,
        
        "indice_abrasion_planimetria.png": None,
        "indice_abrasion_hist.png": None,
        
        "material_planimetria.png": None,
        
        "seccion_planimetria.png": None,
        
        "superficie_intervenccion_planimetria.png": None,
        "superficie_intervenccion_bar_chart.png": None,
        
        "fases_planimetria.png": None,
        
        "descarga_planimetria.png": None,
        
        "metodo_constructivo.png": None,
    }


    # areas-------------------------------------------------------------------------------------------------------------------------------------------------------------------
    try:
        path_out_area = os.path.dirname(area_shape)
        name_out_area = os.path.basename(area_shape).split(".")[0] + "_outfall_diss.gpkg"
        full_output_path_area = os.path.join(path_out_area, name_out_area)
        gpd_df_area = gpd.read_file(full_output_path_area, engine="pyogrio")
        gpd_df_area["area"] = gpd_df_area.geometry.area / 10000

        new_name = get_files_and_new_filename(path_out_figuras, "area_aporte")
        dict_path_figuras["area_aporte_planimetria.png"] = path_out_figuras + os.path.sep + new_name + "_planimetria.png"
        plot_areas(
            gpd_df_area,
            "outfall",
            out_dir=path_out_figuras,
            name=new_name,
            image_path=image_path,
        )

    except Exception as e:
        print("error Areas: ", e)

    try:
        name_out_area = os.path.basename(area_shape).split(".")[0] + "_outfall.gpkg"
        full_output_path_area = os.path.join(path_out_area, name_out_area)
        gpd_df_area = gpd.read_file(full_output_path_area, engine="pyogrio")
        gpd_df_area["area"] = gpd_df_area.geometry.area / 10000

        new_name = get_files_and_new_filename(path_out_figuras, "area_curve_number")
        dict_path_figuras["area_curve_number_planimetria.png"] = path_out_figuras + os.path.sep + new_name + "_planimetria.png"
        plot_areas_variables(
            gpd_df_area,
            "Numero de Curva",
            variable="CN",
            graduated=False,
            out_dir=path_out_figuras,
            name=new_name,
            image_path=image_path,
        )
    except:
        pass

    try:
        new_name = get_files_and_new_filename(path_out_figuras, "area_ramal")
        dict_path_figuras["area_ramal_planimetria.png"] = path_out_figuras + os.path.sep + new_name + "_planimetria.png"
        
        plot_areas_variables(
            gpd_df_area, "Ramal", variable="id_pozo", graduated=False, out_dir=path_out_figuras, name=new_name, image_path=image_path, dissolve=True, label_area=True
        )
    except Exception as e:
        pass

    try:
        new_name = get_files_and_new_filename(path_out_figuras, "area_slope")
        dict_path_figuras["area_slope_planimetria.png"] = path_out_figuras + os.path.sep + new_name + "_planimetria.png"
        plot_areas_variables(
            gpd_df_area,
            "Pendiente [%]",
            variable="slope",
            graduated=True,
            out_dir=path_out_figuras,
            name=new_name,
            image_path=image_path,
        )
    except:
        pass

    try:
        new_name = get_files_and_new_filename(path_out_figuras, "area_imperv")
        dict_path_figuras["area_imperv_planimetria.png"] = path_out_figuras + os.path.sep + new_name + "_planimetria.png"
        
        CN_BASE = 60
        # Calcular la impermeabilización
        gpd_df_area['%imperv'] = ((gpd_df_area['CN'] - CN_BASE) / (100 - CN_BASE)).clip(lower=0)
        
        # Asegurar que los valores estén entre 0 y 1
        gpd_df_area['%imperv'] = gpd_df_area['%imperv'].clip(lower=0.1, upper=1)
        
        plot_areas_variables(
            gpd_df_area, "Impermeabilizacion [%]", variable="%imperv", graduated=False, out_dir=path_out_figuras, name=new_name, image_path=image_path, dissolve=True
        )
    except Exception as e:
        print('%imperv')
        print(e)
        

    try:
        new_name = get_files_and_new_filename(path_out_figuras, "area_densidad")
        dict_path_figuras["area_densidad_planimetria.png"] = path_out_figuras + os.path.sep + new_name + "_planimetria.png"
        plot_areas_variables(gpd_df_area, "Densidad [Hab/Ha]", variable="densidad", graduated=True, out_dir=path_out_figuras, name=new_name, image_path=image_path, dissolve=True)
    except:
        pass

    # estado-------------------------------------------------------------------------------------------------------------------------------------------------------------------
    try:
        new_name = get_files_and_new_filename(path_out_figuras, "estado")
        dict_path_figuras["estado_planimetria.png"] = path_out_figuras + os.path.sep + new_name + "_planimetria.png"
        dpi, width_in_inches, height_in_inches = plot_variables(
            gpd_df,
            "Estado",
            "estado",
            "",
            out_dir=path_out_figuras,
            categorica=True,
            name=new_name,
            image_path=image_path,
        )
        print("estado")
    except Exception as e:
        print("error Estado: ", e)

    # diametros
    try:
        estado_filtro = gpd_df["Estado"] == "nuevo"
        adaptive_bins = adaptive_binning(seccion_str2float(gpd_df["D_ext"][estado_filtro]), threshold=0.01)
        # Create a pandas Interval Index
        intervals = pd.IntervalIndex.from_breaks(adaptive_bins, closed="left")
        diameter_break_point = [round(_.right, 2) for _ in intervals]

        # diametros
        if len(diameter_break_point) < 10:
            categorica_val = True
            diameter_break_point = False
        else:
            categorica_val = False

        new_name = get_files_and_new_filename(path_out_figuras, "diametro")
        dict_path_figuras["diametro_planimetria.png"] = path_out_figuras + os.path.sep + new_name + "_planimetria.png"
        plot_variables(
            gpd_df,
            "D_ext",
            "diametro",
            "m",
            out_dir=path_out_figuras,
            categorica=categorica_val,
            name=new_name,
            image_path=image_path,
            make_existing_new_color=make_existing_new_color,
            hide_existente=False,
            breakpoints=diameter_break_point,
        )

        new_name = get_files_and_new_filename(path_out_figuras, "diametro")
        dict_path_figuras["diametro_bar_chart.png"] = path_out_figuras + os.path.sep + new_name + "_bar_chart.png"
        if size_ > 0:
            filtro_nuevo = gpd_df["Estado"].isin(["nuevo"])
            categorical_variables_bar(
                gpd_df[filtro_nuevo],
                "D_ext",
                "diametro",
                "m",
                out_dir=path_out_figuras,
                name=new_name,
                make_it_graduated=True,
            )
        else:
            categorical_variables_bar(
                gpd_df,
                "D_ext",
                "diametro",
                "m",
                out_dir=path_out_figuras,
                name=new_name,
                make_it_graduated=True,
            )

        print("diametro")
    except Exception as e:
        print("error D_ext: ", e)

    # velocidad
    try:
        new_name = get_files_and_new_filename(path_out_figuras, "velocidad")
        dict_path_figuras["velocidad_planimetria.png"] = path_out_figuras + os.path.sep + new_name + "_planimetria.png"
        v_filtro = gpd_df["v"][indice].to_numpy() > 0
        plot_variables(
            gpd_df,
            "v",
            "velocidad",
            "m/s",
            out_dir=path_out_figuras,
            name=new_name,
            cut_extreme_values=True,
            breakpoints=[0, 2, 3.5, 5.5, 8, 15],
            image_path=image_path,
        )

        new_name = get_files_and_new_filename(path_out_figuras, "velocidad")
        dict_path_figuras["velocidad_hist.png"] = path_out_figuras + os.path.sep + new_name + "_hist.png"
        hist(
            gpd_df["v"][indice].to_numpy()[v_filtro],
            "velocidad",
            "m/s",
            out_dir=path_out_figuras,
            ax=None,
            fig=None,
            name=new_name,
        )

        print("velocidad")
    except Exception as e:
        print("error velocidad: ", e)

    # calado
    try:
        new_name = get_files_and_new_filename(path_out_figuras, "calado")
        dict_path_figuras["calado_planimetria.png"] = path_out_figuras + os.path.sep + new_name + "_planimetria.png"
        plot_variables(
            gpd_df,
            "h/D",
            "calado",
            "h/D",
            out_dir=path_out_figuras,
            name=new_name,
            breakpoints=[0, 0.65, 0.83, 1],
            image_path=image_path,
        )

        new_name = get_files_and_new_filename(path_out_figuras, "calado")
        dict_path_figuras["calado_hist.png"] = path_out_figuras + os.path.sep + new_name + "_hist.png"
        h_D_filtro = gpd_df["h/D"][indice].to_numpy() > 0
        hist(
            gpd_df["h/D"][indice].dropna().to_numpy()[h_D_filtro],
            "Calado",
            "%",
            out_dir=path_out_figuras,
            ax=None,
            fig=None,
            name=new_name,
        )
    except Exception as e:
        print("error calado: ", e)

    # profunidad media
    try:
        breakpoints = [0, 1.4, 2.2, 3, 4, 5.5, 7, gpd_df["HF"].max()]
        max_value_profundidad = np.round(gpd_df["HF"].max(), 1)
        last_item = np.where(breakpoints <= max_value_profundidad)[0][-1]
        breakpoints = breakpoints[:last_item] + [max_value_profundidad]

        new_name = get_files_and_new_filename(path_out_figuras, "profundidad_media")
        dict_path_figuras["profundidad_media_planimetria.png"] = path_out_figuras + os.path.sep + new_name + "_planimetria.png"
        plot_variables(
            gpd_df,
            "HI",
            "profundidad media",
            "m ",
            out_dir=path_out_figuras,
            name=new_name,
            breakpoints=breakpoints,
            image_path=image_path,
            make_existing_new_color=make_existing_new_color,
            hide_existente=False,
        )

        new_name = get_files_and_new_filename(path_out_figuras, "profundidad_media")
        dict_path_figuras["profundidad_media_hist.png"] = path_out_figuras + os.path.sep + new_name + "_hist.png"
        if size_ > 0:
            filtro_nuevo = gpd_df["Estado"].isin(["nuevo"])
            hist(
                gpd_df["HI"][filtro_nuevo].to_numpy(),
                "profundidad media",
                "m",
                out_dir=path_out_figuras,
                ax=None,
                fig=None,
                name=new_name,
            )
        else:
            hist(
                gpd_df["HI"][indice].to_numpy(),
                "profundidad media",
                "m",
                out_dir=path_out_figuras,
                ax=None,
                fig=None,
                name=new_name,
            )

        print("profundidad")
    except Exception as e:
        print("error profunidad: ", e)

    # caudal
    try:
        new_name = get_files_and_new_filename(path_out_figuras, "caudal")
        dict_path_figuras["caudal_planimetria.png"] = path_out_figuras + os.path.sep + new_name + "_planimetria.png"
        plot_variables(gpd_df, "q_accu", "caudal", "L/s", out_dir=path_out_figuras, name=new_name, image_path=image_path, hide_existente=False)

        print("caudal")
    except Exception as e:
        print("error caudal: ", e)

    try:
        # pendiente
        new_name = get_files_and_new_filename(path_out_figuras, "pendiente")
        dict_path_figuras["pendiente_planimetria.png"] = path_out_figuras + os.path.sep + new_name + "_planimetria.png"
        plot_variables(
            gpd_df,
            "S",
            "pendiente",
            "m/m ",
            out_dir=path_out_figuras,
            name=new_name,
            cut_extreme_values=True,
            image_path=image_path,
        )

        new_name = get_files_and_new_filename(path_out_figuras, "pendiente")
        dict_path_figuras["pendiente_hist.png"] = path_out_figuras + os.path.sep + new_name + "_hist.png"
        hist(
            gpd_df["S"][indice].to_numpy() * 100,
            "pendiente",
            "%",
            out_dir=path_out_figuras,
            ax=None,
            fig=None,
            name=new_name,
        )

        print("pendiente")
    except:
        pass

    try:
        gpd_df["indice_abrasion"] = np.where(
            gpd_df["indice_abrasion"].to_numpy() > 100,
            100,
            gpd_df["indice_abrasion"].to_numpy(),
        )
        # indice de desgaste
        new_name = get_files_and_new_filename(path_out_figuras, "indice_abrasion")
        dict_path_figuras["indice_abrasion_planimetria.png"] = path_out_figuras + os.path.sep + new_name + "_planimetria.png"
        plot_variables(
            gpd_df,
            "indice_abrasion",
            "indice de abrasion",
            "",
            out_dir=path_out_figuras,
            name=new_name,
            image_path=image_path,
        )

        new_name = get_files_and_new_filename(path_out_figuras, "indice_abrasion")
        dict_path_figuras["indice_abrasion_hist.png"] = path_out_figuras + os.path.sep + new_name + "_hist.png"
        hist(
            gpd_df["indice_abrasion"][indice].to_numpy(),
            "indice de abrasion",
            "",
            out_dir=path_out_figuras,
            ax=None,
            fig=None,
            name=new_name,
        )

        print("indice_abrasion")
    except:
        pass

    try:
        # material y seccion
        new_name = get_files_and_new_filename(path_out_figuras, "material")
        dict_path_figuras["material_planimetria.png"] = path_out_figuras + os.path.sep + new_name + "_planimetria.png"
        plot_variables(
            gpd_df,
            "Material",
            "material",
            "",
            categorica=True,
            out_dir=path_out_figuras,
            name=new_name,
            image_path=image_path,
            make_existing_new_color=make_existing_new_color,
            hide_existente=False,
        )

        new_name = get_files_and_new_filename(path_out_figuras, "seccion")
        dict_path_figuras["seccion_planimetria.png"] = path_out_figuras + os.path.sep + new_name + "_planimetria.png"
        plot_variables(
            gpd_df,
            "Seccion",
            "seccion",
            "",
            categorica=True,
            out_dir=path_out_figuras,
            name=new_name,
            image_path=image_path,
            make_existing_new_color=make_existing_new_color,
            hide_existente=False,
        )

        print("material_seccion")
    except Exception as e:
        print("error material seccion: ", e)

    try:
        # superficie
        new_name = get_files_and_new_filename(path_out_figuras, "superficie_intervenccion")
        dict_path_figuras["superficie_intervenccion_planimetria.png"] = path_out_figuras + os.path.sep + new_name + "_planimetria.png"
        plot_variables(
            gpd_df,
            "sup_road",
            "superficie",
            "",
            out_dir=path_out_figuras,
            categorica=True,
            name=new_name,
            image_path=image_path,
            make_existing_new_color=make_existing_new_color,
            hide_existente=False,
        )

        new_name = get_files_and_new_filename(path_out_figuras, "superficie_intervenccion")
        dict_path_figuras["superficie_intervenccion_bar_chart.png"] = path_out_figuras + os.path.sep + new_name + "_bar_chart.png"
        categorical_variables_bar(
            gpd_df,
            "sup_road",
            "superficie",
            "m",
            out_dir=path_out_figuras,
            existente=False,
            name=new_name,
        )

        print("superficie")
    except:
        print("error: superficie")

    try:
        # Fase
        new_name = get_files_and_new_filename(path_out_figuras, "fases")
        dict_path_figuras["fases_planimetria.png"] = path_out_figuras + os.path.sep + new_name + "_planimetria.png"
        plot_variables(
            gpd_df,
            "Fase",
            "Fase",
            "",
            out_dir=path_out_figuras,
            categorica=True,
            name=new_name,
            image_path=image_path,
            make_existing_new_color=make_existing_new_color,
            hide_existente=False,
        )

        print("fase")
    except:
        pass

    try:
        # descarga
        new_name = get_files_and_new_filename(path_out_figuras, "descarga")
        dict_path_figuras["descarga_planimetria.png"] = path_out_figuras + os.path.sep + new_name + "_planimetria.png"
        dpi, width_in_inches, height_in_inches = plot_variables(gpd_df, "outfall", "descarga", "", out_dir=path_out_figuras, categorica=True, name=new_name, image_path=image_path)
        print("fase")
    except Exception as e:
        print(e)

    try:
        # metodo constructivo
        new_name = get_files_and_new_filename(path_out_figuras, "metodo_constructivo")
        dict_path_figuras["metodo_constructivo_planimetria.png"] = path_out_figuras + os.path.sep + new_name + "_planimetria.png"
        dpi, width_in_inches, height_in_inches = plot_variables(
            gpd_df,
            "metodo_constructivo",
            "metodo constructivo",
            "",
            out_dir=path_out_figuras,
            categorica=True,
            name=new_name,
            image_path=image_path,
            make_existing_new_color=make_existing_new_color,
            hide_existente=False,
        )

        print("metodo_constructivo")
    except Exception as e:
        print(e, new_name)

    try:
        # mejoramiento suelo
        new_name = get_files_and_new_filename(path_out_figuras, "mejoramiento")
        gpd_df["mejoramiento_suelo"] = gpd_df.apply(categorize_suelo, axis=1)
        dpi, width_in_inches, height_in_inches = plot_variables(
            gpd_df,
            "mejoramiento_suelo",
            "mejoramiento_suelo",
            "",
            out_dir=path_out_figuras,
            categorica=True,
            name=new_name,
            image_path=image_path,
            make_existing_new_color=make_existing_new_color,
            hide_existente=False,
        )

        print("mejoramiento suelo")
    except Exception as e:
        print(e, new_name)

    try:
        # entibado
        new_name = get_files_and_new_filename(path_out_figuras, "entibado")
        gpd_df["entibado"] = gpd_df.apply(categorize_entibado, axis=1)
        dpi, width_in_inches, height_in_inches = plot_variables(
            gpd_df,
            "entibado",
            "entibado",
            "",
            out_dir=path_out_figuras,
            categorica=True,
            name=new_name,
            image_path=image_path,
            make_existing_new_color=make_existing_new_color,
            hide_existente=False,
        )

        print("entibado")
    except Exception as e:
        print(e, new_name)

    try:
        new_name = get_files_and_new_filename(path_out_figuras, "cronograma")
        # cronograma
        new_column = "RamalOutFall"
        group_column = "Fase"

        min_number_ramales = 10
        rcna = RamalesCronogramaNetworkAnalysis()
        gpd_df = rcna.get_ramal_outfall(gpd_df, new_column, group_column, min_number_ramales)

        path_out = path_out_figuras + os.path.sep + group_column
        if not os.path.exists(path_out):
            os.makedirs(path_out)
        image_path_lidar = r"C:\Users\chelo\OneDrive\SANTA_ISABEL\image_ortofoto_SIRES_DMQ.tif"

        grupos = gpd_df.groupby(group_column)
        for pos, grupo in grupos:
            name_ = group_column + grupo[group_column].unique()[0]
            new_name = get_files_and_new_filename(path_out_figuras, name_)

            dpi, width_in_inches, height_in_inches = plot_variables(
                grupo,
                new_column,
                name_,
                "",
                out_dir=path_out,
                categorica=True,
                name=new_name,
                image_path=image_path_lidar,
                make_existing_new_color=make_existing_new_color,
            )

        # fases
        # Crear instancia
        frentes = FrentesTrabajoAlcantarillado(gpd_df)
        # Generar y guardar todos los resultados
        frentes.guardar_resultados(output_dir=path_out_tablas)

        print("cronograma")
    except Exception as e:
        print(e, new_name)

    # try:
    #     # flood losses
    #     path_out = "PROYECTO_" + project_name + os.path.sep + "04_RESULTADOS" + os.path.sep + "01_TABLAS"
    #     df = gpd.read_file(path_out + os.path.sep + "00_flood_losses.gpkg", engine="pyogrio")
    #
    #     # clip data to area
    #     # mask = r'D:\Users\chelo\OneDrive\PROYECTOS\05_EPMAPS_SOLANDA_GRUPO1\01_EJECUCION\03_PROYECTO\ciudadela.gpkg'
    #     # df_mask = gpd.read_file(mask, engine='pyogrio')
    #     # df = gpd.clip(df, df_mask)
    #
    #     new_name = get_files_and_new_filename(path_out_figuras, "perdida_volumen")
    #     plot_flodd_losses(df, colunma="vol", image_path=image_path, mask=mask, lines=path_in, name=new_name, out_dir=path_out_figuras, vol_min=30, )
    # except Exception as e:
    #     print("flood losses: ", e)
    #
    # try:
    #     new_path = "PROYECTO_" + project_name + os.path.sep + "00_GIS" + os.path.sep + "02_OUT" + os.path.sep + "01_RAMALES" + os.path.sep + project_name + "_mod" + ".gpkg"
    #     gpd_df.reset_index(drop=True, inplace=True)
    #     gpd_df.to_file(new_path)
    #
    # except Exception as e:
    #     print(e)

    return dpi, width_in_inches, height_in_inches, dict_path_figuras


def draw_circle(path_out_figuras):
    import matplotlib.pyplot as plt
    import numpy as np
    import matplotlib

    matplotlib.rcParams.update({"font.size": 35})

    # Set up the figure and axes
    fig, ax = plt.subplots(figsize=(10, 10))

    # Set the radius of the circular open channel
    r = 2

    # Calculate the x and y coordinates for the points on the circumference
    theta = np.linspace(0, 2 * np.pi, 100)
    x = r * np.cos(theta)
    y = r * np.sin(theta)

    # Draw the circular open channel
    ax.plot(x, y, "k-", linewidth=3.0)

    # Calculate the x and y coordinates for the line from the center to the wall
    x1 = 0
    y1 = 0
    x2_r = r * np.cos(np.pi / -4)
    y2 = r * np.sin(np.pi / -4)

    # Draw the line from the center to the wall
    ax.plot([x1, x2_r], [y1, y2], linewidth=2, linestyle="--", color="gray", dashes=(3, 5))

    # Calculate the x and y coordinates for the line from the center to the wall
    x1 = 0
    y1 = 0
    x2_i = r * np.cos(5 * np.pi / 4)
    y2 = r * np.sin(5 * np.pi / 4)

    # Draw the line from the center to the wall
    ax.plot([x1, x2_i], [y1, y2], linewidth=2, linestyle="--", color="gray", dashes=(3, 5))

    theta1 = 5 * np.pi / 4
    theta2 = 7 * np.pi / 4
    theta = np.linspace(theta1, theta2, 100)
    x = r * np.cos(theta)
    y = r * np.sin(theta)

    # Draw the circular arc
    ax.plot(x, y, "k-", linewidth=2)

    # anotate radius
    ax.text(1.9, -1, "r", rotation=90)
    ax.annotate(
        "",
        xy=(2.2, -2),
        xytext=(2.2, 0),
        textcoords=ax.transData,
        arrowprops=dict(arrowstyle="<->"),
    )
    ax.annotate(
        "",
        xy=(2.2, -2),
        xytext=(2.2, 0),
        textcoords=ax.transData,
        arrowprops=dict(arrowstyle="|-|"),
    )

    # anotate radius
    ax.text(0, 2.3, "D", rotation=0)
    ax.annotate(
        "",
        xy=(2, 2.2),
        xytext=(-2, 2.2),
        textcoords=ax.transData,
        arrowprops=dict(arrowstyle="<->"),
    )
    ax.annotate(
        "",
        xy=(2, 2.2),
        xytext=(-2, 2.2),
        textcoords=ax.transData,
        arrowprops=dict(arrowstyle="|-|"),
    )

    # anotate h
    ax.text(-2.5, (y2 - 2) / 2, "h", rotation=90)
    ax.annotate(
        "",
        xy=(-2.2, -2),
        xytext=(-2.2, y2),
        textcoords=ax.transData,
        arrowprops=dict(arrowstyle="<->"),
    )
    ax.annotate(
        "",
        xy=(-2.2, -2),
        xytext=(-2.2, y2),
        textcoords=ax.transData,
        arrowprops=dict(arrowstyle="|-|"),
    )

    # anotate b
    ax.text(0, -2.5, "b", rotation=0)
    ax.annotate(
        "",
        xy=(x2_i, -2.2),
        xytext=(x2_r, -2.2),
        textcoords=ax.transData,
        arrowprops=dict(arrowstyle="<->"),
    )
    ax.annotate(
        "",
        xy=(x2_i, -2.2),
        xytext=(x2_r, -2.2),
        textcoords=ax.transData,
        arrowprops=dict(arrowstyle="|-|"),
    )

    # anotate h
    ax.text(0, -0.25, r"$\theta^{\circ}$", ha="center", va="center")

    # Set the aspect ratio of the plot to 1
    ax.set_aspect(1)

    # Remove the axis lines and labels
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # Turn off the axis lines
    plt.axis("off")

    # # Show the plot
    plt.tight_layout()
    fig.savefig(path_out_figuras + os.path.sep + "circular_pipe.png", format="png", bbox_inches="tight")


def draw_rectnagle(path_out_figuras):
    import matplotlib.pyplot as plt
    import matplotlib

    matplotlib.rcParams.update({"font.size": 35})

    # Set up the figure and axes
    fig, ax = plt.subplots(figsize=(10, 10))

    x = [-1, -1, 1, 1]
    y = [0, -2, -2, 0]

    # Draw the rectangular open channel
    ax.plot(x, y, "k-", linewidth=3.0)

    x = [-1, 1]
    y = [-0.5, -0.5]
    # Draw the rectangular open channel
    ax.plot(x, y, linewidth=1, color="k", linestyle="--")

    # anotate radius
    ax.text(1.3, -1, "H", rotation=90)
    ax.annotate(
        "",
        xy=(1.2, -2),
        xytext=(1.2, 0),
        textcoords=ax.transData,
        arrowprops=dict(arrowstyle="<->"),
    )
    ax.annotate(
        "",
        xy=(1.2, -2),
        xytext=(1.2, 0),
        textcoords=ax.transData,
        arrowprops=dict(arrowstyle="|-|"),
    )

    # anotate radius
    ax.text(0, -2.4, "B", rotation=0)
    ax.annotate(
        "",
        xy=(-1, -2.2),
        xytext=(1, -2.2),
        textcoords=ax.transData,
        arrowprops=dict(arrowstyle="<->"),
    )
    ax.annotate(
        "",
        xy=(-1, -2.2),
        xytext=(1, -2.2),
        textcoords=ax.transData,
        arrowprops=dict(arrowstyle="|-|"),
    )

    # anotate radius
    ax.text(-1.4, -1.5, "h", rotation=90)
    ax.annotate(
        "",
        xy=(-1.2, -2),
        xytext=(-1.2, -0.5),
        textcoords=ax.transData,
        arrowprops=dict(arrowstyle="<->"),
    )
    ax.annotate(
        "",
        xy=(-1.2, -2),
        xytext=(-1.2, -0.5),
        textcoords=ax.transData,
        arrowprops=dict(arrowstyle="|-|"),
    )

    # Set the aspect ratio of the plot to 1
    ax.set_aspect(1)

    # Set the aspect ratio of the plot to 1
    ax.set_aspect(1)

    # Remove the axis lines and labels
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    ax.set_ylim(-2.5, 0.0)
    ax.set_xlim(-1.5, 1.5)

    # Turn off the axis lines
    plt.axis("off")

    # Show the plot
    # plt.show()
    plt.tight_layout()
    fig.savefig(path_out_figuras + os.path.sep + "rectangular_pipe.png", format="png", bbox_inches="tight")


def color_velocidad(val, v_max, v_min):
    import pandas as pd
    import numpy as np

    # Debugging
    print("val length:", len(val), "val index:", val.index)
    print("v_max type:", type(v_max), "v_max length:", len(v_max) if hasattr(v_max, '__len__') else "scalar", "v_max:", v_max)
    print("v_min type:", type(v_min), "v_min length:", len(v_min) if hasattr(v_min, '__len__') else "scalar", "v_min:", v_min)

    if not isinstance(val, pd.Series):
        raise ValueError("val must be a Pandas Series")

    # Handle v_max
    if isinstance(v_max, (pd.Series, pd.DataFrame)):
        v_max = v_max.reindex(val.index)  # Align with val's index
        if v_max.isna().any():
            raise ValueError("v_max contains NaN after reindexing")
    elif isinstance(v_max, (list, np.ndarray)):
        if len(v_max) != len(val):
            raise ValueError(f"v_max length ({len(v_max)}) does not match val length ({len(val)})")
        v_max = pd.Series(v_max, index=val.index)
    else:  # Scalar
        v_max = pd.Series(v_max, index=val.index)

    # Handle v_min
    if isinstance(v_min, (pd.Series, pd.DataFrame)):
        v_min = v_min.reindex(val.index)  # Align with val's index
        if v_min.isna().any():
            raise ValueError("v_min contains NaN after reindexing")
    elif isinstance(v_min, (list, np.ndarray)):
        if len(v_min) != len(val):
            raise ValueError(f"v_min length ({len(v_min)}) does not match val length ({len(val)})")
        v_min = pd.Series(v_min, index=val.index)
    else:  # Scalar
        v_min = pd.Series(v_min, index=val.index)

    # Create result Series
    result = pd.Series("", index=val.index, dtype=str)
    result[val >= v_max] = "color: red"
    result[val <= v_min] = "color: blue"
    result[val.isna()] = ""

    return result.sort_index()

def color_calado(val, max_h_D):
    # check for h/D
    hmax_s = (val >= max_h_D).where(np.invert(val >= max_h_D), "color: red")[val >= max_h_D]
    hnot_index = list(set(val.index).difference(set(hmax_s.index)))
    hnot_s = pd.Series([""] * len(hnot_index), index=hnot_index)
    return pd.concat([hmax_s, hnot_s]).sort_index()


def velocidad_minima(D, n, ang_v, tau, rho, g, vmin=0.6):
    v = (
        ((0.397 * D ** (2 / 3)) / n)
        * ((1 - 360.0 * np.sin(np.radians(ang_v)) / (2 * np.pi * ang_v)) ** (2.0 / 3.0))
        * (tau / (rho * g * (D / 4) * (1 - 360.0 * np.sin(np.radians(ang_v)) / (2 * np.pi * ang_v))))
    )
    return np.where(v < vmin, vmin, v)



_OLLAMA_RUNNING = False           # ← guard global
OLLAMA_PORT     = 11434
OLLAMA_URL      = f"http://127.0.0.1:{OLLAMA_PORT}"


class OllamaImageDescriber:
    def __init__(self, model_name: str = "qwen2.5vl:latest"):
        global _OLLAMA_RUNNING
        self.server_process: Optional[subprocess.Popen] = None
        self.api_url = OLLAMA_URL
        self.model_name = model_name
    
        # configurar GPU antes de todo
        self._ensure_gpu_env()
        self.gpu_status()
        
        # Luego verificar/iniciar servidor
        if not _OLLAMA_RUNNING and not self._server_ready():
            self._start_ollama_server()
            _OLLAMA_RUNNING = True
        
        
        # ----------------------------------------------------
   
    @staticmethod
    def _ensure_gpu_env(dev="0", keep="1h"):
        os.environ.setdefault("OLLAMA_FLASH_ATTENTION", "1")
        os.environ.setdefault("OLLAMA_KEEP_ALIVE", keep)
        os.environ.setdefault("CUDA_VISIBLE_DEVICES", dev)
        os.environ.setdefault("OLLAMA_NUM_GPU", "1")
        
    def gpu_status(self):
        import torch
        if torch.cuda.is_available():
            gpu_device = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)
            print(f"GPU disponible: {gpu_device} ({gpu_memory:.2f} GB)")
        else:
            print("GPU no disponible.")


    def _ensure_ollama_running(self):
        """
        Ensure Ollama is installed, downloaded, and running. Start the server if necessary.
        """
        # First check if server is already accessible
        if self._server_ready():
            print("Ollama server is already running and accessible.")
            return

        # If not accessible, try to start it
        try:
            # Try to list models to see if ollama client works
            ollama.list()
            print("Ollama client is available but server might not be running.")
        except Exception as e:
            print(f"Ollama client not accessible: {str(e)}. Attempting to install...")
            self._install_ollama_if_needed()

        # Try to start the server
        print("Starting Ollama server...")
        self._start_ollama_server()

    def _install_ollama_if_needed(self):
        """Install Ollama if it's not found."""
        ollama_binary = self._get_ollama_binary_path()
        if os.path.exists(ollama_binary):
            print("Ollama binary found.")
            return

        print("Ollama binary not found. Downloading and installing...")
        self._download_and_install_ollama()

    def _start_ollama_server_old(self):
        """Start the Ollama server."""
        # Kill any existing ollama processes first
        self._kill_existing_ollama_processes()
        time.sleep(2)  # Give time for processes to fully terminate

        ollama_binary = self._get_ollama_binary_path()
        
        try:
            if sys.platform.startswith("win"):
                # On Windows, use serve command
                cmd = [ollama_binary, "serve"]
                startupinfo = subprocess.STARTUPINFO()
                startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
                self.server_process = subprocess.Popen(
                    cmd,
                    startupinfo=startupinfo,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    creationflags=subprocess.CREATE_NEW_PROCESS_GROUP
                )
            else:
                # On Unix-like systems
                cmd = [ollama_binary, "serve"]
                self.server_process = subprocess.Popen(
                    cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE
                )

            # Wait for server to be ready
            print("Waiting for Ollama server to start...")
            for attempt in range(30):  # Reduced from 60 to 30 seconds
                if self._server_ready():
                    print(f"Ollama server started successfully on {self.api_url}")
                    time.sleep(2)  # Brief stabilization period
                    return
                time.sleep(1)
                print(f"Attempt {attempt + 1}/30...")

            # If we get here, server failed to start
            stderr_output = ""
            if self.server_process and self.server_process.stderr:
                try:
                    stderr_output = self.server_process.stderr.read().decode("utf-8", errors="replace")
                except:
                    stderr_output = "Could not read stderr"
            
            self._stop_server()
            raise RuntimeError(f"Ollama server failed to start within 30 seconds. Error: {stderr_output}")

        except Exception as e:
            self._stop_server()
            raise RuntimeError(f"Failed to start Ollama server: {str(e)}")

    def _start_ollama_server(self):
        """Start Ollama only if el puerto está libre."""
        # 4-a) ¿otro proceso ya está usando 11434?
        import socket
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        if sock.connect_ex(("127.0.0.1", OLLAMA_PORT)) == 0:
            print("Otro proceso Ollama ya escucha; no se lanza uno nuevo.")
            return
        sock.close()

        # 4-b) lanzar normalmente (sin _kill_existing_ollama_processes)
        ollama_binary = self._get_ollama_binary_path()
        cmd = [ollama_binary, "serve"]
        print(f"Iniciando Ollama GPU → {ollama_binary}")

        if sys.platform.startswith("win"):
            startupinfo = subprocess.STARTUPINFO()
            startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
            self.server_process = subprocess.Popen(
                cmd, startupinfo=startupinfo,
                stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT,
                creationflags=subprocess.CREATE_NEW_PROCESS_GROUP
            )
        else:
            self.server_process = subprocess.Popen(
                cmd, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT
            )

        # espera 15 s como máximo
        for _ in range(15):
            if self._server_ready():
                print(f"✓ Ollama listo en {self.api_url}")
                return
            time.sleep(1)
        raise RuntimeError("Ollama no respondió en 15 s")



    def _kill_existing_ollama_processes(self):
        """Kill any existing Ollama processes."""
        print("Checking for existing Ollama processes...")
        if sys.platform.startswith("win"):
            try:
                # Use tasklist to check for running processes
                result = subprocess.run(
                    ["tasklist", "/FI", "IMAGENAME eq ollama.exe"],
                    capture_output=True,
                    text=True
                )
                if "ollama.exe" in result.stdout:
                    print("Found existing Ollama processes. Terminating...")
                    subprocess.run(["taskkill", "/F", "/IM", "ollama.exe"], check=True)
                    print("Existing Ollama processes terminated.")
                else:
                    print("No existing Ollama processes found.")
            except subprocess.CalledProcessError as e:
                print(f"Warning: Could not terminate existing processes: {e}")
        else:
            try:
                result = subprocess.run(["pgrep", "-f", "ollama"], capture_output=True, text=True)
                pids = result.stdout.strip().split("\n")
                for pid in pids:
                    if pid.strip():
                        os.kill(int(pid), signal.SIGTERM)
                        time.sleep(0.5)
                print("Existing Ollama processes terminated.")
            except Exception as e:
                print(f"Warning: Could not terminate existing processes: {e}")

    def _get_ollama_binary_path(self) -> str:
        """Get the path to the Ollama binary."""
        if sys.platform.startswith("win"):
            # Check common installation paths
            possible_paths = [
                os.path.join(os.environ.get("LOCALAPPDATA", ""), "Programs", "Ollama", "ollama.exe"),
                os.path.join(os.environ.get("PROGRAMFILES", ""), "Ollama", "ollama.exe"),
                "ollama.exe"  # If in PATH
            ]
            for path in possible_paths:
                if os.path.exists(path) or path == "ollama.exe":
                    return path
            return possible_paths[0]  # Default to first option
        elif sys.platform.startswith("darwin"):
            return "/usr/local/bin/ollama"
        else:
            return "/usr/bin/ollama"

    def _get_ollama_binary_command(self) -> str:
        """Alias for backward compatibility."""
        return self._get_ollama_binary_path()

    def _download_and_install_ollama(self):
        """Download and install Ollama."""
        if sys.platform.startswith("win"):
            # For Windows, we'll use the installer approach
            url = "https://ollama.com/download/OllamaSetup.exe"
            download_path = os.path.join(os.environ.get("TEMP", ""), "OllamaSetup.exe")
            print(f"Downloading Ollama installer from {url}...")
            
            try:
                urllib.request.urlretrieve(url, download_path)
                print("Running Ollama installer...")
                # Run the installer silently
                subprocess.run([download_path, "/S"], check=True)
                print("Ollama installed successfully.")
                os.remove(download_path)
            except Exception as e:
                print(f"Failed to download/install Ollama: {e}")
                # Fallback: try to run from command line if available
                print("Trying alternative installation method...")
                try:
                    subprocess.run(["winget", "install", "Ollama.Ollama"], check=True)
                    print("Ollama installed via winget.")
                except:
                    raise RuntimeError(f"Failed to install Ollama: {str(e)}")
        else:
            print("Installing Ollama for macOS/Linux...")
            try:
                subprocess.run(
                    "curl -fsSL https://ollama.com/install.sh | sh",
                    shell=True,
                    check=True
                )
                print("Ollama installed successfully.")
            except Exception as e:
                raise RuntimeError(f"Failed to install Ollama: {str(e)}")

    def _server_ready(self) -> bool:
        """Check if the Ollama server is ready."""
        try:
            response = requests.get(self.api_url, timeout=2)
            return response.status_code == 200
        except (requests.ConnectionError, requests.Timeout):
            return False

    def _ensure_model_available(self, model_name: str):
        """
        Ensure the specified model is available in Ollama. Pull it if necessary.
        
        Args:
            model_name (str): The name of the model to check/pull.
        """
        try:
            if not self._server_ready():
                raise RuntimeError("Ollama server is not running. Cannot check model availability.")

            # print("Checking available models...")
            try:
                models_response = ollama.list()
                model_names = []
                
                if hasattr(models_response, 'models'):
                    model_names = [getattr(m, 'name', getattr(m, 'model', str(m))) for m in models_response.models]
                elif isinstance(models_response, dict) and 'models' in models_response:
                    model_names = [m.get('name', m.get('model', str(m))) for m in models_response['models']]
                
                # print(f"Available models: {model_names}")
                
                # Normalize model name - add :latest if no tag specified
                normalized_model = model_name if ':' in model_name else f"{model_name}:latest"
                
                # Check if model exists (exact match or with :latest)
                model_found = False
                for available_name in model_names:
                    if (available_name == model_name or
                        available_name == normalized_model or (available_name.startswith(f"{model_name}:") and model_name != available_name)):
                        model_found = True
                        break
                
                if not model_found:
                    print(f"Model {model_name} not found. Pulling it now...")
                    self._pull_model(model_name)

                    
            except Exception as e:
                print(f"Error checking models: {e}")
                print(f"Attempting to pull model {model_name} anyway...")
                self._pull_model(model_name)

        except Exception as e:
            raise RuntimeError(f"Error ensuring model availability: {str(e)}")

    def _test_model_compatibility(self, model_name: str) -> bool:
        """
        Test if a model is compatible with the current Ollama version.
        
        Args:
            model_name (str): Name of the model to test
            
        Returns:
            bool: True if compatible, False otherwise
        """
        try:
            # Try a simple generation to test compatibility
            test_response = ollama.generate(
                model=model_name,
                prompt="Hello",
                stream=False,
                options={"num_predict": 1}  # Limit to 1 token for quick test
            )
            return True
        except ollama.ResponseError as e:
            if "no longer compatible" in str(e) or "does not support generate" in str(e):
                return False
            # For other errors, assume compatible (might be temporary issues)
            return True
        except Exception:
            # For any other errors, assume compatible
            return True

    def _normalize_model_name(self, model_name: str) -> str:
        """
        Normalize model names to handle common variants.
        
        Args:
            model_name (str): Original model name
            
        Returns:
            str: Normalized model name
        """
        # Map common model name variants
        model_mappings = {
            "llama3": "llama3:latest",
            "llava": "llava:latest",
            "qwq": "qwq:32b",  # Based on your available models
            "gemma3": "gemma3:12b",  # Based on your available models
            'qwen': 'qwen2.5vl:latest',
            
        }
        
        return model_mappings.get(model_name, model_name)

    def _pull_model(self, model_name: str):
        """Pull a model using the ollama client."""
        try:
            print(f"Pulling model {model_name}...")
            
            # Use ollama.pull() if available
            try:
                ollama.pull(model_name)
                print(f"Successfully pulled model {model_name}")
                return
            except Exception as e:
                print(f"ollama.pull() failed: {e}")
                print("Trying command line approach...")

            # Fallback to command line
            ollama_binary = self._get_ollama_binary_path()
            cmd = [ollama_binary, "pull", model_name]
            
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                encoding="utf-8",
                errors="replace"
            )

            # Stream output
            while True:
                output = process.stdout.readline()
                if output == '' and process.poll() is not None:
                    break
                if output:
                    print(f"Pull progress: {output.strip()}")

            return_code = process.wait()
            if return_code != 0:
                stderr_output = process.stderr.read()
                raise RuntimeError(f"Failed to pull model {model_name}. Error: {stderr_output}")

            print(f"Successfully pulled model {model_name}")

        except Exception as e:
            raise RuntimeError(f"Failed to pull model {model_name}: {str(e)}")

    def describe_image(self, image_path: str,
                       model: str = None,
                       prompt: str = "Describe this image in detail.") -> str:
        model = self._normalize_model_name(model or self.model_name)
        self._ensure_model_available(model)
    
        if not self._server_ready():
            raise RuntimeError("Ollama server is not running.")

        response = ollama.generate(
            model=model,
            prompt=prompt,
            images=[image_path],          # ruta PNG/JPG
            stream=False,
            options={
                "gpu_layers": 20,         # ← ajusta a tu VRAM
                "keep_alive": "1h"
            }
        )
        
 
        return response["response"].strip()





    def describe_number_series(self, model: str = None, prompt: str = "Describe this series of numbers in detail:"):
        """
        Use an Ollama model to describe a series of numbers in natural language.

        Args:
            model (str): The Ollama model to use (defaults to self.model_name)
            prompt (str): The prompt to send to the model

        Returns:
            str: The model's description of the series
        """
        if model is None:
            model = self.model_name
        
        # Normalize model name
        model = self._normalize_model_name(model)
        self._ensure_model_available(model)

        try:
            if not self._server_ready():
                raise RuntimeError("Ollama server is not running.")

            print(f"Sending request to Ollama with model {model}")
            response = ollama.generate(model=model, prompt=prompt, stream=False)

            print("Received response from server")
            raw_response = response["response"]
            
            # Clean up response if it contains thinking tags
            if "</think>" in raw_response:
                clean_response = raw_response.split("</think>")
                if len(clean_response) > 1:
                    return clean_response[1].strip()
            
            return raw_response

        except ollama.ResponseError as e:
            if "does not support generate" in str(e):
                # Try with a different model that supports text generation
                fallback_models = ["qwen2.5vl:latest", "llama3:latest", "qwq:32b"]
                for fallback in fallback_models:
                    if fallback != model:  # Don't try the same model again
                        print(f"Model {model} doesn't support generation. Trying {fallback}...")
                        try:
                            self._ensure_model_available(fallback)
                            response = ollama.generate(model=fallback, prompt=prompt, stream=False)
                            raw_response = response["response"]
                            
                            # Clean up response if it contains thinking tags
                            if "</think>" in raw_response:
                                clean_response = raw_response.split("</think>")
                                if len(clean_response) > 1:
                                    return clean_response[1].strip()
                            
                            return raw_response
                        except Exception as fallback_e:
                            print(f"Fallback model {fallback} also failed: {fallback_e}")
                            continue
                
                raise RuntimeError(f"Model {model} does not support text generation and no suitable fallback found: {str(e)}")
            else:
                raise RuntimeError(f"Error describing series: {str(e)}")
        except Exception as e:
            raise RuntimeError(f"Error describing series: {str(e)}")

    def kill_ollama(self):
        """Kill all Ollama processes."""
        print("Stopping all Ollama processes...")
        self._kill_existing_ollama_processes()
        self._stop_server()

    def _stop_server(self):
        """Stop the server process started by this instance."""
        if self.server_process and self.server_process.poll() is None:
            try:
                self.server_process.terminate()
                self.server_process.wait(timeout=5)
                print("Ollama server stopped.")
            except subprocess.TimeoutExpired:
                self.server_process.kill()
                print("Ollama server forcefully killed.")
            except Exception as e:
                print(f"Error stopping server: {e}")
            finally:
                self.server_process = None

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self._stop_server()



class ImagePathMatcher:
    _PREFIX_RE = re.compile(r"^\d+_")       # 01_, 12_, etc.

    def __init__(self, images_directory: str):
        if not os.path.isdir(images_directory):
            raise NotADirectoryError(images_directory)
        self.images_directory = images_directory
        self._index = self._build_index()   # se crea una vez

    # ---------------- API pública ---------------- #
    def fill_paths(
        self,
        figuras: Dict[str, Optional[str]],
    ) -> Dict[str, Optional[str]]:
        resultado = figuras.copy()
        for clave, ruta in figuras.items():
            if ruta is not None:            # ya asignada
                continue
            base = self._normalize(clave)
            cand = self._index.get(base)
            if cand:
                resultado[clave] = os.path.abspath(
                    os.path.join(self.images_directory, cand[0])
                )
            else:
                resultado[clave] = ''
        return resultado

    # --------------- internos -------------------- #
    def _build_index(self) -> Dict[str, List[str]]:
        ix: Dict[str, List[str]] = {}
        for f in os.listdir(self.images_directory):
            if f.lower().endswith(".png"):
                ix.setdefault(self._normalize(f), []).append(f)
        return ix

    def _normalize(self, name: str) -> str:
        """Minúsculas, sin '.png', sin prefijo numérico."""
        name = name.lower().replace(".png", "")
        return self._PREFIX_RE.sub("", name)

def get_file_paths_latex(folder_path):
    """
    Scan a folder for Excel (.xlsx, .xls) and PNG (.png) files, creating a dictionary
    with full file names (including extensions) as keys and absolute paths as values.

    Args:
        folder_path (str): The path to the folder to scan.

    Returns:
        dict: Dictionary with full file names (including extensions) as keys and absolute paths as values.
    """
    # Initialize an empty dictionary to store file information
    file_dict = {}

    try:
        # Ensure the folder path exists
        if not os.path.exists(folder_path):
            raise FileNotFoundError(f"The folder '{folder_path}' does not exist.")

        # Supported file extensions
        extensions = (".png", ".xlsx", ".xls")

        # Walk through the directory (including subfolders)
        for root, dirs, files in os.walk(folder_path):
            for file in files:
                # Check if the file has a supported extension
                if file.lower().endswith(extensions):
                    # Get the absolute path of the file
                    absolute_path = os.path.abspath(os.path.join(root, file))
                    # Use the full file name (including extension) as the key
                    file_name = file  # Full name with extension
                    # Add to the dictionary
                    file_dict[file_name] = absolute_path

        return file_dict

    except Exception as e:
        print(f"Error: {e}")
        return {}


def generate_tabla_resumen_latex(
    gpd_df: gpd.GeoDataFrame,
    group_by_list: list[str],
    sum_by_column: str,
    caption: str,
    label: str,
    rows_per_page: int = 8,
    column_separator: str = "gap",
    porcentaje: bool = False,
) -> str:
    # Group the data
    estado_resumen = gpd_df.groupby(group_by_list)[sum_by_column].sum().reset_index()

    # Calculate percentage if enabled
    if porcentaje:
        estado_resumen["porcentaje"] = np.round((estado_resumen[sum_by_column] / estado_resumen[sum_by_column].sum()) * 100, 2)

    # Define display columns
    display_columns = group_by_list + [sum_by_column]
    if porcentaje:
        display_columns.append("porcentaje")

    num_rows = len(estado_resumen)

    # Generate column format
    num_display_cols = len(display_columns)
    base_col_format = "l" * len(group_by_list) + "r" * (num_display_cols - len(group_by_list))

    if num_rows <= rows_per_page:
        # Single-column layout
        print("Using single-column layout for resumen")
        print("Single-column layout fits on one page (using tabular)")
        # Generate the LaTeX table
        estado_resumen_latex = estado_resumen[display_columns].to_latex(
            longtable=False,
            caption=caption,
            label=label,
            index=False,
            position="H",
            float_format=lambda x: "{:.3f}".format(x) if isinstance(x, (float, int)) else x,
            escape=False,
            column_format=base_col_format,
        )
        # Ensure centering by wrapping in a centered environment
        latex_lines = estado_resumen_latex.splitlines()
        for i, line in enumerate(latex_lines):
            if line.strip().startswith(r"\begin{tabular}"):
                latex_lines.insert(i, r"\centering")
                break
        estado_resumen_latex = "\n".join(latex_lines)
    else:
        # Two-column layout (not relevant here since num_rows = 2)
        print("Using two-column layout for resumen")
        chunk_size = (num_rows + 1) // 2
        chunk1 = estado_resumen.iloc[:chunk_size].reset_index(drop=True)
        chunk2 = estado_resumen.iloc[chunk_size:].reset_index(drop=True)

        if len(chunk2) < len(chunk1):
            chunk2 = chunk2.reindex(range(len(chunk1)), fill_value=pd.NA)
        elif len(chunk1) < len(chunk2):
            chunk1 = chunk1.reindex(range(len(chunk2)), fill_value=pd.NA)

        combined_df = pd.concat([chunk1[display_columns], chunk2[display_columns]], axis=1)

        if column_separator == "gap":
            col_format = f"{base_col_format} @{{ \\hspace{{4em}} }} {base_col_format}"
        elif column_separator == "line":
            col_format = f"{base_col_format} @{{ \\hspace{{0.5em}} }} | @{{ \\hspace{{0.5em}} }} {base_col_format}"
        else:
            raise ValueError("column_separator must be 'gap' or 'line'")

        if chunk_size <= rows_per_page:
            print("Two-column layout fits on one page (using tabular)")
            estado_resumen_latex = combined_df.to_latex(
                longtable=False,
                caption=caption,
                label=label,
                index=False,
                position="H",
                float_format=lambda x: "{:.3f}".format(x) if isinstance(x, (float, int)) else x,
                escape=False,
                column_format=col_format,
            )
        else:
            print("Two-column layout too long (using longtable)")
            estado_resumen_latex = combined_df.to_latex(
                longtable=True,
                caption=caption,
                label=label,
                index=False,
                float_format=lambda x: "{:.3f}".format(x) if isinstance(x, (float, int)) else x,
                escape=False,
                column_format=col_format,
            )

    # Modify the header dynamically
    latex_lines = estado_resumen_latex.splitlines()
    for i, line in enumerate(latex_lines):
        if any(col in line for col in group_by_list):
            header = " & ".join(display_columns)
            if num_rows > rows_per_page:
                header = f"{header} & {header}"
            latex_lines[i] = f"{header} \\\\"
            break

    estado_resumen_latex = "\n".join(latex_lines)
    return estado_resumen_latex




def get_xyz_lidar(m_ramales_shp, path_lidar_in):
    # get shapefile
    mask = gpd.read_file(m_ramales_shp, engine="pyogrio")
    polygons = gpd.GeoDataFrame(mask.buffer(10), columns=["geometry"]).dissolve().explode()

    files = os.listdir(path_lidar_in)
    x_array = []
    y_array = []
    z_array = []
    for file_name in files:
        print(file_name)
        file = path_lidar_in + os.path.sep + file_name
        f = np.load(file, allow_pickle=True).T
        x, y, z = f
        del f
        for geom in polygons.geometry:
            polygon = np.array(geom.exterior.coords.xy).T
            if x.size > 0:
                # get points inside polygon
                points = np.array([x, y]).copy()
                index_in = nb_is_inside_parallel(points, polygon.copy())
                del points

                x_array.append(x[index_in])
                y_array.append(y[index_in])
                z_array.append(z[index_in])
                del index_in
            else:
                x_array.append(x)
                y_array.append(y)
                z_array.append(z)

        del x, y, z

    _x = np.concatenate(x_array)
    del x_array
    _y = np.concatenate(y_array)
    del y_array
    _z = np.concatenate(z_array)
    del z_array
    coords = np.array([_x, _y, _z]).T
    del _x, _y, _z

    path_out = m_ramales_shp.split(os.path.sep)[0] + os.path.sep + r"03_ELEVACION" + os.path.sep + "01_XYZ"
    if not os.path.exists(path_out):
        os.makedirs(path_out)
    np.save(path_out + os.path.sep + "join_clipped.npy", coords)
    del coords


"######################################################################################################################"
" "
"######################################################################################################################"


def adjust_slope_basin(row):
    if row["area"] < 1:
        slope_value = row["slope"]
        return slope_value if slope_value > 2 else 2
    else:
        slope_value = row["slope"]
        return slope_value if slope_value > 0.5 else 0.5


def get_area_from_shp(area_shape, m_ramales, id, path):
    """
    read a shapefile and use the table data to get the area of each ramal
    """

    df = gpd.read_file(area_shape, engine="pyogrio")
    df = df.explode()
    df["area"] = df.geometry.area / 10000.0
    df.index = df[id]

    if "densidad" not in list(df.columns):
        df["densidad"] = 0

    # try:
    #     # df['C'] = [cn_to_c_piecewise(_) for _ in df['CN']]
    #     df['slope'] = df.apply(adjust_slope_basin, axis=1)
    #     df['C'] = rossmiller_conversion(df['CN'], df['%imperv'] / 100, df['slope'] / 100).to_numpy()
    # except:
    #     print('error CN')

    pz_array = [m_ramales[_]["Pozo"] for _ in m_ramales.keys()]
    pz_array = np.concatenate(pz_array)

    data_dict = {}

    pz_in = df[id].to_numpy()

    for pz in pz_array:
        if pz in pz_in:
            _ = df.loc[pz]
            densidad = np.sum((_["densidad"] * _["area"]) / _["area"].sum())
            area = _["area"].sum()

            # C = np.sum(_['C'] * _['area']) / np.sum(_['area'])
            # densidad = np.sum(_['densidad'] * _['area']) / np.sum(_['area'])
            # area = np.sum(_['area'])
            # slope = float(_['slope'].max() / 100)

            # length = _['curblen'].max()
            # if isinstance(_['geometry'], gpd.GeoSeries):
            #     length = np.max([np.max(distance.cdist(np.array(__.exterior.coords), np.array(__.exterior.coords))) for __ in _['geometry']]) * 0.75
            # else:
            #     length = np.max(distance.cdist(np.array(_['geometry'].exterior.coords), np.array(_['geometry'].exterior.coords))) * 0.75

            data_dict[pz] = [pz, densidad, area]
    df_pz = pd.DataFrame(data_dict, index=["pz", "densidad", "area"]).T

    df_out = pd.DataFrame([], columns=["pz", "densidad", "area"], index=pz_array)
    df_out.update(df_pz)

    df_out.to_excel(path + os.path.sep + id + ".xlsx")
    print(path + os.path.sep + id + ".xlsx")
    return df_pz


def to_excell(m_ramales, path, name):
    if not os.path.exists(path):
        os.makedirs(path)

    writer = pd.ExcelWriter(
        path + os.path.sep + "respaldo_hidraulico_" + name + ".xlsx",
        engine="xlsxwriter",
    )
    df = pd.DataFrame()
    for _ in m_ramales.keys():
        df_temp = pd.DataFrame(m_ramales[_])
        df = pd.concat([df, df_temp])
        df_temp.drop([0], inplace=True)
        df_temp.to_excel(writer, sheet_name=str(_))

    writer._save()
    df.to_excel(
        path + os.path.sep + "m_ramales_" + name + ".xlsx",
        index=False,
        sheet_name="m_ramales_join",
    )


def get_conditions(pz_conditions, m_ramales):
    for _ in pz_conditions.keys():
        _ramal, _pos = _.split(".")

        for col in pz_conditions[_].keys():
            if col in ["D_min", "Seccion", "Material", "S_min"]:
                if _pos == "0":
                    m_ramales[_ramal][col][int(_pos)] = pz_conditions[_][col]
                    continue

                if int(_pos) < len(m_ramales[_ramal][col]):
                    try:
                        m_ramales[_ramal][col][int(_pos) + 1] = pz_conditions[_][col]
                    except:
                        m_ramales[_ramal][col][int(_pos)] = pz_conditions[_][col]

            else:
                try:
                    m_ramales[_ramal][col][int(_pos)] = pz_conditions[_][col]
                except:
                    print("error get_conditions: (ramal, pos)", _ramal, int(_pos))
    return m_ramales


def get_street_surface(m_ramales, sup_type, field_name, project_name):
    df_road_type = gpd.read_file(sup_type)
    geom_buffer = df_road_type.buffer(5)

    pz_list = []
    x_list = []
    y_list = []
    for _ramal in m_ramales.keys():
        pz_list.append(m_ramales[_ramal]["Pozo"])
        x_list.append(m_ramales[_ramal]["X"])
        y_list.append(m_ramales[_ramal]["Y"])

    pz_list = np.concatenate(pz_list)
    x_list = np.concatenate(x_list)
    y_list = np.concatenate(y_list)
    cobertura_list = [""] * len(pz_list)

    df = pd.DataFrame(
        np.array([x_list, y_list, cobertura_list]).T,
        index=pz_list,
        columns=["X", "Y", "road_sup"],
        dtype=object,
    )

    for sup_name, geom in zip(df_road_type[field_name], geom_buffer):
        x_polygon, y_polygon = geom.exterior.coords.xy
        polygon = np.array([x_polygon, y_polygon]).T.copy()
        x = df["X"].to_numpy().astype(float)
        y = df["Y"].to_numpy().astype(float)
        points = np.array([x, y])

        index_in = nb_is_inside_parallel(points, polygon)
        len_ = index_in[index_in != False]
        if len(len_) > 0:
            df.iloc[index_in, 2] = sup_name
    df.replace(to_replace="", value="PASTO", inplace=True)

    for i in m_ramales.keys():
        pz = m_ramales[i]["Pozo"]
        m_ramales[i]["sup_road"] = df.loc[pz]["road_sup"].to_numpy()

    df = m_ramales2df(m_ramales)
    filtro_existente = df["Estado"].isin(["nuevo"])
    df = df[filtro_existente]
    if df.size > 0:
        area_list = []
        length_list = []
        sup_type_list = []
        for sup_, s_ in df.groupby("sup_road"):
            filtro_index = s_.index != ""
            s_ = s_[filtro_index]
            width_sup = seccion_str2float(s_["D_ext"]) + 0.5 + 0.5
            length_sup = s_["L"]
            area_sup = np.round(np.sum(length_sup * width_sup), 0)
            area_list.append(area_sup)
            length_list.append(np.sum(length_sup))
            sup_type_list.append(sup_)

        path_out = "PROYECTO_" + project_name + os.path.sep + "04_RESULTADOS" + os.path.sep + "01_TABLAS"
        name_out = "02_resumen_superficie.xlsx"
        df_out = pd.DataFrame(
            np.array([sup_type_list, area_list, length_list]).T,
            columns=["superficie", "area (m2)", "longitud (m)"],
        )
        df_out.to_excel(path_out + os.path.sep + name_out, index=False)

    return m_ramales


def split_area_polyline(m_ramales, ramal, area_shape):
    geometry = []
    for _ramal in ramal.keys():
        geometry.append(LineString([Point(_) for _ in zip(m_ramales[_ramal]["X"], m_ramales[_ramal]["Y"])]))

    df_poly = gpd.GeoDataFrame(ramal.keys(), columns=["Ramal"], geometry=geometry, index=ramal.keys())

    df_area = gpd.read_file(area_shape)
    index_valid = np.where(df_area.area > 10)
    df_area = df_area.iloc[index_valid]

    split_geom = [[] for k in range(df_area.shape[0])]
    for pos, geo_area in enumerate(df_area.geometry):
        cond = True
        for pos1, geo_poly in enumerate(df_poly.geometry):
            splitter = split(geo_area, geo_poly)
            if len(splitter) > 1:
                split_geom[pos].append(np.array([_ for _ in splitter]))
                if len(split_geom[pos]) > 1:
                    comb = list(combinations(np.concatenate(split_geom[pos]), 2))
                    new_geom = []
                    for geo in comb:
                        _ = geo[0] & geo[1]
                        if not _.is_empty and _.geom_type in ["Polygon"]:
                            x, y = _.exterior.xy
                            new_geom.append(Polygon(zip(x, y)))

                    if len(new_geom) > 0:
                        split_geom[pos] = [new_geom]
                cond = False
        if cond:
            split_geom[pos].append(np.array([geo_area]))

    split_geom = np.concatenate([np.concatenate(_) for _ in split_geom])
    gdf = gpd.GeoDataFrame([], geometry=split_geom)

    out_list = area_shape.split(os.path.sep)
    name_new = out_list[-1].split(".")[0] + "_SPLIT.shp"
    out_list[-1] = name_new
    path_out = os.path.sep.join(out_list)
    gdf.to_file(path_out)


def count_points_inside_polygon(area_shape, points_shape):
    """
    counts points inside a series of polygons
    :param area_shape:
    :param points_shape:
    :return:
    """
    df_area = gpd.read_file(area_shape, engine="pyogrio")
    df_points = gpd.read_file(points_shape, engine="pyogrio")

    rows, cols = df_area.shape
    counter = np.zeros(rows, dtype=float)
    points = np.array([df_points.geometry.x.to_numpy(), df_points.geometry.y.to_numpy()])

    for pos, _area in enumerate(df_area.geometry):
        x, y = _area.exterior.coords.xy
        pol = np.array([x, y]).T

        index_in = np.where(nb_is_inside_parallel(points.copy(), pol.copy()))[0]
        if index_in.size > 0:
            counter[pos] = index_in.size

    df_area["p_in"] = counter * 3.5
    df_area["area"] = df_area.geometry.area / 10000.0
    df_area["densidad"] = counter / df_area["area"]

    columns = list(df_area.columns)
    if "C" not in columns:
        df_area["C"] = np.zeros(shape=rows)
    if "pz_eval" not in columns:
        df_area["pz_eval"] = np.empty(shape=rows)
    if "pz_dis" not in columns:
        df_area["pz_dis"] = np.empty(shape=rows)

    df_area.to_file(area_shape, engine="pyogrio")


def get_map_string(map_tile, map_atributtion, coords=None):
    if m_ramales:
        _S, _N, _E, _W = coords
        map_html = f"""
        <!DOCTYPE html>
        <html>
            <head>
                <meta charset="utf-8">
                <script src="qrc:///qtwebchannel/qwebchannel.js"></script>
                <link rel="stylesheet" href="https://unpkg.com/leaflet@1.3.1/dist/leaflet.css" />
                <script src="https://unpkg.com/leaflet@1.3.1/dist/leaflet.js"></script>

                <script src="leaflet.textpath.js"></script>
                <style>
                    body {{ padding: 0; margin: 0; background-color: rgb(86, 86, 86); }}
                    html, body, #map {{ height: 100%; width:100%}}
                </style>
            </head>
            <body onload="initialize()">
                <div id="map"></div>
                <script type="text/javascript">
                    var map;
                    var _tile;
                    function initialize(){{

                    // add tile
                    var tile_opt = {{maxZoom: 10000, reuseTiles: true, noWrap: true, opacity: 0.7 }};
                    if (typeof map === 'undefined') {{
                    var _tile = L.tileLayer('{map_tile}', tile_opt);
                    }}

                    // add map
                    var map_opt = {{zoomSnap: 0, zoomControl: false, inertia: false, doubleClickZoom: false, preferCanvas: true, wheelPxPerZoomLevel: 70, zoomDelta:0.1}};
                    map = L.map('map', map_opt).addLayer(_tile);

                  // Add an attribution control to the map in the bototm left corner
                    L.control.attribution({{position: 'bottomleft', prefix: 'Copyright &copy;'}})
                      .addAttribution('{map_atributtion}')
                      .addTo(map)
                      .getContainer()
                      .getElementsByTagName('a')[0]
                      .addEventListener('click', function(e) {{
                        e.preventDefault();
                        window.open(this.href, '_blank');
                      }});

                    // disable rigth click menu
                    document.addEventListener('contextmenu', event => event.preventDefault());

                    // disable left and right pannig
                    document.addEventListener('mousedown', (e) => {{
                    if (e.button != 1) {{map.dragging.disable();}}
                    }}
                    );

                 document.addEventListener('mouseup', (e) => {{
                                if (e.button != 1) {{map.dragging.enable();}}
                                }}
                                );

                    // add scale
                    var scale = L.control.scale();
                    scale.addTo(map);

                    //set bounds
                    var southWest = new L.LatLng({str(_S)} , {str(_W)}),
                    northEast = new L.LatLng({str(_N)}, {str(_E)}),
                    bounds = new L.LatLngBounds(southWest, northEast);
                    map.fitBounds(bounds, {{padding: [0, 0]}});


                           // pyqt5 signal
                           new QWebChannel(qt.webChannelTransport, function (channel) {{
                               window.MainWindow = channel.objects.MainWindow;
                               if (typeof MainWindow != 'undefined') {{
                                   var onMapMove = function () {{
                                       MainWindow.onMapMove(map.getBounds().getWest(), map.getBounds().getNorth(), map.getBounds().getSouth(), map.getBounds().getEast())
                                   }};
                                    map.on('move', onMapMove);
                                    map.on('zoom', onMapMove);        // Fires continuously during zooming
                                    map.on('zoomstart', onMapMove); // Fires when zoom starts
                                    map.on('zoomend', onMapMove);     // Fires when zoom ends
                                    

                                   onMapMove();

                                   // Connect the new signal to the setMapBounds function
                                   MainWindow.update_map_bounds.connect(setMapBounds);

                                    // Add a new signal to update the map tile
                                   MainWindow.update_map_tile.connect(changeMapTile);
                                   
                                   // Add a new signal to sync zoom to the map
                                   MainWindow.zoom_in_signal.connect(zoom_in_pyqt);
                                   MainWindow.zoom_out_signal.connect(zoom_out_pyqt);

                               }}

                           }});


                    // end of initialize function
                    }}

                    // Function to change map bounds
                   function setMapBounds(W, N, S, E) {{
                        var southWest = new L.LatLng(S, W),
                        northEast = new L.LatLng(N, E),
                        newBounds = new L.LatLngBounds(southWest, northEast);
                        map.fitBounds(newBounds, {{ padding: [0, 0] }});
                    }}

                    // Function to change the map tile and attribution
                    function changeMapTile(tileUrl, newAttribution) {{
                      // Find the current tile layer
                      var currentTileLayer;
                      map.eachLayer(function (layer) {{
                        if (layer instanceof L.TileLayer) {{
                          currentTileLayer = layer;
                        }}
                      }});

                      // Change the tile URL
                      currentTileLayer.setUrl(tileUrl);

                      // Update the attribution
                      var attributionControl = map.attributionControl;
                      var currentAttributions = attributionControl._attributions;

                      // Remove all existing attributions
                      for (var attribution in currentAttributions) {{
                        attributionControl.removeAttribution(attribution);
                      }}

                      // Add the new attribution
                      attributionControl.addAttribution(newAttribution);

                      // Update the tile layer's attribution option
                      currentTileLayer.options.attribution = newAttribution;
                    }}


                    function panToCoordinates(south, north, west, east) {{
                      // Calculate the center of the bounding box
                      var centerY = (north + south) / 2;
                      var centerX = (east + west) / 2;
                      var center = new L.LatLng(centerY, centerX);

                      // Pan the map to the center of the bounding box
                      map.panTo(center);
                    }}

                    function zoomToBounds(south, north, west, east) {{
                      // Calculate the bounding box
                      var southWest = new L.LatLng(south, west);
                      var northEast = new L.LatLng(north, east);
                      var bounds = new L.LatLngBounds(southWest, northEast);

                      // Calculate the optimal zoom level for the given bounding box
                      var padding = [0, 0]; // Optional padding for the bounding box
                      var optimalZoom = map.getBoundsZoom(bounds, false, padding);

                      // Set the map zoom to the optimal zoom level
                      map.setZoom(optimalZoom);
                    }}
                    
                    
                    function zoom_in_pyqt(value) {{
                        map.zoomIn(value)
                    }}
                    
                    function zoom_out_pyqt(value) {{
                        map.zoomOut(value)
                    }}


                    initialize();


                </script>
            </body>
        </html>
    """

    return map_html


def rotate_vector_pyqt5(origin, point, angle):
    """
    rotate a point counterclockwise by a given angle around a given origin. the angle should be given in radians.

    :param origin: source point arrays, [x_source, y_source], len n
    :param point:  destination point, [x_dest, y_dest], len n
    :param angle:  array of angle to rotate vector (origin --> point), [ang], len n
    :return:

    """
    ox, oy = origin
    px, py = point

    qx = ox + np.cos(angle) * (px - ox) - np.sin(angle) * (py - oy)
    qy = oy + np.sin(angle) * (px - ox) + np.cos(angle) * (py - oy)
    return qx, qy


def ang_vector_pyqt5(x, y):
    dx = x[1:] - x[:-1]
    dy = y[1:] - y[:-1]
    ang = np.arctan(dy / dx)
    fy, fx = (dy / np.abs(dy)), (dx / np.abs(dx))
    fx, fy = np.nan_to_num(fx, nan=0), np.nan_to_num(fy, nan=0)
    return ang, fx, fy


def coords_transform(x, y, ProjFrom="epsg:32717", ProjTo="epsg:4326"):
    transformer = Transformer.from_crs(ProjFrom, ProjTo, always_xy=True)
    return transformer.transform(x, y)


def export_to_Map(m_ramales, map_ref="Google Hybrid"):
    copy_m_ramales = m_ramales.copy()

    map_tile = {
        "None": 0,
        "ESRI Imagery": "https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}",
        "ESRI Streets": "https://server.arcgisonline.com/ArcGIS/rest/services/World_Street_Map/MapServer/tile/{z}/{y}/{x}",
        "Google Hybrid": "https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}",
        "Google Maps": "https://mt1.google.com/vt/lyrs=r&x={x}&y={y}&z={z}",
        "Google Satellite": "http://www.google.cn/maps/vt?lyrs=s@189&gl=cn&x={x}&y={y}&z={z}",
        "OSM Black and White": "http://tiles.wmflabs.org/bw-mapnik/{z}/{x}/{y}.png",
        "Stamen Terrain": "http://a.tile.stamen.com/terrain/{z}/{x}/{y}.png",
        "Stamen Watercolor": "http://tile.stamen.com/watercolor/{z}/{x}/{y}.jpg",
        "Stamen Toner": "http://tile.stamen.com/toner/{z}/{x}/{y}.png",
        "OpenStreetMap": "http://a.tile.openstreetmap.org/{z}/{x}/{y}.png",
        "OpenTopoMap": "https://tile.opentopomap.org/{z}/{x}/{y}.png",
        "Cartodb Positron": "https://cartodb-basemaps-{s}.global.ssl.fastly.net/light_all/{z}/{x}/{y}.png",
    }
    map_atributtion = {
        "None": 0,
        "ESRI Imagery": 'Map data: &copy; <a href="http://www.esri.com/">Esri</a>, DigitalGlobe, GeoEye, i-cubed, USDA FSA, USGS, AEX, Getmapping, Aerogrid, IGN, IGP, swisstopo, and the GIS User Community',
        "ESRI Streets": 'Map data: &copy; <a href="http://www.esri.com/">Esri</a>, DeLorme, HERE, USGS, Intermap, iPC, NRCAN, Esri Japan, METI, Esri China (Hong Kong), '
        "Esri (Thailand), MapmyIndia, Tomtom",
        "Google Hybrid": 'Map data: &copy; <a href="https://developers.google.com/maps"> Google</a>, <a href="https://developers.google.com/maps/terms"> Terms of Use. </a>',
        "Google Maps": 'Map data: &copy; <a href="https://developers.google.com/maps"> Google</a>, <a href="https://developers.google.com/maps/terms"> Terms of Use. </a>',
        "Google Satellite": 'Map data: &copy; <a href="https://developers.google.com/maps"> Google</a>, <a href="https://developers.google.com/maps/terms"> Terms of Use. </a>',
        "OSM Black and White": "1",
        "Stamen Terrain": "1",
        "Stamen Watercolor": "1",
        "Stamen Toner": "1",
        "OpenStreetMap": 'Map data: &copy; <a href="http://openstreetmap.org">OpenStreetMap</a> contributors, '
        '<a href="http://creativecommons.org/licenses/by-sa/2.0/">CC-BY-SA</a>, Imagery © <a href="http://cloudmade.com">CloudMade</a>',
        "OpenTopoMap": 'Map data: &copy; <a href="https://openstreetmap.org/copyright">OpenStreetMap</a>-Mitwirkende, <a href="http://viewfinderpanoramas.org">SRTM</a> | '
        'Kartendarstellung: &copy; <a href="https://opentopomap.org">OpenTopoMap</a> (<a href="https://creativecommons.org/licenses/by-sa/3.0/">CC-BY-SA</a>)',
        "Cartodb Positron": "1",
    }

    if map_ref != "None":
        ProjFrom = "epsg:32717"
        ProjTo = "epsg:4326"

        # writte html map leaft
        _coords, _arrows, _text, _X, _Y = [], [], [], [], []
        key_text = [
            "Tramo",
            "L",
            "D_ext",
            "Material",
            "Seccion",
            "S",
            "HI",
            "HF",
            "Fase",
            "Obs",
            "q_accu",
            "h/D",
            "v",
        ]
        unit_text = [
            "",
            " m",
            " m",
            "",
            "",
            "%",
            " m, ",
            "m",
            "",
            "",
            " m3/s",
            "",
            " m/s",
        ]
        sep_text = [
            "<br>",
            "<br>",
            " ",
            "<br>",
            "<br>",
            "<br>",
            " ",
            "<br>",
            "<br>",
            "<br>",
            "<br>",
            "<br>",
            "",
        ]
        _width_arrow, _len_arrow, radio = 0.25, 0.75, 0.4
        for i in copy_m_ramales.keys():
            # COORDENADAS
            x_p = copy_m_ramales[i]["X"]
            y_p = copy_m_ramales[i]["Y"]
            _X.append(x_p)
            _Y.append(y_p)

            # TEXTO TRAMO
            copy_m_ramales[i]["h/D"] = np.round(copy_m_ramales[i]["h/D"], 2)
            copy_m_ramales[i]["v"] = np.round(copy_m_ramales[i]["v"], 2)
            copy_m_ramales[i]["HI"] = np.round(copy_m_ramales[i]["HI"], 2)
            copy_m_ramales[i]["HF"] = np.round(copy_m_ramales[i]["HF"], 2)
            copy_m_ramales[i]["S"] = np.round(copy_m_ramales[i]["S"] * 100, 2)
            copy_m_ramales[i]["q_accu"] = np.round(copy_m_ramales[i]["q_accu"] / 1000, 3)
            _temp = []
            for _i in np.array([copy_m_ramales[i][_][1:] for _ in key_text]).T:
                _text_i = " ".join([key_text[_] + ":" + _i[_] + unit_text[_] + sep_text[_] for _ in range(len(_i))])
                _temp.append(_text_i)
            _text.append(_temp)

            # FLECHAS
            # ANGULOS ENTRE PUNTOS
            _ang, _fx, _fy = ang_vector_pyqt5(x_p, y_p)

            # PUNTOS MEDIOS ENTRE EXTREMOS
            x_mean = (x_p[:-1] + x_p[1:]) / 2.0
            y_mean = (y_p[:-1] + y_p[1:]) / 2.0

            # PUNTOS DE ORIGEN
            _px = x_mean + (_width_arrow - 1.9 * _len_arrow) * np.abs(np.cos(_ang)) * _fx
            _py = y_mean + (_width_arrow - 1.9 * _len_arrow) * np.abs(np.sin(_ang)) * _fy

            # PUNTOS DE LA FLECHA
            _px0 = x_mean + _width_arrow * np.abs(np.cos(_ang)) * _fx
            _py0 = y_mean + _width_arrow * np.abs(np.sin(_ang)) * _fy

            _ang1 = np.array([np.deg2rad(338)] * len(_px))
            _px1, _py1 = rotate_vector_pyqt5(origin=[_px0, _py0], point=[_px, _py], angle=_ang1)

            _px2 = x_mean - _len_arrow * 0.7 * np.abs(np.cos(_ang)) * _fx
            _py2 = y_mean - _len_arrow * 0.7 * np.abs(np.sin(_ang)) * _fy

            _ang3 = np.array([np.deg2rad(22)] * len(_px0))
            _px3, _py3 = rotate_vector_pyqt5(origin=[_px0, _py0], point=[_px, _py], angle=_ang3)

            # AGREGAR A LISTA
            _arrow = list(
                map(
                    list,
                    list(
                        zip(
                            list(map(list, list(zip(_px0, _py0)))),
                            list(map(list, list(zip(_px1, _py1)))),
                            list(map(list, list(zip(_px2, _py2)))),
                            list(map(list, list(zip(_px3, _py3)))),
                        )
                    ),
                )
            )
            _arrows.append(_arrow)

        n, s, e, w = (
            np.max(np.concatenate(_Y)),
            np.min(np.concatenate(_Y)),
            np.max(np.concatenate(_X)),
            np.min(np.concatenate(_X)),
        )
        _E, _N = coords_transform(y=n, x=e, ProjFrom=ProjFrom, ProjTo=ProjTo)
        _W, _S = coords_transform(y=s, x=w, ProjFrom=ProjFrom, ProjTo=ProjTo)

        # LISTA DE PUNTOS DE VERTICES
        index_pos = list(map(len, np.array(_X, dtype=object)))
        _x, _y = coords_transform(y=np.concatenate(_Y), x=np.concatenate(_X), ProjFrom=ProjFrom, ProjTo=ProjTo)
        _x, _y = (
            np.split(_x, np.cumsum(index_pos))[:-1],
            np.split(_y, np.cumsum(index_pos))[:-1],
        )
        _del = [_coords.append(list(map(list, list(zip(j.tolist(), i.tolist()))))) for j, i in zip(_y, _x)]
        del _del, index_pos, _x, _y

        # LISTA DE PUNTOS DE FLECHAS
        index_pos = list(map(len, np.array(_arrows, dtype=object)))
        _X, _Y = np.concatenate(np.concatenate(_arrows)).T
        _x, _y = coords_transform(y=_Y, x=_X, ProjFrom=ProjFrom, ProjTo=ProjTo)
        index_arrow = np.cumsum(np.array(index_pos) * 4)
        _arrows1 = [np.array(_arrow).tolist() for _arrow in np.split(np.array(list(zip(_y, _x))), index_arrow)[:-1]]
        _arrows = [np.array(np.split(_arrow, np.cumsum([4] * idx))[:-1]).tolist() for _arrow, idx in zip(_arrows1, index_pos)]
        del index_pos, index_arrow, _x, _y, _X, _Y, _arrows1

        map_js = (
            r"""
                    var coords = """
            + str(_coords)
            + r""";
                var arrows = """
            + str(_arrows)
            + r""";
                var texts = """
            + str(_text)
            + r""";

                function initialize(){
                // ADD TILE
                var tile_opt = {attribution: """
            + r"'"
            + map_atributtion[map_ref]
            + "'"
            + r""" , maxZoom: 60, reuseTiles: true, noWrap: true ,opacity: 0.5}
                var _tile = L.tileLayer("""
            + r"'"
            + map_tile[map_ref]
            + "'"
            + r""", tile_opt);

                // ADD MAP
                var map_opt = {zoomSnap: 0, zoomControl: true, inertia: true, doubleClickZoom: true, preferCanvas: true, wheelPxPerZoomLevel: 60}
                var map = L.map('map', map_opt).addLayer(_tile);

                // ADD LINES
                //var style = {color: "#F44336", weight: 5, opacity: 1};
                //for (let i of coords) {L.polyline(i, style).addTo(map);}
                
                // Define the regular expression pattern for 'Tramo'
                var tramoPattern = /E\d+(_\d+)?(\.\d+)?-E\d+(_\d+)?(\.\d+)?/;

                
                // Modify the ADD LINES section
                for (let i = 0; i < coords.length; i++) {
                    // Extract the 'Tramo' text from the texts array
                    var tramoText = texts[i].find(text => text.includes('Tramo'));
                
                    // Determine the color based on whether the 'Tramo' text matches the pattern
                    var lineColor = tramoPattern.test(tramoText) ? "#00FF00" : "#F44336"; // Use green if it matches, otherwise red
                
                    // Set the style for the polyline with the determined color
                    var style = { color: lineColor, weight: 5, opacity: 1 };
                
                    // Add the polyline to the map with the specific style
                    L.polyline(coords[i], style).addTo(map);
                }
                
                // ADD CIRCLES
                for (let i = 0; i < coords.length; i++) {
                for (let j = 0; j < coords[i].length; j++){L.circle([coords[i][j][0],coords[i][j][1]], {color: '#00B4FF',fillColor: '#00B4FF',fillOpacity: 1,radius: 0.45}).addTo(map);}
                }

                // ADD ARROWS
                var style_arrow = { color: '#00B4FF', fillColor: '#00B4FF', weight: 3, fillOpacity: 1};

                for (let i = 0; i < arrows.length; i++) {
                for (let j = 0; j < arrows[i].length; j++){L.polygon(arrows[i][j], style_arrow)
                                                            .bringToFront()
                                                            .bindTooltip(texts[i][j], {permanent: false, className: 'custom-tooltip'})
                                                            .addTo(map);}
                                                        }

                // ADD SCALE
                var scale = L.control.scale();
                scale.addTo(map);

                //SET BOUNDS
                var southWest = new L.LatLng("""
            + str(_S)
            + ","
            + str(_W)
            + """),
                northEast = new L.LatLng("""
            + str(_N)
            + ","
            + str(_E)
            + """),
                bounds = new L.LatLngBounds(southWest, northEast);
                map.fitBounds(bounds, {padding: [0, 0]});


                // Now that the map is set up, call the function to show the user's location
                function onLocationFound(e) {
                var radius = e.accuracy / 2;
            
                L.marker(e.latlng).addTo(map)
                  .bindPopup("Presicion " + radius.toFixed(2) + " metros").openPopup();
            
                L.circle(e.latlng, radius).addTo(map);
              }
            
              function onLocationError(e) {
                alert(e.message);
              }
              
              
            // INITIATE LOCATION SERVICES
            map.on('locationfound', onLocationFound);
            map.on('locationerror', onLocationError);
            map.locate({setView: true, maxZoom: 16, watch: true});
            

           
               }

           """
        )

        # Now format the HTML with the map_js code
        map_html = f"""
            <!DOCTYPE html>
            <html>
            <head>
                <meta charset="utf-8">
                <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet.locatecontrol/dist/L.Control.Locate.min.css" />
                <script src="https://cdn.jsdelivr.net/npm/leaflet.locatecontrol/dist/L.Control.Locate.min.js"></script>

                <link rel="stylesheet" href="https://unpkg.com/leaflet@1.3.1/dist/leaflet.css" />
                <script src="https://unpkg.com/leaflet@1.3.1/dist/leaflet.js"></script>
                <script type="text/javascript">
                
                {map_js}
                </script>
                <style>
                   body {{ padding: 0; margin: 0; }}
                   html, body, #map {{ height: 100%; width: 100%;}}
                   .custom-tooltip {{ font-size: 32px; }}
                </style>
            </head>
            <body onload="initialize()">
                <div id="map"></div>
            </body>
            </html>
            """

        path = "PROYECTO_" + project_name + os.path.sep + "00_GIS" + os.path.sep + "02_OUT" + os.path.sep + "01_RAMALES" + os.path.sep
        # Write the complete HTML content to a file
        with open(path + project_name + ".html", "w") as out:
            out.write(map_html)


def cn_to_c_piecewise(cn):
    if cn < 61:
        return 0.05
    elif cn < 76:
        return 0.10 + 0.02 * (cn - 65)
    elif cn < 86:
        return 0.40 + 0.05 * (cn - 83)
    elif cn < 99:
        return 0.8 + 0.01 * (cn - 92)
    else:
        return 0.90


def rossmiller_conversion(CN, IMP, S, RI=10):
    """
    Convert CN values to C values using Rossmiller's Conversion.

    Parameters:
    CN (float): Curve number.
    RI (float): Return interval in years.
    IMP (float): Impervious coverage as a decimal 0 -1.
    S (float: Average land slope in m/m (0-)

    Returns:
    float: Computed C value.
    """

    # Convert the land slope S from whole number percent to decimal
    # S_decimal = S / 100

    # Calculate the C value using the provided formula
    C = 7.2 * (10**-7) * (CN**3) * (RI**0.05) * ((0.01 * CN) ** 0.6) ** (-(S**0.2)) * ((0.001 * CN**1.48) ** (0.15 - 0.1 * S)) * (((IMP + 1) / 2) ** 0.7)

    return C


def m_ramales2df(m_ramales):
    type_values_dict = {
        "Ramal": "U256",
        "Tipo": "U256",
        "Conexion": object,
        "Pozo": "U256",  # 'tipo_nudo': 'U256',
        "Tramo": "U256",
        "X": float,
        "Y": float,
        "Z": float,
        "L": float,
        "LT": float,
        "Material": "U256",
        "Seccion": "U256",
        "S": float,
        "Rug": float,
        "Rugosidad": "U256",
        "D_int": "U256",
        "D_ext": "U256",
        "ZTI": float,
        "ZTF": float,
        "ZFI": float,
        "ZFF": float,
        "HI": float,
        "HF": float,
        "SALTO": float,
        "Estado": "U256",
        "Pozo_hmin": float,
        "cobertura_min": float,
        "D_min": float,
        "S_min": float,
        "Derivacion": bool,
        "Fase": "U256",
        "Obs": "U256",
        "q_san": float,
        "q_pluvial": float,
    }

    # columns_read = list(type_values_dict.keys())
    columns_read = list(m_ramales[next(iter(m_ramales))].keys())

    # Get the first outer key
    first_outer_key = next(iter(m_ramales))

    # Get the column names (inner keys) from the first outer key
    columns = list(m_ramales[first_outer_key].keys())

    # Initialize an empty dictionary with column names as keys
    data = {column: [] for column in columns}

    # Iterate through the outer keys
    for outer_key in m_ramales.keys():
        # Get the inner dictionary corresponding to the current outer key
        outer_dictionary = m_ramales[outer_key]

        # Iterate through the inner keys (columns)
        for inner_key in columns:
            # Extend the list for each inner key with the values from the current inner dictionary
            data[inner_key].extend(outer_dictionary[inner_key])

    # Create a DataFrame from the data dictionary and return it
    df = pd.DataFrame(data)

    # Apply the data types to the DataFrame
    # df = df.astype(type_values_dict)

    index_split = list(df["Tramo"].replace("", np.nan).dropna().index)
    # get rela indexes
    new_index = []
    # for loop de ramales
    for j in m_ramales.keys():
        length = m_ramales[j]["Ramal"].size - 1
        # for loop de coordenadas de pozos
        for i in range(0, length, 1):
            if i == 0:
                # "nombre Tramo"
                if m_ramales[j]["Conexion"][i + 1] is None:
                    str1 = m_ramales[j]["Tramo"][i + 1]
                else:
                    if m_ramales[j]["Conexion"][i + 1] == m_ramales[j]["Conexion"][-1]:
                        for k in m_ramales[j]["Conexion"][i + 1].split(","):
                            pz_ramal, pz = k.split(".")[0], int(k.split(".")[1])
                            # escribe str1 si la conexion es diferente significa que es una conexion de otro ramal
                            if m_ramales[pz_ramal]["Conexion"][pz] != m_ramales[pz_ramal]["Conexion"][-1]:
                                str1 = np.array([m_ramales[j]["Pozo"][i] + "-" + k])[0]
                                break
                            else:
                                # escribe str1 si la conexion es a un pozo final pero es una conexion de otro ramal
                                if j != pz_ramal:
                                    str1 = np.array([m_ramales[j]["Pozo"][i] + "-" + k])[0]
                                else:
                                    print("error: ", j, i)
                    else:
                        str1 = m_ramales[j]["Tramo"][i + 1]
                new_index.append(str1)

            else:
                # nombre Tramo
                if m_ramales[j]["Conexion"][i + 1] is None:
                    str1 = m_ramales[j]["Tramo"][i + 1]
                else:
                    if m_ramales[j]["Conexion"][i + 1] == m_ramales[j]["Conexion"][-1]:
                        for k in m_ramales[j]["Conexion"][i + 1].split(","):
                            pz_ramal, pz = k.split(".")[0], int(k.split(".")[1])
                            # escribe str1 si la conexion es diferente significa que es una conexion de otro ramal
                            if m_ramales[pz_ramal]["Conexion"][pz] != m_ramales[pz_ramal]["Conexion"][-1]:
                                str1 = np.array([m_ramales[j]["Pozo"][i] + "-" + k])[0]
                                break
                            else:
                                # escribe str1 si la conexion es a un pozo final pero es una conexion de otro ramal
                                if j != pz_ramal:
                                    str1 = np.array([m_ramales[j]["Pozo"][i] + "-" + k])[0]
                                else:
                                    print("error: ", j, i)
                    else:
                        str1 = m_ramales[j]["Tramo"][i + 1]
                new_index.append(str1)

    string_index = df["Tramo"].to_numpy()
    string_index[index_split] = new_index
    # set new index
    df.index = string_index

    df = df.loc[:, columns_read]
    return df


# Function to remove holes from a polygon
def remove_holes(geom):
    if geom.geom_type == "Polygon":
        return Polygon(geom.exterior)
    elif geom.geom_type == "MultiPolygon":
        return MultiPolygon([Polygon(poly.exterior) for poly in geom.geoms])
    else:
        return geom  # Return the geometry itself if it's not a Polygon or MultiPolygon


def find_outfall(G, start_node):
    current_node = start_node
    # Traverse downstream until a node with no outgoing edges is found
    while True:
        successors = list(G.successors(current_node))
        if len(successors) == 0:  # This is an outfall node
            return current_node
        else:
            current_node = successors[0]  # Continue with the next node downstream


def get_outfall(m_ramales, crs_utm_epsg):
    # Create a directed graph
    G = nx.DiGraph()
    df = m_ramales2df(m_ramales)

    # Iterate over the DataFrame rows
    for connection, row in df.iterrows():
        # Skip rows where the index is an empty string
        if connection == "":
            continue

        # Parse the source and target nodes from the index
        source, target = connection.split("-")

        # Add nodes and edge to the graph
        G.add_node(source)
        G.add_node(target)
        G.add_edge(source, target)

    # Dictionary to store the outfall node for each edge
    edge_to_outfall = {}

    # Iterate over all edges to find their corresponding outfall nodes
    for edge in G.edges:
        start_node = edge[0]
        outfall_node = find_outfall(G, start_node)
        key = edge[0] + "-" + edge[1]
        edge_to_outfall[key] = outfall_node.split(".")[0]

    df["outfall"] = df.index.to_series().map(edge_to_outfall).fillna(method="bfill")

    for index, s in df.groupby("Ramal")["outfall"]:
        m_ramales[index]["outfall"] = s.to_numpy()

    return m_ramales


class cls_Guardar:
    def __init__(self):
        self.parametros_basicos = {
            "circular": {
                "cobertura_minima": 1.2,
                "seccion_minima": 0.284,
                "calado_maximo": 0.65,
            },
            "rectangular": {
                "cobertura_minima": 1.2,
                "seccion_minima": 0.6,
                "calado_maximo": 0.65,
            },
        }

        base = np.arange(self.parametros_basicos["rectangular"]["seccion_minima"], 5, 0.1)
        altura = np.round(base * 2 / 3, 1)
        altura = np.where(altura < 0.6, 0.6, altura)
        self.rectangular_base_altura_pypiper = {
            "HA": dict(zip(base, altura)),
            "HS": dict(zip(base, altura)),
        }

        self.seccion_material = {
            "circular": diametro_interno_externo_pypiper,
            "rectangular": self.rectangular_base_altura_pypiper,
        }

        self.parametros_generales_pypiper = {
            "parametros_basicos": self.parametros_basicos,
            "velocidad_maxima": velocidad_maxima_pypiper,
            "pendiente_minima": pendiente_minima_pypiper,
            "rugosidad": rugosidad_pypiper,
            "seccion_material": self.seccion_material,
            "crs": str(32717),
        }

    def f_Guardar(self):
        saved_dict = [
            m_ramales,
            ramal,
            xy_inter,
            self.parametros_generales_pypiper,
        ]

        self.save_and_compress_dicts(saved_dict, path_proy, project_name)

    def save_and_compress_dicts(self, list_of_dicts, path, filename_base):
        import pickle
        import zipfile

        npy_filenames = []
        for i, dictionary in enumerate(list_of_dicts):
            # Serialize the dictionary with pickle
            serialized_dict = pickle.dumps(dictionary)

            # Modify filename for each dictionary
            filename = f"{filename_base}_{i}"

            # Save the serialized dictionary to a file with numpy
            npy_file_name = os.path.join(path, filename + ".npy")
            np.save(npy_file_name, serialized_dict)
            npy_filenames.append(npy_file_name)

        # Create a new Zip file and add all the .npy files to it
        with zipfile.ZipFile(
            path_proy + os.path.sep + project_name + str(".pyp"),
            "w",
            zipfile.ZIP_DEFLATED,
        ) as zipf:
            for npy_file_name in npy_filenames:
                zipf.write(npy_file_name, arcname=os.path.basename(npy_file_name))  # Save with only the basename to avoid directory issues

        # Remove the temporary .npy files
        for npy_file_name in npy_filenames:
            os.remove(npy_file_name)


def set_numeric_types(df):
    """
    Converts all columns in the DataFrame that can be converted to numeric types.

    Parameters:
    df (pd.DataFrame): The DataFrame to convert.

    Returns:
    pd.DataFrame: The DataFrame with columns converted to numeric types where possible.
    """
    for col in df.columns:
        # Try to convert the column to a numeric type
        df[col] = pd.to_numeric(df[col], errors="ignore")
    return df


def plot_series(df, name, y_axis, path_out=None):
    import matplotlib.pyplot as plt

    fig, ax = plt.subplots(figsize=(26, 13))  # Adjusted size for more white space
    markers = ["o", "v", "s", "p", "*", "x", "o"] * 100

    for i, column in enumerate(df.columns):
        ax.plot(
            df.index,
            df[column],
            marker=markers[i],
            label=column,
            linewidth=3,
            markersize=20,
        )

    # Formatting the plot with Spanish titles and labels
    ax.set_xlabel("Tiempo (minutos)", fontsize=40, fontweight="bold")
    ax.set_ylabel(y_axis, fontsize=40, fontweight="bold")
    ax.grid(True, which="both", linestyle="--", linewidth=1)
    ax.tick_params(axis="both", which="major", labelsize=35)
    plt.legend(fontsize=35)

    # Show plot with tight layout and save
    plt.tight_layout(pad=2)  # Adjust padding as necessary

    if not path_out:
        path_out = "PROYECTO_" + project_name + os.path.sep + "04_RESULTADOS" + os.path.sep + "01_TABLAS"

    plt.savefig(path_out + os.path.sep + f"{name}.png")


def plot_series_compare(df, name, y_axis, path_out=None):
    import matplotlib.pyplot as plt
    import numpy as np
    import os

    fig, ax = plt.subplots(figsize=(26, 13))  # Adjusted size for more white space
    markers = ["o", "v", "s", "p", "*", "x", "o"] * 100

    # Plot each column in the dataframe
    lines = []  # To store line objects
    labels = []  # To store labels
    for i, column in enumerate(df.columns):
        (line,) = ax.plot(
            df.index,
            df[column],
            marker=markers[i],
            label=column,
            linewidth=3,
            markersize=20,
        )
        lines.append(line)
        labels.append(column)

    # Formatting the primary y-axis (left)
    ax.set_xlabel("Tiempo (minutos)", fontsize=40, fontweight="bold")
    ax.set_ylabel(y_axis, fontsize=40, fontweight="bold")
    ax.grid(True, which="both", linestyle="--", linewidth=1)
    ax.tick_params(axis="both", which="major", labelsize=35)

    # Create a twin axis for the percentage difference
    ax2 = ax.twinx()
    if len(df.columns) > 1:
        percentage_diff = (np.round((df.iloc[:, 1] - df.iloc[:, 0]), 2)).fillna(0)
        (line,) = ax2.plot(
            df.index,
            percentage_diff,
            label="Caudal disminuido (L/s)",
            linewidth=3,
            color="k",
            linestyle="--",
        )
        lines.append(line)
        labels.append("Caudal disminuido")
        ax2.set_ylabel("Caudal disminuido", fontsize=40, fontweight="bold")
        ax2.tick_params(axis="y", labelsize=35)

    # Combine legends from both axes
    ax.legend(lines, labels, loc="center right", fontsize=35)

    plt.tight_layout(pad=2)  # Adjust padding as necessary

    if not path_out:
        path_out = "PROYECTO_" + project_name + os.path.sep + "04_RESULTADOS" + os.path.sep + "01_TABLAS"

    plt.savefig(path_out + os.path.sep + f"{name}.png")


# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
def string_concat(array1, array2):
    # Ensure both arrays have the same shape
    if array1.shape != array2.shape:
        raise ValueError("Both arrays must have the same shape")

    # Convert both arrays to 'U256' to ensure compatibility
    array1 = np.array(array1, dtype="U256")
    array2 = np.array(array2, dtype="U256")

    # Create the result array
    result = np.empty(array1.size, dtype="U256")

    # Iterate over the arrays and apply the concatenation logic
    for i in range(array1.size):
        if array1[i] != "":
            result[i] = f"{array1[i]}, {array2[i]}"
        else:
            result[i] = array2[i]

    return result


def get_point_valueTo_m_ramales_interpolate(xyzv_path, m_ramales, xyzv_column, average_value=False):
    from scipy.interpolate import interp1d

    gdf = gpd.read_file(xyzv_path, engine="pyogrio")
    xyz_coordinates = gdf.geometry.get_coordinates().to_numpy()
    grupos = gdf.groupby("name")
    names = gdf["name"]
    df_dict = {_[0]: _[1] for _ in grupos}

    for _ramal in m_ramales.keys():
        if np.any(m_ramales[_ramal]["Estado"] == "nuevo"):
            new_x = m_ramales[_ramal]["X"]
            new_y = m_ramales[_ramal]["Y"]
            new_depth = np.concatenate([[m_ramales[_ramal]["HI"][1]], m_ramales[_ramal]["HF"][1:]])

            points = np.array([new_x, new_y]).T
            ramal_values = []

            for pos in range(len(points)):
                dist = np.concatenate(distance.cdist(xyz_coordinates, [points[pos]]))

                pos_min = np.argmin(dist)
                name = names[pos_min]

                _depth, _M = (
                    np.append(df_dict[name]["depth"].to_numpy(), 1000),
                    np.append(
                        df_dict[name][xyzv_column].to_numpy(),
                        df_dict[name][xyzv_column].to_numpy()[-1],
                    ),
                )
                if not _depth[0] == 0:
                    _depth = np.insert(_depth, 0, 0)
                    _M = np.insert(_M, 0, _M[0])

                interpolator = interp1d(_depth, _M, kind="linear")

                if dist[pos_min] < 200:
                    if average_value:
                        ramal_values.append(round(np.mean(interpolator(new_depth)), 1))
                    else:
                        ramal_values.append(np.round(interpolator(new_depth[pos]), 1))

                else:
                    ramal_values.append(np.nan)

            if average_value:
                # m_ramales[_ramal][xyzv_column + '_u'] = np.array(ramal_values).astype(float)
                m_ramales[_ramal][xyzv_column] = np.array(ramal_values).astype(float)
            else:
                m_ramales[_ramal][xyzv_column] = np.array(ramal_values).astype(float)

            # comment = np.where(m_ramales[_ramal]['M_value'] < 2.5, 'mejorar suelo', '')  # m_ramales[_ramal]['Obs'] = string_concat(m_ramales[_ramal]['Obs'], comment)

        else:
            m_ramales[_ramal][xyzv_column] = np.full(m_ramales[_ramal]["Estado"].size, fill_value=1000)

    return m_ramales


def get_point_valueTo_m_ramales_interpolate_old(xyzv_path, m_ramales, raster):
    from scipy.interpolate import interp1d

    df = pd.read_excel(xyzv_path)
    gdf = gpd.read_file(r"F:\SOLANDA_GEOTECNIA\suelo\interpolador_suelo.shp")
    gdf["name"] = df["name"]
    # x, y = transform_coordinates_v2(df['x'], df['y'])
    x, y, z = df["x"], df["y"], df["z"]
    grupos = df.groupby("name")
    coordenadas = gdf.geometry.get_coordinates().to_numpy()
    df_dict = {_: __ for _, __ in grupos}

    depth = df["depth"].to_numpy()
    value = df["M"].to_numpy()
    # xyzv_points = np.array([x, y, z - depth ]).T

    for _ramal in m_ramales.keys():
        m_ramales[_ramal]["wilmer"] = []

    for _ramal in ["2", "183", "257", "261"]:
        new_x = m_ramales[_ramal]["X"]
        new_y = m_ramales[_ramal]["Y"]
        new_z = m_ramales[_ramal]["Z"]
        new_depth = np.concatenate([[m_ramales[_ramal]["HI"][1]], m_ramales[_ramal]["HF"][1:]])
        new_depths_array = np.arange(0, np.max(new_depth) + 1)

        points = np.array([new_x, new_y, new_z]).T

        pos_min = np.argmin(distance.cdist(coordenadas, points[:, :2]), axis=0)
        dist_min = np.min(distance.cdist(coordenadas, points[:, :2]), axis=0)
        m_values_list = []

        for pos, point in enumerate(points):
            # local_m_values = []

            # for _depth in new_depths_array:

            name = gdf["name"][pos_min[pos]]
            # min_pos = np.argmin(np.abs(_depth - df_dict[name]['depth']))
            interpolator = interp1d(
                np.append(df_dict[name]["depth"].to_numpy(), 1000),
                np.append(df_dict[name]["M"].to_numpy(), df_dict[name]["M"].to_numpy()[-1]),
                kind="linear",
            )

            # value = df_dict[name]['M'].to_numpy()[min_pos]

            if dist_min[pos] < 200:
                local_m_values = np.round(interpolator(new_depths_array), 2)
            else:
                local_m_values = np.full(new_depths_array.size, fill_value=np.nan)

            m_values_list.append(local_m_values)

        m_ramales[_ramal]["wilmer"] = np.array(m_values_list)

    return m_ramales


def transform_coordinates(x, y, toEPSG, fromEPSG):
    """
    Transforms coordinates from a custom CRS to EPSG: using the Transformer class.

    Parameters:
    - custom_crs_proj_string: A PROJ string or EPSG code defining the custom CRS.
    - x: The x coordinate (longitude) in the custom CRS.
    - y: The y coordinate (latitude) in the custom CRS.

    Returns:
    - A tuple (x, y) representing the transformed coordinates in toEPSG.
    """

    # Initialize the Transformer
    transformer = Transformer.from_crs(fromEPSG, toEPSG, always_xy=True)

    # Perform the transformation
    x_transformed, y_transformed = transformer.transform(x, y)

    return x_transformed, y_transformed


def find_closest_point_to_centroid(coords_list):
    # Extract longitude and latitude from the list of coordinates
    lons, lats = zip(*coords_list)

    # Create GeoDataFrame from longitude and latitude
    gdf = gpd.GeoDataFrame(geometry=gpd.points_from_xy(lons, lats))

    # Create a LineString from the points to calculate the centroid
    line = LineString(gdf["geometry"].tolist())
    centroid = line.centroid

    # Calculate the distances from each point to the centroid
    gdf["distance_to_centroid"] = gdf["geometry"].distance(centroid)

    # Find the closest point to the centroid
    closest_point = gdf.loc[gdf["distance_to_centroid"].idxmin()].geometry

    return closest_point


def convert_utm_to_ellipsoidal(
    easting_list,
    northing_list,
    orthometric_elevations,
    crs_utm_epsg=32717,
    geoid_model_path=r"C:\ProgramData\GeographicLib\geoids\egm2008-1.pgm",
):
    """
    Convert UTM coordinates to ellipsoidal elevations using a specified geoid model.

    Parameters:
    - easting_list (list): List of UTM easting coordinates.
    - northing_list (list): List of UTM northing coordinates.
    - orthometric_elevations (list): List of orthometric (geoid) elevations.
    - crs_utm_epsg (int): EPSG code of the UTM projection (default is 32717).
    - geoid_model_path (str): Path to the geoid model (default is EGM2008 model).

    Returns:
    - results (list of tuples): List containing tuples with latitude, longitude, geoid offset, and ellipsoidal elevation.
    """
    # Hardcoded CRS removed to allow dynamic argument usage
    # The crs_utm_epsg argument will be used directly
    # Initialize a transformer from UTM to geographic (WGS84)
    # crs_utm = CRS.from_epsg(crs_utm_epsg)
    crs_wgs84 = CRS.from_epsg(4326)
    transformer = Transformer.from_crs(crs_utm_epsg, crs_wgs84)

    # Initialize the geoid interpolator
    ginterpolator = GeoidKarney(geoid_model_path)

    # Store the results in a list
    results = []

    # Process each UTM coordinate
    for easting, northing, orthometric_elevation in zip(easting_list, northing_list, orthometric_elevations):
        # Convert to latitude and longitude
        latitude, longitude = transformer.transform(easting, northing)

        # Calculate the geoid offset
        position = ellipsoidalKarney.LatLon(latitude, longitude)
        geoid_offset = ginterpolator(position)

        # Calculate the ellipsoidal height
        ellipsoidal_elevation = orthometric_elevation - geoid_offset

        # Append results
        results.append((latitude, longitude, geoid_offset, ellipsoidal_elevation))  # results.append(ellipsoidal_elevation)

    return results


def translate_geoidal_elevation(m_ramales):
    for ramal_ in m_ramales.keys():
        x_coords, y_coords, z_elev = (
            m_ramales[ramal_]["X"],
            m_ramales[ramal_]["Y"],
            m_ramales[ramal_]["Z"],
        )

        converted = convert_utm_to_ellipsoidal(x_coords, y_coords, z_elev)
        m_ramales[ramal_]["Z"] = np.round(np.array(converted), 3)

        ZTI = convert_utm_to_ellipsoidal(x_coords[:-1], y_coords[:-1], m_ramales[ramal_]["ZTI"][1:])
        ZFI = convert_utm_to_ellipsoidal(x_coords[:-1], y_coords[:-1], m_ramales[ramal_]["ZFI"][1:])
        ZTF = convert_utm_to_ellipsoidal(x_coords[1:], y_coords[1:], m_ramales[ramal_]["ZTF"][1:])
        ZFF = convert_utm_to_ellipsoidal(x_coords[1:], y_coords[1:], m_ramales[ramal_]["ZFF"][1:])

        m_ramales[ramal_]["ZTI"] = np.round(np.array([0] + ZTI), 3)
        m_ramales[ramal_]["ZFI"] = np.round(np.array([0] + ZFI), 3)
        m_ramales[ramal_]["ZTF"] = np.round(np.array([0] + ZTF), 3)
        m_ramales[ramal_]["ZFF"] = np.round(np.array([0] + ZFF), 3)

    return m_ramales


def classify_pz(diameters, salto, secciones, pozo_inicial, pozo_final):
    tolerance = 0.06
    classifications = np.full(diameters.shape, 'pz-esp', dtype='<U10')

    # Define boundary values in meters
    boundaries = [0.2, 0.6, 0.8, 1.0, 1.3]
    # Apply tolerances to boundaries
    adjusted_boundaries = [b * (1 - tolerance) for b in boundaries[:-1]] + [boundaries[-1]]

    # Classify based on diameters
    for i, (lower, upper) in enumerate(zip(adjusted_boundaries[:-1], adjusted_boundaries[1:]), 1):
        condition = (diameters >= lower) & (diameters < upper)
        classifications[condition] = f'pz-b{i}'

    # Propagate larger classifications backwards
    for i in range(1, len(classifications)):
        if classifications[i].startswith('pz-b'):
            current_class = int(classifications[i][4:]) if classifications[i][4:].isdigit() else 0
            prev_class = int(classifications[i - 1][4:]) if classifications[i - 1].startswith('pz-b') and \
                                                            classifications[i - 1][4:].isdigit() else 0
            if current_class > prev_class:
                classifications[i - 1] = classifications[i]

    # Apply 'salto' classifications to the previous row
    salto_s1 = 0.7
    salto_s2 = 1.2
    salto_especial = 2.5

    salto_conditions = [(salto > salto_s1) & (salto <= salto_s2), (salto > salto_s2) & (salto <= salto_especial),
                        salto > salto_especial]

    for i, condition in enumerate(salto_conditions, 1):
        classifications[:-1][condition[1:]] = f'pz-s{i}'

    # remover pozos de canales superficiales abiertos
    # -------------------------------------------------------------------------------------------------------------
    filtro_rectangular = secciones == 'rectangular'
    if len(filtro_rectangular.nonzero()[0]) > 0:
        # smaller depth from each trench
        h_min = np.min([pozo_inicial[filtro_rectangular], pozo_final[filtro_rectangular]], axis=0)
        # altura seccion
        h_seccion = diameters[filtro_rectangular]

        # canal abierto
        filtro_canal_abierto = np.isclose(h_seccion, h_min, atol=0.4)
        try:
            if len(filtro_canal_abierto.nonzero()[0]) > 0:
                classifications[filtro_canal_abierto] = ''
        except:
            pass

    return classifications


def get_pz_class(m_ramales):
    # remover metodos constructivos porque ya se pone esto en los datos hidraulicos
    metodos_lista = ["mejorar suelo", "Perforacion Horizontal Dirigida", "Tunel", "Reparacion", "Colector",
                     "Zanja Mano", ]
    metodos_lista = [_.lower() for _ in metodos_lista]
    metodos_pattern = '|'.join(r'\b{}\b'.format(re.escape(word)) for word in metodos_lista)

    pz_list = ['pz-b1', 'pz-b2', 'pz-b3', 'pz-b4', 'pz-esp', 'pz-s1', 'pz-s2', 'pz-s3']
    pz_list = '|'.join(r'\b{}\b'.format(re.escape(word)) for word in pz_list)

    for ramal in m_ramales.keys():
        diametros = seccion_str2float(m_ramales[ramal]['D_ext'], return_b=True)
        saltos = m_ramales[ramal]['SALTO']
        secciones = m_ramales[ramal]['Seccion']
        pozo_inicial = m_ramales[ramal]['HI']
        pozo_final = m_ramales[ramal]['HF']

        if 'nuevo' in m_ramales[ramal]['Estado']:
            m_ramales[ramal]['pz_class'] = classify_pz(diametros, saltos, secciones, pozo_inicial, pozo_final)
            obs = pd.Series(m_ramales[ramal]['Obs'])
            obs = obs.str.replace(pz_list, ' ', regex=True)
            obs = pd.Series(m_ramales[ramal]['pz_class']) + ' ' + obs
            obs = obs.str.replace(metodos_pattern, ' ', regex=True)
            m_ramales[ramal]['Obs'] = obs.to_numpy()
        else:
            m_ramales[ramal]['pz_class'] = np.full(diametros.shape, '', dtype=object)

    return m_ramales


def create_q_dict_from_flows(m_ramales, ramal, flows_dict):
    # 1. Generar estructura idéntica a q_v_Func original
    pz = np.concatenate([m_ramales[_]["Pozo"] for _ in ramal.keys()])

    # Inicializar caudales en cero
    q_san = np.zeros(len(pz))
    q_pluvial = np.zeros(len(pz))

    # Crear DataFrame
    df = pd.DataFrame(np.array([pz, q_san, q_pluvial]).T, columns=["pz", "q_san", "q_pluvial"])
    df.index = df["pz"]

    # 2. Asignar valores directamente usando la key de flows_dict como índice
    for key, flow in flows_dict.items():

        # Aseguramos que la key sea string para coincidir con el índice pz
        if key in df.index:
            df.at[key, "q_pluvial"] = flow * 1000.0

    # 3. Convertir columnas a numérico (igual que en tu flujo original)
    df["q_pluvial"] = pd.to_numeric(df["q_pluvial"])
    df["q_san"] = pd.to_numeric(df["q_san"])

    return df


#####################################################################

class SewerPipeline:
    """
    Clase contenedora del antiguo bloque `if __name__ == "__main__":`.
    • Sólo recibe tres argumentos en el constructor.
    • El método `.run()` ejecuta TODO el flujo original.
    """

    def __init__(self, elev_file_path:str, vector_file_path:str, project_name: str, flows_dict: dict, proj_to: str, path_out: str = None):
        self.elev_file_path = elev_file_path
        self.vector_file_path = vector_file_path
        self.project_name = project_name
        self.flows_dict = flows_dict
        self.proj_to = proj_to
        self.path_out = path_out

    def run(self):
        """
        Executes the sewer design pipeline.
        Updated to handle multiple flows (one per ramal start).
        """
        tqdm.write("-----------------------------------------------")

        # Input Data
        elev_file_path = self.elev_file_path
        vector_file_path = self.vector_file_path
        project_name = self.project_name
        proj_to = self.proj_to
        flows_dict = self.flows_dict
        
        scale_viewport = 1.0

        t0 = time.time()
        path_proy = "PROYECTO_" + str(project_name) + os.path.sep
        elev_file = [elev_file_path]
        dmax = 0.5


        # Initialize Progress Bar
        total_steps = 24
        with tqdm(total=total_steps, desc=f"Designing {project_name}", unit="step") as pbar:
    
            # 1. Leer Geometria
            m_ramales, ramal = get_geometry_pypiper_GIS([vector_file_path], dmax=dmax)
            pbar.set_description("Reading Geometry (GIS)...")
            pbar.update(1)
    
            # 2. Preparar Datos Elevacion (Source)
            ges = ElevationSource(path_proy, proj_to)
            elevation_shift = 0
            tree = ges.get_elev_source(elev_file, check_unique_values=False, ellipsoidal2orthometric=False, m_ramales=None, elevation_shift=elevation_shift)
            pbar.set_description("Processing Elevation Source...")
            pbar.update(1)
            
            # 3. Elevation Getter
            elev_source = ElevationGetter(tree=tree, m_ramales=m_ramales, threshold_distance=0.7)
            shape_file = vector_file_path
            skip_ramal = []
            elev_source.m_ramales = m_ramales

            # 4. Simplificar Geometria
            m_ramales, ramal, xy_inter = simple_geometryV3(m_ramales, ramal, dmax=dmax)
            pbar.set_description("Simplifying Geometry...")
            pbar.update(1)
        
            # 5. Asignar Elevaciones
            m_ramales = elev_source.get_elevation_m_ramales()
            pbar.set_description("Assigning Elevations...")
            pbar.update(1)

        
            # 6. Longitudes
            m_ramales, ramal = get_len(m_ramales, ramal)
            pbar.set_description("Calculating Lengths...")
            pbar.update(1)

            # 7. Asignar Pendiente Natural
            m_ramales, ramal = get_slope(m_ramales, ramal)
            pbar.set_description("Assigning Natural Slopes...")
            pbar.update(1)

            # 8. Asignar Rugosidades
            m_ramales, ramal = get_roughness(m_ramales, ramal)
            pbar.set_description("Assigning Roughness...")
            pbar.update(1)
        
            # 9. Agregar Metodologia Constructiva
            m_ramales = get_add_metodologia_constructiva(m_ramales)
            pbar.set_description("Adding Construction Methods...")
            pbar.update(1)

            # 10. Generar Outfall (1)
            m_ramales = get_outfall(m_ramales, proj_to)
            pbar.set_description("Identifying Outfalls...")
            pbar.update(1)
        
            # 11. Caudales Dict
            q_dict = create_q_dict_from_flows(m_ramales, ramal, flows_dict)
            q_dict['q_pluvial'] = pd.to_numeric(q_dict['q_pluvial'])
            q_dict['q_san'] = pd.to_numeric(q_dict['q_san'])
            pbar.set_description("Processing Flows...")
            pbar.update(1)

            # 12. Sumatoria Caudales
            m_ramales, ramal = get_flowsum(m_ramales, ramal, q_v=q_dict)
            # tqdm.write(f"Caudal Pluvial Sistema: {np.round(np.sum([np.sum(_['q_pluvial']) for _ in m_ramales.values()]), 2)}")
            # tqdm.write(f"Caudal Sanitario Sistema: {np.round(np.sum([np.sum(_['q_san']) for _ in m_ramales.values()]), 2)}")
            pbar.set_description("Summing Flows...")
            pbar.update(1)

            # 13. Dimensionamiento Diametro Interno
            m_ramales, ramal = get_sizing_int(m_ramales, ramal, xy_inter)
            pbar.set_description("Sizing Internal Diameters...")
            pbar.update(1)
        
            # 14. Asignacion Diametro Externo
            m_ramales, ramal = get_sizing_ext(m_ramales, ramal)
            pbar.set_description("Sizing External Diameters...")
            pbar.update(1)

            # 15. Seccion Llena
            m_ramales, ramal = get_SLL(m_ramales, ramal)
            pbar.set_description("Checking Full Section...")
            pbar.update(1)

            # 16. Seccion Parcialmente Llena
            m_ramales, ramal = get_SPLL(m_ramales, ramal)
            pbar.set_description("Checking Partial Section...")
            pbar.update(1)

            # 17. Dimensionar Tuberias
            m_ramales, ramal = get_sizing_SPLL(m_ramales, ramal, xy_inter)
            pbar.set_description("Finalizing Pipe Sizing...")
            pbar.update(1)
        
            # 18. Elevaciones y Alturas Pozo Iniciales
            m_ramales, ramal = get_pz_init(m_ramales, ramal)
            pbar.set_description("Initializing Manholes...")
            pbar.update(1)

            # 19. Optimizar Alturas Pozos
            m_ramales, ramal = get_opt_S(m_ramales, ramal, xy_inter)
            pbar.set_description("Optimizing Slopes & Depths...")
            pbar.update(1)

            # 20. Revision Elevacion Llegada/Salida
            m_ramales, ramal = check_pz(m_ramales, ramal, xy_inter)
            pbar.set_description("Verifying Manhole Connections...")
            pbar.update(1)

            # 21. Optimizar Velocidad Tramo
            m_ramales, ramal = get_opt_V(m_ramales, ramal, xy_inter)
            pbar.set_description("Optimizing Velocities...")
            pbar.update(1)
        
            # 22. Condiciones Hidraulicas
            m_ramales, ramal = hydraulic_conditions(m_ramales, ramal)
            m_ramales, ramal = force_format_diameter(m_ramales, ramal)
            pbar.set_description("Checking Hydraulic Conditions...")
            pbar.update(1)

            # 23. Generar Outfall (2)
            m_ramales = get_outfall(m_ramales, proj_to)
            pbar.set_description("Updating Outfalls...")
            pbar.update(1)

            # 24. Segmentacion Pozos EPMAPS
            m_ramales = get_pz_class(m_ramales)
            pbar.set_description("Classifying Manholes...")
            pbar.update(1)

            # 25. Generar Vector Out
            m_ramales_gdf = shp_out(m_ramales, project_name, EPSG=proj_to, path_out=self.path_out)
            pbar.set_description("Saving Output Vector...")
            pbar.update(1)
            


        t1 = time.time()
        tqdm.write(f"Numero de ramales: {len(ramal)}")

        L_total = 0
        P_total = 0
        for i in ramal.values():
            L_total = np.sum(m_ramales[i]["L"]) + L_total
            P_total = np.sum(len(m_ramales[i]["L"])) + P_total

        tqdm.write(f"{np.round(np.asarray(L_total / 1000.0), 3)} longitud total (km)")
        tqdm.write(f"{round(t1 - t0, 3)} duracion simulacion(s)")
        tqdm.write(f"{round((t1 - t0) / len(ramal), 3)} (s)/ramal")
        tqdm.write("Fin de la ejecución.")
        tqdm.write("-----------------------------------------------")





if __name__ == "__main__":

    # definir sistema de coordenadas del proyecto
    source_crs = CRS("""PROJCRS["SIRES-DMQ",
       BASEGEOGCRS["WGS 84",
           DATUM["World Geodetic System 1984",
               ELLIPSOID["WGS 84",6378137,298.257223563,
               LENGTHUNIT["metre",1]],ID["EPSG",6326]],
           PRIMEM["Greenwich",0,
               ANGLEUNIT["Degree",0.0174532925199433]]],
       CONVERSION["unnamed",
           METHOD["Transverse Mercator",ID["EPSG",9807]],
           PARAMETER["Latitude of natural origin",0,
               ANGLEUNIT["Degree",0.0174532925199433],ID["EPSG",8801]],
           PARAMETER["Longitude of natural origin",-78.5,
               ANGLEUNIT["Degree",0.0174532925199433],ID["EPSG",8802]],
           PARAMETER["Scale factor at natural origin",1.0004584,
               SCALEUNIT["unity",1],ID["EPSG",8805]],
           PARAMETER["False easting",500000,
               LENGTHUNIT["metre",1],ID["EPSG",8806]],
           PARAMETER["False northing",10000000,
               LENGTHUNIT["metre",1],ID["EPSG",8807]]],
       CS[Cartesian,3],
       AXIS["(E)",east,ORDER[1],
           LENGTHUNIT["metre",1,ID["EPSG",9001]]],
       AXIS["(N)",north,ORDER[2],
           LENGTHUNIT["metre",1,ID["EPSG",9001]]],
       AXIS["ellipsoidal height (h)",up,ORDER[3],
       LENGTHUNIT["metre",1,ID["EPSG",9001]]]]""")
    proj_to = source_crs.to_2d()

    # Se asume ejecución desde carpeta codigos: root = parent dir
    project_root = Path(os.getcwd()).parent
    elev_file = project_root / r"gis\01_raster\elev_10_dmq_reprojected.tif"


    df = gpd.read_file(r'C:\Users\Alienware\OneDrive\SANTA_ISABEL\00_tanque_tormenta\codigos\optimization_results\Seq_Iter_20\input_routes.gpkg', engine='pyogrio')
    flows_dict = {}
    pozo_hmin_dict = {}
    for i, pair in enumerate([4] * len(df)):
        ramal_name = str(i)
        flows_dict[ramal_name + '.0'] = pair
        pozo_hmin_dict[ramal_name + '.0'] = 6

    pipeline = SewerPipeline(
        elev_file_path=str(elev_file),
        vector_file_path=r'C:\Users\Alienware\OneDrive\SANTA_ISABEL\00_tanque_tormenta\codigos\optimization_results\Seq_Iter_20\input_routes.gpkg',
        project_name='Seq_Iter_20',
        flows_dict=flows_dict,
        proj_to=str(proj_to),
        path_out=r'C:\Users\Alienware\OneDrive\SANTA_ISABEL\00_tanque_tormenta\codigos\optimization_results\Seq_Iter_20'
    )

    pipeline.run()


